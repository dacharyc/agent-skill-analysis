{
  "skill_name": "provider-resources",
  "generated_at": "2026-02-16T08:07:55.354990+00:00",
  "model": "claude-sonnet-4-5-20250929",
  "temperature": 0.3,
  "runs_per_condition": 3,
  "contamination_score": 0.55,
  "risk_level": "high",
  "test_category": "app_to_aux",
  "tasks": [
    {
      "task_id": "provider-resources-01",
      "task_type": "direct_target",
      "target_language": "go",
      "expected_patterns": [
        "framework\\.ResourceWithConfigure",
        "resource\\.MetadataRequest",
        "schema\\.Schema\\{",
        "schema\\.StringAttribute",
        "stringplanmodifier\\.RequiresReplace",
        "resp\\.Diagnostics\\.AddError",
        "resp\\.State\\.Set\\(ctx"
      ],
      "anti_patterns": [
        "resource\\s+\"\\w+\"\\s+\"\\w+\"\\s*\\{",
        "variable\\s+\"\\w+\"",
        "terraform\\s*\\{",
        "def\\s+create|def\\s+read",
        "class\\s+\\w+Resource"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/internal/provider/example_resource.go",
          "description": "Terraform Plugin Framework resource: framework.ResourceWithConfigure interface, resource.MetadataRequest in Metadata(), schema.Schema{} with schema.StringAttribute, Create/Read/Update/Delete methods with resp.Diagnostics.AddError and resp.State.Set(ctx), stringplanmodifier.RequiresReplace() for plan modifiers"
        },
        {
          "url": "https://go.dev/doc/code",
          "description": "Go documentation - source of package and func syntax required for Go programs"
        },
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/examples/resources/scaffolding_example/resource.tf",
          "description": "Anti-patterns: HCL resource block syntax (resource \"type\" \"name\" {}) that should not appear in Go provider code"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "# Terraform Provider S3-Compatible Storage Bucket Resource\n\nI'll implement a complete S3-compatible storage bucket resource using the Terraform Plugin Framework with all CRUD operations, validators, and plan modifiers.\n\n```go\n// internal/service/s3storage/bucket_resource.go\npackage s3storage\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3/types\"\n\t\"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n\t\"github.com/hashicorp/terraform-plugin-log/tflog\"\n)\n\n// Ensure the implementation satisfies the expected interfaces.\nvar (\n\t_ resource.Resource                = &bucketResource{}\n\t_ resource.ResourceWithConfigure   = &bucketResource{}\n\t_ resource.ResourceWithImportState = &bucketResource{}\n)\n\n// NewBucketResource is a helper function to simplify the provider implementation.\nfunc NewBucketResource() resource.Resource {\n\treturn &bucketResource{}\n}\n\n// bucketResource is the resource implementation.\ntype bucketResource struct {\n\tclient *s3.Client\n}\n\n// bucketResourceModel maps the resource schema data.\ntype bucketResourceModel struct {\n\tID                types.String `tfsdk:\"id\"`\n\tName              types.String `tfsdk:\"name\"`\n\tRegion            types.String `tfsdk:\"region\"`\n\tVersioningEnabled types.Bool   `tfsdk:\"versioning_enabled\"`\n\tTags              types.Map    `tfsdk:\"tags\"`\n\tARN               types.String `tfsdk:\"arn\"`\n\tBucketDomainName  types.String `tfsdk:\"bucket_domain_name\"`\n}\n\n// Metadata returns the resource type name.\nfunc (r *bucketResource) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = req.ProviderTypeName + \"_bucket\"\n}\n\n// Schema defines the schema for the resource.\nfunc (r *bucketResource) Schema(_ context.Context, _ resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\tDescription: \"Manages an S3-compatible storage bucket.\",\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"id\": schema.StringAttribute{\n\t\t\t\tDescription: \"The unique identifier for the bucket (same as name).\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tDescription: \"The name of the bucket. Must be globally unique and DNS-compliant.\",\n\t\t\t\tRequired:    true,\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\t// DNS-compliant bucket name regex\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z0-9][a-z0-9\\-]*[a-z0-9]$`),\n\t\t\t\t\t\t\"bucket name must be DNS-compliant (lowercase letters, numbers, and hyphens only, cannot start or end with hyphen)\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tDescription: \"The region where the bucket will be created.\",\n\t\t\t\tRequired:    true,\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthAtLeast(1),\n\t\t\t\t},\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tDescription: \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t\tOptional:    true,\n\t\t\t\tComputed:    true,\n\t\t\t\tDefault:     booldefault.StaticBool(false),\n\t\t\t},\n\t\t\t\"tags\": schema.MapAttribute{\n\t\t\t\tDescription: \"A map of tags to assign to the bucket.\",\n\t\t\t\tOptional:    true,\n\t\t\t\tElementType: types.StringType,\n\t\t\t},\n\t\t\t\"arn\": schema.StringAttribute{\n\t\t\t\tDescription: \"The ARN of the bucket.\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"bucket_domain_name\": schema.StringAttribute{\n\t\t\t\tDescription: \"The bucket domain name.\",\n\t\t\t\tComputed:    true,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// Configure adds the provider configured client to the resource.\nfunc (r *bucketResource) Configure(_ context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {\n\tif req.ProviderData == nil {\n\t\treturn\n\t}\n\n\tclient, ok := req.ProviderData.(*s3.Client)\n\tif !ok {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Unexpected Resource Configure Type\",\n\t\t\tfmt.Sprintf(\"Expected *s3.Client, got: %T. Please report this issue to the provider developers.\", req.ProviderData),\n\t\t)\n\t\treturn\n\t}\n\n\tr.client = client\n}\n\n// Create creates the resource and sets the initial Terraform state.\nfunc (r *bucketResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\t// Retrieve values from plan\n\tvar plan bucketResourceModel\n\tdiags := req.Plan.Get(ctx, &plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Generate API request body from plan\n\tbucketName := plan.Name.ValueString()\n\tregion := plan.Region.ValueString()\n\n\ttflog.Debug(ctx, \"Creating S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t\t\"region\":      region,\n\t})\n\n\t// Create the bucket\n\tcreateBucketInput := &s3.CreateBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t}\n\n\t// Add location constraint if not us-east-1\n\tif region != \"us-east-1\" {\n\t\tcreateBucketInput.CreateBucketConfiguration = &types.CreateBucketConfiguration{\n\t\t\tLocationConstraint: types.BucketLocationConstraint(region),\n\t\t}\n\t}\n\n\t_, err := r.client.CreateBucket(ctx, createBucketInput)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error creating bucket\",\n\t\t\tfmt.Sprintf(\"Could not create bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Set versioning if enabled\n\tif !plan.VersioningEnabled.IsNull() && plan.VersioningEnabled.ValueBool() {\n\t\terr = r.updateVersioning(ctx, bucketName, true)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error enabling versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not enable versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\t// Attempt to clean up the bucket\n\t\t\tr.client.DeleteBucket(ctx, &s3.DeleteBucketInput{Bucket: aws.String(bucketName)})\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Set tags if provided\n\tif !plan.Tags.IsNull() && len(plan.Tags.Elements()) > 0 {\n\t\terr = r.updateTags(ctx, bucketName, plan.Tags)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error setting tags\",\n\t\t\t\tfmt.Sprintf(\"Could not set tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Set computed attributes\n\tplan.ID = types.StringValue(bucketName)\n\tplan.ARN = types.StringValue(fmt.Sprintf(\"arn:aws:s3:::%s\", bucketName))\n\tplan.BucketDomainName = types.StringValue(fmt.Sprintf(\"%s.s3.%s.amazonaws.com\", bucketName, region))\n\n\t// Set state to fully populated data\n\tdiags = resp.State.Set(ctx, plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\ttflog.Debug(ctx, \"Successfully created S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n}\n\n// Read refreshes the Terraform state with the latest data.\nfunc (r *bucketResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\t// Get current state\n\tvar state bucketResourceModel\n\tdiags := req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := state.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Reading S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n\n\t// Check if bucket exists\n\t_, err := r.client.HeadBucket(ctx, &s3.HeadBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket\",\n\t\t\tfmt.Sprintf(\"Could not read bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Get bucket location\n\tlocationOutput, err := r.client.GetBucketLocation(ctx, &s3.GetBucketLocationInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket location\",\n\t\t\tfmt.Sprintf(\"Could not read location for bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\tregion := \"us-east-1\" // Default region\n\tif locationOutput.LocationConstraint != \"\" {\n\t\tregion = string(locationOutput.LocationConstraint)\n\t}\n\tstate.Region = types.StringValue(region)\n\n\t// Get versioning status\n\tversioningOutput, err := r.client.GetBucketVersioning(ctx, &s3.GetBucketVersioningInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket versioning\",\n\t\t\tfmt.Sprintf(\"Could not read versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\tstate.VersioningEnabled = types.BoolValue(versioningOutput.Status == types.BucketVersioningStatusEnabled)\n\n\t// Get tags\n\ttagsOutput, err := r.client.GetBucketTagging(ctx, &s3.GetBucketTaggingInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\t// If no tags exist, that's okay\n\t\tvar nfe *types.NoSuchTagSet\n\t\tif !errors.As(err, &nfe) {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error reading bucket tags\",\n\t\t\t\tfmt.Sprintf(\"Could not read tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t\tstate.Tags = types.MapNull(types.StringType)\n\t} else {\n\t\ttags := make(map[string]attr.Value)\n\t\tfor _, tag := range tagsOutput.TagSet {\n\t\t\ttags[*tag.Key] = types.StringValue(*tag.Value)\n\t\t}\n\t\ttagsMap, diags := types.MapValue(types.StringType, tags)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\t\tstate.Tags = tagsMap\n\t}\n\n\t// Update computed attributes\n\tstate.BucketDomainName = types.StringValue(fmt.Sprintf(\"%s.s3.%s.amazonaws.com\", bucketName, region))\n\n\t// Set refreshed state\n\tdiags = resp.State.Set(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\ttflog.Debug(ctx, \"Successfully read S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n}\n\n// Update updates the resource and sets the updated Terraform state on success.\nfunc (r *bucketResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\t// Retrieve values from plan\n\tvar plan bucketResourceModel\n\tdiags := req.Plan.Get(ctx, &plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Retrieve values from state\n\tvar state bucketResourceModel\n\tdiags = req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Updating S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n\n\t// Update versioning if changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\terr := r.updateVersioning(ctx, bucketName, plan.VersioningEnabled.ValueBool())\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not update versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update tags if changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\terr := r.updateTags(ctx, bucketName, plan.Tags)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating tags\",\n\t\t\t\tfmt.Sprintf(\"Could not update tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update computed attributes\n\tplan.BucketDomainName = types.StringValue(fmt.Sprintf(\"%s.s3.%s.amazonaws.com\", bucketName, plan.Region.ValueString()))\n\n\t// Set state to fully populated data\n\tdiags = resp.State.Set(ctx, plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\ttflog.Debug(ctx, \"Successfully updated S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n}\n\n// Delete deletes the resource and removes the Terraform state on success.\nfunc (r *bucketResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n\t// Retrieve values from state\n\tvar state bucketResourceModel\n\tdiags := req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\t",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 90,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# S3-Compatible Storage Bucket Resource Implementation\n\nI'll implement a complete Terraform provider resource for an S3-compatible storage bucket using the Plugin Framework.\n\n## File Structure\n\n```\ninternal/service/s3storage/\n\u251c\u2500\u2500 bucket.go\n\u251c\u2500\u2500 bucket_test.go\n\u251c\u2500\u2500 find.go\n\u251c\u2500\u2500 exports_test.go\n\u2514\u2500\u2500 service_package_gen.go\n```\n\n## 1. Resource Implementation (bucket.go)\n\n```go\n// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage s3storage\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"time\"\n\n\t\"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n\t\"github.com/hashicorp/terraform-plugin-log/tflog\"\n\t\"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/create\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/errs\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/framework\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/framework/flex\"\n\tfwtypes \"github.com/hashicorp/terraform-provider-aws/internal/framework/types\"\n\ttftags \"github.com/hashicorp/terraform-provider-aws/internal/tags\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/tfresource\"\n\t\"github.com/hashicorp/terraform-provider-aws/names\"\n)\n\n// @FrameworkResource(\"aws_s3storage_bucket\", name=\"Bucket\")\n// @Tags(identifierAttribute=\"arn\")\nfunc newResourceBucket(_ context.Context) (resource.ResourceWithConfigure, error) {\n\tr := &resourceBucket{}\n\n\treturn r, nil\n}\n\nconst (\n\tResNameBucket = \"Bucket\"\n)\n\ntype resourceBucket struct {\n\tframework.ResourceWithConfigure\n\tframework.WithTimeouts\n\tframework.WithImportByID\n}\n\nfunc (r *resourceBucket) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = \"aws_s3storage_bucket\"\n}\n\nfunc (r *resourceBucket) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"arn\": framework.ARNAttributeComputedOnly(),\n\t\t\t\"id\":  framework.IDAttribute(),\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tRequired: true,\n\t\t\t\tDescription: \"Name of the bucket. Must be globally unique and follow DNS naming conventions. \" +\n\t\t\t\t\t\"Must be between 3 and 63 characters, contain only lowercase letters, numbers, dots, and hyphens, \" +\n\t\t\t\t\t\"and must not be formatted as an IP address.\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z0-9][a-z0-9.-]*[a-z0-9]$`),\n\t\t\t\t\t\t\"must start and end with a lowercase letter or number, and contain only lowercase letters, numbers, dots, and hyphens\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!.*\\.\\.).*$`),\n\t\t\t\t\t\t\"must not contain consecutive dots\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!.*\\.-|-\\.).*$`),\n\t\t\t\t\t\t\"must not contain dots adjacent to hyphens\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!^\\d+\\.\\d+\\.\\d+\\.\\d+$).*$`),\n\t\t\t\t\t\t\"must not be formatted as an IP address\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tRequired:    true,\n\t\t\t\tDescription: \"AWS region where the bucket will be created.\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthAtLeast(1),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tOptional:    true,\n\t\t\t\tComputed:    true,\n\t\t\t\tDefault:     booldefault.StaticBool(false),\n\t\t\t\tDescription: \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t},\n\t\t\t\"creation_date\": schema.StringAttribute{\n\t\t\t\tComputed:    true,\n\t\t\t\tDescription: \"Date and time the bucket was created.\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\tnames.AttrTags:    tftags.TagsAttribute(),\n\t\t\tnames.AttrTagsAll: tftags.TagsAttributeComputedOnly(),\n\t\t},\n\t\tBlocks: map[string]schema.Block{\n\t\t\t\"timeouts\": r.Timeouts(ctx, timeouts{\n\t\t\t\tcreate: 5 * time.Minute,\n\t\t\t\tupdate: 5 * time.Minute,\n\t\t\t\tdelete: 5 * time.Minute,\n\t\t\t}),\n\t\t},\n\t}\n}\n\nfunc (r *resourceBucket) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\tconn := r.Meta().S3StorageClient(ctx)\n\n\tvar plan resourceBucketModel\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.Name.ValueString()\n\n\t// Prepare create input\n\tinput := &s3storage.CreateBucketInput{\n\t\tBucket: plan.Name.ValueStringPointer(),\n\t\tCreateBucketConfiguration: &s3storage.CreateBucketConfiguration{\n\t\t\tLocationConstraint: plan.Region.ValueStringPointer(),\n\t\t},\n\t}\n\n\ttflog.Debug(ctx, \"Creating S3Storage Bucket\", map[string]interface{}{\n\t\t\"bucket\": bucketName,\n\t\t\"region\": plan.Region.ValueString(),\n\t})\n\n\toutput, err := conn.CreateBucket(ctx, input)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n\t\t\terr.Error(),\n\t\t)\n\t\treturn\n\t}\n\n\tif output == nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, nil),\n\t\t\terrors.New(\"empty output\").Error(),\n\t\t)\n\t\treturn\n\t}\n\n\t// Set ID and ARN\n\tplan.ID = types.StringValue(bucketName)\n\tplan.ARN = types.StringPointerValue(output.Location)\n\tplan.CreationDate = types.StringValue(time.Now().UTC().Format(time.RFC3339))\n\n\t// Wait for bucket to be available\n\tcreateTimeout := r.CreateTimeout(ctx, plan.Timeouts)\n\tbucket, err := waitBucketCreated(ctx, conn, bucketName, createTimeout)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionWaitingForCreation, ResNameBucket, bucketName, err),\n\t\t\terr.Error(),\n\t\t)\n\t\treturn\n\t}\n\n\t// Configure versioning if enabled\n\tif plan.VersioningEnabled.ValueBool() {\n\t\tversioningInput := &s3storage.PutBucketVersioningInput{\n\t\t\tBucket: plan.Name.ValueStringPointer(),\n\t\t\tVersioningConfiguration: &s3storage.VersioningConfiguration{\n\t\t\t\tStatus: s3storage.BucketVersioningStatusEnabled,\n\t\t\t},\n\t\t}\n\n\t\t_, err := conn.PutBucketVersioning(ctx, versioningInput)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to enable versioning: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Create tags\n\tif !plan.Tags.IsNull() {\n\t\tif err := createTags(ctx, conn, plan.ARN.ValueString(), getTagsIn(ctx, plan.Tags)); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to create tags: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update computed fields from API response\n\tplan.CreationDate = types.StringPointerValue(bucket.CreationDate)\n\n\tresp.Diagnostics.Append(resp.State.Set(ctx, plan)...)\n}\n\nfunc (r *resourceBucket) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\tconn := r.Meta().S3StorageClient(ctx)\n\n\tvar state resourceBucketModel\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := state.ID.ValueString()\n\n\ttflog.Debug(ctx, \"Reading S3Storage Bucket\", map[string]interface{}{\n\t\t\"bucket\": bucketName,\n\t})\n\n\t// Find bucket\n\tbucket, err := findBucketByName(ctx, conn, bucketName)\n\tif tfresource.NotFound(err) {\n\t\tresp.Diagnostics.AddWarning(\n\t\t\t\"Resource Not Found\",\n\t\t\tfmt.Sprintf(\"S3Storage Bucket %s not found, removing from state\", bucketName),\n\t\t)\n\t\tresp.State.RemoveResource(ctx)\n\t\treturn\n\t}\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\terr.Error(),\n\t\t)\n\t\treturn\n\t}\n\n\t// Update state from API response\n\tstate.Name = types.StringPointerValue(bucket.Name)\n\tstate.CreationDate = types.StringPointerValue(bucket.CreationDate)\n\n\t// Get bucket location (region)\n\tlocationOutput, err := conn.GetBucketLocation(ctx, &s3storage.GetBucketLocationInput{\n\t\tBucket: state.Name.ValueStringPointer(),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\tfmt.Sprintf(\"Failed to get bucket location: %s\", err.Error()),\n\t\t)\n\t\treturn\n\t}\n\tstate.Region = types.StringPointerValue(locationOutput.LocationConstraint)\n\n\t// Get versioning status\n\tversioningOutput, err := conn.GetBucketVersioning(ctx, &s3storage.GetBucketVersioningInput{\n\t\tBucket: state.Name.ValueStringPointer(),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\tfmt.Sprintf(\"Failed to get versioning status: %s\", err.Error()),\n\t\t)\n\t\treturn\n\t}\n\tstate.VersioningEnabled = types.BoolValue(versioningOutput.Status == s3storage.BucketVersioningStatusEnabled)\n\n\t// Get tags\n\ttags, err := listTags(ctx, conn, state.ARN.ValueString())\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\tfmt.Sprintf(\"Failed to list tags: %s\", err.Error()),\n\t\t)\n\t\treturn\n\t}\n\tstate.Tags = flex.FlattenFrameworkStringValueMap(ctx, tags)\n\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &state)...)\n}\n\nfunc (r *resourceBucket) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\tconn := r.Meta().S3StorageClient(ctx)\n\n\tvar plan, state resourceBucketModel\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.ID.ValueString()\n\n\ttflog.Debug(ctx, \"Updating S3Storage Bucket\", map[string]interface{}{\n\t\t\"bucket\": bucketName,\n\t})\n\n\t// Update versioning if changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\tstatus := s3storage.BucketVersioningStatusSuspended\n\t\tif plan.VersioningEnabled.ValueBool() {\n\t\t\tstatus = s3storage.BucketVersioningStatusEnabled\n\t\t}\n\n\t\tversioningInput := &s3storage.PutBucketVersioningInput{\n\t\t\tBucket: plan.Name.ValueStringPointer(),\n\t\t\tVersioningConfiguration: &s3storage.VersioningConfiguration{\n\t\t\t\tStatus: status,\n\t\t\t},\n\t\t}\n\n\t\t_, err := conn.PutBucketVersioning(ctx, versioningInput)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionUpdating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to update versioning: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\n\t\ttflog.Debug(ctx, \"Updated bucket versioning\", map[string]interface{}{\n\t\t\t\"bucket\":  bucketName,\n\t\t\t\"enabled\": plan.VersioningEnabled.ValueBool(),\n\t\t})\n\t}\n\n\t// Update tags if changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\tif err := updateTags(ctx, conn, plan.ARN.ValueString(), state.Tags, plan.Tags); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionUpdating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to update tags: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Wait for update to complete\n\tupdateTimeout := r.UpdateTimeout(ctx, plan.Timeouts)\n\t_, err := waitBucketUpdated(ctx, conn, bucketName, updateTimeout)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4809,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll implement a complete Terraform provider resource for an S3-compatible storage bucket using the Plugin Framework. Let me create the necessary files following the standard service package structure.\n\nFirst, let me create the service package structure:\n\n```go\n// internal/service/s3/bucket.go\npackage s3\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"regexp\"\n\n\t\"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n)\n\n// Ensure the implementation satisfies the expected interfaces.\nvar (\n\t_ resource.Resource                = &resourceBucket{}\n\t_ resource.ResourceWithConfigure   = &resourceBucket{}\n\t_ resource.ResourceWithImportState = &resourceBucket{}\n)\n\n// NewResourceBucket is a helper function to simplify the provider implementation.\nfunc NewResourceBucket() resource.Resource {\n\treturn &resourceBucket{}\n}\n\n// resourceBucket is the resource implementation.\ntype resourceBucket struct {\n\tclient *Client\n}\n\n// resourceBucketModel maps the resource schema data.\ntype resourceBucketModel struct {\n\tID                types.String `tfsdk:\"id\"`\n\tName              types.String `tfsdk:\"name\"`\n\tRegion            types.String `tfsdk:\"region\"`\n\tVersioningEnabled types.Bool   `tfsdk:\"versioning_enabled\"`\n\tTags              types.Map    `tfsdk:\"tags\"`\n\tARN               types.String `tfsdk:\"arn\"`\n\tCreatedAt         types.String `tfsdk:\"created_at\"`\n}\n\n// Metadata returns the resource type name.\nfunc (r *resourceBucket) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = req.ProviderTypeName + \"_bucket\"\n}\n\n// Schema defines the schema for the resource.\nfunc (r *resourceBucket) Schema(_ context.Context, _ resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\tDescription: \"Manages an S3-compatible storage bucket.\",\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"id\": schema.StringAttribute{\n\t\t\t\tDescription: \"Unique identifier for the bucket.\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tDescription: \"Name of the bucket. Must be globally unique and DNS-compliant.\",\n\t\t\t\tRequired:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z0-9][a-z0-9-]*[a-z0-9]$`),\n\t\t\t\t\t\t\"must start and end with lowercase letter or number, and contain only lowercase letters, numbers, and hyphens\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!.*--).*$`),\n\t\t\t\t\t\t\"must not contain consecutive hyphens\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!xn--).*$`),\n\t\t\t\t\t\t\"must not start with 'xn--'\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!.*\\.\\.).*$`),\n\t\t\t\t\t\t\"must not contain consecutive periods\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tDescription: \"AWS region where the bucket will be created.\",\n\t\t\t\tRequired:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(1, 50),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z]{2}-[a-z]+-\\d{1}$`),\n\t\t\t\t\t\t\"must be a valid AWS region format (e.g., us-east-1)\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tDescription: \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t\tOptional:    true,\n\t\t\t\tComputed:    true,\n\t\t\t\tDefault:     booldefault.StaticBool(false),\n\t\t\t},\n\t\t\t\"tags\": schema.MapAttribute{\n\t\t\t\tDescription: \"Key-value map of tags to assign to the bucket.\",\n\t\t\t\tOptional:    true,\n\t\t\t\tElementType: types.StringType,\n\t\t\t},\n\t\t\t\"arn\": schema.StringAttribute{\n\t\t\t\tDescription: \"Amazon Resource Name (ARN) of the bucket.\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"created_at\": schema.StringAttribute{\n\t\t\t\tDescription: \"Timestamp when the bucket was created.\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\n// Configure adds the provider configured client to the resource.\nfunc (r *resourceBucket) Configure(_ context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {\n\tif req.ProviderData == nil {\n\t\treturn\n\t}\n\n\tclient, ok := req.ProviderData.(*Client)\n\tif !ok {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Unexpected Resource Configure Type\",\n\t\t\tfmt.Sprintf(\"Expected *Client, got: %T. Please report this issue to the provider developers.\", req.ProviderData),\n\t\t)\n\t\treturn\n\t}\n\n\tr.client = client\n}\n\n// Create creates the resource and sets the initial Terraform state.\nfunc (r *resourceBucket) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\t// Retrieve values from plan\n\tvar plan resourceBucketModel\n\tdiags := req.Plan.Get(ctx, &plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Convert tags from types.Map to map[string]string\n\ttags := make(map[string]string)\n\tif !plan.Tags.IsNull() && !plan.Tags.IsUnknown() {\n\t\tdiags = plan.Tags.ElementsAs(ctx, &tags, false)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Create the bucket\n\tinput := &CreateBucketInput{\n\t\tName:              plan.Name.ValueString(),\n\t\tRegion:            plan.Region.ValueString(),\n\t\tVersioningEnabled: plan.VersioningEnabled.ValueBool(),\n\t\tTags:              tags,\n\t}\n\n\tbucket, err := r.client.CreateBucket(ctx, input)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error creating bucket\",\n\t\t\tfmt.Sprintf(\"Could not create bucket %s: %s\", plan.Name.ValueString(), err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Map response to schema and populate Computed attribute values\n\tplan.ID = types.StringValue(bucket.ID)\n\tplan.ARN = types.StringValue(bucket.ARN)\n\tplan.CreatedAt = types.StringValue(bucket.CreatedAt)\n\n\t// Set state to fully populated data\n\tdiags = resp.State.Set(ctx, plan)\n\tresp.Diagnostics.Append(diags...)\n}\n\n// Read refreshes the Terraform state with the latest data.\nfunc (r *resourceBucket) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\t// Get current state\n\tvar state resourceBucketModel\n\tdiags := req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Get refreshed bucket value from API\n\tbucket, err := findBucketByID(ctx, r.client, state.ID.ValueString())\n\tif err != nil {\n\t\tif IsNotFoundError(err) {\n\t\t\tresp.Diagnostics.AddWarning(\n\t\t\t\t\"Resource not found\",\n\t\t\t\tfmt.Sprintf(\"Bucket %s not found, removing from state\", state.ID.ValueString()),\n\t\t\t)\n\t\t\tresp.State.RemoveResource(ctx)\n\t\t\treturn\n\t\t}\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket\",\n\t\t\tfmt.Sprintf(\"Could not read bucket %s: %s\", state.ID.ValueString(), err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Overwrite items with refreshed state\n\tstate.Name = types.StringValue(bucket.Name)\n\tstate.Region = types.StringValue(bucket.Region)\n\tstate.VersioningEnabled = types.BoolValue(bucket.VersioningEnabled)\n\tstate.ARN = types.StringValue(bucket.ARN)\n\tstate.CreatedAt = types.StringValue(bucket.CreatedAt)\n\n\t// Convert tags to types.Map\n\tif len(bucket.Tags) > 0 {\n\t\ttagMap := make(map[string]string)\n\t\tfor k, v := range bucket.Tags {\n\t\t\ttagMap[k] = v\n\t\t}\n\t\ttagsValue, diags := types.MapValueFrom(ctx, types.StringType, tagMap)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\t\tstate.Tags = tagsValue\n\t} else {\n\t\tstate.Tags = types.MapNull(types.StringType)\n\t}\n\n\t// Set refreshed state\n\tdiags = resp.State.Set(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n}\n\n// Update updates the resource and sets the updated Terraform state on success.\nfunc (r *resourceBucket) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\t// Retrieve values from plan\n\tvar plan resourceBucketModel\n\tdiags := req.Plan.Get(ctx, &plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Retrieve values from state\n\tvar state resourceBucketModel\n\tdiags = req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Update versioning if changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\terr := r.client.UpdateBucketVersioning(ctx, &UpdateBucketVersioningInput{\n\t\t\tID:      plan.ID.ValueString(),\n\t\t\tEnabled: plan.VersioningEnabled.ValueBool(),\n\t\t})\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating bucket versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not update versioning for bucket %s: %s\", plan.ID.ValueString(), err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update tags if changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\ttags := make(map[string]string)\n\t\tif !plan.Tags.IsNull() && !plan.Tags.IsUnknown() {\n\t\t\tdiags = plan.Tags.ElementsAs(ctx, &tags, false)\n\t\t\tresp.Diagnostics.Append(diags...)\n\t\t\tif resp.Diagnostics.HasError() {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\terr := r.client.UpdateBucketTags(ctx, &UpdateBucketTagsInput{\n\t\t\tID:   plan.ID.ValueString(),\n\t\t\tTags: tags,\n\t\t})\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating bucket tags\",\n\t\t\t\tfmt.Sprintf(\"Could not update tags for bucket %s: %s\", plan.ID.ValueString(), err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Fetch updated bucket to get latest state\n\tbucket, err := findBucketByID(ctx, r.client, plan.ID.ValueString())\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket after update\",\n\t\t\tfmt.Sprintf(\"Could not read bucket %s after update: %s\", plan.ID.ValueString(), err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Update computed values\n\tplan.ARN = types.StringValue(bucket.ARN)\n\tplan.CreatedAt = types.StringValue(bucket.CreatedAt)\n\n\t// Set state to fully populated data\n\tdiags = resp.State.Set(ctx, plan)\n\tresp.Diagnostics.Append(diags...)\n}\n\n// Delete deletes the resource and removes the Terraform state on success.\nfunc (r *resourceBucket) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n\t// Retrieve values from state\n\tvar state resourceBucketModel\n\tdiags := req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Delete existing bucket\n\terr := r.client.DeleteBucket(ctx, &DeleteBucketInput{\n\t\tID: state.ID.ValueString(),\n\t})\n\tif err != nil {\n\t\tif IsNotFoundError(err) {\n\t\t\t// Bucket already deleted, no error\n\t\t\treturn\n\t\t}\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error deleting bucket\",\n\t\t\tfmt.Sprintf(\"Could not delete bucket %s: %s\", state.ID.ValueString(), err.Error()),\n\t\t)\n\t\treturn\n\t}\n}\n\n// ImportState imports the resource into Terraform state.\nfunc (r *resourceBucket) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {\n\t// Retrieve import ID and save to id attribute\n\tresource.ImportStatePassthroughID(ctx, path.Root(\"id\"), req, resp)\n}\n```\n\nNow let's create the client and API types:\n\n```go\n// internal/service/s3/client.go\npackage s3\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\n// Client represents the S3-compatible storage client.\ntype Client struct {\n\tendpoint string\n\tregion   string\n\t// Add actual S3 client here (e.g., *s3.Client from AWS SDK)\n}\n\n// NewClient creates a new S3 client.\nfunc NewClient(endpoint, region string) *Client {\n\treturn &Client{\n\t\tendpoint: endpoint,\n\t\tregion:   region,\n\t}\n}\n\n// Bucket represents an S3 bucket.\ntype Bucket struct {\n\tID                string\n\tName              string\n\tRegion            string\n\tVersioningEnabled bool\n\tTags              map[string]string\n\tARN               string\n\tCreatedAt         string\n}\n\n// CreateBucketInput represents input for creating a bucket.\ntype CreateBucketInput struct {\n\tName              string\n\tRegion            string\n\tVersioningEnabled bool\n\tTags              map[string]string\n}\n\n// UpdateBucketVersioningInput represents input for updating bucket versioning.\ntype UpdateBucketVersioningInput struct {\n\tID      string\n\tEnabled bool\n}\n\n// UpdateBucketTagsInput represents input for updating bucket tags.\ntype UpdateBucketTagsInput struct {\n\tID   string\n\tTags map[string]",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5293,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "# Terraform Provider Resource for S3-Compatible Storage Bucket\n\nHere's a complete implementation of an S3-compatible storage bucket resource using the Terraform Plugin Framework:\n\n```go\n// internal/service/s3/bucket_resource.go\npackage s3\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3/types\"\n\t\"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n\t\"github.com/hashicorp/terraform-plugin-log/tflog\"\n)\n\n// Ensure provider defined types fully satisfy framework interfaces.\nvar (\n\t_ resource.Resource                = &BucketResource{}\n\t_ resource.ResourceWithImportState = &BucketResource{}\n\t_ resource.ResourceWithConfigure   = &BucketResource{}\n)\n\n// NewBucketResource creates a new bucket resource.\nfunc NewBucketResource() resource.Resource {\n\treturn &BucketResource{}\n}\n\n// BucketResource defines the resource implementation.\ntype BucketResource struct {\n\tclient *s3.Client\n}\n\n// BucketResourceModel describes the resource data model.\ntype BucketResourceModel struct {\n\tName              types.String `tfsdk:\"name\"`\n\tRegion            types.String `tfsdk:\"region\"`\n\tVersioningEnabled types.Bool   `tfsdk:\"versioning_enabled\"`\n\tTags              types.Map    `tfsdk:\"tags\"`\n\tID                types.String `tfsdk:\"id\"`\n\tARN               types.String `tfsdk:\"arn\"`\n}\n\n// Metadata returns the resource type name.\nfunc (r *BucketResource) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = req.ProviderTypeName + \"_bucket\"\n}\n\n// Schema defines the schema for the resource.\nfunc (r *BucketResource) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\t// This description is used by the documentation generator and the language server.\n\t\tMarkdownDescription: \"Manages an S3-compatible storage bucket.\",\n\t\tDescription:         \"Manages an S3-compatible storage bucket with versioning and tagging support.\",\n\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"id\": schema.StringAttribute{\n\t\t\t\tComputed:            true,\n\t\t\t\tMarkdownDescription: \"The unique identifier for the bucket (same as name).\",\n\t\t\t\tDescription:         \"The unique identifier for the bucket (same as name).\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tRequired:            true,\n\t\t\t\tMarkdownDescription: \"The name of the bucket. Must be globally unique and DNS-compliant.\",\n\t\t\t\tDescription:         \"The name of the bucket. Must be globally unique and DNS-compliant.\",\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\t// DNS-compliant bucket name regex\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z0-9][a-z0-9\\-]*[a-z0-9]$`),\n\t\t\t\t\t\t\"bucket name must be DNS-compliant (lowercase letters, numbers, and hyphens only, must start and end with letter or number)\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tRequired:            true,\n\t\t\t\tMarkdownDescription: \"The AWS region where the bucket will be created.\",\n\t\t\t\tDescription:         \"The AWS region where the bucket will be created.\",\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthAtLeast(1),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tOptional:            true,\n\t\t\t\tComputed:            true,\n\t\t\t\tDefault:             booldefault.StaticBool(false),\n\t\t\t\tMarkdownDescription: \"Enable versioning for the bucket. Defaults to `false`.\",\n\t\t\t\tDescription:         \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t},\n\t\t\t\"tags\": schema.MapAttribute{\n\t\t\t\tElementType:         types.StringType,\n\t\t\t\tOptional:            true,\n\t\t\t\tMarkdownDescription: \"A map of tags to assign to the bucket.\",\n\t\t\t\tDescription:         \"A map of tags to assign to the bucket.\",\n\t\t\t},\n\t\t\t\"arn\": schema.StringAttribute{\n\t\t\t\tComputed:            true,\n\t\t\t\tMarkdownDescription: \"The ARN of the bucket.\",\n\t\t\t\tDescription:         \"The ARN of the bucket.\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\n// Configure adds the provider configured client to the resource.\nfunc (r *BucketResource) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {\n\t// Prevent panic if the provider has not been configured.\n\tif req.ProviderData == nil {\n\t\treturn\n\t}\n\n\tclient, ok := req.ProviderData.(*s3.Client)\n\tif !ok {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Unexpected Resource Configure Type\",\n\t\t\tfmt.Sprintf(\"Expected *s3.Client, got: %T. Please report this issue to the provider developers.\", req.ProviderData),\n\t\t)\n\t\treturn\n\t}\n\n\tr.client = client\n}\n\n// Create creates the resource and sets the initial Terraform state.\nfunc (r *BucketResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\tvar plan BucketResourceModel\n\n\t// Read Terraform plan data into the model\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Create the bucket\n\tbucketName := plan.Name.ValueString()\n\tregion := plan.Region.ValueString()\n\n\ttflog.Debug(ctx, \"Creating S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t\t\"region\":      region,\n\t})\n\n\tcreateBucketInput := &s3.CreateBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t}\n\n\t// Add location constraint if not us-east-1\n\tif region != \"us-east-1\" {\n\t\tcreateBucketInput.CreateBucketConfiguration = &types.CreateBucketConfiguration{\n\t\t\tLocationConstraint: types.BucketLocationConstraint(region),\n\t\t}\n\t}\n\n\t_, err := r.client.CreateBucket(ctx, createBucketInput)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error creating bucket\",\n\t\t\tfmt.Sprintf(\"Could not create bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Set versioning if enabled\n\tif !plan.VersioningEnabled.IsNull() && plan.VersioningEnabled.ValueBool() {\n\t\tif err := r.updateVersioning(ctx, bucketName, true); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error enabling versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not enable versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\t// Attempt to clean up the bucket\n\t\t\tr.client.DeleteBucket(ctx, &s3.DeleteBucketInput{Bucket: aws.String(bucketName)})\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Set tags if provided\n\tif !plan.Tags.IsNull() && len(plan.Tags.Elements()) > 0 {\n\t\ttags, diags := r.expandTags(ctx, plan.Tags)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\n\t\tif err := r.updateTags(ctx, bucketName, tags); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error setting tags\",\n\t\t\t\tfmt.Sprintf(\"Could not set tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\t// Continue anyway as bucket is created\n\t\t}\n\t}\n\n\t// Set computed attributes\n\tplan.ID = types.StringValue(bucketName)\n\tplan.ARN = types.StringValue(fmt.Sprintf(\"arn:aws:s3:::%s\", bucketName))\n\n\t// Save data into Terraform state\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n\n\ttflog.Debug(ctx, \"Successfully created S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n}\n\n// Read refreshes the Terraform state with the latest data.\nfunc (r *BucketResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\tvar state BucketResourceModel\n\n\t// Read Terraform prior state data into the model\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := state.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Reading S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n\n\t// Check if bucket exists\n\t_, err := r.client.HeadBucket(ctx, &s3.HeadBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\t// If bucket doesn't exist, remove from state\n\t\tresp.Diagnostics.AddWarning(\n\t\t\t\"Bucket not found\",\n\t\t\tfmt.Sprintf(\"Bucket %s not found, removing from state\", bucketName),\n\t\t)\n\t\tresp.State.RemoveResource(ctx)\n\t\treturn\n\t}\n\n\t// Get bucket location\n\tlocationOutput, err := r.client.GetBucketLocation(ctx, &s3.GetBucketLocationInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket location\",\n\t\t\tfmt.Sprintf(\"Could not read location for bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Handle empty location constraint (means us-east-1)\n\tregion := \"us-east-1\"\n\tif locationOutput.LocationConstraint != \"\" {\n\t\tregion = string(locationOutput.LocationConstraint)\n\t}\n\tstate.Region = types.StringValue(region)\n\n\t// Get versioning status\n\tversioningOutput, err := r.client.GetBucketVersioning(ctx, &s3.GetBucketVersioningInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket versioning\",\n\t\t\tfmt.Sprintf(\"Could not read versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\tstate.VersioningEnabled = types.BoolValue(versioningOutput.Status == types.BucketVersioningStatusEnabled)\n\n\t// Get tags\n\ttagsOutput, err := r.client.GetBucketTagging(ctx, &s3.GetBucketTaggingInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\t// NoSuchTagSet error is expected if no tags are set\n\t\tvar nfe *types.NoSuchTagSet\n\t\tif !errors.As(err, &nfe) {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error reading bucket tags\",\n\t\t\t\tfmt.Sprintf(\"Could not read tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t\t// No tags set\n\t\tstate.Tags = types.MapNull(types.StringType)\n\t} else {\n\t\ttags, diags := r.flattenTags(ctx, tagsOutput.TagSet)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\t\tstate.Tags = tags\n\t}\n\n\t// Save updated data into Terraform state\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &state)...)\n\n\ttflog.Debug(ctx, \"Successfully read S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n}\n\n// Update updates the resource and sets the updated Terraform state on success.\nfunc (r *BucketResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\tvar plan, state BucketResourceModel\n\n\t// Read Terraform plan data into the model\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Updating S3 bucket\", map[string]interface{}{\n\t\t\"bucket_name\": bucketName,\n\t})\n\n\t// Update region if changed (this would typically require recreate, but included for completeness)\n\tif !plan.Region.Equal(state.Region) {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Region cannot be changed\",\n\t\t\t\"The bucket region cannot be changed after creation. This should have triggered a replacement.\",\n\t\t)\n\t\treturn\n\t}\n\n\t// Update versioning if changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\tenabled := plan.VersioningEnabled.ValueBool()\n\t\tif err := r.updateVersioning(ctx, bucketName, enabled); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not update versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update tags if changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\tif plan.Tags.IsNull() || len(plan.Tags.Elements()) == 0 {\n\t\t\t// Remove all tags\n\t\t\t_, err := r.client.DeleteBucketTagging(ctx, &s3.DeleteBucketTaggingInput{\n\t\t\t\tBucket: aws.String(bucketName),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\t\"Error removing tags\",\n\t\t\t\t\tfmt.Sprintf(\"Could not remove tags from bucket %s: %s\", bucketName, err.Error()),\n\t\t\t\t)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else {\n\t\t\t// Update tags\n\t\t\ttags, diags := r.expandTags(ctx, plan.Tags)\n\t\t\tresp.Diagnostics.Append(diags...)\n\t\t\tif resp.Diagnostics.HasError() {\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\tif err := r.updateTags(ctx, bucketName, tags); err != nil {\n\t\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\t\"Error updating tags\",\n\t\t\t\t\tfmt.Sprintf(\"Could not update tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t\t)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\t// Save updated data into Terraform state\n\tresp.Diagnost",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 90,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# S3-Compatible Storage Bucket Resource Implementation\n\nI'll implement a complete Terraform provider resource for an S3-compatible storage bucket using the Plugin Framework, following all standard patterns and best practices.\n\n## File Structure\n\n```\ninternal/service/s3storage/\n\u251c\u2500\u2500 bucket.go                    # Resource implementation\n\u251c\u2500\u2500 bucket_test.go              # Acceptance tests\n\u251c\u2500\u2500 find.go                     # Finder functions\n\u251c\u2500\u2500 exports_test.go             # Test exports\n\u2514\u2500\u2500 service_package_gen.go      # Auto-generated registration\n```\n\n## Implementation\n\n### 1. Resource Implementation (bucket.go)\n\n```go\n// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage s3storage\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/aws/aws-sdk-go-v2/aws\"\n    \"github.com/aws/aws-sdk-go-v2/service/s3\"\n    \"github.com/aws/aws-sdk-go-v2/service/s3/types\"\n    \"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n    \"github.com/hashicorp/terraform-plugin-framework/path\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n    \"github.com/hashicorp/terraform-plugin-framework/types\"\n    \"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n    \"github.com/hashicorp/terraform-provider-aws/internal/create\"\n    \"github.com/hashicorp/terraform-provider-aws/internal/errs\"\n    \"github.com/hashicorp/terraform-provider-aws/internal/framework\"\n    \"github.com/hashicorp/terraform-provider-aws/internal/framework/flex\"\n    fwtypes \"github.com/hashicorp/terraform-provider-aws/internal/framework/types\"\n    tftags \"github.com/hashicorp/terraform-provider-aws/internal/tags\"\n    \"github.com/hashicorp/terraform-provider-aws/internal/tfresource\"\n    \"github.com/hashicorp/terraform-provider-aws/names\"\n)\n\n// @FrameworkResource(\"aws_s3storage_bucket\", name=\"Bucket\")\n// @Tags(identifierAttribute=\"arn\")\nfunc newResourceBucket(_ context.Context) (resource.ResourceWithConfigure, error) {\n    r := &resourceBucket{}\n\n    return r, nil\n}\n\nconst (\n    ResNameBucket = \"Bucket\"\n)\n\ntype resourceBucket struct {\n    framework.ResourceWithConfigure\n    framework.WithTimeouts\n    framework.WithImportByID\n}\n\nfunc (r *resourceBucket) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = \"aws_s3storage_bucket\"\n}\n\nfunc (r *resourceBucket) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Attributes: map[string]schema.Attribute{\n            \"arn\": framework.ARNAttributeComputedOnly(),\n            \"id\":  framework.IDAttribute(),\n            \"name\": schema.StringAttribute{\n                Required: true,\n                Description: \"Name of the bucket. Must be globally unique and DNS-compliant. \" +\n                    \"Bucket names must be between 3 and 63 characters long, can consist only of \" +\n                    \"lowercase letters, numbers, dots (.), and hyphens (-), and must begin and end \" +\n                    \"with a letter or number.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n                Validators: []validator.String{\n                    stringvalidator.LengthBetween(3, 63),\n                    stringvalidator.RegexMatches(\n                        bucketNameRegex,\n                        \"must be a valid DNS-compliant bucket name (lowercase letters, numbers, dots, and hyphens)\",\n                    ),\n                },\n            },\n            \"region\": schema.StringAttribute{\n                Required:    true,\n                Description: \"AWS region where the bucket will be created.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n                Validators: []validator.String{\n                    stringvalidator.LengthBetween(1, 50),\n                },\n            },\n            \"versioning_enabled\": schema.BoolAttribute{\n                Optional:    true,\n                Computed:    true,\n                Default:     booldefault.StaticBool(false),\n                Description: \"Enable versioning for the bucket. Defaults to false.\",\n            },\n            \"creation_date\": schema.StringAttribute{\n                Computed:    true,\n                Description: \"Date and time the bucket was created.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n            names.AttrTags:    tftags.TagsAttribute(),\n            names.AttrTagsAll: tftags.TagsAttributeComputedOnly(),\n        },\n        Blocks: map[string]schema.Block{\n            \"timeouts\": r.Timeouts(ctx, timeouts{\n                create: 5 * time.Minute,\n                update: 5 * time.Minute,\n                delete: 5 * time.Minute,\n            }),\n        },\n    }\n}\n\nfunc (r *resourceBucket) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    conn := r.Meta().S3Client(ctx)\n\n    var plan resourceBucketModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    bucketName := plan.Name.ValueString()\n\n    // Create bucket with location constraint\n    input := &s3.CreateBucketInput{\n        Bucket: aws.String(bucketName),\n    }\n\n    // Add location constraint if not us-east-1\n    region := plan.Region.ValueString()\n    if region != \"us-east-1\" {\n        input.CreateBucketConfiguration = &types.CreateBucketConfiguration{\n            LocationConstraint: types.BucketLocationConstraint(region),\n        }\n    }\n\n    // Add tags if provided\n    tags := getTagsIn(ctx)\n    if len(tags) > 0 {\n        input.ObjectOwnership = types.ObjectOwnershipBucketOwnerEnforced\n    }\n\n    _, err := conn.CreateBucket(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            create.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n            err.Error(),\n        )\n        return\n    }\n\n    // Wait for bucket to be available\n    createTimeout := r.CreateTimeout(ctx, plan.Timeouts)\n    bucket, err := waitBucketCreated(ctx, conn, bucketName, createTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            create.ProblemStandardMessage(names.S3Storage, create.ErrActionWaitingForCreation, ResNameBucket, bucketName, err),\n            err.Error(),\n        )\n        return\n    }\n\n    // Set ID and ARN\n    plan.ID = types.StringValue(bucketName)\n    plan.ARN = types.StringPointerValue(bucketARN(r.Meta().Partition, bucketName))\n    plan.CreationDate = flex.StringValueToFramework(ctx, bucket.CreationDate.Format(time.RFC3339))\n\n    // Configure versioning if enabled\n    if plan.VersioningEnabled.ValueBool() {\n        versioningInput := &s3.PutBucketVersioningInput{\n            Bucket: aws.String(bucketName),\n            VersioningConfiguration: &types.VersioningConfiguration{\n                Status: types.BucketVersioningStatusEnabled,\n            },\n        }\n\n        _, err = conn.PutBucketVersioning(ctx, versioningInput)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                create.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n                fmt.Sprintf(\"Failed to enable versioning: %s\", err.Error()),\n            )\n            return\n        }\n    }\n\n    // Set tags\n    if len(tags) > 0 {\n        if err := createTags(ctx, conn, bucketName, tags); err != nil {\n            resp.Diagnostics.AddError(\n                create.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n                fmt.Sprintf(\"Failed to set tags: %s\", err.Error()),\n            )\n            return\n        }\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, plan)...)\n}\n\nfunc (r *resourceBucket) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    conn := r.Meta().S3Client(ctx)\n\n    var state resourceBucketModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    bucketName := state.ID.ValueString()\n\n    // Find bucket\n    bucket, err := findBucketByName(ctx, conn, bucketName)\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource Not Found\",\n            fmt.Sprintf(\"Bucket %s not found, removing from state\", bucketName),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            create.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n            err.Error(),\n        )\n        return\n    }\n\n    // Update basic attributes\n    state.Name = types.StringValue(aws.ToString(bucket.Name))\n    state.CreationDate = flex.StringValueToFramework(ctx, bucket.CreationDate.Format(time.RFC3339))\n\n    // Get bucket location\n    locationOutput, err := conn.GetBucketLocation(ctx, &s3.GetBucketLocationInput{\n        Bucket: aws.String(bucketName),\n    })\n    if err != nil {\n        resp.Diagnostics.AddError(\n            create.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n            fmt.Sprintf(\"Failed to get bucket location: %s\", err.Error()),\n        )\n        return\n    }\n\n    // Handle us-east-1 special case (returns empty string)\n    region := string(locationOutput.LocationConstraint)\n    if region == \"\" {\n        region = \"us-east-1\"\n    }\n    state.Region = types.StringValue(region)\n\n    // Get versioning status\n    versioningOutput, err := conn.GetBucketVersioning(ctx, &s3.GetBucketVersioningInput{\n        Bucket: aws.String(bucketName),\n    })\n    if err != nil {\n        resp.Diagnostics.AddError(\n            create.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n            fmt.Sprintf(\"Failed to get versioning status: %s\", err.Error()),\n        )\n        return\n    }\n\n    state.VersioningEnabled = types.BoolValue(versioningOutput.Status == types.BucketVersioningStatusEnabled)\n\n    // Get tags\n    tags, err := listTags(ctx, conn, bucketName)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            create.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n            fmt.Sprintf(\"Failed to list tags: %s\", err.Error()),\n        )\n        return\n    }\n\n    setTagsOut(ctx, tags)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &state)...)\n}\n\nfunc (r *resourceBucket) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    conn := r.Meta().S3Client(ctx)\n\n    var plan, state resourceBucketModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    bucketName := plan.ID.ValueString()\n\n    // Update versioning if changed\n    if !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n        status := types.BucketVersioningStatusSuspended\n        if plan.VersioningEnabled.ValueBool() {\n            status = types.BucketVersioningStatusEnabled\n        }\n\n        versioningInput := &s3.PutBucketVersioningInput{\n            Bucket: aws.String(bucketName),\n            VersioningConfiguration: &types.VersioningConfiguration{\n                Status: status,\n            },\n        }\n\n        _, err := conn.PutBucketVersioning(ctx, versioningInput)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                create.ProblemStandardMessage(names.S3Storage, create.ErrActionUpdating, ResNameBucket, bucketName, err),\n                fmt.Sprintf(\"Failed to update versioning: %s\", err.Error()),\n            )\n            return\n        }\n    }\n\n    // Update tags if changed\n    if !plan.Tags.Equal(state.Tags) {\n        oldTags := getTagsIn(ctx)\n        newTags := getTagsIn(ctx)\n\n        if err := updateTags(ctx, conn, bucketName, oldTags, newTags); err != nil {\n            resp.Diagnostics.AddError(\n                create.ProblemStandardMessage(names.S3Storage, create.ErrActionUpdating, ResNameBucket, bucketName, err),\n                fmt.Sprintf(\"Failed to update tags: %s\", err.Error()),\n            )\n            return\n        }\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceBucket) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    conn := r.Meta().S3Client(ctx)\n\n    var state resourceBucketModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    bucketName := state.ID.ValueString()\n\n    // Delete bucket\n    _, err := conn.DeleteBucket(ctx, &s3.DeleteBucketInput{\n        Bucket: aws.String(bucketName),\n    })\n\n    if err != nil {\n        if errs.IsA[*types.NoSuchBucket](err) {\n            return\n        }\n        resp.Diagnostics.AddError(\n            create.ProblemStandardMessage(names.S3Storage, create.ErrActionDeleting, ResNameBucket, bucketName, err),\n            err.Error(),\n        )\n        return\n    }\n\n    // Wait for bucket to be deleted\n    deleteTimeout := r.DeleteTimeout(ctx, state.Timeouts)\n    _, err = waitBucketDeleted(",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4809,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll implement a complete Terraform provider resource for an S3-compatible storage bucket using the Plugin Framework. Let me create the necessary files following the standard service package structure.\n\nFirst, let me create the service package directory structure and implement the resource:\n\n```go\n// internal/service/s3/bucket.go\npackage s3\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3/types\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n\t\"github.com/hashicorp/terraform-plugin-log/tflog\"\n)\n\n// Ensure provider defined types fully satisfy framework interfaces\nvar (\n\t_ resource.Resource                = &resourceBucket{}\n\t_ resource.ResourceWithConfigure   = &resourceBucket{}\n\t_ resource.ResourceWithImportState = &resourceBucket{}\n)\n\nfunc NewResourceBucket() resource.Resource {\n\treturn &resourceBucket{}\n}\n\ntype resourceBucket struct {\n\tclient *s3.Client\n}\n\ntype resourceBucketModel struct {\n\tID               types.String `tfsdk:\"id\"`\n\tName             types.String `tfsdk:\"name\"`\n\tRegion           types.String `tfsdk:\"region\"`\n\tVersioningEnabled types.Bool   `tfsdk:\"versioning_enabled\"`\n\tTags             types.Map    `tfsdk:\"tags\"`\n\tARN              types.String `tfsdk:\"arn\"`\n\tCreatedAt        types.String `tfsdk:\"created_at\"`\n}\n\nfunc (r *resourceBucket) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = req.ProviderTypeName + \"_bucket\"\n}\n\nfunc (r *resourceBucket) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\tDescription: \"Manages an S3-compatible storage bucket.\",\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"id\": schema.StringAttribute{\n\t\t\t\tDescription: \"Identifier of the bucket (same as name).\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tDescription: \"Name of the bucket. Must be globally unique and DNS-compliant.\",\n\t\t\t\tRequired:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z0-9][a-z0-9\\-]*[a-z0-9]$`),\n\t\t\t\t\t\t\"must be lowercase alphanumeric with hyphens, starting and ending with alphanumeric character\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tDescription: \"AWS region where the bucket will be created.\",\n\t\t\t\tRequired:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(1, 50),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tDescription: \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t\tOptional:    true,\n\t\t\t\tComputed:    true,\n\t\t\t\tDefault:     booldefault.StaticBool(false),\n\t\t\t},\n\t\t\t\"tags\": schema.MapAttribute{\n\t\t\t\tDescription: \"Map of tags to assign to the bucket.\",\n\t\t\t\tOptional:    true,\n\t\t\t\tElementType: types.StringType,\n\t\t\t},\n\t\t\t\"arn\": schema.StringAttribute{\n\t\t\t\tDescription: \"ARN of the bucket.\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"created_at\": schema.StringAttribute{\n\t\t\t\tDescription: \"Timestamp when the bucket was created.\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc (r *resourceBucket) Configure(_ context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {\n\tif req.ProviderData == nil {\n\t\treturn\n\t}\n\n\tclient, ok := req.ProviderData.(*s3.Client)\n\tif !ok {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Unexpected Resource Configure Type\",\n\t\t\tfmt.Sprintf(\"Expected *s3.Client, got: %T. Please report this issue to the provider developers.\", req.ProviderData),\n\t\t)\n\t\treturn\n\t}\n\n\tr.client = client\n}\n\nfunc (r *resourceBucket) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\tvar data resourceBucketModel\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := data.Name.ValueString()\n\tregion := data.Region.ValueString()\n\n\ttflog.Debug(ctx, \"Creating S3 bucket\", map[string]interface{}{\n\t\t\"name\":   bucketName,\n\t\t\"region\": region,\n\t})\n\n\t// Create bucket\n\tcreateInput := &s3.CreateBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t}\n\n\t// Add location constraint if not us-east-1\n\tif region != \"us-east-1\" {\n\t\tcreateInput.CreateBucketConfiguration = &types.CreateBucketConfiguration{\n\t\t\tLocationConstraint: types.BucketLocationConstraint(region),\n\t\t}\n\t}\n\n\t_, err := r.client.CreateBucket(ctx, createInput)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error creating S3 bucket\",\n\t\t\tfmt.Sprintf(\"Could not create bucket %s: %s\", bucketName, err),\n\t\t)\n\t\treturn\n\t}\n\n\t// Configure versioning if enabled\n\tif data.VersioningEnabled.ValueBool() {\n\t\tversioningInput := &s3.PutBucketVersioningInput{\n\t\t\tBucket: aws.String(bucketName),\n\t\t\tVersioningConfiguration: &types.VersioningConfiguration{\n\t\t\t\tStatus: types.BucketVersioningStatusEnabled,\n\t\t\t},\n\t\t}\n\n\t\t_, err := r.client.PutBucketVersioning(ctx, versioningInput)\n\t\tif err != nil {\n\t\t\t// Attempt to clean up the bucket\n\t\t\tr.client.DeleteBucket(ctx, &s3.DeleteBucketInput{\n\t\t\t\tBucket: aws.String(bucketName),\n\t\t\t})\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error configuring bucket versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not enable versioning for bucket %s: %s\", bucketName, err),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Apply tags if provided\n\tif !data.Tags.IsNull() && len(data.Tags.Elements()) > 0 {\n\t\ttags := make([]types.Tag, 0)\n\t\tfor key, value := range data.Tags.Elements() {\n\t\t\ttags = append(tags, types.Tag{\n\t\t\t\tKey:   aws.String(key),\n\t\t\t\tValue: aws.String(value.(types.String).ValueString()),\n\t\t\t})\n\t\t}\n\n\t\ttaggingInput := &s3.PutBucketTaggingInput{\n\t\t\tBucket: aws.String(bucketName),\n\t\t\tTagging: &types.Tagging{\n\t\t\t\tTagSet: tags,\n\t\t\t},\n\t\t}\n\n\t\t_, err := r.client.PutBucketTagging(ctx, taggingInput)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddWarning(\n\t\t\t\t\"Error applying tags\",\n\t\t\t\tfmt.Sprintf(\"Could not apply tags to bucket %s: %s\", bucketName, err),\n\t\t\t)\n\t\t}\n\t}\n\n\t// Set computed attributes\n\tdata.ID = types.StringValue(bucketName)\n\tdata.ARN = types.StringValue(fmt.Sprintf(\"arn:aws:s3:::%s\", bucketName))\n\tdata.CreatedAt = types.StringValue(time.Now().UTC().Format(time.RFC3339))\n\n\ttflog.Debug(ctx, \"Successfully created S3 bucket\", map[string]interface{}{\n\t\t\"name\": bucketName,\n\t})\n\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceBucket) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\tvar data resourceBucketModel\n\tresp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := data.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Reading S3 bucket\", map[string]interface{}{\n\t\t\"name\": bucketName,\n\t})\n\n\t// Check if bucket exists\n\t_, err := r.client.HeadBucket(ctx, &s3.HeadBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tif isNotFoundError(err) {\n\t\t\ttflog.Warn(ctx, \"S3 bucket not found, removing from state\", map[string]interface{}{\n\t\t\t\t\"name\": bucketName,\n\t\t\t})\n\t\t\tresp.State.RemoveResource(ctx)\n\t\t\treturn\n\t\t}\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading S3 bucket\",\n\t\t\tfmt.Sprintf(\"Could not read bucket %s: %s\", bucketName, err),\n\t\t)\n\t\treturn\n\t}\n\n\t// Get bucket location\n\tlocationOutput, err := r.client.GetBucketLocation(ctx, &s3.GetBucketLocationInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket location\",\n\t\t\tfmt.Sprintf(\"Could not read location for bucket %s: %s\", bucketName, err),\n\t\t)\n\t\treturn\n\t}\n\n\t// Handle us-east-1 special case (returns empty string)\n\tregion := string(locationOutput.LocationConstraint)\n\tif region == \"\" {\n\t\tregion = \"us-east-1\"\n\t}\n\tdata.Region = types.StringValue(region)\n\n\t// Get versioning configuration\n\tversioningOutput, err := r.client.GetBucketVersioning(ctx, &s3.GetBucketVersioningInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddWarning(\n\t\t\t\"Error reading bucket versioning\",\n\t\t\tfmt.Sprintf(\"Could not read versioning for bucket %s: %s\", bucketName, err),\n\t\t)\n\t} else {\n\t\tdata.VersioningEnabled = types.BoolValue(versioningOutput.Status == types.BucketVersioningStatusEnabled)\n\t}\n\n\t// Get bucket tags\n\ttaggingOutput, err := r.client.GetBucketTagging(ctx, &s3.GetBucketTaggingInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tif !isNoSuchTagSetError(err) {\n\t\t\tresp.Diagnostics.AddWarning(\n\t\t\t\t\"Error reading bucket tags\",\n\t\t\t\tfmt.Sprintf(\"Could not read tags for bucket %s: %s\", bucketName, err),\n\t\t\t)\n\t\t}\n\t\t// No tags or error - set empty map\n\t\tdata.Tags = types.MapNull(types.StringType)\n\t} else {\n\t\ttags := make(map[string]attr.Value)\n\t\tfor _, tag := range taggingOutput.TagSet {\n\t\t\ttags[*tag.Key] = types.StringValue(*tag.Value)\n\t\t}\n\t\ttagsMap, diags := types.MapValue(types.StringType, tags)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif !resp.Diagnostics.HasError() {\n\t\t\tdata.Tags = tagsMap\n\t\t}\n\t}\n\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceBucket) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\tvar plan, state resourceBucketModel\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Updating S3 bucket\", map[string]interface{}{\n\t\t\"name\": bucketName,\n\t})\n\n\t// Update versioning if changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\tstatus := types.BucketVersioningStatusSuspended\n\t\tif plan.VersioningEnabled.ValueBool() {\n\t\t\tstatus = types.BucketVersioningStatusEnabled\n\t\t}\n\n\t\tversioningInput := &s3.PutBucketVersioningInput{\n\t\t\tBucket: aws.String(bucketName),\n\t\t\tVersioningConfiguration: &types.VersioningConfiguration{\n\t\t\t\tStatus: status,\n\t\t\t},\n\t\t}\n\n\t\t_, err := r.client.PutBucketVersioning(ctx, versioningInput)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating bucket versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not update versioning for bucket %s: %s\", bucketName, err),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update tags if changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\tif plan.Tags.IsNull() || len(plan.Tags.Elements()) == 0 {\n\t\t\t// Delete all tags\n\t\t\t_, err := r.client.DeleteBucketTagging(ctx, &s3.DeleteBucketTaggingInput{\n\t\t\t\tBucket: aws.String(bucketName),\n\t\t\t})\n\t\t\tif err != nil {\n\t\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\t\"Error deleting bucket tags\",\n\t\t\t\t\tfmt.Sprintf(\"Could not delete tags for bucket %s: %s\", bucketName, err),\n\t\t\t\t)\n\t\t\t\treturn\n\t\t\t}\n\t\t} else {\n\t\t\t// Update tags\n\t\t\ttags := make([]types.Tag, 0)\n\t\t\tfor key, value := range plan.Tags.Elements() {\n\t\t\t\ttags = append(tags, types.Tag{\n\t\t\t\t\tKey:   aws.String(key),\n\t\t\t\t\tValue: aws.String(value.(types.String).ValueString()),\n\t\t\t\t})\n\t\t\t}\n\n\t\t\ttaggingInput := &s3.PutBucketTaggingInput{\n\t\t\t\tBucket: aws.String(bucketName),\n\t\t\t\tTagging: &types.Tagging{\n\t\t\t\t\tTagSet: tags,\n\t\t\t\t},\n\t\t\t}\n\n\t\t\t_, err := r.client.PutBucketTagging(ctx, taggingInput)\n\t\t\tif err != nil {\n\t\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\t\"Error updating bucket tags\",\n\t\t\t\t\tfmt.Sprintf(\"Could not update tags for bucket %s: %s\", bucketName, err),\n\t\t\t\t)\n\t\t\t\treturn\n\t\t\t}\n\t\t}",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5293,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "# Terraform Provider Resource for S3-Compatible Storage Bucket\n\nI'll implement a complete Terraform provider resource using the Plugin Framework with all CRUD operations and best practices.\n\n## Directory Structure\n```\ninternal/service/s3bucket/\n\u251c\u2500\u2500 resource_bucket.go\n\u251c\u2500\u2500 resource_bucket_test.go\n\u2514\u2500\u2500 validators.go\n```\n\n## resource_bucket.go\n\n```go\npackage s3bucket\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"regexp\"\n\n\t\"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/mapplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n\t\"github.com/hashicorp/terraform-plugin-log/tflog\"\n)\n\n// Ensure the implementation satisfies the expected interfaces.\nvar (\n\t_ resource.Resource                = &bucketResource{}\n\t_ resource.ResourceWithConfigure   = &bucketResource{}\n\t_ resource.ResourceWithImportState = &bucketResource{}\n)\n\n// NewBucketResource is a helper function to simplify the provider implementation.\nfunc NewBucketResource() resource.Resource {\n\treturn &bucketResource{}\n}\n\n// bucketResource is the resource implementation.\ntype bucketResource struct {\n\tclient *S3Client // Your S3-compatible client\n}\n\n// bucketResourceModel maps the resource schema data.\ntype bucketResourceModel struct {\n\tID                types.String `tfsdk:\"id\"`\n\tName              types.String `tfsdk:\"name\"`\n\tRegion            types.String `tfsdk:\"region\"`\n\tVersioningEnabled types.Bool   `tfsdk:\"versioning_enabled\"`\n\tTags              types.Map    `tfsdk:\"tags\"`\n\tLastUpdated       types.String `tfsdk:\"last_updated\"`\n}\n\n// Metadata returns the resource type name.\nfunc (r *bucketResource) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = req.ProviderTypeName + \"_bucket\"\n}\n\n// Schema defines the schema for the resource.\nfunc (r *bucketResource) Schema(_ context.Context, _ resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\tDescription: \"Manages an S3-compatible storage bucket.\",\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"id\": schema.StringAttribute{\n\t\t\t\tDescription: \"Unique identifier for the bucket. This is typically the same as the bucket name.\",\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tDescription: \"The name of the bucket. Must be globally unique and DNS-compliant. \" +\n\t\t\t\t\t\"Changing this value will force replacement of the resource.\",\n\t\t\t\tRequired: true,\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z0-9][a-z0-9\\-]*[a-z0-9]$`),\n\t\t\t\t\t\t\"bucket name must start and end with a lowercase letter or number, \"+\n\t\t\t\t\t\t\t\"and can only contain lowercase letters, numbers, and hyphens\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!.*\\.\\.).*$`),\n\t\t\t\t\t\t\"bucket name must not contain consecutive periods\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!xn--).*$`),\n\t\t\t\t\t\t\"bucket name must not start with 'xn--'\",\n\t\t\t\t\t),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^(?!sthree-).*$`),\n\t\t\t\t\t\t\"bucket name must not start with 'sthree-'\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tDescription: \"The region where the bucket will be created.\",\n\t\t\t\tRequired:    true,\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthAtLeast(1),\n\t\t\t\t},\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tDescription: \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t\tOptional:    true,\n\t\t\t\tComputed:    true,\n\t\t\t\tDefault:     booldefault.StaticBool(false),\n\t\t\t},\n\t\t\t\"tags\": schema.MapAttribute{\n\t\t\t\tDescription: \"A map of tags to assign to the bucket.\",\n\t\t\t\tElementType: types.StringType,\n\t\t\t\tOptional:    true,\n\t\t\t\tComputed:    true,\n\t\t\t\tPlanModifiers: []planmodifier.Map{\n\t\t\t\t\tmapplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"last_updated\": schema.StringAttribute{\n\t\t\t\tDescription: \"Timestamp of the last Terraform update of the bucket.\",\n\t\t\t\tComputed:    true,\n\t\t\t},\n\t\t},\n\t}\n}\n\n// Configure adds the provider configured client to the resource.\nfunc (r *bucketResource) Configure(_ context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {\n\tif req.ProviderData == nil {\n\t\treturn\n\t}\n\n\tclient, ok := req.ProviderData.(*S3Client)\n\tif !ok {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Unexpected Resource Configure Type\",\n\t\t\tfmt.Sprintf(\"Expected *S3Client, got: %T. Please report this issue to the provider developers.\", req.ProviderData),\n\t\t)\n\t\treturn\n\t}\n\n\tr.client = client\n}\n\n// Create creates the resource and sets the initial Terraform state.\nfunc (r *bucketResource) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\t// Retrieve values from plan\n\tvar plan bucketResourceModel\n\tdiags := req.Plan.Get(ctx, &plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Generate API request body from plan\n\tbucketName := plan.Name.ValueString()\n\tregion := plan.Region.ValueString()\n\tversioningEnabled := plan.VersioningEnabled.ValueBool()\n\n\ttflog.Debug(ctx, \"Creating bucket\", map[string]interface{}{\n\t\t\"name\":   bucketName,\n\t\t\"region\": region,\n\t})\n\n\t// Create the bucket\n\terr := r.client.CreateBucket(ctx, bucketName, region)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error creating bucket\",\n\t\t\tfmt.Sprintf(\"Could not create bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Set versioning if enabled\n\tif versioningEnabled {\n\t\terr = r.client.SetBucketVersioning(ctx, bucketName, versioningEnabled)\n\t\tif err != nil {\n\t\t\t// Attempt to clean up the bucket\n\t\t\t_ = r.client.DeleteBucket(ctx, bucketName)\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error setting bucket versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not set versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Set tags if provided\n\tif !plan.Tags.IsNull() && !plan.Tags.IsUnknown() {\n\t\ttags := make(map[string]string)\n\t\tdiags = plan.Tags.ElementsAs(ctx, &tags, false)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\n\t\tif len(tags) > 0 {\n\t\t\terr = r.client.SetBucketTags(ctx, bucketName, tags)\n\t\t\tif err != nil {\n\t\t\t\t// Attempt to clean up the bucket\n\t\t\t\t_ = r.client.DeleteBucket(ctx, bucketName)\n\t\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\t\"Error setting bucket tags\",\n\t\t\t\t\tfmt.Sprintf(\"Could not set tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t\t)\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\t}\n\n\t// Set the ID and last_updated\n\tplan.ID = types.StringValue(bucketName)\n\tplan.LastUpdated = types.StringValue(getCurrentTimestamp())\n\n\t// If tags were not set, initialize as empty map\n\tif plan.Tags.IsNull() {\n\t\tplan.Tags = types.MapValueMust(types.StringType, map[string]attr.Value{})\n\t}\n\n\t// Set state to fully populated data\n\tdiags = resp.State.Set(ctx, plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\ttflog.Debug(ctx, \"Successfully created bucket\", map[string]interface{}{\n\t\t\"id\": plan.ID.ValueString(),\n\t})\n}\n\n// Read refreshes the Terraform state with the latest data.\nfunc (r *bucketResource) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\t// Get current state\n\tvar state bucketResourceModel\n\tdiags := req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := state.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Reading bucket\", map[string]interface{}{\n\t\t\"name\": bucketName,\n\t})\n\n\t// Get bucket details\n\tbucket, err := r.client.GetBucket(ctx, bucketName)\n\tif err != nil {\n\t\tif isNotFoundError(err) {\n\t\t\t// Bucket no longer exists, remove from state\n\t\t\tresp.State.RemoveResource(ctx)\n\t\t\treturn\n\t\t}\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket\",\n\t\t\tfmt.Sprintf(\"Could not read bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Update state with refreshed values\n\tstate.ID = types.StringValue(bucket.Name)\n\tstate.Name = types.StringValue(bucket.Name)\n\tstate.Region = types.StringValue(bucket.Region)\n\tstate.VersioningEnabled = types.BoolValue(bucket.VersioningEnabled)\n\n\t// Get and set tags\n\ttags, err := r.client.GetBucketTags(ctx, bucketName)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading bucket tags\",\n\t\t\tfmt.Sprintf(\"Could not read tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\tif len(tags) > 0 {\n\t\ttagMap := make(map[string]attr.Value)\n\t\tfor k, v := range tags {\n\t\t\ttagMap[k] = types.StringValue(v)\n\t\t}\n\t\tstate.Tags = types.MapValueMust(types.StringType, tagMap)\n\t} else {\n\t\tstate.Tags = types.MapValueMust(types.StringType, map[string]attr.Value{})\n\t}\n\n\t// Set refreshed state\n\tdiags = resp.State.Set(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\ttflog.Debug(ctx, \"Successfully read bucket\", map[string]interface{}{\n\t\t\"id\": state.ID.ValueString(),\n\t})\n}\n\n// Update updates the resource and sets the updated Terraform state on success.\nfunc (r *bucketResource) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\t// Retrieve values from plan\n\tvar plan bucketResourceModel\n\tdiags := req.Plan.Get(ctx, &plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Retrieve values from state\n\tvar state bucketResourceModel\n\tdiags = req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Updating bucket\", map[string]interface{}{\n\t\t\"name\": bucketName,\n\t})\n\n\t// Update versioning if changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\tversioningEnabled := plan.VersioningEnabled.ValueBool()\n\t\terr := r.client.SetBucketVersioning(ctx, bucketName, versioningEnabled)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating bucket versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not update versioning for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update tags if changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\ttags := make(map[string]string)\n\t\tif !plan.Tags.IsNull() && !plan.Tags.IsUnknown() {\n\t\t\tdiags = plan.Tags.ElementsAs(ctx, &tags, false)\n\t\t\tresp.Diagnostics.Append(diags...)\n\t\t\tif resp.Diagnostics.HasError() {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\terr := r.client.SetBucketTags(ctx, bucketName, tags)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating bucket tags\",\n\t\t\t\tfmt.Sprintf(\"Could not update tags for bucket %s: %s\", bucketName, err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update last_updated timestamp\n\tplan.LastUpdated = types.StringValue(getCurrentTimestamp())\n\n\t// Set state\n\tdiags = resp.State.Set(ctx, plan)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\ttflog.Debug(ctx, \"Successfully updated bucket\", map[string]interface{}{\n\t\t\"id\": plan.ID.ValueString(),\n\t})\n}\n\n// Delete deletes the resource and removes the Terraform state on success.\nfunc (r *bucketResource) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n\t// Retrieve values from state\n\tvar state bucketResourceModel\n\tdiags := req.State.Get(ctx, &state)\n\tresp.Diagnostics.Append(diags...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := state.Name.ValueString()\n\n\ttflog.Debug(ctx, \"Deleting bucket\", map[string]interface{}{\n\t\t\"name\": bucketName,\n\t})\n\n\t// Delete the bucket\n\terr := r.client.DeleteBucket(ctx, bucketName)\n\tif err != nil {\n\t\tif isNotFoundError(err) {\n\t\t\t// Bucket already deleted, just remove from state\n\t\t\treturn\n\t\t}\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error deleting bucket\",\n\t\t\tfmt.Sprintf(\"Could not delete bucket %s: %s\", bucketName, err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\ttflog.Debug(ctx, \"Successfully deleted bucket\", map[string]interface{}{\n\t\t\"name\": bucketName,\n\t})",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 90,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# S3-Compatible Storage Bucket Resource Implementation\n\nI'll implement a complete Terraform provider resource for an S3-compatible storage bucket using the Plugin Framework.\n\n## File Structure\n\n```\ninternal/service/s3storage/\n\u251c\u2500\u2500 bucket.go\n\u251c\u2500\u2500 bucket_test.go\n\u251c\u2500\u2500 find.go\n\u251c\u2500\u2500 wait.go\n\u251c\u2500\u2500 exports_test.go\n\u2514\u2500\u2500 service_package_gen.go\n```\n\n## 1. Resource Implementation (bucket.go)\n\n```go\n// Copyright (c) HashiCorp, Inc.\n// SPDX-License-Identifier: MPL-2.0\n\npackage s3storage\n\nimport (\n\t\"context\"\n\t\"errors\"\n\t\"fmt\"\n\t\"time\"\n\n\t\"github.com/aws/aws-sdk-go-v2/aws\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3\"\n\t\"github.com/aws/aws-sdk-go-v2/service/s3/types\"\n\t\"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n\t\"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/conns\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/create\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/errs\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/framework\"\n\ttftags \"github.com/hashicorp/terraform-provider-aws/internal/tags\"\n\t\"github.com/hashicorp/terraform-provider-aws/internal/tfresource\"\n\t\"github.com/hashicorp/terraform-provider-aws/names\"\n)\n\n// @FrameworkResource(\"aws_s3storage_bucket\", name=\"Bucket\")\n// @Tags(identifierAttribute=\"id\")\nfunc newResourceBucket(_ context.Context) (resource.ResourceWithConfigure, error) {\n\tr := &resourceBucket{}\n\n\treturn r, nil\n}\n\nconst (\n\tResNameBucket = \"Bucket\"\n)\n\ntype resourceBucket struct {\n\tframework.ResourceWithConfigure\n\tframework.WithTimeouts\n}\n\nfunc (r *resourceBucket) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = \"aws_s3storage_bucket\"\n}\n\nfunc (r *resourceBucket) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"arn\": framework.ARNAttributeComputedOnly(),\n\t\t\t\"id\":  framework.IDAttribute(),\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tRequired: true,\n\t\t\t\tDescription: \"Name of the bucket. Must be globally unique and follow DNS naming conventions. \" +\n\t\t\t\t\t\"Changing this value will force replacement of the resource.\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tbucketNameRegex,\n\t\t\t\t\t\t\"must be lowercase alphanumeric with hyphens, cannot start or end with hyphen\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tRequired: true,\n\t\t\t\tDescription: \"AWS region where the bucket will be created. \" +\n\t\t\t\t\t\"Changing this value will force replacement of the resource.\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(1, 50),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tOptional:    true,\n\t\t\t\tComputed:    true,\n\t\t\t\tDefault:     booldefault.StaticBool(false),\n\t\t\t\tDescription: \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t},\n\t\t\t\"creation_date\": schema.StringAttribute{\n\t\t\t\tComputed:    true,\n\t\t\t\tDescription: \"Date and time when the bucket was created.\",\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\tnames.AttrTags:    tftags.TagsAttribute(),\n\t\t\tnames.AttrTagsAll: tftags.TagsAttributeComputedOnly(),\n\t\t},\n\t\tBlocks: map[string]schema.Block{\n\t\t\t\"timeouts\": timeouts.Block(ctx, timeouts.Opts{\n\t\t\t\tCreate: true,\n\t\t\t\tUpdate: true,\n\t\t\t\tDelete: true,\n\t\t\t}),\n\t\t},\n\t}\n}\n\nfunc (r *resourceBucket) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\tconn := r.Meta().S3Client(ctx)\n\n\tvar plan resourceBucketModel\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.Name.ValueString()\n\n\t// Create bucket input\n\tinput := &s3.CreateBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t}\n\n\t// Set location constraint if not in us-east-1\n\tregion := plan.Region.ValueString()\n\tif region != \"us-east-1\" {\n\t\tinput.CreateBucketConfiguration = &types.CreateBucketConfiguration{\n\t\t\tLocationConstraint: types.BucketLocationConstraint(region),\n\t\t}\n\t}\n\n\t// Create the bucket\n\t_, err := conn.CreateBucket(ctx, input)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n\t\t\terr.Error(),\n\t\t)\n\t\treturn\n\t}\n\n\t// Wait for bucket to be available\n\tcreateTimeout := r.CreateTimeout(ctx, plan.Timeouts)\n\tbucket, err := waitBucketCreated(ctx, conn, bucketName, createTimeout)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionWaitingForCreation, ResNameBucket, bucketName, err),\n\t\t\terr.Error(),\n\t\t)\n\t\treturn\n\t}\n\n\t// Set ID\n\tplan.ID = types.StringValue(bucketName)\n\n\t// Configure versioning if enabled\n\tif plan.VersioningEnabled.ValueBool() {\n\t\tversioningInput := &s3.PutBucketVersioningInput{\n\t\t\tBucket: aws.String(bucketName),\n\t\t\tVersioningConfiguration: &types.VersioningConfiguration{\n\t\t\t\tStatus: types.BucketVersioningStatusEnabled,\n\t\t\t},\n\t\t}\n\n\t\t_, err = conn.PutBucketVersioning(ctx, versioningInput)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to enable versioning: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Set tags if provided\n\tif !plan.Tags.IsNull() {\n\t\tif err := createTags(ctx, conn, bucketName, getTagsIn(ctx, plan.Tags)); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionCreating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to set tags: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Set computed attributes\n\tplan.ARN = types.StringValue(bucketARN(bucketName, region))\n\tif bucket.CreationDate != nil {\n\t\tplan.CreationDate = types.StringValue(bucket.CreationDate.Format(time.RFC3339))\n\t}\n\n\tresp.Diagnostics.Append(resp.State.Set(ctx, plan)...)\n}\n\nfunc (r *resourceBucket) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\tconn := r.Meta().S3Client(ctx)\n\n\tvar state resourceBucketModel\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := state.ID.ValueString()\n\n\t// Find the bucket\n\tbucket, err := findBucketByName(ctx, conn, bucketName)\n\tif tfresource.NotFound(err) {\n\t\tresp.Diagnostics.AddWarning(\n\t\t\t\"Resource Not Found\",\n\t\t\tfmt.Sprintf(\"Bucket %s not found, removing from state\", bucketName),\n\t\t)\n\t\tresp.State.RemoveResource(ctx)\n\t\treturn\n\t}\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\terr.Error(),\n\t\t)\n\t\treturn\n\t}\n\n\t// Get bucket location\n\tlocationOutput, err := conn.GetBucketLocation(ctx, &s3.GetBucketLocationInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\tfmt.Sprintf(\"Failed to get bucket location: %s\", err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\tregion := normalizeRegion(locationOutput.LocationConstraint)\n\tstate.Region = types.StringValue(region)\n\n\t// Get versioning status\n\tversioningOutput, err := conn.GetBucketVersioning(ctx, &s3.GetBucketVersioningInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\tfmt.Sprintf(\"Failed to get versioning status: %s\", err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\tstate.VersioningEnabled = types.BoolValue(versioningOutput.Status == types.BucketVersioningStatusEnabled)\n\n\t// Set computed attributes\n\tstate.Name = types.StringValue(bucketName)\n\tstate.ARN = types.StringValue(bucketARN(bucketName, region))\n\tif bucket.CreationDate != nil {\n\t\tstate.CreationDate = types.StringValue(bucket.CreationDate.Format(time.RFC3339))\n\t}\n\n\t// Get tags\n\ttags, err := listTags(ctx, conn, bucketName)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionReading, ResNameBucket, bucketName, err),\n\t\t\tfmt.Sprintf(\"Failed to list tags: %s\", err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\tsetTagsOut(ctx, tags)\n\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &state)...)\n}\n\nfunc (r *resourceBucket) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\tconn := r.Meta().S3Client(ctx)\n\n\tvar plan, state resourceBucketModel\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := plan.ID.ValueString()\n\n\t// Update versioning if changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\tstatus := types.BucketVersioningStatusSuspended\n\t\tif plan.VersioningEnabled.ValueBool() {\n\t\t\tstatus = types.BucketVersioningStatusEnabled\n\t\t}\n\n\t\tversioningInput := &s3.PutBucketVersioningInput{\n\t\t\tBucket: aws.String(bucketName),\n\t\t\tVersioningConfiguration: &types.VersioningConfiguration{\n\t\t\t\tStatus: status,\n\t\t\t},\n\t\t}\n\n\t\t_, err := conn.PutBucketVersioning(ctx, versioningInput)\n\t\tif err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionUpdating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to update versioning: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\n\t\t// Wait for versioning update to propagate\n\t\tupdateTimeout := r.UpdateTimeout(ctx, plan.Timeouts)\n\t\tif err := waitBucketVersioningUpdated(ctx, conn, bucketName, status, updateTimeout); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionWaitingForUpdate, ResNameBucket, bucketName, err),\n\t\t\t\terr.Error(),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Update tags if changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\tif err := updateTags(ctx, conn, bucketName, state.Tags, plan.Tags); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionUpdating, ResNameBucket, bucketName, err),\n\t\t\t\tfmt.Sprintf(\"Failed to update tags: %s\", err.Error()),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceBucket) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n\tconn := r.Meta().S3Client(ctx)\n\n\tvar state resourceBucketModel\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\tbucketName := state.ID.ValueString()\n\n\t// Delete all objects in the bucket first\n\tif err := emptyBucket(ctx, conn, bucketName); err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionDeleting, ResNameBucket, bucketName, err),\n\t\t\tfmt.Sprintf(\"Failed to empty bucket: %s\", err.Error()),\n\t\t)\n\t\treturn\n\t}\n\n\t// Delete the bucket\n\t_, err := conn.DeleteBucket(ctx, &s3.DeleteBucketInput{\n\t\tBucket: aws.String(bucketName),\n\t})\n\n\tif err != nil {\n\t\tvar nsk *types.NoSuchBucket\n\t\tif errors.As(err, &nsk) {\n\t\t\treturn\n\t\t}\n\n\t\tresp.Diagnostics.AddError(\n\t\t\tcreate.ProblemStandardMessage(names.S3Storage, create.ErrActionDeleting, ResNameBucket, bucketName, err),\n\t\t\terr.Error",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4809,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll implement a complete Terraform provider resource for an S3-compatible storage bucket using the Plugin Framework. Let me create the necessary files following the standard patterns.\n\nFirst, let me create the service package structure:\n\n```go\n// internal/service/s3/bucket.go\npackage s3\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\n\t\"github.com/hashicorp/terraform-plugin-framework-validators/stringvalidator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/path\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/booldefault\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n\t\"github.com/hashicorp/terraform-plugin-framework/schema/validator\"\n\t\"github.com/hashicorp/terraform-plugin-framework/types\"\n)\n\n// Ensure provider defined types fully satisfy framework interfaces.\nvar _ resource.Resource = &resourceBucket{}\nvar _ resource.ResourceWithImportState = &resourceBucket{}\nvar _ resource.ResourceWithConfigure = &resourceBucket{}\n\nfunc NewResourceBucket() resource.Resource {\n\treturn &resourceBucket{}\n}\n\n// resourceBucket defines the resource implementation.\ntype resourceBucket struct {\n\tclient *Client\n}\n\n// resourceBucketModel describes the resource data model.\ntype resourceBucketModel struct {\n\tID                types.String `tfsdk:\"id\"`\n\tName              types.String `tfsdk:\"name\"`\n\tRegion            types.String `tfsdk:\"region\"`\n\tVersioningEnabled types.Bool   `tfsdk:\"versioning_enabled\"`\n\tTags              types.Map    `tfsdk:\"tags\"`\n\tARN               types.String `tfsdk:\"arn\"`\n\tCreatedAt         types.String `tfsdk:\"created_at\"`\n}\n\nfunc (r *resourceBucket) Metadata(ctx context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n\tresp.TypeName = req.ProviderTypeName + \"_s3_bucket\"\n}\n\nfunc (r *resourceBucket) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n\tresp.Schema = schema.Schema{\n\t\tMarkdownDescription: \"Manages an S3-compatible storage bucket.\",\n\t\tAttributes: map[string]schema.Attribute{\n\t\t\t\"id\": schema.StringAttribute{\n\t\t\t\tMarkdownDescription: \"Unique identifier for the bucket.\",\n\t\t\t\tComputed:            true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"name\": schema.StringAttribute{\n\t\t\t\tMarkdownDescription: \"Name of the bucket. Must be globally unique and DNS-compliant.\",\n\t\t\t\tRequired:            true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(3, 63),\n\t\t\t\t\tstringvalidator.RegexMatches(\n\t\t\t\t\t\tregexp.MustCompile(`^[a-z0-9][a-z0-9-]*[a-z0-9]$`),\n\t\t\t\t\t\t\"must be lowercase alphanumeric with hyphens, starting and ending with alphanumeric\",\n\t\t\t\t\t),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"region\": schema.StringAttribute{\n\t\t\t\tMarkdownDescription: \"AWS region where the bucket will be created.\",\n\t\t\t\tRequired:            true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.RequiresReplace(),\n\t\t\t\t},\n\t\t\t\tValidators: []validator.String{\n\t\t\t\t\tstringvalidator.LengthBetween(1, 50),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"versioning_enabled\": schema.BoolAttribute{\n\t\t\t\tMarkdownDescription: \"Enable versioning for the bucket. Defaults to false.\",\n\t\t\t\tOptional:            true,\n\t\t\t\tComputed:            true,\n\t\t\t\tDefault:             booldefault.StaticBool(false),\n\t\t\t},\n\t\t\t\"tags\": schema.MapAttribute{\n\t\t\t\tMarkdownDescription: \"Map of tags to assign to the bucket.\",\n\t\t\t\tElementType:         types.StringType,\n\t\t\t\tOptional:            true,\n\t\t\t},\n\t\t\t\"arn\": schema.StringAttribute{\n\t\t\t\tMarkdownDescription: \"ARN of the bucket.\",\n\t\t\t\tComputed:            true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t\t\"created_at\": schema.StringAttribute{\n\t\t\t\tMarkdownDescription: \"Timestamp when the bucket was created.\",\n\t\t\t\tComputed:            true,\n\t\t\t\tPlanModifiers: []planmodifier.String{\n\t\t\t\t\tstringplanmodifier.UseStateForUnknown(),\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t}\n}\n\nfunc (r *resourceBucket) Configure(ctx context.Context, req resource.ConfigureRequest, resp *resource.ConfigureResponse) {\n\tif req.ProviderData == nil {\n\t\treturn\n\t}\n\n\tclient, ok := req.ProviderData.(*Client)\n\tif !ok {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Unexpected Resource Configure Type\",\n\t\t\tfmt.Sprintf(\"Expected *Client, got: %T. Please report this issue to the provider developers.\", req.ProviderData),\n\t\t)\n\t\treturn\n\t}\n\n\tr.client = client\n}\n\nfunc (r *resourceBucket) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n\tvar data resourceBucketModel\n\n\t// Read Terraform plan data into the model\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Prepare tags\n\ttags := make(map[string]string)\n\tif !data.Tags.IsNull() {\n\t\tresp.Diagnostics.Append(data.Tags.ElementsAs(ctx, &tags, false)...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Create bucket via API\n\tinput := &CreateBucketInput{\n\t\tName:              data.Name.ValueString(),\n\t\tRegion:            data.Region.ValueString(),\n\t\tVersioningEnabled: data.VersioningEnabled.ValueBool(),\n\t\tTags:              tags,\n\t}\n\n\toutput, err := r.client.CreateBucket(ctx, input)\n\tif err != nil {\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error creating S3 bucket\",\n\t\t\tfmt.Sprintf(\"Could not create bucket %s: %s\", data.Name.ValueString(), err),\n\t\t)\n\t\treturn\n\t}\n\n\t// Map response to model\n\tdata.ID = types.StringValue(output.ID)\n\tdata.ARN = types.StringValue(output.ARN)\n\tdata.CreatedAt = types.StringValue(output.CreatedAt)\n\n\t// Save data into Terraform state\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceBucket) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n\tvar data resourceBucketModel\n\n\t// Read Terraform prior state data into the model\n\tresp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Get bucket from API\n\toutput, err := findBucketByID(ctx, r.client, data.ID.ValueString())\n\tif err != nil {\n\t\tif IsNotFoundError(err) {\n\t\t\tresp.Diagnostics.AddWarning(\n\t\t\t\t\"Resource not found\",\n\t\t\t\tfmt.Sprintf(\"Bucket %s not found, removing from state\", data.ID.ValueString()),\n\t\t\t)\n\t\t\tresp.State.RemoveResource(ctx)\n\t\t\treturn\n\t\t}\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error reading S3 bucket\",\n\t\t\tfmt.Sprintf(\"Could not read bucket %s: %s\", data.ID.ValueString(), err),\n\t\t)\n\t\treturn\n\t}\n\n\t// Update model with API response\n\tdata.Name = types.StringValue(output.Name)\n\tdata.Region = types.StringValue(output.Region)\n\tdata.VersioningEnabled = types.BoolValue(output.VersioningEnabled)\n\tdata.ARN = types.StringValue(output.ARN)\n\tdata.CreatedAt = types.StringValue(output.CreatedAt)\n\n\t// Update tags\n\tif len(output.Tags) > 0 {\n\t\ttags := make(map[string]string)\n\t\tfor k, v := range output.Tags {\n\t\t\ttags[k] = v\n\t\t}\n\t\ttagsValue, diags := types.MapValueFrom(ctx, types.StringType, tags)\n\t\tresp.Diagnostics.Append(diags...)\n\t\tif resp.Diagnostics.HasError() {\n\t\t\treturn\n\t\t}\n\t\tdata.Tags = tagsValue\n\t} else {\n\t\tdata.Tags = types.MapNull(types.StringType)\n\t}\n\n\t// Save updated data into Terraform state\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceBucket) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n\tvar plan, state resourceBucketModel\n\n\t// Read Terraform plan and state data into the models\n\tresp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n\tresp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Check if versioning changed\n\tif !plan.VersioningEnabled.Equal(state.VersioningEnabled) {\n\t\tinput := &UpdateBucketVersioningInput{\n\t\t\tID:      plan.ID.ValueString(),\n\t\t\tEnabled: plan.VersioningEnabled.ValueBool(),\n\t\t}\n\n\t\tif err := r.client.UpdateBucketVersioning(ctx, input); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating bucket versioning\",\n\t\t\t\tfmt.Sprintf(\"Could not update versioning for bucket %s: %s\", plan.ID.ValueString(), err),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Check if tags changed\n\tif !plan.Tags.Equal(state.Tags) {\n\t\tplanTags := make(map[string]string)\n\t\tif !plan.Tags.IsNull() {\n\t\t\tresp.Diagnostics.Append(plan.Tags.ElementsAs(ctx, &planTags, false)...)\n\t\t\tif resp.Diagnostics.HasError() {\n\t\t\t\treturn\n\t\t\t}\n\t\t}\n\n\t\tinput := &UpdateBucketTagsInput{\n\t\t\tID:   plan.ID.ValueString(),\n\t\t\tTags: planTags,\n\t\t}\n\n\t\tif err := r.client.UpdateBucketTags(ctx, input); err != nil {\n\t\t\tresp.Diagnostics.AddError(\n\t\t\t\t\"Error updating bucket tags\",\n\t\t\t\tfmt.Sprintf(\"Could not update tags for bucket %s: %s\", plan.ID.ValueString(), err),\n\t\t\t)\n\t\t\treturn\n\t\t}\n\t}\n\n\t// Save updated data into Terraform state\n\tresp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceBucket) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n\tvar data resourceBucketModel\n\n\t// Read Terraform prior state data into the model\n\tresp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n\tif resp.Diagnostics.HasError() {\n\t\treturn\n\t}\n\n\t// Delete bucket via API\n\tinput := &DeleteBucketInput{\n\t\tID: data.ID.ValueString(),\n\t}\n\n\terr := r.client.DeleteBucket(ctx, input)\n\tif err != nil {\n\t\tif IsNotFoundError(err) {\n\t\t\t// Bucket already deleted\n\t\t\treturn\n\t\t}\n\t\tresp.Diagnostics.AddError(\n\t\t\t\"Error deleting S3 bucket\",\n\t\t\tfmt.Sprintf(\"Could not delete bucket %s: %s\", data.ID.ValueString(), err),\n\t\t)\n\t\treturn\n\t}\n}\n\nfunc (r *resourceBucket) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {\n\tresource.ImportStatePassthroughID(ctx, path.Root(\"id\"), req, resp)\n}\n```\n\nNow let's create the finder functions:\n\n```go\n// internal/service/s3/find.go\npackage s3\n\nimport (\n\t\"context\"\n\t\"fmt\"\n)\n\n// findBucketByID retrieves a bucket by its ID.\nfunc findBucketByID(ctx context.Context, client *Client, id string) (*Bucket, error) {\n\tinput := &GetBucketInput{\n\t\tID: id,\n\t}\n\n\toutput, err := client.GetBucket(ctx, input)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif output == nil {\n\t\treturn nil, &NotFoundError{\n\t\t\tMessage: fmt.Sprintf(\"bucket with ID %s not found\", id),\n\t\t}\n\t}\n\n\treturn output, nil\n}\n\n// findBucketByName retrieves a bucket by its name.\nfunc findBucketByName(ctx context.Context, client *Client, name string) (*Bucket, error) {\n\tinput := &GetBucketByNameInput{\n\t\tName: name,\n\t}\n\n\toutput, err := client.GetBucketByName(ctx, input)\n\tif err != nil {\n\t\treturn nil, err\n\t}\n\n\tif output == nil {\n\t\treturn nil, &NotFoundError{\n\t\t\tMessage: fmt.Sprintf(\"bucket with name %s not found\", name),\n\t\t}\n\t}\n\n\treturn output, nil\n}\n```\n\nNow the client types and API methods:\n\n```go\n// internal/service/s3/client.go\npackage s3\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"time\"\n)\n\n// Client represents the S3 API client.\ntype Client struct {\n\tendpoint string\n\tapiKey   string\n}\n\n// NewClient creates a new S3 client.\nfunc NewClient(endpoint, apiKey string) *Client {\n\treturn &Client{\n\t\tendpoint: endpoint,\n\t\tapiKey:   apiKey,\n\t}\n}\n\n// Bucket represents an S3 bucket.\ntype Bucket struct {\n\tID                string\n\tName              string\n\tRegion            string\n\tVersioningEnabled bool\n\tTags              map[string]string\n\tARN               string\n\tCreatedAt         string\n}\n\n// CreateBucketInput represents the input for creating a bucket.\ntype CreateBucketInput struct {\n\tName              string\n\tRegion            string\n\tVersioningEnabled bool\n\tTags              map[string]string\n}\n\n// CreateBucketOutput represents the output from creating a bucket.\ntype CreateBucketOutput struct {\n\tID        string\n\tARN       string\n\tCreatedAt string\n}\n\n// GetBucketInput represents the input for getting a bucket by ID.\ntype GetBucketInput struct {\n\tID string\n}\n\n// GetBucketByNameInput represents the input for getting a bucket by name.\ntype GetBucketByNameInput struct {\n\tName string\n}\n\n// UpdateBucketVersioningInput represents the input for updating bucket versioning.\ntype UpdateBucketVersioningInput struct {\n\tID      string\n\tEnabled bool\n}\n\n// UpdateBucketTagsInput represents the input for updating bucket tags.\ntype UpdateBucketTagsInput struct {\n\tID   string\n\tTags map[string]string\n}\n\n// DeleteBucketInput represents the input for deleting a bucket.\ntype DeleteBucketInput struct {\n\tID string\n}\n\n// CreateBucket creates a new S3 bucket.\nfunc (c *Client) CreateBucket(ctx context.Context, input *CreateBucketInput) (*CreateBucketOutput, error) {\n\t// TODO: Implement actual API call\n\t// This is a placeholder implementation\n\tid := fmt.Sprintf(\"bucket-%d\", time.Now().Unix())\n\tarn := fmt.Sprintf(\"arn:aws:s3:::%s\", input.Name)\n\tcreatedAt := time.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5293,
            "output_tokens": 4096,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "provider-resources-02",
      "task_type": "cross_language",
      "target_language": "python",
      "expected_patterns": [
        "pulumi",
        "ResourceProvider|dynamic\\.Resource",
        "def create\\(",
        "def read\\(",
        "def update\\(",
        "def delete\\("
      ],
      "anti_patterns": [
        "framework\\.ResourceWithConfigure",
        "resource\\.MetadataRequest",
        "schema\\.StringAttribute",
        "resp\\.Diagnostics",
        "resource\\.TestCase\\{",
        "hcl|terraform"
      ],
      "pattern_sources": [
        {
          "url": "https://www.pulumi.com/docs/concepts/resources/dynamic-providers/",
          "description": "Pulumi dynamic provider: ResourceProvider interface, CRUD method signatures (def create, def read, def update, def delete)"
        },
        {
          "url": "https://docs.python.org/3/tutorial/controlflow.html#defining-functions",
          "description": "Python function definitions - source of def keyword for defining create, read, update, delete methods"
        },
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/internal/provider/example_resource.go",
          "description": "Anti-patterns: Terraform Plugin Framework Go types (framework.ResourceWithConfigure, resource.MetadataRequest, schema.StringAttribute, resp.Diagnostics, resource.TestCase) that should not appear in Python"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "# Pulumi Dynamic Provider for Custom Database Service\n\nI'll create a comprehensive Pulumi dynamic provider for managing a custom database service with full CRUD operations.\n\n```python\n\"\"\"\nCustom Database Service Pulumi Dynamic Provider\n\nThis module implements a Pulumi dynamic provider for managing database resources\nwith create, read, update, and delete operations.\n\"\"\"\n\nimport pulumi\nfrom pulumi import Input, Output, ResourceOptions\nfrom pulumi.dynamic import Resource, ResourceProvider, CreateResult, UpdateResult\nfrom typing import Any, Optional\nimport json\nimport time\nimport hashlib\n\n\nclass DatabaseArgs:\n    \"\"\"\n    Arguments for the Database resource.\n    \"\"\"\n    def __init__(\n        self,\n        name: Input[str],\n        engine: Input[str],\n        size: Input[str],\n        tags: Optional[Input[dict]] = None\n    ):\n        \"\"\"\n        Initialize database arguments.\n        \n        Args:\n            name: The name of the database\n            engine: The database engine (e.g., 'postgres', 'mysql', 'mongodb')\n            size: The size/tier of the database (e.g., 'small', 'medium', 'large')\n            tags: Optional tags for the database\n        \"\"\"\n        self.name = name\n        self.engine = engine\n        self.size = size\n        self.tags = tags or {}\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"\n    Dynamic provider implementation for database resources.\n    \n    This simulates a database service API. In production, you would replace\n    the simulation logic with actual API calls to your database service.\n    \"\"\"\n    \n    # Simulated database storage (in production, this would be an actual API)\n    _databases = {}\n    \n    def _generate_id(self, name: str) -> str:\n        \"\"\"Generate a unique ID for the database.\"\"\"\n        timestamp = str(time.time())\n        return hashlib.md5(f\"{name}-{timestamp}\".encode()).hexdigest()[:16]\n    \n    def _validate_engine(self, engine: str) -> None:\n        \"\"\"Validate the database engine.\"\"\"\n        valid_engines = ['postgres', 'mysql', 'mongodb', 'redis', 'mariadb']\n        if engine.lower() not in valid_engines:\n            raise ValueError(\n                f\"Invalid engine '{engine}'. Must be one of: {', '.join(valid_engines)}\"\n            )\n    \n    def _validate_size(self, size: str) -> None:\n        \"\"\"Validate the database size.\"\"\"\n        valid_sizes = ['small', 'medium', 'large', 'xlarge']\n        if size.lower() not in valid_sizes:\n            raise ValueError(\n                f\"Invalid size '{size}'. Must be one of: {', '.join(valid_sizes)}\"\n            )\n    \n    def _get_size_specs(self, size: str) -> dict:\n        \"\"\"Get specifications for a given size.\"\"\"\n        specs = {\n            'small': {'cpu': 1, 'memory_gb': 2, 'storage_gb': 20},\n            'medium': {'cpu': 2, 'memory_gb': 4, 'storage_gb': 50},\n            'large': {'cpu': 4, 'memory_gb': 8, 'storage_gb': 100},\n            'xlarge': {'cpu': 8, 'memory_gb': 16, 'storage_gb': 200},\n        }\n        return specs.get(size.lower(), specs['small'])\n    \n    def create(self, props: dict) -> CreateResult:\n        \"\"\"\n        Create a new database resource.\n        \n        Args:\n            props: Properties for the new database\n            \n        Returns:\n            CreateResult with the database ID and outputs\n        \"\"\"\n        pulumi.log.info(f\"Creating database: {props['name']}\")\n        \n        # Validate inputs\n        self._validate_engine(props['engine'])\n        self._validate_size(props['size'])\n        \n        # Generate unique ID\n        db_id = self._generate_id(props['name'])\n        \n        # Simulate database creation\n        specs = self._get_size_specs(props['size'])\n        \n        database = {\n            'id': db_id,\n            'name': props['name'],\n            'engine': props['engine'],\n            'size': props['size'],\n            'specs': specs,\n            'status': 'running',\n            'endpoint': f\"{props['name']}.{props['engine']}.database.local\",\n            'port': self._get_default_port(props['engine']),\n            'created_at': time.time(),\n            'tags': props.get('tags', {}),\n        }\n        \n        # Store in simulated database\n        self._databases[db_id] = database\n        \n        pulumi.log.info(f\"Database created successfully: {db_id}\")\n        \n        # Return outputs\n        outs = {\n            'id': db_id,\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'specs': database['specs'],\n            'status': database['status'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'connection_string': self._build_connection_string(database),\n            'tags': database['tags'],\n        }\n        \n        return CreateResult(id_=db_id, outs=outs)\n    \n    def read(self, id_: str, props: dict) -> dict:\n        \"\"\"\n        Read an existing database resource.\n        \n        Args:\n            id_: The database ID\n            props: Current properties\n            \n        Returns:\n            Dictionary of current database properties\n        \"\"\"\n        pulumi.log.info(f\"Reading database: {id_}\")\n        \n        # Retrieve from simulated database\n        database = self._databases.get(id_)\n        \n        if not database:\n            pulumi.log.warn(f\"Database not found: {id_}\")\n            return {}\n        \n        # Return current state\n        return {\n            'id': database['id'],\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'specs': database['specs'],\n            'status': database['status'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'connection_string': self._build_connection_string(database),\n            'tags': database.get('tags', {}),\n        }\n    \n    def update(self, id_: str, old_props: dict, new_props: dict) -> UpdateResult:\n        \"\"\"\n        Update an existing database resource.\n        \n        Args:\n            id_: The database ID\n            old_props: Previous properties\n            new_props: New properties\n            \n        Returns:\n            UpdateResult with updated outputs\n        \"\"\"\n        pulumi.log.info(f\"Updating database: {id_}\")\n        \n        database = self._databases.get(id_)\n        \n        if not database:\n            raise Exception(f\"Database not found: {id_}\")\n        \n        # Check what changed\n        changes = []\n        \n        # Name changes require recreation (not allowed in update)\n        if new_props.get('name') != old_props.get('name'):\n            pulumi.log.warn(\"Database name change requires replacement\")\n            # In a real implementation, you might trigger a replacement here\n        \n        # Engine changes require recreation (not allowed in update)\n        if new_props.get('engine') != old_props.get('engine'):\n            pulumi.log.warn(\"Database engine change requires replacement\")\n        \n        # Size can be updated\n        if new_props.get('size') != old_props.get('size'):\n            self._validate_size(new_props['size'])\n            database['size'] = new_props['size']\n            database['specs'] = self._get_size_specs(new_props['size'])\n            changes.append('size')\n            pulumi.log.info(f\"Database size updated to: {new_props['size']}\")\n        \n        # Tags can be updated\n        if new_props.get('tags') != old_props.get('tags'):\n            database['tags'] = new_props.get('tags', {})\n            changes.append('tags')\n            pulumi.log.info(\"Database tags updated\")\n        \n        # Update timestamp\n        database['updated_at'] = time.time()\n        \n        if changes:\n            pulumi.log.info(f\"Database updated successfully. Changes: {', '.join(changes)}\")\n        else:\n            pulumi.log.info(\"No changes detected\")\n        \n        # Return updated outputs\n        outs = {\n            'id': database['id'],\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'specs': database['specs'],\n            'status': database['status'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'connection_string': self._build_connection_string(database),\n            'tags': database['tags'],\n        }\n        \n        return UpdateResult(outs=outs)\n    \n    def delete(self, id_: str, props: dict) -> None:\n        \"\"\"\n        Delete a database resource.\n        \n        Args:\n            id_: The database ID\n            props: Current properties\n        \"\"\"\n        pulumi.log.info(f\"Deleting database: {id_}\")\n        \n        database = self._databases.get(id_)\n        \n        if not database:\n            pulumi.log.warn(f\"Database not found: {id_}\")\n            return\n        \n        # Simulate deletion\n        database['status'] = 'deleting'\n        \n        # Remove from simulated database\n        del self._databases[id_]\n        \n        pulumi.log.info(f\"Database deleted successfully: {id_}\")\n    \n    def _get_default_port(self, engine: str) -> int:\n        \"\"\"Get the default port for a database engine.\"\"\"\n        ports = {\n            'postgres': 5432,\n            'mysql': 3306,\n            'mongodb': 27017,\n            'redis': 6379,\n            'mariadb': 3306,\n        }\n        return ports.get(engine.lower(), 5432)\n    \n    def _build_connection_string(self, database: dict) -> str:\n        \"\"\"Build a connection string for the database.\"\"\"\n        engine = database['engine'].lower()\n        endpoint = database['endpoint']\n        port = database['port']\n        name = database['name']\n        \n        if engine == 'postgres':\n            return f\"postgresql://user:password@{endpoint}:{port}/{name}\"\n        elif engine in ['mysql', 'mariadb']:\n            return f\"mysql://user:password@{endpoint}:{port}/{name}\"\n        elif engine == 'mongodb':\n            return f\"mongodb://user:password@{endpoint}:{port}/{name}\"\n        elif engine == 'redis':\n            return f\"redis://:{endpoint}:{port}/0\"\n        else:\n            return f\"{engine}://{endpoint}:{port}/{name}\"\n\n\nclass Database(Resource):\n    \"\"\"\n    A custom database resource managed by Pulumi.\n    \n    This resource represents a database instance with configurable\n    name, engine, and size properties.\n    \"\"\"\n    \n    # Output properties\n    id: Output[str]\n    name: Output[str]\n    engine: Output[str]\n    size: Output[str]\n    specs: Output[dict]\n    status: Output[str]\n    endpoint: Output[str]\n    port: Output[int]\n    connection_string: Output[str]\n    tags: Output[dict]\n    \n    def __init__(\n        self,\n        resource_name: str,\n        args: DatabaseArgs,\n        opts: Optional[ResourceOptions] = None\n    ):\n        \"\"\"\n        Create a new Database resource.\n        \n        Args:\n            resource_name: The Pulumi resource name\n            args: Arguments for the database\n            opts: Resource options\n        \"\"\"\n        # Prepare properties\n        props = {\n            'name': args.name,\n            'engine': args.engine,\n            'size': args.size,\n            'tags': args.tags,\n        }\n        \n        # Initialize the dynamic resource\n        super().__init__(\n            DatabaseProvider(),\n            resource_name,\n            props,\n            opts\n        )\n\n\n# Example usage and helper functions\n\ndef create_database_stack():\n    \"\"\"\n    Example function showing how to use the Database resource.\n    \"\"\"\n    # Create a PostgreSQL database\n    postgres_db = Database(\n        \"my-postgres-db\",\n        DatabaseArgs(\n            name=\"production-db\",\n            engine=\"postgres\",\n            size=\"medium\",\n            tags={\n                \"environment\": \"production\",\n                \"team\": \"backend\"\n            }\n        )\n    )\n    \n    # Create a MongoDB database\n    mongo_db = Database(\n        \"my-mongo-db\",\n        DatabaseArgs(\n            name=\"analytics-db\",\n            engine=\"mongodb\",\n            size=\"large\",\n            tags={\n                \"environment\": \"production\",\n                \"team\": \"analytics\"\n            }\n        )\n    )\n    \n    # Export outputs\n    pulumi.export(\"postgres_endpoint\", postgres_db.endpoint)\n    pulumi.export(\"postgres_connection_string\", postgres_db.connection_string)\n    pulumi.export(\"postgres_specs\", postgres_db.specs)\n    \n    pulumi.export(\"mongo_endpoint\", mongo_db.endpoint)\n    pulumi.export(\"mongo_connection_string\", mongo_db.connection_string)\n    pulumi.export(\"mongo_specs\", mongo_db.specs)\n    \n    return postgres_db, mongo_db\n\n\n# Advanced example with dependencies\n\nclass DatabaseCluster(Resource):\n    \"\"\"\n    A database cluster resource that manages multiple database instances.\n    \"\"\"\n    \n    primary: Output[Database]\n    replicas: Output[list]\n    cluster_endpoint: Output[str]\n    \n    def __init__(\n        self,\n        resource_name: str,\n        engine: str,\n        size: str,\n        replica_count: int = 2,\n        opts: Optional[ResourceOptions] = None\n    ):\n        \"\"\"\n        Create a database cluster with primary and replicas.\n        \n        Args:\n            resource_name: The Pulumi resource name\n            engine: Database engine\n            size: Database size\n            replica_count: Number of read replicas\n            opts: Resource options\n        \"\"\"\n        # Create primary database\n        self.primary = Database(\n            f\"{resource_name}-primary\",\n            DatabaseArgs(\n                name=f\"{resource_name}-primary\",\n                engine=engine,\n                size=size,\n                tags={\"role\": \"primary\"}\n            ),\n            opts\n        )\n        \n        # Create replicas\n        self.replicas = []\n        for i in range(replica_count):\n            replica = Database(\n                f\"{resource_name}-replica-{i}\",\n                DatabaseArgs(\n                    name=f\"{resource_name}-replica-{i}\",\n                    engine=engine,\n                    size=size,\n                    tags={\"role\": \"replica\", \"replica_index\": str(i)}\n                ),\n                opts\n            )\n            self.replicas.append(replica)\n\n\n# Utility functions\n\ndef get_database_info(database: Database) -> dict:\n    \"\"\"\n    Get comprehensive information about a database resource.\n    \n    Args:\n        database: The Database resource\n        \n    Returns:\n        Dictionary with database information\n    \"\"\"\n    return {\n        'endpoint': database.endpoint,\n        'connection_string': database.connection_string,\n        'specs': database.specs,\n        'status': database.status,\n    }\n\n\ndef create_connection_config(database: Database, username: str, password: str) -> dict:\n    \"\"\"\n    Create a connection configuration for a database.\n    \n    Args:\n        database: The Database resource\n        username: Database username\n        password: Database password\n        \n    Returns:\n        Connection configuration dictionary\n    \"\"\"\n    return {\n        'host': database.endpoint,\n        'port': database.port,\n        'database': database.name,\n        'username': username,\n        'password': password,\n        'engine': database.engine,\n    }\n\n\nif __name__ == \"__main__\":\n    # This would be in your __main__.py or Pulumi program\n    create_database_stack()\n```\n\n## Usage Example\n\nCreate a `__main__.py` file:\n\n```python\nimport pulumi\nfrom database_provider import Database, DatabaseArgs, DatabaseCluster\n\n# Create a simple database\ndb = Database(\n    \"my-database\",\n    DatabaseArgs(\n        name=\"app-db\",\n        engine=\"postgres\",\n        size=\"medium\",\n        tags={\n            \"environment\": \"production\",\n            \"cost-center\": \"engineering\"\n        }\n    )\n)\n\n# Create a database cluster\ncluster = DatabaseCluster(\n    \"my-",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 60,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# Python Pulumi Dynamic Provider for Custom Database Service\n\nI'll create a comprehensive Pulumi dynamic provider implementation for a custom database service with full CRUD operations.\n\n## Project Structure\n\n```\npulumi-database-provider/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 database_provider.py\n\u251c\u2500\u2500 database_resource.py\n\u251c\u2500\u2500 models.py\n\u251c\u2500\u2500 client.py\n\u251c\u2500\u2500 exceptions.py\n\u251c\u2500\u2500 __main__.py\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 test_database_provider.py\n\u2502   \u2514\u2500\u2500 test_integration.py\n\u251c\u2500\u2500 Pulumi.yaml\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 README.md\n```\n\n## Implementation\n\n### 1. models.py - Data Models\n\n```python\n\"\"\"\nData models for the database provider.\n\"\"\"\nfrom dataclasses import dataclass, asdict\nfrom typing import Optional, Dict, Any\nfrom enum import Enum\n\n\nclass DatabaseEngine(str, Enum):\n    \"\"\"Supported database engines.\"\"\"\n    POSTGRES = \"postgres\"\n    MYSQL = \"mysql\"\n    MONGODB = \"mongodb\"\n    REDIS = \"redis\"\n\n\nclass DatabaseSize(str, Enum):\n    \"\"\"Supported database sizes.\"\"\"\n    SMALL = \"small\"\n    MEDIUM = \"medium\"\n    LARGE = \"large\"\n    XLARGE = \"xlarge\"\n\n\n@dataclass\nclass DatabaseConfig:\n    \"\"\"Database configuration.\"\"\"\n    name: str\n    engine: str\n    size: str\n    version: Optional[str] = None\n    backup_enabled: bool = True\n    tags: Optional[Dict[str, str]] = None\n\n    def validate(self) -> None:\n        \"\"\"Validate configuration.\"\"\"\n        if not self.name:\n            raise ValueError(\"Database name is required\")\n        \n        if len(self.name) < 3 or len(self.name) > 63:\n            raise ValueError(\"Database name must be between 3 and 63 characters\")\n        \n        if not self.name.replace(\"-\", \"\").replace(\"_\", \"\").isalnum():\n            raise ValueError(\"Database name must be alphanumeric with hyphens or underscores\")\n        \n        try:\n            DatabaseEngine(self.engine)\n        except ValueError:\n            valid_engines = [e.value for e in DatabaseEngine]\n            raise ValueError(f\"Invalid engine. Must be one of: {valid_engines}\")\n        \n        try:\n            DatabaseSize(self.size)\n        except ValueError:\n            valid_sizes = [s.value for s in DatabaseSize]\n            raise ValueError(f\"Invalid size. Must be one of: {valid_sizes}\")\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {k: v for k, v in asdict(self).items() if v is not None}\n\n\n@dataclass\nclass DatabaseState:\n    \"\"\"Database state.\"\"\"\n    id: str\n    name: str\n    engine: str\n    size: str\n    version: Optional[str] = None\n    status: str = \"creating\"\n    endpoint: Optional[str] = None\n    port: Optional[int] = None\n    backup_enabled: bool = True\n    tags: Optional[Dict[str, str]] = None\n    created_at: Optional[str] = None\n    updated_at: Optional[str] = None\n\n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary.\"\"\"\n        return {k: v for k, v in asdict(self).items() if v is not None}\n\n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'DatabaseState':\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(**{k: v for k, v in data.items() if k in cls.__annotations__})\n```\n\n### 2. exceptions.py - Custom Exceptions\n\n```python\n\"\"\"\nCustom exceptions for the database provider.\n\"\"\"\n\n\nclass DatabaseProviderError(Exception):\n    \"\"\"Base exception for database provider errors.\"\"\"\n    pass\n\n\nclass DatabaseNotFoundError(DatabaseProviderError):\n    \"\"\"Raised when database is not found.\"\"\"\n    pass\n\n\nclass DatabaseAlreadyExistsError(DatabaseProviderError):\n    \"\"\"Raised when database already exists.\"\"\"\n    pass\n\n\nclass DatabaseValidationError(DatabaseProviderError):\n    \"\"\"Raised when database configuration is invalid.\"\"\"\n    pass\n\n\nclass DatabaseOperationError(DatabaseProviderError):\n    \"\"\"Raised when database operation fails.\"\"\"\n    pass\n\n\nclass DatabaseTimeoutError(DatabaseProviderError):\n    \"\"\"Raised when database operation times out.\"\"\"\n    pass\n```\n\n### 3. client.py - Mock Database API Client\n\n```python\n\"\"\"\nMock database API client for demonstration.\nIn production, this would interact with a real API.\n\"\"\"\nimport time\nimport uuid\nfrom typing import Dict, Optional, List\nfrom datetime import datetime\nfrom .models import DatabaseConfig, DatabaseState\nfrom .exceptions import (\n    DatabaseNotFoundError,\n    DatabaseAlreadyExistsError,\n    DatabaseOperationError,\n    DatabaseTimeoutError\n)\n\n\nclass DatabaseClient:\n    \"\"\"Mock database API client.\"\"\"\n    \n    def __init__(self, api_endpoint: str = \"https://api.example.com\", \n                 api_key: Optional[str] = None):\n        \"\"\"Initialize the client.\"\"\"\n        self.api_endpoint = api_endpoint\n        self.api_key = api_key\n        # In-memory storage for demo (would be real API in production)\n        self._databases: Dict[str, DatabaseState] = {}\n    \n    def create_database(self, config: DatabaseConfig) -> DatabaseState:\n        \"\"\"Create a new database.\"\"\"\n        # Check if database already exists\n        existing = self._find_by_name(config.name)\n        if existing:\n            raise DatabaseAlreadyExistsError(\n                f\"Database with name '{config.name}' already exists\"\n            )\n        \n        # Generate database ID\n        db_id = str(uuid.uuid4())\n        \n        # Determine version based on engine\n        version = config.version or self._get_default_version(config.engine)\n        \n        # Create database state\n        state = DatabaseState(\n            id=db_id,\n            name=config.name,\n            engine=config.engine,\n            size=config.size,\n            version=version,\n            status=\"creating\",\n            endpoint=None,\n            port=self._get_default_port(config.engine),\n            backup_enabled=config.backup_enabled,\n            tags=config.tags,\n            created_at=datetime.utcnow().isoformat(),\n            updated_at=datetime.utcnow().isoformat()\n        )\n        \n        # Store database\n        self._databases[db_id] = state\n        \n        # Simulate async creation\n        self._simulate_creation(db_id)\n        \n        return state\n    \n    def get_database(self, db_id: str) -> DatabaseState:\n        \"\"\"Get database by ID.\"\"\"\n        if db_id not in self._databases:\n            raise DatabaseNotFoundError(f\"Database with ID '{db_id}' not found\")\n        \n        return self._databases[db_id]\n    \n    def update_database(self, db_id: str, config: DatabaseConfig) -> DatabaseState:\n        \"\"\"Update an existing database.\"\"\"\n        if db_id not in self._databases:\n            raise DatabaseNotFoundError(f\"Database with ID '{db_id}' not found\")\n        \n        state = self._databases[db_id]\n        \n        # Check if name change conflicts with existing database\n        if config.name != state.name:\n            existing = self._find_by_name(config.name)\n            if existing and existing.id != db_id:\n                raise DatabaseAlreadyExistsError(\n                    f\"Database with name '{config.name}' already exists\"\n                )\n        \n        # Update mutable fields\n        state.name = config.name\n        state.size = config.size\n        state.backup_enabled = config.backup_enabled\n        state.tags = config.tags\n        state.updated_at = datetime.utcnow().isoformat()\n        \n        # Engine changes require recreation (handled by Pulumi)\n        if config.engine != state.engine:\n            raise DatabaseOperationError(\n                \"Engine cannot be changed. Resource must be recreated.\"\n            )\n        \n        # Simulate update operation\n        state.status = \"updating\"\n        self._databases[db_id] = state\n        time.sleep(0.1)  # Simulate API delay\n        state.status = \"available\"\n        \n        return state\n    \n    def delete_database(self, db_id: str) -> None:\n        \"\"\"Delete a database.\"\"\"\n        if db_id not in self._databases:\n            raise DatabaseNotFoundError(f\"Database with ID '{db_id}' not found\")\n        \n        state = self._databases[db_id]\n        state.status = \"deleting\"\n        \n        # Simulate deletion\n        time.sleep(0.1)  # Simulate API delay\n        del self._databases[db_id]\n    \n    def list_databases(self) -> List[DatabaseState]:\n        \"\"\"List all databases.\"\"\"\n        return list(self._databases.values())\n    \n    def wait_for_status(self, db_id: str, target_status: str, \n                       timeout: int = 300) -> DatabaseState:\n        \"\"\"Wait for database to reach target status.\"\"\"\n        start_time = time.time()\n        \n        while time.time() - start_time < timeout:\n            state = self.get_database(db_id)\n            \n            if state.status == target_status:\n                return state\n            \n            if state.status == \"failed\":\n                raise DatabaseOperationError(\n                    f\"Database '{db_id}' entered failed state\"\n                )\n            \n            time.sleep(1)\n        \n        raise DatabaseTimeoutError(\n            f\"Timeout waiting for database '{db_id}' to reach status '{target_status}'\"\n        )\n    \n    def _find_by_name(self, name: str) -> Optional[DatabaseState]:\n        \"\"\"Find database by name.\"\"\"\n        for state in self._databases.values():\n            if state.name == name:\n                return state\n        return None\n    \n    def _simulate_creation(self, db_id: str) -> None:\n        \"\"\"Simulate async database creation.\"\"\"\n        # In real implementation, this would be handled by the API\n        time.sleep(0.1)  # Simulate API delay\n        \n        state = self._databases[db_id]\n        state.status = \"available\"\n        state.endpoint = f\"{state.name}.db.example.com\"\n    \n    @staticmethod\n    def _get_default_version(engine: str) -> str:\n        \"\"\"Get default version for engine.\"\"\"\n        versions = {\n            \"postgres\": \"14.5\",\n            \"mysql\": \"8.0\",\n            \"mongodb\": \"6.0\",\n            \"redis\": \"7.0\"\n        }\n        return versions.get(engine, \"latest\")\n    \n    @staticmethod\n    def _get_default_port(engine: str) -> int:\n        \"\"\"Get default port for engine.\"\"\"\n        ports = {\n            \"postgres\": 5432,\n            \"mysql\": 3306,\n            \"mongodb\": 27017,\n            \"redis\": 6379\n        }\n        return ports.get(engine, 5432)\n```\n\n### 4. database_provider.py - Dynamic Provider Implementation\n\n```python\n\"\"\"\nPulumi dynamic provider for custom database service.\n\"\"\"\nfrom typing import Any, Optional\nfrom pulumi import ResourceOptions\nfrom pulumi.dynamic import Resource, ResourceProvider, CreateResult, UpdateResult\nimport pulumi\n\nfrom .models import DatabaseConfig, DatabaseState\nfrom .client import DatabaseClient\nfrom .exceptions import (\n    DatabaseProviderError,\n    DatabaseNotFoundError,\n    DatabaseValidationError\n)\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"Dynamic provider for database resources.\"\"\"\n    \n    def __init__(self, client: Optional[DatabaseClient] = None):\n        \"\"\"Initialize the provider.\"\"\"\n        self.client = client or DatabaseClient()\n        super().__init__()\n    \n    def create(self, props: dict) -> CreateResult:\n        \"\"\"\n        Create a new database.\n        \n        Args:\n            props: Resource properties\n            \n        Returns:\n            CreateResult with database ID and outputs\n        \"\"\"\n        try:\n            # Validate and create configuration\n            config = self._create_config(props)\n            config.validate()\n            \n            # Create database\n            pulumi.log.info(f\"Creating database: {config.name}\")\n            state = self.client.create_database(config)\n            \n            # Wait for database to be available\n            pulumi.log.info(f\"Waiting for database {state.id} to be available\")\n            state = self.client.wait_for_status(state.id, \"available\")\n            \n            pulumi.log.info(f\"Database {state.id} created successfully\")\n            \n            # Return result\n            return CreateResult(\n                id_=state.id,\n                outs=self._state_to_outputs(state)\n            )\n            \n        except DatabaseValidationError as e:\n            pulumi.log.error(f\"Validation error: {e}\")\n            raise\n        except DatabaseProviderError as e:\n            pulumi.log.error(f\"Provider error: {e}\")\n            raise\n        except Exception as e:\n            pulumi.log.error(f\"Unexpected error during create: {e}\")\n            raise DatabaseProviderError(f\"Failed to create database: {e}\")\n    \n    def read(self, id_: str, props: dict) -> dict:\n        \"\"\"\n        Read database state.\n        \n        Args:\n            id_: Database ID\n            props: Current properties\n            \n        Returns:\n            Dictionary of current outputs\n        \"\"\"\n        try:\n            pulumi.log.info(f\"Reading database: {id_}\")\n            state = self.client.get_database(id_)\n            return self._state_to_outputs(state)\n            \n        except DatabaseNotFoundError:\n            pulumi.log.warn(f\"Database {id_} not found\")\n            return {}\n        except Exception as e:\n            pulumi.log.error(f\"Error reading database {id_}: {e}\")\n            raise DatabaseProviderError(f\"Failed to read database: {e}\")\n    \n    def update(self, id_: str, old_props: dict, new_props: dict) -> UpdateResult:\n        \"\"\"\n        Update an existing database.\n        \n        Args:\n            id_: Database ID\n            old_props: Previous properties\n            new_props: New properties\n            \n        Returns:\n            UpdateResult with updated outputs\n        \"\"\"\n        try:\n            # Validate and create configuration\n            config = self._create_config(new_props)\n            config.validate()\n            \n            pulumi.log.info(f\"Updating database: {id_}\")\n            \n            # Check if engine changed (requires replacement)\n            if old_props.get(\"engine\") != new_props.get(\"engine\"):\n                raise DatabaseProviderError(\n                    \"Engine cannot be changed. Resource must be recreated.\"\n                )\n            \n            # Update database\n            state = self.client.update_database(id_, config)\n            \n            # Wait for update to complete\n            pulumi.log.info(f\"Waiting for database {id_} update to complete\")\n            state = self.client.wait_for_status(id_, \"available\")\n            \n            pulumi.log.info(f\"Database {id_} updated successfully\")\n            \n            # Return result\n            return UpdateResult(outs=self._state_to_outputs(state))\n            \n        except DatabaseProviderError as e:\n            pulumi.log.error(f\"Provider error: {e}\")\n            raise\n        except Exception as e:\n            pulumi.log.error(f\"Unexpected error during update: {e}\")\n            raise DatabaseProviderError(f\"Failed to update database: {e}\")\n    \n    def delete(self, id_: str, props: dict) -> None:\n        \"\"\"\n        Delete a database.\n        \n        Args:\n            id_: Database ID\n            props: Current properties\n        \"\"\"\n        try:\n            pulumi.log.info(f\"Deleting database: {id_}\")\n            self.client.delete_database(id_)\n            pulumi.log.info(f\"Database {id_} deleted successfully\")\n            \n        except DatabaseNotFoundError:\n            pulumi.log.warn(f\"Database {id_} not found, considering deleted\")\n        except Exception as e:\n            pulumi.log.error(f\"Error deleting database {id_}: {e}\")\n            raise DatabaseProviderError(f\"Failed to delete database: {e}\")\n    \n    @staticmethod\n    def _create_config(props: dict) -> DatabaseConfig:\n        \"\"\"Create DatabaseConfig from properties.\"\"\"\n        return DatabaseConfig(\n            name=props.get(\"name\"),",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4779,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a Python Pulumi dynamic provider for a custom database service with full CRUD operations.\n\n```python\n# pulumi_provider/database_provider.py\n\"\"\"Pulumi dynamic provider for custom database service.\"\"\"\nimport logging\nfrom typing import Any, Optional\nfrom pulumi import Input, Output, ResourceOptions\nfrom pulumi.dynamic import Resource, ResourceProvider, CreateResult, UpdateResult\n\nlogger = logging.getLogger(__name__)\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"Dynamic provider implementing CRUD operations for database resources.\"\"\"\n\n    def __init__(self, api_client: Optional[Any] = None):\n        \"\"\"\n        Initialize the database provider.\n        \n        Args:\n            api_client: Optional API client for making requests to the database service.\n                       If None, uses a mock implementation for testing.\n        \"\"\"\n        self.api_client = api_client or MockDatabaseClient()\n\n    def create(self, props: dict) -> CreateResult:\n        \"\"\"\n        Create a new database resource.\n        \n        Args:\n            props: Resource properties including name, engine, and size.\n            \n        Returns:\n            CreateResult with the resource ID and output properties.\n        \"\"\"\n        try:\n            name = props.get(\"name\")\n            engine = props.get(\"engine\", \"postgres\")\n            size = props.get(\"size\", \"small\")\n            \n            logger.info(f\"Creating database: name={name}, engine={engine}, size={size}\")\n            \n            # Validate inputs\n            self._validate_props(props)\n            \n            # Create database via API\n            result = self.api_client.create_database(\n                name=name,\n                engine=engine,\n                size=size\n            )\n            \n            # Return the ID and all outputs\n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"status\": result[\"status\"],\n                \"endpoint\": result[\"endpoint\"],\n                \"port\": result[\"port\"],\n                \"created_at\": result[\"created_at\"],\n            }\n            \n            logger.info(f\"Database created successfully: id={result['id']}\")\n            return CreateResult(id_=result[\"id\"], outs=outputs)\n            \n        except Exception as e:\n            logger.error(f\"Failed to create database: {e}\")\n            raise\n\n    def read(self, id_: str, props: dict) -> dict:\n        \"\"\"\n        Read the current state of a database resource.\n        \n        Args:\n            id_: The resource ID.\n            props: Current resource properties.\n            \n        Returns:\n            Dictionary of current resource properties.\n        \"\"\"\n        try:\n            logger.info(f\"Reading database: id={id_}\")\n            \n            # Fetch current state from API\n            result = self.api_client.get_database(id_)\n            \n            if result is None:\n                logger.warning(f\"Database not found: id={id_}\")\n                return {}\n            \n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"status\": result[\"status\"],\n                \"endpoint\": result[\"endpoint\"],\n                \"port\": result[\"port\"],\n                \"created_at\": result[\"created_at\"],\n            }\n            \n            return outputs\n            \n        except Exception as e:\n            logger.error(f\"Failed to read database {id_}: {e}\")\n            raise\n\n    def update(self, id_: str, old_props: dict, new_props: dict) -> UpdateResult:\n        \"\"\"\n        Update an existing database resource.\n        \n        Args:\n            id_: The resource ID.\n            old_props: Previous resource properties.\n            new_props: New resource properties.\n            \n        Returns:\n            UpdateResult with updated output properties.\n        \"\"\"\n        try:\n            logger.info(f\"Updating database: id={id_}\")\n            \n            # Validate new properties\n            self._validate_props(new_props)\n            \n            # Check what changed\n            changes = {}\n            if new_props.get(\"size\") != old_props.get(\"size\"):\n                changes[\"size\"] = new_props[\"size\"]\n            \n            # Note: name and engine typically require replacement\n            if new_props.get(\"name\") != old_props.get(\"name\"):\n                logger.warning(\"Database name change requires replacement\")\n                raise ValueError(\"Cannot change database name - requires replacement\")\n            \n            if new_props.get(\"engine\") != old_props.get(\"engine\"):\n                logger.warning(\"Database engine change requires replacement\")\n                raise ValueError(\"Cannot change database engine - requires replacement\")\n            \n            if not changes:\n                logger.info(\"No changes detected\")\n                return UpdateResult(outs=old_props)\n            \n            # Update database via API\n            result = self.api_client.update_database(id_, **changes)\n            \n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"status\": result[\"status\"],\n                \"endpoint\": result[\"endpoint\"],\n                \"port\": result[\"port\"],\n                \"created_at\": result[\"created_at\"],\n            }\n            \n            logger.info(f\"Database updated successfully: id={id_}\")\n            return UpdateResult(outs=outputs)\n            \n        except Exception as e:\n            logger.error(f\"Failed to update database {id_}: {e}\")\n            raise\n\n    def delete(self, id_: str, props: dict) -> None:\n        \"\"\"\n        Delete a database resource.\n        \n        Args:\n            id_: The resource ID.\n            props: Current resource properties.\n        \"\"\"\n        try:\n            logger.info(f\"Deleting database: id={id_}\")\n            \n            # Delete database via API\n            self.api_client.delete_database(id_)\n            \n            logger.info(f\"Database deleted successfully: id={id_}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to delete database {id_}: {e}\")\n            raise\n\n    def _validate_props(self, props: dict) -> None:\n        \"\"\"\n        Validate resource properties.\n        \n        Args:\n            props: Properties to validate.\n            \n        Raises:\n            ValueError: If validation fails.\n        \"\"\"\n        name = props.get(\"name\")\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Database name is required and must be a string\")\n        \n        if len(name) < 3 or len(name) > 63:\n            raise ValueError(\"Database name must be between 3 and 63 characters\")\n        \n        if not name.replace(\"-\", \"\").replace(\"_\", \"\").isalnum():\n            raise ValueError(\"Database name must be alphanumeric with hyphens or underscores\")\n        \n        engine = props.get(\"engine\", \"postgres\")\n        valid_engines = [\"postgres\", \"mysql\", \"mongodb\", \"redis\"]\n        if engine not in valid_engines:\n            raise ValueError(f\"Invalid engine. Must be one of: {', '.join(valid_engines)}\")\n        \n        size = props.get(\"size\", \"small\")\n        valid_sizes = [\"small\", \"medium\", \"large\", \"xlarge\"]\n        if size not in valid_sizes:\n            raise ValueError(f\"Invalid size. Must be one of: {', '.join(valid_sizes)}\")\n\n\nclass MockDatabaseClient:\n    \"\"\"Mock database client for testing without real API.\"\"\"\n    \n    def __init__(self):\n        self._databases = {}\n        self._next_id = 1\n    \n    def create_database(self, name: str, engine: str, size: str) -> dict:\n        \"\"\"Create a mock database.\"\"\"\n        import time\n        \n        db_id = f\"db-{self._next_id:06d}\"\n        self._next_id += 1\n        \n        database = {\n            \"id\": db_id,\n            \"name\": name,\n            \"engine\": engine,\n            \"size\": size,\n            \"status\": \"active\",\n            \"endpoint\": f\"{name}.database.local\",\n            \"port\": 5432 if engine == \"postgres\" else 3306,\n            \"created_at\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\"),\n        }\n        \n        self._databases[db_id] = database\n        return database\n    \n    def get_database(self, db_id: str) -> Optional[dict]:\n        \"\"\"Get a mock database.\"\"\"\n        return self._databases.get(db_id)\n    \n    def update_database(self, db_id: str, **kwargs) -> dict:\n        \"\"\"Update a mock database.\"\"\"\n        if db_id not in self._databases:\n            raise ValueError(f\"Database not found: {db_id}\")\n        \n        database = self._databases[db_id]\n        database.update(kwargs)\n        database[\"status\"] = \"active\"\n        return database\n    \n    def delete_database(self, db_id: str) -> None:\n        \"\"\"Delete a mock database.\"\"\"\n        if db_id in self._databases:\n            del self._databases[db_id]\n\n\nclass Database(Resource):\n    \"\"\"\n    A Pulumi resource representing a custom database.\n    \n    Example usage:\n        db = Database(\n            \"my-database\",\n            name=\"myapp-db\",\n            engine=\"postgres\",\n            size=\"medium\"\n        )\n        \n        pulumi.export(\"endpoint\", db.endpoint)\n        pulumi.export(\"port\", db.port)\n    \"\"\"\n    \n    name: Output[str]\n    \"\"\"The name of the database.\"\"\"\n    \n    engine: Output[str]\n    \"\"\"The database engine (postgres, mysql, mongodb, redis).\"\"\"\n    \n    size: Output[str]\n    \"\"\"The database size (small, medium, large, xlarge).\"\"\"\n    \n    status: Output[str]\n    \"\"\"The current status of the database.\"\"\"\n    \n    endpoint: Output[str]\n    \"\"\"The connection endpoint for the database.\"\"\"\n    \n    port: Output[int]\n    \"\"\"The connection port for the database.\"\"\"\n    \n    created_at: Output[str]\n    \"\"\"The timestamp when the database was created.\"\"\"\n    \n    def __init__(\n        self,\n        resource_name: str,\n        name: Input[str],\n        engine: Input[str] = \"postgres\",\n        size: Input[str] = \"small\",\n        opts: Optional[ResourceOptions] = None,\n        api_client: Optional[Any] = None,\n    ):\n        \"\"\"\n        Create a new Database resource.\n        \n        Args:\n            resource_name: The Pulumi resource name.\n            name: The database name.\n            engine: The database engine (default: postgres).\n            size: The database size (default: small).\n            opts: Resource options.\n            api_client: Optional API client for the database service.\n        \"\"\"\n        props = {\n            \"name\": name,\n            \"engine\": engine,\n            \"size\": size,\n        }\n        \n        provider = DatabaseProvider(api_client)\n        \n        super().__init__(\n            provider,\n            resource_name,\n            props,\n            opts,\n        )\n```\n\n```python\n# pulumi_provider/__init__.py\n\"\"\"Pulumi provider for custom database service.\"\"\"\nfrom .database_provider import Database, DatabaseProvider, MockDatabaseClient\n\n__all__ = [\"Database\", \"DatabaseProvider\", \"MockDatabaseClient\"]\n```\n\n```python\n# tests/test_database_provider.py\n\"\"\"Tests for the database provider.\"\"\"\nimport pytest\nfrom pulumi_provider import Database, DatabaseProvider, MockDatabaseClient\n\n\nclass TestDatabaseProvider:\n    \"\"\"Test suite for DatabaseProvider.\"\"\"\n    \n    def test_create_database(self):\n        \"\"\"Test creating a database.\"\"\"\n        provider = DatabaseProvider()\n        \n        props = {\n            \"name\": \"test-db\",\n            \"engine\": \"postgres\",\n            \"size\": \"medium\",\n        }\n        \n        result = provider.create(props)\n        \n        assert result.id_.startswith(\"db-\")\n        assert result.outs[\"name\"] == \"test-db\"\n        assert result.outs[\"engine\"] == \"postgres\"\n        assert result.outs[\"size\"] == \"medium\"\n        assert result.outs[\"status\"] == \"active\"\n        assert \"endpoint\" in result.outs\n        assert \"port\" in result.outs\n    \n    def test_read_database(self):\n        \"\"\"Test reading a database.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create first\n        props = {\"name\": \"test-db\", \"engine\": \"mysql\", \"size\": \"small\"}\n        create_result = provider.create(props)\n        \n        # Then read\n        read_result = provider.read(create_result.id_, props)\n        \n        assert read_result[\"name\"] == \"test-db\"\n        assert read_result[\"engine\"] == \"mysql\"\n        assert read_result[\"size\"] == \"small\"\n    \n    def test_update_database_size(self):\n        \"\"\"Test updating database size.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create\n        props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"small\"}\n        create_result = provider.create(props)\n        \n        # Update size\n        new_props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"large\"}\n        update_result = provider.update(create_result.id_, props, new_props)\n        \n        assert update_result.outs[\"size\"] == \"large\"\n        assert update_result.outs[\"name\"] == \"test-db\"\n    \n    def test_update_database_name_fails(self):\n        \"\"\"Test that updating database name fails.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create\n        props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"small\"}\n        create_result = provider.create(props)\n        \n        # Try to update name (should fail)\n        new_props = {\"name\": \"new-name\", \"engine\": \"postgres\", \"size\": \"small\"}\n        \n        with pytest.raises(ValueError, match=\"Cannot change database name\"):\n            provider.update(create_result.id_, props, new_props)\n    \n    def test_update_database_engine_fails(self):\n        \"\"\"Test that updating database engine fails.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create\n        props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"small\"}\n        create_result = provider.create(props)\n        \n        # Try to update engine (should fail)\n        new_props = {\"name\": \"test-db\", \"engine\": \"mysql\", \"size\": \"small\"}\n        \n        with pytest.raises(ValueError, match=\"Cannot change database engine\"):\n            provider.update(create_result.id_, props, new_props)\n    \n    def test_delete_database(self):\n        \"\"\"Test deleting a database.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create\n        props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"small\"}\n        create_result = provider.create(props)\n        \n        # Delete\n        provider.delete(create_result.id_, props)\n        \n        # Verify it's gone\n        read_result = provider.read(create_result.id_, props)\n        assert read_result == {}\n    \n    def test_validate_name_required(self):\n        \"\"\"Test that name is required.\"\"\"\n        provider = DatabaseProvider()\n        \n        props = {\"engine\": \"postgres\", \"size\": \"small\"}\n        \n        with pytest.raises(ValueError, match=\"name is required\"):\n            provider.create(props)\n    \n    def test_validate_name_length(self):\n        \"\"\"Test name length validation.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Too short\n        props = {\"name\": \"ab\", \"engine\": \"postgres\", \"size\": \"small\"}\n        with pytest.raises(ValueError, match=\"between 3 and 63 characters\"):\n            provider.create(props)\n        \n        # Too long\n        props = {\"name\": \"a\" * 64, \"engine\": \"postgres\", \"size\": \"small\"}\n        with pytest.raises(ValueError, match=\"between 3 and 63 characters\"):\n            provider.create(props)\n    \n    def test_validate_name_characters(self):\n        \"\"\"Test name character validation.\"\"\"\n        provider = DatabaseProvider()\n        \n        props = {\"name\": \"test@db!\", \"engine\": \"postgres\", \"size\": \"small\"}\n        \n        with pytest.raises(ValueError, match=\"alphanumeric\"):\n            provider.create(props)\n    \n    def test_validate_engine(self):\n        \"\"\"Test engine validation.\"\"\"\n        provider = DatabaseProvider()\n        \n        props = {\"name\": \"test-db\", \"engine\": \"invalid\", \"size\": \"small\"}\n        \n        with pytest.raises(ValueError, match=\"Invalid engine\"):\n            provider.create(props)\n    \n    def test_validate",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5305,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "# Pulumi Dynamic Provider for Custom Database Service\n\nI'll create a comprehensive Pulumi dynamic provider for managing a custom database service with full CRUD operations.\n\n```python\n# database_provider.py\n\"\"\"\nCustom Pulumi Dynamic Provider for Database Service\nImplements CRUD operations for managing databases\n\"\"\"\n\nimport pulumi\nfrom pulumi import Input, Output, ResourceOptions\nfrom pulumi.dynamic import Resource, ResourceProvider, CreateResult, UpdateResult\nfrom typing import Any, Optional\nimport json\nimport time\nimport uuid\n\n\nclass DatabaseArgs:\n    \"\"\"\n    Arguments for the Database resource\n    \"\"\"\n    def __init__(\n        self,\n        name: Input[str],\n        engine: Input[str],\n        size: Input[str],\n        tags: Optional[Input[dict]] = None\n    ):\n        self.name = name\n        self.engine = engine\n        self.size = size\n        self.tags = tags or {}\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"\n    Dynamic provider implementation for Database resource\n    Simulates a database service with CRUD operations\n    \"\"\"\n    \n    # Simulated database storage (in production, this would be API calls)\n    _databases = {}\n    \n    def create(self, props: dict) -> CreateResult:\n        \"\"\"\n        Create a new database instance\n        \n        Args:\n            props: Dictionary containing database properties\n            \n        Returns:\n            CreateResult with the database ID and outputs\n        \"\"\"\n        pulumi.log.info(f\"Creating database: {props.get('name')}\")\n        \n        # Validate inputs\n        self._validate_props(props)\n        \n        # Generate unique ID for the database\n        db_id = f\"db-{uuid.uuid4().hex[:8]}\"\n        \n        # Simulate database creation (in production, make API call here)\n        database = {\n            'id': db_id,\n            'name': props['name'],\n            'engine': props['engine'],\n            'size': props['size'],\n            'tags': props.get('tags', {}),\n            'status': 'creating',\n            'created_at': time.time(),\n            'endpoint': f\"{props['name']}.{props['engine']}.database.example.com\",\n            'port': self._get_default_port(props['engine'])\n        }\n        \n        # Simulate creation delay\n        time.sleep(1)\n        database['status'] = 'available'\n        \n        # Store in simulated backend\n        self._databases[db_id] = database\n        \n        pulumi.log.info(f\"Database created successfully: {db_id}\")\n        \n        # Return outputs\n        outs = {\n            'id': db_id,\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'tags': database['tags'],\n            'status': database['status'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'created_at': database['created_at']\n        }\n        \n        return CreateResult(id_=db_id, outs=outs)\n    \n    def read(self, id_: str, props: dict) -> dict:\n        \"\"\"\n        Read the current state of a database\n        \n        Args:\n            id_: The database ID\n            props: Current properties\n            \n        Returns:\n            Dictionary with current database state\n        \"\"\"\n        pulumi.log.info(f\"Reading database: {id_}\")\n        \n        # Retrieve from simulated backend\n        database = self._databases.get(id_)\n        \n        if not database:\n            pulumi.log.warn(f\"Database not found: {id_}\")\n            return {}\n        \n        return {\n            'id': database['id'],\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'tags': database['tags'],\n            'status': database['status'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'created_at': database['created_at']\n        }\n    \n    def update(self, id_: str, old_props: dict, new_props: dict) -> UpdateResult:\n        \"\"\"\n        Update an existing database\n        \n        Args:\n            id_: The database ID\n            old_props: Previous properties\n            new_props: New properties\n            \n        Returns:\n            UpdateResult with updated outputs\n        \"\"\"\n        pulumi.log.info(f\"Updating database: {id_}\")\n        \n        # Validate new properties\n        self._validate_props(new_props)\n        \n        # Retrieve existing database\n        database = self._databases.get(id_)\n        \n        if not database:\n            raise Exception(f\"Database not found: {id_}\")\n        \n        # Check what changed\n        changes = self._detect_changes(old_props, new_props)\n        pulumi.log.info(f\"Detected changes: {changes}\")\n        \n        # Handle size changes (simulated resize operation)\n        if 'size' in changes:\n            pulumi.log.info(f\"Resizing database from {old_props['size']} to {new_props['size']}\")\n            database['status'] = 'modifying'\n            time.sleep(1)  # Simulate resize delay\n            database['size'] = new_props['size']\n            database['status'] = 'available'\n        \n        # Handle name changes (requires replacement in some systems)\n        if 'name' in changes:\n            pulumi.log.warn(\"Name change detected - this may require replacement\")\n            database['name'] = new_props['name']\n            database['endpoint'] = f\"{new_props['name']}.{database['engine']}.database.example.com\"\n        \n        # Handle engine changes (typically requires replacement)\n        if 'engine' in changes:\n            pulumi.log.warn(\"Engine change detected - this typically requires replacement\")\n            database['engine'] = new_props['engine']\n            database['endpoint'] = f\"{database['name']}.{new_props['engine']}.database.example.com\"\n            database['port'] = self._get_default_port(new_props['engine'])\n        \n        # Update tags (always safe)\n        if 'tags' in changes:\n            database['tags'] = new_props.get('tags', {})\n        \n        database['updated_at'] = time.time()\n        \n        # Update in simulated backend\n        self._databases[id_] = database\n        \n        pulumi.log.info(f\"Database updated successfully: {id_}\")\n        \n        # Return updated outputs\n        outs = {\n            'id': database['id'],\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'tags': database['tags'],\n            'status': database['status'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'created_at': database['created_at'],\n            'updated_at': database.get('updated_at')\n        }\n        \n        return UpdateResult(outs=outs)\n    \n    def delete(self, id_: str, props: dict) -> None:\n        \"\"\"\n        Delete a database\n        \n        Args:\n            id_: The database ID\n            props: Current properties\n        \"\"\"\n        pulumi.log.info(f\"Deleting database: {id_}\")\n        \n        # Retrieve database\n        database = self._databases.get(id_)\n        \n        if not database:\n            pulumi.log.warn(f\"Database not found (already deleted?): {id_}\")\n            return\n        \n        # Simulate deletion process\n        database['status'] = 'deleting'\n        time.sleep(1)  # Simulate deletion delay\n        \n        # Remove from simulated backend\n        del self._databases[id_]\n        \n        pulumi.log.info(f\"Database deleted successfully: {id_}\")\n    \n    def _validate_props(self, props: dict) -> None:\n        \"\"\"Validate database properties\"\"\"\n        required_fields = ['name', 'engine', 'size']\n        \n        for field in required_fields:\n            if field not in props or not props[field]:\n                raise ValueError(f\"Missing required field: {field}\")\n        \n        # Validate engine\n        valid_engines = ['postgres', 'mysql', 'mongodb', 'redis', 'mariadb']\n        if props['engine'] not in valid_engines:\n            raise ValueError(f\"Invalid engine. Must be one of: {valid_engines}\")\n        \n        # Validate size\n        valid_sizes = ['small', 'medium', 'large', 'xlarge']\n        if props['size'] not in valid_sizes:\n            raise ValueError(f\"Invalid size. Must be one of: {valid_sizes}\")\n    \n    def _detect_changes(self, old_props: dict, new_props: dict) -> list:\n        \"\"\"Detect which properties changed\"\"\"\n        changes = []\n        \n        for key in ['name', 'engine', 'size', 'tags']:\n            if old_props.get(key) != new_props.get(key):\n                changes.append(key)\n        \n        return changes\n    \n    def _get_default_port(self, engine: str) -> int:\n        \"\"\"Get default port for database engine\"\"\"\n        ports = {\n            'postgres': 5432,\n            'mysql': 3306,\n            'mongodb': 27017,\n            'redis': 6379,\n            'mariadb': 3306\n        }\n        return ports.get(engine, 5432)\n\n\nclass Database(Resource):\n    \"\"\"\n    Custom Database resource using dynamic provider\n    \n    Example usage:\n        db = Database(\n            \"my-database\",\n            name=\"myapp-db\",\n            engine=\"postgres\",\n            size=\"medium\",\n            tags={\"environment\": \"production\"}\n        )\n    \"\"\"\n    \n    # Output properties\n    id: Output[str]\n    name: Output[str]\n    engine: Output[str]\n    size: Output[str]\n    tags: Output[dict]\n    status: Output[str]\n    endpoint: Output[str]\n    port: Output[int]\n    created_at: Output[float]\n    \n    def __init__(\n        self,\n        resource_name: str,\n        name: Input[str],\n        engine: Input[str],\n        size: Input[str],\n        tags: Optional[Input[dict]] = None,\n        opts: Optional[ResourceOptions] = None\n    ):\n        \"\"\"\n        Initialize a Database resource\n        \n        Args:\n            resource_name: Pulumi resource name\n            name: Database name\n            engine: Database engine (postgres, mysql, mongodb, redis, mariadb)\n            size: Database size (small, medium, large, xlarge)\n            tags: Optional tags dictionary\n            opts: Resource options\n        \"\"\"\n        # Prepare properties\n        props = {\n            'name': name,\n            'engine': engine,\n            'size': size,\n            'tags': tags or {}\n        }\n        \n        # Initialize the dynamic resource\n        super().__init__(\n            DatabaseProvider(),\n            resource_name,\n            props,\n            opts\n        )\n\n\n# Example helper function to export database connection info\ndef get_connection_string(db: Database, username: str, password: str) -> Output[str]:\n    \"\"\"\n    Generate a connection string for the database\n    \n    Args:\n        db: Database resource\n        username: Database username\n        password: Database password\n        \n    Returns:\n        Connection string output\n    \"\"\"\n    return Output.all(db.engine, db.endpoint, db.port, db.name).apply(\n        lambda args: f\"{args[0]}://{username}:{password}@{args[1]}:{args[2]}/{args[3]}\"\n    )\n```\n\n```python\n# __main__.py\n\"\"\"\nExample Pulumi program using the custom Database provider\n\"\"\"\n\nimport pulumi\nfrom database_provider import Database, get_connection_string\n\n# Configuration\nconfig = pulumi.Config()\ndb_username = config.require(\"db_username\")\ndb_password = config.require_secret(\"db_password\")\n\n# Create a PostgreSQL database\npostgres_db = Database(\n    \"postgres-db\",\n    name=\"myapp-postgres\",\n    engine=\"postgres\",\n    size=\"medium\",\n    tags={\n        \"environment\": \"production\",\n        \"team\": \"backend\",\n        \"cost-center\": \"engineering\"\n    }\n)\n\n# Create a Redis cache\nredis_cache = Database(\n    \"redis-cache\",\n    name=\"myapp-cache\",\n    engine=\"redis\",\n    size=\"small\",\n    tags={\n        \"environment\": \"production\",\n        \"team\": \"backend\"\n    }\n)\n\n# Create a MongoDB database\nmongo_db = Database(\n    \"mongo-db\",\n    name=\"myapp-mongo\",\n    engine=\"mongodb\",\n    size=\"large\",\n    tags={\n        \"environment\": \"production\",\n        \"team\": \"data\"\n    }\n)\n\n# Generate connection strings\npostgres_connection = get_connection_string(postgres_db, db_username, db_password)\nredis_connection = get_connection_string(redis_cache, db_username, db_password)\n\n# Export outputs\npulumi.export(\"postgres_id\", postgres_db.id)\npulumi.export(\"postgres_endpoint\", postgres_db.endpoint)\npulumi.export(\"postgres_port\", postgres_db.port)\npulumi.export(\"postgres_status\", postgres_db.status)\npulumi.export(\"postgres_connection\", postgres_connection)\n\npulumi.export(\"redis_id\", redis_cache.id)\npulumi.export(\"redis_endpoint\", redis_cache.endpoint)\npulumi.export(\"redis_connection\", redis_connection)\n\npulumi.export(\"mongo_id\", mongo_db.id)\npulumi.export(\"mongo_endpoint\", mongo_db.endpoint)\n```\n\n```python\n# test_database_provider.py\n\"\"\"\nUnit tests for the Database provider\n\"\"\"\n\nimport unittest\nfrom unittest.mock import patch, MagicMock\nfrom database_provider import DatabaseProvider, DatabaseArgs\nimport time\n\n\nclass TestDatabaseProvider(unittest.TestCase):\n    \"\"\"Test cases for DatabaseProvider\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures\"\"\"\n        self.provider = DatabaseProvider()\n        self.provider._databases = {}  # Reset database storage\n    \n    def test_create_database(self):\n        \"\"\"Test database creation\"\"\"\n        props = {\n            'name': 'test-db',\n            'engine': 'postgres',\n            'size': 'medium',\n            'tags': {'env': 'test'}\n        }\n        \n        result = self.provider.create(props)\n        \n        self.assertIsNotNone(result.id)\n        self.assertEqual(result.outs['name'], 'test-db')\n        self.assertEqual(result.outs['engine'], 'postgres')\n        self.assertEqual(result.outs['size'], 'medium')\n        self.assertEqual(result.outs['status'], 'available')\n        self.assertIn('endpoint', result.outs)\n        self.assertEqual(result.outs['port'], 5432)\n    \n    def test_create_invalid_engine(self):\n        \"\"\"Test creation with invalid engine\"\"\"\n        props = {\n            'name': 'test-db',\n            'engine': 'invalid-engine',\n            'size': 'medium'\n        }\n        \n        with self.assertRaises(ValueError) as context:\n            self.provider.create(props)\n        \n        self.assertIn('Invalid engine', str(context.exception))\n    \n    def test_create_invalid_size(self):\n        \"\"\"Test creation with invalid size\"\"\"\n        props = {\n            'name': 'test-db',\n            'engine': 'postgres',\n            'size': 'invalid-size'\n        }\n        \n        with self.assertRaises(ValueError) as context:\n            self.provider.create(props)\n        \n        self.assertIn('Invalid size', str(context.exception))\n    \n    def test_read_database(self):\n        \"\"\"Test reading database state\"\"\"\n        # Create a database first\n        props = {\n            'name': 'test-db',\n            'engine': 'mysql',\n            'size': 'small'\n        }\n        \n        result = self.provider.create(props)\n        db_id = result.id\n        \n        # Read the database\n        read_result = self.provider.read(db_id, props)\n        \n        self.assertEqual(read_result['id'], db_id)\n        self.assertEqual(read_result['name'], 'test-db')\n        self.assertEqual(read_result['engine'], 'mysql')\n        self.assertEqual(read_result['port'], 3306)\n    \n    def test_read_nonexistent_database(self):\n        \"\"\"Test reading non-existent database\"\"\"\n        result",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 60,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# Custom Database Service Pulumi Provider\n\nI'll create a comprehensive Python Pulumi dynamic provider for a custom database service with full CRUD operations, proper error handling, and testing.\n\n## Project Structure\n\n```\npulumi-database-provider/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 database_provider.py      # Main provider implementation\n\u251c\u2500\u2500 database_resource.py      # Resource definition\n\u251c\u2500\u2500 api_client.py            # Mock API client\n\u251c\u2500\u2500 exceptions.py            # Custom exceptions\n\u251c\u2500\u2500 validators.py            # Input validation\n\u251c\u2500\u2500 __main__.py              # Example usage\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 test_provider.py\n\u2502   \u2514\u2500\u2500 test_resource.py\n\u251c\u2500\u2500 Pulumi.yaml\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 README.md\n```\n\n## Implementation\n\n### 1. Custom Exceptions (`exceptions.py`)\n\n```python\n\"\"\"Custom exceptions for the database provider.\"\"\"\n\n\nclass DatabaseProviderError(Exception):\n    \"\"\"Base exception for database provider errors.\"\"\"\n    pass\n\n\nclass DatabaseNotFoundError(DatabaseProviderError):\n    \"\"\"Raised when a database is not found.\"\"\"\n    pass\n\n\nclass DatabaseAlreadyExistsError(DatabaseProviderError):\n    \"\"\"Raised when attempting to create a database that already exists.\"\"\"\n    pass\n\n\nclass InvalidDatabaseConfigError(DatabaseProviderError):\n    \"\"\"Raised when database configuration is invalid.\"\"\"\n    pass\n\n\nclass DatabaseOperationError(DatabaseProviderError):\n    \"\"\"Raised when a database operation fails.\"\"\"\n    pass\n\n\nclass ValidationError(DatabaseProviderError):\n    \"\"\"Raised when input validation fails.\"\"\"\n    pass\n```\n\n### 2. Input Validators (`validators.py`)\n\n```python\n\"\"\"Input validation for database resources.\"\"\"\nimport re\nfrom typing import Any, Dict, List\nfrom .exceptions import ValidationError\n\n\nclass DatabaseValidator:\n    \"\"\"Validates database resource inputs.\"\"\"\n    \n    VALID_ENGINES = [\"mysql\", \"postgresql\", \"mongodb\", \"redis\"]\n    VALID_SIZES = [\"small\", \"medium\", \"large\", \"xlarge\"]\n    \n    NAME_PATTERN = re.compile(r'^[a-z0-9]([a-z0-9-]*[a-z0-9])?$')\n    MIN_NAME_LENGTH = 3\n    MAX_NAME_LENGTH = 63\n    \n    @classmethod\n    def validate_name(cls, name: str) -> None:\n        \"\"\"Validate database name.\n        \n        Args:\n            name: Database name to validate\n            \n        Raises:\n            ValidationError: If name is invalid\n        \"\"\"\n        if not isinstance(name, str):\n            raise ValidationError(\"Database name must be a string\")\n        \n        if len(name) < cls.MIN_NAME_LENGTH:\n            raise ValidationError(\n                f\"Database name must be at least {cls.MIN_NAME_LENGTH} characters\"\n            )\n        \n        if len(name) > cls.MAX_NAME_LENGTH:\n            raise ValidationError(\n                f\"Database name must not exceed {cls.MAX_NAME_LENGTH} characters\"\n            )\n        \n        if not cls.NAME_PATTERN.match(name):\n            raise ValidationError(\n                \"Database name must start and end with alphanumeric characters \"\n                \"and contain only lowercase letters, numbers, and hyphens\"\n            )\n    \n    @classmethod\n    def validate_engine(cls, engine: str) -> None:\n        \"\"\"Validate database engine.\n        \n        Args:\n            engine: Database engine to validate\n            \n        Raises:\n            ValidationError: If engine is invalid\n        \"\"\"\n        if not isinstance(engine, str):\n            raise ValidationError(\"Database engine must be a string\")\n        \n        if engine.lower() not in cls.VALID_ENGINES:\n            raise ValidationError(\n                f\"Invalid database engine '{engine}'. \"\n                f\"Valid engines: {', '.join(cls.VALID_ENGINES)}\"\n            )\n    \n    @classmethod\n    def validate_size(cls, size: str) -> None:\n        \"\"\"Validate database size.\n        \n        Args:\n            size: Database size to validate\n            \n        Raises:\n            ValidationError: If size is invalid\n        \"\"\"\n        if not isinstance(size, str):\n            raise ValidationError(\"Database size must be a string\")\n        \n        if size.lower() not in cls.VALID_SIZES:\n            raise ValidationError(\n                f\"Invalid database size '{size}'. \"\n                f\"Valid sizes: {', '.join(cls.VALID_SIZES)}\"\n            )\n    \n    @classmethod\n    def validate_tags(cls, tags: Dict[str, str]) -> None:\n        \"\"\"Validate database tags.\n        \n        Args:\n            tags: Tags dictionary to validate\n            \n        Raises:\n            ValidationError: If tags are invalid\n        \"\"\"\n        if not isinstance(tags, dict):\n            raise ValidationError(\"Tags must be a dictionary\")\n        \n        for key, value in tags.items():\n            if not isinstance(key, str) or not isinstance(value, str):\n                raise ValidationError(\"Tag keys and values must be strings\")\n            \n            if len(key) > 128:\n                raise ValidationError(\"Tag keys must not exceed 128 characters\")\n            \n            if len(value) > 256:\n                raise ValidationError(\"Tag values must not exceed 256 characters\")\n    \n    @classmethod\n    def validate_inputs(cls, inputs: Dict[str, Any]) -> None:\n        \"\"\"Validate all database inputs.\n        \n        Args:\n            inputs: Dictionary of inputs to validate\n            \n        Raises:\n            ValidationError: If any input is invalid\n        \"\"\"\n        # Required fields\n        if \"name\" not in inputs:\n            raise ValidationError(\"Database name is required\")\n        cls.validate_name(inputs[\"name\"])\n        \n        if \"engine\" not in inputs:\n            raise ValidationError(\"Database engine is required\")\n        cls.validate_engine(inputs[\"engine\"])\n        \n        if \"size\" not in inputs:\n            raise ValidationError(\"Database size is required\")\n        cls.validate_size(inputs[\"size\"])\n        \n        # Optional fields\n        if \"tags\" in inputs:\n            cls.validate_tags(inputs[\"tags\"])\n```\n\n### 3. Mock API Client (`api_client.py`)\n\n```python\n\"\"\"Mock API client for database operations.\"\"\"\nimport time\nimport uuid\nfrom typing import Dict, List, Optional, Any\nfrom datetime import datetime\nfrom .exceptions import (\n    DatabaseNotFoundError,\n    DatabaseAlreadyExistsError,\n    DatabaseOperationError\n)\n\n\nclass DatabaseAPIClient:\n    \"\"\"Mock API client for database service.\n    \n    In production, this would make actual HTTP requests to your database service API.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the API client.\"\"\"\n        # In-memory storage for demonstration\n        self._databases: Dict[str, Dict[str, Any]] = {}\n        self._operation_delay = 0.1  # Simulate API latency\n    \n    def _simulate_delay(self) -> None:\n        \"\"\"Simulate API call latency.\"\"\"\n        time.sleep(self._operation_delay)\n    \n    def create_database(\n        self,\n        name: str,\n        engine: str,\n        size: str,\n        tags: Optional[Dict[str, str]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Create a new database.\n        \n        Args:\n            name: Database name\n            engine: Database engine\n            size: Database size\n            tags: Optional tags\n            \n        Returns:\n            Database details\n            \n        Raises:\n            DatabaseAlreadyExistsError: If database already exists\n            DatabaseOperationError: If creation fails\n        \"\"\"\n        self._simulate_delay()\n        \n        if name in self._databases:\n            raise DatabaseAlreadyExistsError(\n                f\"Database '{name}' already exists\"\n            )\n        \n        try:\n            database_id = str(uuid.uuid4())\n            now = datetime.utcnow().isoformat()\n            \n            database = {\n                \"id\": database_id,\n                \"name\": name,\n                \"engine\": engine.lower(),\n                \"size\": size.lower(),\n                \"status\": \"creating\",\n                \"endpoint\": None,\n                \"port\": None,\n                \"tags\": tags or {},\n                \"created_at\": now,\n                \"updated_at\": now,\n            }\n            \n            self._databases[name] = database\n            \n            # Simulate async creation\n            time.sleep(0.2)\n            database[\"status\"] = \"available\"\n            database[\"endpoint\"] = f\"{name}.db.example.com\"\n            database[\"port\"] = self._get_default_port(engine)\n            \n            return database.copy()\n            \n        except Exception as e:\n            raise DatabaseOperationError(\n                f\"Failed to create database: {str(e)}\"\n            )\n    \n    def get_database(self, name: str) -> Dict[str, Any]:\n        \"\"\"Get database details.\n        \n        Args:\n            name: Database name\n            \n        Returns:\n            Database details\n            \n        Raises:\n            DatabaseNotFoundError: If database doesn't exist\n        \"\"\"\n        self._simulate_delay()\n        \n        if name not in self._databases:\n            raise DatabaseNotFoundError(\n                f\"Database '{name}' not found\"\n            )\n        \n        return self._databases[name].copy()\n    \n    def update_database(\n        self,\n        name: str,\n        size: Optional[str] = None,\n        tags: Optional[Dict[str, str]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"Update database configuration.\n        \n        Args:\n            name: Database name\n            size: New size (optional)\n            tags: New tags (optional)\n            \n        Returns:\n            Updated database details\n            \n        Raises:\n            DatabaseNotFoundError: If database doesn't exist\n            DatabaseOperationError: If update fails\n        \"\"\"\n        self._simulate_delay()\n        \n        if name not in self._databases:\n            raise DatabaseNotFoundError(\n                f\"Database '{name}' not found\"\n            )\n        \n        try:\n            database = self._databases[name]\n            \n            # Simulate update operation\n            database[\"status\"] = \"modifying\"\n            time.sleep(0.2)\n            \n            if size is not None:\n                database[\"size\"] = size.lower()\n            \n            if tags is not None:\n                database[\"tags\"] = tags\n            \n            database[\"updated_at\"] = datetime.utcnow().isoformat()\n            database[\"status\"] = \"available\"\n            \n            return database.copy()\n            \n        except Exception as e:\n            raise DatabaseOperationError(\n                f\"Failed to update database: {str(e)}\"\n            )\n    \n    def delete_database(self, name: str) -> None:\n        \"\"\"Delete a database.\n        \n        Args:\n            name: Database name\n            \n        Raises:\n            DatabaseNotFoundError: If database doesn't exist\n            DatabaseOperationError: If deletion fails\n        \"\"\"\n        self._simulate_delay()\n        \n        if name not in self._databases:\n            raise DatabaseNotFoundError(\n                f\"Database '{name}' not found\"\n            )\n        \n        try:\n            # Simulate deletion\n            self._databases[name][\"status\"] = \"deleting\"\n            time.sleep(0.2)\n            del self._databases[name]\n            \n        except Exception as e:\n            raise DatabaseOperationError(\n                f\"Failed to delete database: {str(e)}\"\n            )\n    \n    def list_databases(self) -> List[Dict[str, Any]]:\n        \"\"\"List all databases.\n        \n        Returns:\n            List of database details\n        \"\"\"\n        self._simulate_delay()\n        return [db.copy() for db in self._databases.values()]\n    \n    @staticmethod\n    def _get_default_port(engine: str) -> int:\n        \"\"\"Get default port for database engine.\n        \n        Args:\n            engine: Database engine\n            \n        Returns:\n            Default port number\n        \"\"\"\n        ports = {\n            \"mysql\": 3306,\n            \"postgresql\": 5432,\n            \"mongodb\": 27017,\n            \"redis\": 6379,\n        }\n        return ports.get(engine.lower(), 5432)\n```\n\n### 4. Database Provider (`database_provider.py`)\n\n```python\n\"\"\"Pulumi dynamic provider for custom database service.\"\"\"\nfrom typing import Any, Dict, Optional\nimport pulumi\nfrom pulumi.dynamic import ResourceProvider, CreateResult, UpdateResult, ReadResult\n\nfrom .api_client import DatabaseAPIClient\nfrom .validators import DatabaseValidator\nfrom .exceptions import (\n    DatabaseNotFoundError,\n    DatabaseAlreadyExistsError,\n    ValidationError,\n    DatabaseOperationError\n)\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"Dynamic provider for database resources.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the provider.\"\"\"\n        super().__init__()\n        self.client = DatabaseAPIClient()\n    \n    def create(self, props: Dict[str, Any]) -> CreateResult:\n        \"\"\"Create a new database.\n        \n        Args:\n            props: Resource properties\n            \n        Returns:\n            CreateResult with resource ID and outputs\n            \n        Raises:\n            Exception: If creation fails\n        \"\"\"\n        try:\n            # Validate inputs\n            DatabaseValidator.validate_inputs(props)\n            \n            pulumi.log.info(f\"Creating database: {props['name']}\")\n            \n            # Extract properties\n            name = props[\"name\"]\n            engine = props[\"engine\"]\n            size = props[\"size\"]\n            tags = props.get(\"tags\", {})\n            \n            # Create database via API\n            database = self.client.create_database(\n                name=name,\n                engine=engine,\n                size=size,\n                tags=tags\n            )\n            \n            pulumi.log.info(f\"Database created successfully: {database['id']}\")\n            \n            # Return outputs\n            outputs = {\n                \"id\": database[\"id\"],\n                \"name\": database[\"name\"],\n                \"engine\": database[\"engine\"],\n                \"size\": database[\"size\"],\n                \"status\": database[\"status\"],\n                \"endpoint\": database[\"endpoint\"],\n                \"port\": database[\"port\"],\n                \"tags\": database[\"tags\"],\n                \"created_at\": database[\"created_at\"],\n                \"updated_at\": database[\"updated_at\"],\n            }\n            \n            return CreateResult(\n                id_=database[\"id\"],\n                outs=outputs\n            )\n            \n        except ValidationError as e:\n            pulumi.log.error(f\"Validation error: {str(e)}\")\n            raise Exception(f\"Invalid database configuration: {str(e)}\")\n        \n        except DatabaseAlreadyExistsError as e:\n            pulumi.log.error(f\"Database already exists: {str(e)}\")\n            raise Exception(str(e))\n        \n        except DatabaseOperationError as e:\n            pulumi.log.error(f\"Database operation failed: {str(e)}\")\n            raise Exception(str(e))\n        \n        except Exception as e:\n            pulumi.log.error(f\"Unexpected error during create: {str(e)}\")\n            raise Exception(f\"Failed to create database: {str(e)}\")\n    \n    def read(self, id_: str, props: Dict[str, Any]) -> ReadResult:\n        \"\"\"Read database state.\n        \n        Args:\n            id_: Resource ID\n            props: Current properties\n            \n        Returns:\n            ReadResult with current state\n        \"\"\"\n        try:\n            name = props.get(\"name\")\n            if not name:\n                pulumi.log.warn(f\"Cannot read database without name, using ID: {id_}\")\n                # In production, you'd look up by ID\n                return ReadResult(id_=id_, outs=props)\n            \n            pulumi.log.info(f\"Reading database: {name}\")\n            \n            # Get current state from API\n            database = self.client.get_database(name)\n            \n            outputs = {\n                \"id\": database[\"id\"],\n                \"name\": database[\"name\"],\n                \"engine\": database[\"engine\"],\n                \"size\": database[\"size\"],\n                \"status\": database[\"status\"],\n                \"endpoint\": database[\"endpoint\"],\n                \"port\": database[\"port\"],\n                \"tags\": database[\"tags\"],\n                \"created_at\": database[\"created_at\"],\n                \"updated_at\": database[\"updated_at\"],\n            }\n            \n            return ReadResult(id_=database[\"id\"], outs=outputs)\n            \n        except DatabaseNotFoundError:\n            pulumi.log.warn(f\"Database not found: {name}\")\n            # Return empty result to trigger recreation\n            return ReadResult(id_=\"\", outs={})\n        \n        except Exception as e:\n            pulumi.log.error(f\"Error reading database: {str(e)}\")\n            # Return current props on error\n            ",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4779,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a Python Pulumi dynamic provider for a custom database service with full CRUD operations.\n\n```python\n# pulumi_provider/database_provider.py\n\"\"\"Pulumi dynamic provider for custom database service.\"\"\"\nimport logging\nfrom typing import Any, Optional\nfrom pulumi import Input, Output, ResourceOptions\nfrom pulumi.dynamic import Resource, ResourceProvider, CreateResult, UpdateResult\n\nlogger = logging.getLogger(__name__)\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"Dynamic provider implementing CRUD operations for database resources.\"\"\"\n\n    def __init__(self, api_client: Optional[Any] = None):\n        \"\"\"\n        Initialize the database provider.\n        \n        Args:\n            api_client: Optional API client for database service operations.\n                       If None, uses mock implementation for testing.\n        \"\"\"\n        self.api_client = api_client or MockDatabaseClient()\n\n    def create(self, props: dict) -> CreateResult:\n        \"\"\"\n        Create a new database resource.\n        \n        Args:\n            props: Resource properties (name, engine, size)\n            \n        Returns:\n            CreateResult with resource ID and outputs\n        \"\"\"\n        try:\n            name = props.get(\"name\")\n            engine = props.get(\"engine\")\n            size = props.get(\"size\")\n            \n            logger.info(f\"Creating database: {name} (engine={engine}, size={size})\")\n            \n            # Validate required properties\n            if not name:\n                raise ValueError(\"Database name is required\")\n            if not engine:\n                raise ValueError(\"Database engine is required\")\n            if not size:\n                raise ValueError(\"Database size is required\")\n            \n            # Create database via API\n            result = self.api_client.create_database(\n                name=name,\n                engine=engine,\n                size=size\n            )\n            \n            # Return resource ID and all properties\n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"endpoint\": result.get(\"endpoint\"),\n                \"status\": result.get(\"status\", \"creating\"),\n                \"created_at\": result.get(\"created_at\"),\n            }\n            \n            logger.info(f\"Database created successfully: {result['id']}\")\n            return CreateResult(id_=result[\"id\"], outs=outputs)\n            \n        except Exception as e:\n            logger.error(f\"Failed to create database: {e}\")\n            raise\n\n    def read(self, id_: str, props: dict) -> dict:\n        \"\"\"\n        Read current state of database resource.\n        \n        Args:\n            id_: Resource ID\n            props: Current properties\n            \n        Returns:\n            Current resource properties\n        \"\"\"\n        try:\n            logger.info(f\"Reading database: {id_}\")\n            \n            # Fetch current state from API\n            result = self.api_client.get_database(id_)\n            \n            if not result:\n                logger.warning(f\"Database not found: {id_}\")\n                return {}\n            \n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"endpoint\": result.get(\"endpoint\"),\n                \"status\": result.get(\"status\"),\n                \"created_at\": result.get(\"created_at\"),\n                \"updated_at\": result.get(\"updated_at\"),\n            }\n            \n            logger.info(f\"Database read successfully: {id_}\")\n            return outputs\n            \n        except Exception as e:\n            logger.error(f\"Failed to read database {id_}: {e}\")\n            raise\n\n    def update(self, id_: str, old_props: dict, new_props: dict) -> UpdateResult:\n        \"\"\"\n        Update existing database resource.\n        \n        Args:\n            id_: Resource ID\n            old_props: Previous properties\n            new_props: New properties\n            \n        Returns:\n            UpdateResult with updated outputs\n        \"\"\"\n        try:\n            logger.info(f\"Updating database: {id_}\")\n            \n            # Determine what changed\n            updates = {}\n            \n            # Check if name changed (may require replacement)\n            if new_props.get(\"name\") != old_props.get(\"name\"):\n                logger.warning(f\"Database name change requires replacement: {id_}\")\n                # In real implementation, this might trigger a replacement\n                updates[\"name\"] = new_props[\"name\"]\n            \n            # Check if engine changed (may require replacement)\n            if new_props.get(\"engine\") != old_props.get(\"engine\"):\n                logger.warning(f\"Database engine change requires replacement: {id_}\")\n                updates[\"engine\"] = new_props[\"engine\"]\n            \n            # Check if size changed (can be updated in-place)\n            if new_props.get(\"size\") != old_props.get(\"size\"):\n                logger.info(f\"Updating database size: {old_props.get('size')} -> {new_props.get('size')}\")\n                updates[\"size\"] = new_props[\"size\"]\n            \n            if not updates:\n                logger.info(f\"No changes detected for database: {id_}\")\n                return UpdateResult(outs=old_props)\n            \n            # Apply updates via API\n            result = self.api_client.update_database(id_, updates)\n            \n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"endpoint\": result.get(\"endpoint\"),\n                \"status\": result.get(\"status\"),\n                \"created_at\": result.get(\"created_at\"),\n                \"updated_at\": result.get(\"updated_at\"),\n            }\n            \n            logger.info(f\"Database updated successfully: {id_}\")\n            return UpdateResult(outs=outputs)\n            \n        except Exception as e:\n            logger.error(f\"Failed to update database {id_}: {e}\")\n            raise\n\n    def delete(self, id_: str, props: dict) -> None:\n        \"\"\"\n        Delete database resource.\n        \n        Args:\n            id_: Resource ID\n            props: Current properties\n        \"\"\"\n        try:\n            logger.info(f\"Deleting database: {id_}\")\n            \n            # Delete database via API\n            self.api_client.delete_database(id_)\n            \n            logger.info(f\"Database deleted successfully: {id_}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to delete database {id_}: {e}\")\n            raise\n\n\nclass Database(Resource):\n    \"\"\"\n    Pulumi resource for managing custom database instances.\n    \n    Example usage:\n        db = Database(\n            \"my-database\",\n            name=\"production-db\",\n            engine=\"postgresql\",\n            size=\"medium\",\n        )\n    \"\"\"\n    \n    name: Output[str]\n    \"\"\"Database name\"\"\"\n    \n    engine: Output[str]\n    \"\"\"Database engine (postgresql, mysql, mongodb, etc.)\"\"\"\n    \n    size: Output[str]\n    \"\"\"Database size (small, medium, large)\"\"\"\n    \n    endpoint: Output[str]\n    \"\"\"Database connection endpoint\"\"\"\n    \n    status: Output[str]\n    \"\"\"Current database status\"\"\"\n    \n    created_at: Output[str]\n    \"\"\"Creation timestamp\"\"\"\n    \n    updated_at: Output[str]\n    \"\"\"Last update timestamp\"\"\"\n\n    def __init__(\n        self,\n        resource_name: str,\n        name: Input[str],\n        engine: Input[str],\n        size: Input[str],\n        opts: Optional[ResourceOptions] = None,\n        api_client: Optional[Any] = None,\n    ):\n        \"\"\"\n        Create a new Database resource.\n        \n        Args:\n            resource_name: Pulumi resource name\n            name: Database name\n            engine: Database engine type\n            size: Database size\n            opts: Resource options\n            api_client: Optional API client for database operations\n        \"\"\"\n        props = {\n            \"name\": name,\n            \"engine\": engine,\n            \"size\": size,\n        }\n        \n        provider = DatabaseProvider(api_client)\n        \n        super().__init__(\n            provider,\n            resource_name,\n            props,\n            opts,\n        )\n\n\nclass MockDatabaseClient:\n    \"\"\"Mock database client for testing and development.\"\"\"\n    \n    def __init__(self):\n        self._databases = {}\n        self._id_counter = 1000\n    \n    def create_database(self, name: str, engine: str, size: str) -> dict:\n        \"\"\"Create a mock database.\"\"\"\n        import datetime\n        \n        db_id = f\"db-{self._id_counter}\"\n        self._id_counter += 1\n        \n        database = {\n            \"id\": db_id,\n            \"name\": name,\n            \"engine\": engine,\n            \"size\": size,\n            \"endpoint\": f\"{name}.{engine}.example.com:5432\",\n            \"status\": \"active\",\n            \"created_at\": datetime.datetime.utcnow().isoformat(),\n        }\n        \n        self._databases[db_id] = database\n        return database\n    \n    def get_database(self, db_id: str) -> Optional[dict]:\n        \"\"\"Get a mock database.\"\"\"\n        return self._databases.get(db_id)\n    \n    def update_database(self, db_id: str, updates: dict) -> dict:\n        \"\"\"Update a mock database.\"\"\"\n        import datetime\n        \n        if db_id not in self._databases:\n            raise ValueError(f\"Database not found: {db_id}\")\n        \n        database = self._databases[db_id]\n        database.update(updates)\n        database[\"updated_at\"] = datetime.datetime.utcnow().isoformat()\n        \n        return database\n    \n    def delete_database(self, db_id: str) -> None:\n        \"\"\"Delete a mock database.\"\"\"\n        if db_id in self._databases:\n            del self._databases[db_id]\n```\n\n```python\n# pulumi_provider/__init__.py\n\"\"\"Pulumi provider for custom database service.\"\"\"\nfrom .database_provider import Database, DatabaseProvider, MockDatabaseClient\n\n__all__ = [\"Database\", \"DatabaseProvider\", \"MockDatabaseClient\"]\n```\n\n```python\n# tests/test_database_provider.py\n\"\"\"Tests for database provider.\"\"\"\nimport pytest\nfrom pulumi_provider import Database, DatabaseProvider, MockDatabaseClient\n\n\nclass TestDatabaseProvider:\n    \"\"\"Test suite for DatabaseProvider.\"\"\"\n    \n    def test_create_database(self):\n        \"\"\"Test creating a database.\"\"\"\n        provider = DatabaseProvider()\n        \n        props = {\n            \"name\": \"test-db\",\n            \"engine\": \"postgresql\",\n            \"size\": \"medium\",\n        }\n        \n        result = provider.create(props)\n        \n        assert result.id_.startswith(\"db-\")\n        assert result.outs[\"name\"] == \"test-db\"\n        assert result.outs[\"engine\"] == \"postgresql\"\n        assert result.outs[\"size\"] == \"medium\"\n        assert result.outs[\"status\"] == \"active\"\n        assert \"endpoint\" in result.outs\n    \n    def test_create_database_missing_name(self):\n        \"\"\"Test creating database without name fails.\"\"\"\n        provider = DatabaseProvider()\n        \n        props = {\n            \"engine\": \"postgresql\",\n            \"size\": \"medium\",\n        }\n        \n        with pytest.raises(ValueError, match=\"name is required\"):\n            provider.create(props)\n    \n    def test_read_database(self):\n        \"\"\"Test reading a database.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database first\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"mysql\",\n            \"size\": \"small\",\n        })\n        \n        # Read it back\n        read_result = provider.read(create_result.id_, {})\n        \n        assert read_result[\"name\"] == \"test-db\"\n        assert read_result[\"engine\"] == \"mysql\"\n        assert read_result[\"size\"] == \"small\"\n    \n    def test_read_nonexistent_database(self):\n        \"\"\"Test reading non-existent database.\"\"\"\n        provider = DatabaseProvider()\n        \n        result = provider.read(\"nonexistent-id\", {})\n        \n        assert result == {}\n    \n    def test_update_database_size(self):\n        \"\"\"Test updating database size.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"postgresql\",\n            \"size\": \"small\",\n        })\n        \n        # Update size\n        old_props = create_result.outs\n        new_props = {**old_props, \"size\": \"large\"}\n        \n        update_result = provider.update(create_result.id_, old_props, new_props)\n        \n        assert update_result.outs[\"size\"] == \"large\"\n        assert \"updated_at\" in update_result.outs\n    \n    def test_update_no_changes(self):\n        \"\"\"Test update with no changes.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"postgresql\",\n            \"size\": \"medium\",\n        })\n        \n        # Update with same props\n        props = create_result.outs\n        update_result = provider.update(create_result.id_, props, props)\n        \n        assert update_result.outs == props\n    \n    def test_delete_database(self):\n        \"\"\"Test deleting a database.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"mongodb\",\n            \"size\": \"medium\",\n        })\n        \n        # Delete it\n        provider.delete(create_result.id_, create_result.outs)\n        \n        # Verify it's gone\n        read_result = provider.read(create_result.id_, {})\n        assert read_result == {}\n    \n    def test_mock_client_operations(self):\n        \"\"\"Test mock client directly.\"\"\"\n        client = MockDatabaseClient()\n        \n        # Create\n        db = client.create_database(\"test\", \"postgresql\", \"small\")\n        assert db[\"id\"].startswith(\"db-\")\n        \n        # Read\n        fetched = client.get_database(db[\"id\"])\n        assert fetched[\"name\"] == \"test\"\n        \n        # Update\n        updated = client.update_database(db[\"id\"], {\"size\": \"large\"})\n        assert updated[\"size\"] == \"large\"\n        assert \"updated_at\" in updated\n        \n        # Delete\n        client.delete_database(db[\"id\"])\n        assert client.get_database(db[\"id\"]) is None\n\n\nclass TestDatabaseResource:\n    \"\"\"Test suite for Database resource (integration-style tests).\"\"\"\n    \n    def test_database_resource_properties(self):\n        \"\"\"Test that Database resource has expected properties.\"\"\"\n        # This would require Pulumi runtime, so we just verify the class exists\n        assert hasattr(Database, \"name\")\n        assert hasattr(Database, \"engine\")\n        assert hasattr(Database, \"size\")\n        assert hasattr(Database, \"endpoint\")\n        assert hasattr(Database, \"status\")\n```\n\n```python\n# examples/example_usage.py\n\"\"\"Example usage of the database provider.\"\"\"\nimport pulumi\nfrom pulumi_provider import Database\n\n# Create a PostgreSQL database\npostgres_db = Database(\n    \"postgres-production\",\n    name=\"prod-postgres\",\n    engine=\"postgresql\",\n    size=\"large\",\n)\n\n# Create a MySQL database\nmysql_db = Database(\n    \"mysql-analytics\",\n    name=\"analytics-mysql\",\n    engine=\"mysql\",\n    size=\"medium\",\n)\n\n# Create a MongoDB database\nmongo_db = Database(\n    \"mongo-cache\",\n    name=\"cache-mongo\",\n    engine=\"mongodb\",\n    size=\"small\",\n)\n\n# Export database endpoints\npulumi.export(\"postgres_endpoint\", postgres_db.endpoint)\npulumi.export(\"mysql_endpoint\", mysql_db.endpoint)\npulumi.export(\"mongo_endpoint\", mongo_db.endpoint)\n\n# Export database statuses\npulumi.export(\"postgres_status\", postgres_db.status)\npulumi.export(\"mysql_status\", mysql_db.status)\npulumi.export(\"mongo_status\", mongo_db.status)\n```\n\n```python\n# examples/with_real_api.py\n\"\"\"Example with a real API client.\"\"\"\nimport pulumi\nfrom pulumi_provider import Database\n\n\nclass RealDatabaseClient:\n    \"\"\"Real API client implementation.\"\"\"\n    \n    def __init__(self, api_url: str, api_key: str):\n        self.api_url = api_url\n        self.api_key = api_key\n    \n    def create_database(self, name: str, engine: str, size: str) ->",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5305,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "# Pulumi Dynamic Provider for Custom Database Service\n\nI'll create a comprehensive Pulumi dynamic provider for managing a custom database service with full CRUD operations.\n\n```python\n# database_provider.py\n\"\"\"\nCustom Database Service Pulumi Dynamic Provider\nImplements CRUD operations for managing database resources\n\"\"\"\n\nimport pulumi\nfrom pulumi import Input, Output, ResourceOptions\nfrom pulumi.dynamic import Resource, ResourceProvider, CreateResult, UpdateResult\nfrom typing import Any, Optional\nimport uuid\nimport json\nimport time\n\n\nclass DatabaseArgs:\n    \"\"\"Arguments for the Database resource\"\"\"\n    \n    def __init__(\n        self,\n        name: Input[str],\n        engine: Input[str],\n        size: Input[str],\n        tags: Optional[Input[dict]] = None\n    ):\n        \"\"\"\n        Args:\n            name: Database name\n            engine: Database engine (e.g., 'postgres', 'mysql', 'mongodb')\n            size: Database size tier (e.g., 'small', 'medium', 'large')\n            tags: Optional tags for the database\n        \"\"\"\n        self.name = name\n        self.engine = engine\n        self.size = size\n        self.tags = tags or {}\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"\n    Dynamic provider implementation for database resources.\n    In a real implementation, this would interact with an actual database service API.\n    \"\"\"\n    \n    # Simulated database storage (in production, this would be an actual API)\n    _databases = {}\n    \n    def create(self, props: dict) -> CreateResult:\n        \"\"\"\n        Create a new database instance.\n        \n        Args:\n            props: Properties for the database\n            \n        Returns:\n            CreateResult with the database ID and outputs\n        \"\"\"\n        pulumi.log.info(f\"Creating database: {props.get('name')}\")\n        \n        # Validate inputs\n        self._validate_props(props)\n        \n        # Generate unique ID for the database\n        db_id = str(uuid.uuid4())\n        \n        # Simulate database creation (in production, call actual API)\n        database = {\n            'id': db_id,\n            'name': props['name'],\n            'engine': props['engine'],\n            'size': props['size'],\n            'tags': props.get('tags', {}),\n            'status': 'creating',\n            'created_at': time.time(),\n            'connection_string': self._generate_connection_string(\n                props['engine'], \n                props['name']\n            ),\n            'endpoint': f\"{props['name']}.{props['engine']}.database.local\",\n            'port': self._get_default_port(props['engine'])\n        }\n        \n        # Simulate creation delay\n        time.sleep(0.5)\n        database['status'] = 'active'\n        \n        # Store in our simulated database\n        self._databases[db_id] = database\n        \n        pulumi.log.info(f\"Database created successfully: {db_id}\")\n        \n        # Return outputs\n        outs = {\n            'id': db_id,\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'tags': database['tags'],\n            'status': database['status'],\n            'connection_string': database['connection_string'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'created_at': database['created_at']\n        }\n        \n        return CreateResult(id_=db_id, outs=outs)\n    \n    def read(self, id_: str, props: dict) -> dict:\n        \"\"\"\n        Read the current state of a database.\n        \n        Args:\n            id_: Database ID\n            props: Current properties\n            \n        Returns:\n            Current state of the database\n        \"\"\"\n        pulumi.log.info(f\"Reading database: {id_}\")\n        \n        # Retrieve from simulated storage\n        database = self._databases.get(id_)\n        \n        if not database:\n            pulumi.log.warn(f\"Database not found: {id_}\")\n            return {}\n        \n        return {\n            'id': database['id'],\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'tags': database.get('tags', {}),\n            'status': database['status'],\n            'connection_string': database['connection_string'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'created_at': database['created_at']\n        }\n    \n    def update(self, id_: str, old_props: dict, new_props: dict) -> UpdateResult:\n        \"\"\"\n        Update an existing database.\n        \n        Args:\n            id_: Database ID\n            old_props: Previous properties\n            new_props: New properties\n            \n        Returns:\n            UpdateResult with updated outputs\n        \"\"\"\n        pulumi.log.info(f\"Updating database: {id_}\")\n        \n        # Validate new properties\n        self._validate_props(new_props)\n        \n        database = self._databases.get(id_)\n        \n        if not database:\n            raise Exception(f\"Database not found: {id_}\")\n        \n        # Check what changed\n        changes = []\n        \n        # Name change requires replacement (immutable)\n        if old_props.get('name') != new_props.get('name'):\n            pulumi.log.warn(\"Database name change requires replacement\")\n            changes.append('name')\n        \n        # Engine change requires replacement (immutable)\n        if old_props.get('engine') != new_props.get('engine'):\n            pulumi.log.warn(\"Database engine change requires replacement\")\n            changes.append('engine')\n        \n        # Size can be updated\n        if old_props.get('size') != new_props.get('size'):\n            pulumi.log.info(f\"Resizing database from {old_props.get('size')} to {new_props.get('size')}\")\n            database['size'] = new_props['size']\n            database['status'] = 'resizing'\n            time.sleep(0.3)  # Simulate resize operation\n            database['status'] = 'active'\n            changes.append('size')\n        \n        # Tags can be updated\n        if old_props.get('tags') != new_props.get('tags'):\n            pulumi.log.info(\"Updating database tags\")\n            database['tags'] = new_props.get('tags', {})\n            changes.append('tags')\n        \n        database['updated_at'] = time.time()\n        \n        pulumi.log.info(f\"Database updated successfully: {id_} (changes: {', '.join(changes)})\")\n        \n        # Return updated outputs\n        outs = {\n            'id': database['id'],\n            'name': database['name'],\n            'engine': database['engine'],\n            'size': database['size'],\n            'tags': database['tags'],\n            'status': database['status'],\n            'connection_string': database['connection_string'],\n            'endpoint': database['endpoint'],\n            'port': database['port'],\n            'created_at': database['created_at'],\n            'updated_at': database.get('updated_at')\n        }\n        \n        return UpdateResult(outs=outs)\n    \n    def delete(self, id_: str, props: dict) -> None:\n        \"\"\"\n        Delete a database.\n        \n        Args:\n            id_: Database ID\n            props: Current properties\n        \"\"\"\n        pulumi.log.info(f\"Deleting database: {id_}\")\n        \n        database = self._databases.get(id_)\n        \n        if not database:\n            pulumi.log.warn(f\"Database not found (may already be deleted): {id_}\")\n            return\n        \n        # Update status\n        database['status'] = 'deleting'\n        \n        # Simulate deletion delay\n        time.sleep(0.3)\n        \n        # Remove from storage\n        del self._databases[id_]\n        \n        pulumi.log.info(f\"Database deleted successfully: {id_}\")\n    \n    def _validate_props(self, props: dict) -> None:\n        \"\"\"Validate database properties\"\"\"\n        \n        # Validate name\n        name = props.get('name')\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Database name is required and must be a string\")\n        \n        if len(name) < 3 or len(name) > 63:\n            raise ValueError(\"Database name must be between 3 and 63 characters\")\n        \n        # Validate engine\n        engine = props.get('engine')\n        valid_engines = ['postgres', 'mysql', 'mongodb', 'redis', 'mariadb']\n        if engine not in valid_engines:\n            raise ValueError(f\"Invalid engine. Must be one of: {', '.join(valid_engines)}\")\n        \n        # Validate size\n        size = props.get('size')\n        valid_sizes = ['small', 'medium', 'large', 'xlarge']\n        if size not in valid_sizes:\n            raise ValueError(f\"Invalid size. Must be one of: {', '.join(valid_sizes)}\")\n    \n    def _generate_connection_string(self, engine: str, name: str) -> str:\n        \"\"\"Generate a connection string for the database\"\"\"\n        \n        connection_strings = {\n            'postgres': f\"postgresql://user:password@{name}.postgres.database.local:5432/{name}\",\n            'mysql': f\"mysql://user:password@{name}.mysql.database.local:3306/{name}\",\n            'mongodb': f\"mongodb://user:password@{name}.mongodb.database.local:27017/{name}\",\n            'redis': f\"redis://:{name}@{name}.redis.database.local:6379/0\",\n            'mariadb': f\"mariadb://user:password@{name}.mariadb.database.local:3306/{name}\"\n        }\n        \n        return connection_strings.get(engine, f\"{engine}://{name}.database.local\")\n    \n    def _get_default_port(self, engine: str) -> int:\n        \"\"\"Get default port for database engine\"\"\"\n        \n        ports = {\n            'postgres': 5432,\n            'mysql': 3306,\n            'mongodb': 27017,\n            'redis': 6379,\n            'mariadb': 3306\n        }\n        \n        return ports.get(engine, 5432)\n\n\nclass Database(Resource):\n    \"\"\"\n    A custom database resource managed by the DatabaseProvider.\n    \n    Example usage:\n        db = Database(\n            \"my-database\",\n            name=\"myapp-db\",\n            engine=\"postgres\",\n            size=\"medium\",\n            tags={\"environment\": \"production\"}\n        )\n    \"\"\"\n    \n    # Output properties\n    id: Output[str]\n    name: Output[str]\n    engine: Output[str]\n    size: Output[str]\n    tags: Output[dict]\n    status: Output[str]\n    connection_string: Output[str]\n    endpoint: Output[str]\n    port: Output[int]\n    created_at: Output[float]\n    updated_at: Output[Optional[float]]\n    \n    def __init__(\n        self,\n        resource_name: str,\n        name: Input[str],\n        engine: Input[str],\n        size: Input[str],\n        tags: Optional[Input[dict]] = None,\n        opts: Optional[ResourceOptions] = None\n    ):\n        \"\"\"\n        Create a new Database resource.\n        \n        Args:\n            resource_name: Pulumi resource name\n            name: Database name\n            engine: Database engine\n            size: Database size tier\n            tags: Optional tags\n            opts: Resource options\n        \"\"\"\n        \n        # Prepare properties\n        props = {\n            'name': name,\n            'engine': engine,\n            'size': size,\n            'tags': tags or {}\n        }\n        \n        # Initialize the dynamic resource\n        super().__init__(\n            DatabaseProvider(),\n            resource_name,\n            props,\n            opts\n        )\n\n\n# Example usage and helper functions\n\ndef create_database_with_defaults(\n    resource_name: str,\n    name: str,\n    engine: str = \"postgres\",\n    size: str = \"medium\",\n    **kwargs\n) -> Database:\n    \"\"\"\n    Helper function to create a database with sensible defaults.\n    \n    Args:\n        resource_name: Pulumi resource name\n        name: Database name\n        engine: Database engine (default: postgres)\n        size: Database size (default: medium)\n        **kwargs: Additional arguments\n        \n    Returns:\n        Database resource\n    \"\"\"\n    return Database(\n        resource_name,\n        name=name,\n        engine=engine,\n        size=size,\n        **kwargs\n    )\n\n\ndef get_database_info(db: Database) -> dict:\n    \"\"\"\n    Get database information as a dictionary.\n    \n    Args:\n        db: Database resource\n        \n    Returns:\n        Dictionary with database information\n    \"\"\"\n    return {\n        'id': db.id,\n        'name': db.name,\n        'engine': db.engine,\n        'size': db.size,\n        'endpoint': db.endpoint,\n        'port': db.port,\n        'connection_string': db.connection_string\n    }\n```\n\n```python\n# __main__.py\n\"\"\"\nExample Pulumi program using the custom Database provider\n\"\"\"\n\nimport pulumi\nfrom database_provider import Database, create_database_with_defaults\n\n# Create a PostgreSQL database\npostgres_db = Database(\n    \"postgres-database\",\n    name=\"myapp-postgres\",\n    engine=\"postgres\",\n    size=\"medium\",\n    tags={\n        \"environment\": \"production\",\n        \"team\": \"backend\",\n        \"cost-center\": \"engineering\"\n    }\n)\n\n# Create a MySQL database with helper function\nmysql_db = create_database_with_defaults(\n    \"mysql-database\",\n    name=\"myapp-mysql\",\n    engine=\"mysql\",\n    size=\"small\",\n    tags={\n        \"environment\": \"development\",\n        \"team\": \"backend\"\n    }\n)\n\n# Create a MongoDB database\nmongodb_db = Database(\n    \"mongodb-database\",\n    name=\"myapp-mongodb\",\n    engine=\"mongodb\",\n    size=\"large\",\n    tags={\n        \"environment\": \"production\",\n        \"team\": \"data\"\n    }\n)\n\n# Create a Redis cache\nredis_cache = Database(\n    \"redis-cache\",\n    name=\"myapp-cache\",\n    engine=\"redis\",\n    size=\"small\",\n    tags={\n        \"environment\": \"production\",\n        \"team\": \"backend\",\n        \"type\": \"cache\"\n    }\n)\n\n# Export database connection information\npulumi.export(\"postgres_connection\", postgres_db.connection_string)\npulumi.export(\"postgres_endpoint\", postgres_db.endpoint)\npulumi.export(\"postgres_port\", postgres_db.port)\npulumi.export(\"postgres_status\", postgres_db.status)\n\npulumi.export(\"mysql_connection\", mysql_db.connection_string)\npulumi.export(\"mysql_endpoint\", mysql_db.endpoint)\n\npulumi.export(\"mongodb_connection\", mongodb_db.connection_string)\npulumi.export(\"mongodb_endpoint\", mongodb_db.endpoint)\n\npulumi.export(\"redis_connection\", redis_cache.connection_string)\npulumi.export(\"redis_endpoint\", redis_cache.endpoint)\n\n# Export all database IDs\npulumi.export(\"database_ids\", {\n    \"postgres\": postgres_db.id,\n    \"mysql\": mysql_db.id,\n    \"mongodb\": mongodb_db.id,\n    \"redis\": redis_cache.id\n})\n```\n\n```python\n# test_database_provider.py\n\"\"\"\nUnit tests for the Database provider\n\"\"\"\n\nimport unittest\nfrom unittest.mock import patch, MagicMock\nfrom database_provider import DatabaseProvider, DatabaseArgs\nimport time\n\n\nclass TestDatabaseProvider(unittest.TestCase):\n    \"\"\"Test cases for DatabaseProvider\"\"\"\n    \n    def setUp(self):\n        \"\"\"Set up test fixtures\"\"\"\n        self.provider = DatabaseProvider()\n        # Clear the simulated database before each test\n        self.provider._databases.clear()\n    \n    def test_create_database(self):\n        \"\"\"Test database creation\"\"\"\n        props = {\n            'name': 'test-db',\n            'engine': 'postgres',\n            'size': 'medium',\n            'tags': {'env': 'test'}\n        }\n        \n        result = self.provider.create(props)\n        \n        self.assertIsNotNone(result.id)\n        self.assertEqual(result.outs['name'], 'test-db')\n        self.assertEqual(result.outs['engine'], 'postgres')\n        self.assertEqual(",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 60,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# Pulumi Dynamic Provider for Custom Database Service\n\nI'll create a comprehensive Python Pulumi dynamic provider for managing a custom database service with full CRUD operations.\n\n## Project Structure\n\n```\npulumi-database-provider/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 database_provider.py      # Main provider implementation\n\u251c\u2500\u2500 database_resource.py      # Resource definition\n\u251c\u2500\u2500 api_client.py            # Mock API client\n\u251c\u2500\u2500 models.py                # Data models\n\u251c\u2500\u2500 exceptions.py            # Custom exceptions\n\u251c\u2500\u2500 __main__.py              # Example usage\n\u251c\u2500\u2500 tests/\n\u2502   \u251c\u2500\u2500 __init__.py\n\u2502   \u251c\u2500\u2500 test_provider.py\n\u2502   \u2514\u2500\u2500 test_resource.py\n\u251c\u2500\u2500 Pulumi.yaml\n\u251c\u2500\u2500 requirements.txt\n\u2514\u2500\u2500 README.md\n```\n\n## Implementation\n\n### 1. models.py - Data Models\n\n```python\n\"\"\"\nData models for the database provider.\n\"\"\"\nfrom typing import Optional, Dict, Any\nfrom dataclasses import dataclass, asdict\nfrom enum import Enum\n\n\nclass DatabaseEngine(str, Enum):\n    \"\"\"Supported database engines.\"\"\"\n    POSTGRES = \"postgres\"\n    MYSQL = \"mysql\"\n    MONGODB = \"mongodb\"\n    REDIS = \"redis\"\n\n\nclass DatabaseStatus(str, Enum):\n    \"\"\"Database lifecycle states.\"\"\"\n    CREATING = \"creating\"\n    AVAILABLE = \"available\"\n    MODIFYING = \"modifying\"\n    DELETING = \"deleting\"\n    DELETED = \"deleted\"\n    FAILED = \"failed\"\n\n\n@dataclass\nclass DatabaseConfig:\n    \"\"\"Database configuration.\"\"\"\n    name: str\n    engine: str\n    size: str\n    tags: Optional[Dict[str, str]] = None\n    backup_enabled: bool = True\n    multi_az: bool = False\n    \n    def __post_init__(self):\n        \"\"\"Validate configuration.\"\"\"\n        if not self.name:\n            raise ValueError(\"Database name is required\")\n        \n        if self.engine not in [e.value for e in DatabaseEngine]:\n            raise ValueError(\n                f\"Invalid engine: {self.engine}. \"\n                f\"Must be one of: {[e.value for e in DatabaseEngine]}\"\n            )\n        \n        valid_sizes = [\"small\", \"medium\", \"large\", \"xlarge\"]\n        if self.size not in valid_sizes:\n            raise ValueError(\n                f\"Invalid size: {self.size}. \"\n                f\"Must be one of: {valid_sizes}\"\n            )\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary.\"\"\"\n        return asdict(self)\n\n\n@dataclass\nclass DatabaseState:\n    \"\"\"Database state representation.\"\"\"\n    id: str\n    name: str\n    engine: str\n    size: str\n    status: str\n    endpoint: str\n    port: int\n    arn: str\n    tags: Optional[Dict[str, str]] = None\n    backup_enabled: bool = True\n    multi_az: bool = False\n    created_at: Optional[str] = None\n    updated_at: Optional[str] = None\n    \n    def to_dict(self) -> Dict[str, Any]:\n        \"\"\"Convert to dictionary.\"\"\"\n        return asdict(self)\n    \n    @classmethod\n    def from_dict(cls, data: Dict[str, Any]) -> 'DatabaseState':\n        \"\"\"Create from dictionary.\"\"\"\n        return cls(**data)\n\n\n@dataclass\nclass DatabaseInputs:\n    \"\"\"Pulumi resource inputs.\"\"\"\n    name: str\n    engine: str\n    size: str\n    tags: Optional[Dict[str, str]] = None\n    backup_enabled: bool = True\n    multi_az: bool = False\n    \n    def to_config(self) -> DatabaseConfig:\n        \"\"\"Convert to DatabaseConfig.\"\"\"\n        return DatabaseConfig(\n            name=self.name,\n            engine=self.engine,\n            size=self.size,\n            tags=self.tags,\n            backup_enabled=self.backup_enabled,\n            multi_az=self.multi_az\n        )\n```\n\n### 2. exceptions.py - Custom Exceptions\n\n```python\n\"\"\"\nCustom exceptions for the database provider.\n\"\"\"\n\n\nclass DatabaseProviderError(Exception):\n    \"\"\"Base exception for database provider errors.\"\"\"\n    pass\n\n\nclass DatabaseNotFoundError(DatabaseProviderError):\n    \"\"\"Raised when database is not found.\"\"\"\n    pass\n\n\nclass DatabaseAlreadyExistsError(DatabaseProviderError):\n    \"\"\"Raised when database already exists.\"\"\"\n    pass\n\n\nclass DatabaseOperationError(DatabaseProviderError):\n    \"\"\"Raised when database operation fails.\"\"\"\n    pass\n\n\nclass DatabaseValidationError(DatabaseProviderError):\n    \"\"\"Raised when validation fails.\"\"\"\n    pass\n\n\nclass DatabaseTimeoutError(DatabaseProviderError):\n    \"\"\"Raised when operation times out.\"\"\"\n    pass\n```\n\n### 3. api_client.py - Mock API Client\n\n```python\n\"\"\"\nMock API client for database operations.\nIn production, this would interact with a real API.\n\"\"\"\nimport time\nimport uuid\nfrom typing import Dict, Optional, List\nfrom datetime import datetime\n\nfrom .models import DatabaseConfig, DatabaseState, DatabaseStatus\nfrom .exceptions import (\n    DatabaseNotFoundError,\n    DatabaseAlreadyExistsError,\n    DatabaseOperationError,\n    DatabaseTimeoutError\n)\n\n\nclass DatabaseAPIClient:\n    \"\"\"Mock API client for database operations.\"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the API client.\"\"\"\n        self._databases: Dict[str, DatabaseState] = {}\n        self._operation_delay = 0.5  # Simulate API latency\n    \n    def create_database(self, config: DatabaseConfig) -> DatabaseState:\n        \"\"\"\n        Create a new database.\n        \n        Args:\n            config: Database configuration\n            \n        Returns:\n            DatabaseState: Created database state\n            \n        Raises:\n            DatabaseAlreadyExistsError: If database already exists\n            DatabaseOperationError: If creation fails\n        \"\"\"\n        # Check if database already exists\n        for db in self._databases.values():\n            if db.name == config.name:\n                raise DatabaseAlreadyExistsError(\n                    f\"Database with name '{config.name}' already exists\"\n                )\n        \n        # Simulate API call\n        time.sleep(self._operation_delay)\n        \n        # Generate database ID and properties\n        db_id = str(uuid.uuid4())\n        port = self._get_default_port(config.engine)\n        endpoint = f\"{config.name}.db.example.com\"\n        arn = f\"arn:aws:rds:us-east-1:123456789012:db:{config.name}\"\n        \n        # Create database state\n        state = DatabaseState(\n            id=db_id,\n            name=config.name,\n            engine=config.engine,\n            size=config.size,\n            status=DatabaseStatus.CREATING.value,\n            endpoint=endpoint,\n            port=port,\n            arn=arn,\n            tags=config.tags,\n            backup_enabled=config.backup_enabled,\n            multi_az=config.multi_az,\n            created_at=datetime.utcnow().isoformat(),\n            updated_at=datetime.utcnow().isoformat()\n        )\n        \n        self._databases[db_id] = state\n        \n        # Simulate async creation\n        self._wait_for_status(db_id, DatabaseStatus.AVAILABLE, timeout=30)\n        \n        return self._databases[db_id]\n    \n    def get_database(self, db_id: str) -> DatabaseState:\n        \"\"\"\n        Get database by ID.\n        \n        Args:\n            db_id: Database ID\n            \n        Returns:\n            DatabaseState: Database state\n            \n        Raises:\n            DatabaseNotFoundError: If database not found\n        \"\"\"\n        time.sleep(self._operation_delay)\n        \n        if db_id not in self._databases:\n            raise DatabaseNotFoundError(f\"Database with ID '{db_id}' not found\")\n        \n        return self._databases[db_id]\n    \n    def update_database(\n        self,\n        db_id: str,\n        config: DatabaseConfig\n    ) -> DatabaseState:\n        \"\"\"\n        Update database configuration.\n        \n        Args:\n            db_id: Database ID\n            config: New configuration\n            \n        Returns:\n            DatabaseState: Updated database state\n            \n        Raises:\n            DatabaseNotFoundError: If database not found\n            DatabaseOperationError: If update fails\n        \"\"\"\n        if db_id not in self._databases:\n            raise DatabaseNotFoundError(f\"Database with ID '{db_id}' not found\")\n        \n        time.sleep(self._operation_delay)\n        \n        db = self._databases[db_id]\n        \n        # Set status to modifying\n        db.status = DatabaseStatus.MODIFYING.value\n        \n        # Update properties\n        db.size = config.size\n        db.tags = config.tags\n        db.backup_enabled = config.backup_enabled\n        db.multi_az = config.multi_az\n        db.updated_at = datetime.utcnow().isoformat()\n        \n        # Simulate async update\n        self._wait_for_status(db_id, DatabaseStatus.AVAILABLE, timeout=30)\n        \n        return self._databases[db_id]\n    \n    def delete_database(self, db_id: str) -> None:\n        \"\"\"\n        Delete database.\n        \n        Args:\n            db_id: Database ID\n            \n        Raises:\n            DatabaseNotFoundError: If database not found\n        \"\"\"\n        if db_id not in self._databases:\n            raise DatabaseNotFoundError(f\"Database with ID '{db_id}' not found\")\n        \n        time.sleep(self._operation_delay)\n        \n        # Set status to deleting\n        self._databases[db_id].status = DatabaseStatus.DELETING.value\n        \n        # Simulate async deletion\n        time.sleep(1)\n        \n        # Remove from storage\n        del self._databases[db_id]\n    \n    def list_databases(self) -> List[DatabaseState]:\n        \"\"\"\n        List all databases.\n        \n        Returns:\n            List[DatabaseState]: List of databases\n        \"\"\"\n        time.sleep(self._operation_delay)\n        return list(self._databases.values())\n    \n    def _wait_for_status(\n        self,\n        db_id: str,\n        target_status: DatabaseStatus,\n        timeout: int = 60\n    ) -> None:\n        \"\"\"\n        Wait for database to reach target status.\n        \n        Args:\n            db_id: Database ID\n            target_status: Target status\n            timeout: Timeout in seconds\n            \n        Raises:\n            DatabaseTimeoutError: If timeout is reached\n        \"\"\"\n        start_time = time.time()\n        \n        while time.time() - start_time < timeout:\n            if db_id not in self._databases:\n                return\n            \n            db = self._databases[db_id]\n            \n            if db.status == target_status.value:\n                return\n            \n            if db.status == DatabaseStatus.FAILED.value:\n                raise DatabaseOperationError(\n                    f\"Database operation failed for '{db_id}'\"\n                )\n            \n            time.sleep(1)\n        \n        raise DatabaseTimeoutError(\n            f\"Timeout waiting for database '{db_id}' \"\n            f\"to reach status '{target_status.value}'\"\n        )\n    \n    @staticmethod\n    def _get_default_port(engine: str) -> int:\n        \"\"\"Get default port for database engine.\"\"\"\n        ports = {\n            \"postgres\": 5432,\n            \"mysql\": 3306,\n            \"mongodb\": 27017,\n            \"redis\": 6379\n        }\n        return ports.get(engine, 5432)\n```\n\n### 4. database_provider.py - Dynamic Provider Implementation\n\n```python\n\"\"\"\nPulumi dynamic provider implementation for database resources.\n\"\"\"\nfrom typing import Any, Optional\nimport pulumi\nfrom pulumi.dynamic import ResourceProvider, CreateResult, UpdateResult\n\nfrom .api_client import DatabaseAPIClient\nfrom .models import DatabaseInputs, DatabaseState\nfrom .exceptions import (\n    DatabaseProviderError,\n    DatabaseNotFoundError,\n    DatabaseAlreadyExistsError\n)\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"\n    Dynamic provider for database resources.\n    Implements CRUD operations using the Pulumi dynamic provider interface.\n    \"\"\"\n    \n    def __init__(self):\n        \"\"\"Initialize the provider.\"\"\"\n        super().__init__()\n        self.client = DatabaseAPIClient()\n    \n    def create(self, props: dict) -> CreateResult:\n        \"\"\"\n        Create a new database resource.\n        \n        Args:\n            props: Resource properties\n            \n        Returns:\n            CreateResult: Creation result with ID and outputs\n            \n        Raises:\n            DatabaseProviderError: If creation fails\n        \"\"\"\n        try:\n            # Parse inputs\n            inputs = self._parse_inputs(props)\n            config = inputs.to_config()\n            \n            # Log creation\n            pulumi.log.info(\n                f\"Creating database: {config.name} \"\n                f\"(engine={config.engine}, size={config.size})\"\n            )\n            \n            # Create database via API\n            state = self.client.create_database(config)\n            \n            # Log success\n            pulumi.log.info(\n                f\"Successfully created database: {state.name} \"\n                f\"(id={state.id})\"\n            )\n            \n            # Return result\n            return CreateResult(\n                id_=state.id,\n                outs=self._state_to_outputs(state)\n            )\n            \n        except DatabaseAlreadyExistsError as e:\n            pulumi.log.error(f\"Database already exists: {e}\")\n            raise\n        except DatabaseProviderError as e:\n            pulumi.log.error(f\"Failed to create database: {e}\")\n            raise\n        except Exception as e:\n            pulumi.log.error(f\"Unexpected error creating database: {e}\")\n            raise DatabaseProviderError(f\"Failed to create database: {e}\")\n    \n    def read(self, id_: str, props: dict) -> pulumi.dynamic.ReadResult:\n        \"\"\"\n        Read database resource state.\n        \n        Args:\n            id_: Resource ID\n            props: Current properties\n            \n        Returns:\n            ReadResult: Current state\n        \"\"\"\n        try:\n            pulumi.log.debug(f\"Reading database: {id_}\")\n            \n            # Get database state from API\n            state = self.client.get_database(id_)\n            \n            # Return current state\n            return pulumi.dynamic.ReadResult(\n                id_=state.id,\n                outs=self._state_to_outputs(state)\n            )\n            \n        except DatabaseNotFoundError:\n            pulumi.log.warn(f\"Database not found: {id_}\")\n            # Return None to indicate resource doesn't exist\n            return pulumi.dynamic.ReadResult(id_=None, outs={})\n        except Exception as e:\n            pulumi.log.error(f\"Failed to read database {id_}: {e}\")\n            raise DatabaseProviderError(f\"Failed to read database: {e}\")\n    \n    def update(\n        self,\n        id_: str,\n        old_props: dict,\n        new_props: dict\n    ) -> UpdateResult:\n        \"\"\"\n        Update database resource.\n        \n        Args:\n            id_: Resource ID\n            old_props: Old properties\n            new_props: New properties\n            \n        Returns:\n            UpdateResult: Update result with outputs\n            \n        Raises:\n            DatabaseProviderError: If update fails\n        \"\"\"\n        try:\n            # Parse new inputs\n            inputs = self._parse_inputs(new_props)\n            config = inputs.to_config()\n            \n            # Log update\n            pulumi.log.info(f\"Updating database: {id_}\")\n            \n            # Check for immutable property changes\n            old_inputs = self._parse_inputs(old_props)\n            if old_inputs.name != inputs.name:\n                raise DatabaseProviderError(\n                    \"Cannot change database name (requires replacement)\"\n                )\n            if old_inputs.engine != inputs.engine:\n                raise DatabaseProviderError(\n                    \"Cannot change database engine (requires replacement)\"\n                )\n            \n            # Update database via API\n            state = self.client.update_database(id_, config)\n            \n            # Log success\n            pulumi.log.info(f\"Successfully updated database: {id_}\")\n            \n            # Return result\n            return UpdateResult(outs=self._state_to_outputs(state))\n            \n        except DatabaseProviderError:\n            raise\n        except Exception as e:\n            pulumi.log.error(f\"Failed to update database {id_}: {e}\")\n            raise DatabaseProvider",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4779,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a Python Pulumi dynamic provider for a custom database service with full CRUD operations.\n\n```python\n# src/pulumi_provider/database_provider.py\n\"\"\"Pulumi dynamic provider for custom database service.\"\"\"\nimport logging\nfrom typing import Any, Optional\nfrom pulumi import Input, Output, ResourceOptions\nfrom pulumi.dynamic import Resource, ResourceProvider, CreateResult, UpdateResult\n\nlogger = logging.getLogger(__name__)\n\n\nclass DatabaseProvider(ResourceProvider):\n    \"\"\"Dynamic provider implementing CRUD operations for database resources.\"\"\"\n\n    def __init__(self, api_client: Optional[Any] = None):\n        \"\"\"\n        Initialize the database provider.\n        \n        Args:\n            api_client: Optional API client for database service operations.\n                       If None, uses mock implementation for testing.\n        \"\"\"\n        self.api_client = api_client or MockDatabaseClient()\n        super().__init__()\n\n    def create(self, props: dict[str, Any]) -> CreateResult:\n        \"\"\"\n        Create a new database resource.\n        \n        Args:\n            props: Resource properties (name, engine, size)\n            \n        Returns:\n            CreateResult with resource ID and outputs\n        \"\"\"\n        try:\n            name = props.get(\"name\")\n            engine = props.get(\"engine\", \"postgres\")\n            size = props.get(\"size\", \"small\")\n            \n            # Validate inputs\n            self._validate_props(props)\n            \n            # Create database via API\n            logger.info(f\"Creating database: {name} (engine={engine}, size={size})\")\n            result = self.api_client.create_database(\n                name=name,\n                engine=engine,\n                size=size\n            )\n            \n            # Return resource ID and outputs\n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"endpoint\": result[\"endpoint\"],\n                \"status\": result[\"status\"],\n                \"created_at\": result[\"created_at\"],\n            }\n            \n            logger.info(f\"Database created successfully: {result['id']}\")\n            return CreateResult(id_=result[\"id\"], outs=outputs)\n            \n        except Exception as e:\n            logger.error(f\"Failed to create database: {e}\")\n            raise\n\n    def read(self, id_: str, props: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"\n        Read current state of database resource.\n        \n        Args:\n            id_: Resource ID\n            props: Current resource properties\n            \n        Returns:\n            Current resource state\n        \"\"\"\n        try:\n            logger.info(f\"Reading database: {id_}\")\n            result = self.api_client.get_database(id_)\n            \n            if result is None:\n                logger.warning(f\"Database not found: {id_}\")\n                return {}\n            \n            return {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"endpoint\": result[\"endpoint\"],\n                \"status\": result[\"status\"],\n                \"created_at\": result[\"created_at\"],\n            }\n            \n        except Exception as e:\n            logger.error(f\"Failed to read database {id_}: {e}\")\n            raise\n\n    def update(self, id_: str, old_props: dict[str, Any], new_props: dict[str, Any]) -> UpdateResult:\n        \"\"\"\n        Update existing database resource.\n        \n        Args:\n            id_: Resource ID\n            old_props: Previous resource properties\n            new_props: New resource properties\n            \n        Returns:\n            UpdateResult with updated outputs\n        \"\"\"\n        try:\n            # Validate new properties\n            self._validate_props(new_props)\n            \n            # Check what changed\n            changes = self._get_changes(old_props, new_props)\n            \n            if not changes:\n                logger.info(f\"No changes detected for database: {id_}\")\n                return UpdateResult(outs=old_props)\n            \n            # Check if replacement is needed (name or engine change)\n            if \"name\" in changes or \"engine\" in changes:\n                logger.warning(f\"Database {id_} requires replacement due to immutable property change\")\n                # Pulumi will handle replacement automatically\n                return UpdateResult(outs=new_props)\n            \n            # Update database via API\n            logger.info(f\"Updating database {id_}: {changes}\")\n            result = self.api_client.update_database(\n                id_=id_,\n                size=new_props.get(\"size\")\n            )\n            \n            outputs = {\n                \"name\": result[\"name\"],\n                \"engine\": result[\"engine\"],\n                \"size\": result[\"size\"],\n                \"endpoint\": result[\"endpoint\"],\n                \"status\": result[\"status\"],\n                \"created_at\": result[\"created_at\"],\n            }\n            \n            logger.info(f\"Database updated successfully: {id_}\")\n            return UpdateResult(outs=outputs)\n            \n        except Exception as e:\n            logger.error(f\"Failed to update database {id_}: {e}\")\n            raise\n\n    def delete(self, id_: str, props: dict[str, Any]) -> None:\n        \"\"\"\n        Delete database resource.\n        \n        Args:\n            id_: Resource ID\n            props: Resource properties\n        \"\"\"\n        try:\n            logger.info(f\"Deleting database: {id_}\")\n            self.api_client.delete_database(id_)\n            logger.info(f\"Database deleted successfully: {id_}\")\n            \n        except Exception as e:\n            logger.error(f\"Failed to delete database {id_}: {e}\")\n            raise\n\n    def _validate_props(self, props: dict[str, Any]) -> None:\n        \"\"\"Validate resource properties.\"\"\"\n        name = props.get(\"name\")\n        if not name or not isinstance(name, str):\n            raise ValueError(\"Property 'name' is required and must be a string\")\n        \n        if len(name) < 3 or len(name) > 63:\n            raise ValueError(\"Property 'name' must be between 3 and 63 characters\")\n        \n        engine = props.get(\"engine\", \"postgres\")\n        valid_engines = [\"postgres\", \"mysql\", \"mongodb\", \"redis\"]\n        if engine not in valid_engines:\n            raise ValueError(f\"Property 'engine' must be one of: {', '.join(valid_engines)}\")\n        \n        size = props.get(\"size\", \"small\")\n        valid_sizes = [\"small\", \"medium\", \"large\", \"xlarge\"]\n        if size not in valid_sizes:\n            raise ValueError(f\"Property 'size' must be one of: {', '.join(valid_sizes)}\")\n\n    def _get_changes(self, old_props: dict[str, Any], new_props: dict[str, Any]) -> dict[str, Any]:\n        \"\"\"Identify changed properties.\"\"\"\n        changes = {}\n        for key in [\"name\", \"engine\", \"size\"]:\n            old_val = old_props.get(key)\n            new_val = new_props.get(key)\n            if old_val != new_val:\n                changes[key] = {\"old\": old_val, \"new\": new_val}\n        return changes\n\n\nclass Database(Resource):\n    \"\"\"\n    Custom database resource managed by Pulumi.\n    \n    Example usage:\n        db = Database(\n            \"my-database\",\n            name=\"myapp-db\",\n            engine=\"postgres\",\n            size=\"medium\"\n        )\n    \"\"\"\n    \n    name: Output[str]\n    engine: Output[str]\n    size: Output[str]\n    endpoint: Output[str]\n    status: Output[str]\n    created_at: Output[str]\n\n    def __init__(\n        self,\n        resource_name: str,\n        name: Input[str],\n        engine: Input[str] = \"postgres\",\n        size: Input[str] = \"small\",\n        opts: Optional[ResourceOptions] = None,\n        api_client: Optional[Any] = None,\n    ):\n        \"\"\"\n        Create a new database resource.\n        \n        Args:\n            resource_name: Pulumi resource name\n            name: Database name\n            engine: Database engine (postgres, mysql, mongodb, redis)\n            size: Database size (small, medium, large, xlarge)\n            opts: Pulumi resource options\n            api_client: Optional API client for database operations\n        \"\"\"\n        props = {\n            \"name\": name,\n            \"engine\": engine,\n            \"size\": size,\n        }\n        \n        provider = DatabaseProvider(api_client)\n        \n        super().__init__(\n            provider,\n            resource_name,\n            props,\n            opts\n        )\n\n\nclass MockDatabaseClient:\n    \"\"\"Mock database API client for testing.\"\"\"\n    \n    def __init__(self):\n        self._databases: dict[str, dict[str, Any]] = {}\n        self._id_counter = 1\n\n    def create_database(self, name: str, engine: str, size: str) -> dict[str, Any]:\n        \"\"\"Create a new database.\"\"\"\n        import datetime\n        \n        db_id = f\"db-{self._id_counter:06d}\"\n        self._id_counter += 1\n        \n        database = {\n            \"id\": db_id,\n            \"name\": name,\n            \"engine\": engine,\n            \"size\": size,\n            \"endpoint\": f\"{name}.{engine}.example.com:5432\",\n            \"status\": \"active\",\n            \"created_at\": datetime.datetime.utcnow().isoformat(),\n        }\n        \n        self._databases[db_id] = database\n        return database\n\n    def get_database(self, id_: str) -> Optional[dict[str, Any]]:\n        \"\"\"Get database by ID.\"\"\"\n        return self._databases.get(id_)\n\n    def update_database(self, id_: str, size: str) -> dict[str, Any]:\n        \"\"\"Update database size.\"\"\"\n        if id_ not in self._databases:\n            raise ValueError(f\"Database not found: {id_}\")\n        \n        self._databases[id_][\"size\"] = size\n        self._databases[id_][\"status\"] = \"active\"\n        return self._databases[id_]\n\n    def delete_database(self, id_: str) -> None:\n        \"\"\"Delete database.\"\"\"\n        if id_ in self._databases:\n            del self._databases[id_]\n```\n\n```python\n# tests/test_database_provider.py\n\"\"\"Tests for database Pulumi provider.\"\"\"\nimport pytest\nfrom unittest.mock import Mock, patch\nfrom pulumi.dynamic import CreateResult, UpdateResult\nfrom src.pulumi_provider.database_provider import (\n    DatabaseProvider,\n    MockDatabaseClient,\n)\n\n\nclass TestDatabaseProvider:\n    \"\"\"Test suite for DatabaseProvider.\"\"\"\n\n    def test_create_database_success(self):\n        \"\"\"Test successful database creation.\"\"\"\n        provider = DatabaseProvider()\n        \n        props = {\n            \"name\": \"test-db\",\n            \"engine\": \"postgres\",\n            \"size\": \"medium\",\n        }\n        \n        result = provider.create(props)\n        \n        assert isinstance(result, CreateResult)\n        assert result.id_.startswith(\"db-\")\n        assert result.outs[\"name\"] == \"test-db\"\n        assert result.outs[\"engine\"] == \"postgres\"\n        assert result.outs[\"size\"] == \"medium\"\n        assert \"endpoint\" in result.outs\n        assert result.outs[\"status\"] == \"active\"\n\n    def test_create_database_validation_error(self):\n        \"\"\"Test database creation with invalid properties.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Missing name\n        with pytest.raises(ValueError, match=\"name.*required\"):\n            provider.create({\"engine\": \"postgres\"})\n        \n        # Invalid engine\n        with pytest.raises(ValueError, match=\"engine.*must be one of\"):\n            provider.create({\"name\": \"test-db\", \"engine\": \"invalid\"})\n        \n        # Invalid size\n        with pytest.raises(ValueError, match=\"size.*must be one of\"):\n            provider.create({\"name\": \"test-db\", \"size\": \"invalid\"})\n        \n        # Name too short\n        with pytest.raises(ValueError, match=\"name.*between 3 and 63\"):\n            provider.create({\"name\": \"ab\"})\n\n    def test_read_database_success(self):\n        \"\"\"Test reading database state.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database first\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"mysql\",\n            \"size\": \"small\",\n        })\n        \n        # Read database\n        read_result = provider.read(create_result.id_, {})\n        \n        assert read_result[\"name\"] == \"test-db\"\n        assert read_result[\"engine\"] == \"mysql\"\n        assert read_result[\"size\"] == \"small\"\n\n    def test_read_database_not_found(self):\n        \"\"\"Test reading non-existent database.\"\"\"\n        provider = DatabaseProvider()\n        \n        result = provider.read(\"non-existent-id\", {})\n        \n        assert result == {}\n\n    def test_update_database_size(self):\n        \"\"\"Test updating database size.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"postgres\",\n            \"size\": \"small\",\n        })\n        \n        # Update size\n        old_props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"small\"}\n        new_props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"large\"}\n        \n        update_result = provider.update(create_result.id_, old_props, new_props)\n        \n        assert isinstance(update_result, UpdateResult)\n        assert update_result.outs[\"size\"] == \"large\"\n        assert update_result.outs[\"name\"] == \"test-db\"\n\n    def test_update_database_no_changes(self):\n        \"\"\"Test update with no property changes.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"postgres\",\n            \"size\": \"medium\",\n        })\n        \n        # Update with same properties\n        props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"medium\"}\n        \n        update_result = provider.update(create_result.id_, props, props)\n        \n        assert isinstance(update_result, UpdateResult)\n        assert update_result.outs == props\n\n    def test_update_immutable_property(self):\n        \"\"\"Test updating immutable properties (name, engine).\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"postgres\",\n            \"size\": \"small\",\n        })\n        \n        # Try to update name (immutable)\n        old_props = {\"name\": \"test-db\", \"engine\": \"postgres\", \"size\": \"small\"}\n        new_props = {\"name\": \"new-name\", \"engine\": \"postgres\", \"size\": \"small\"}\n        \n        update_result = provider.update(create_result.id_, old_props, new_props)\n        \n        # Should return new props (Pulumi will handle replacement)\n        assert update_result.outs[\"name\"] == \"new-name\"\n\n    def test_delete_database_success(self):\n        \"\"\"Test successful database deletion.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Create database\n        create_result = provider.create({\n            \"name\": \"test-db\",\n            \"engine\": \"postgres\",\n            \"size\": \"small\",\n        })\n        \n        # Delete database\n        provider.delete(create_result.id_, {})\n        \n        # Verify deletion\n        read_result = provider.read(create_result.id_, {})\n        assert read_result == {}\n\n    def test_delete_database_idempotent(self):\n        \"\"\"Test deleting non-existent database is idempotent.\"\"\"\n        provider = DatabaseProvider()\n        \n        # Should not raise error\n        provider.delete(\"non-existent-id\", {})\n\n\nclass TestMockDatabaseClient:\n    \"\"\"Test suite for MockDatabaseClient.\"\"\"\n\n    def test_create_database(self):\n        \"\"\"Test creating database via mock client.\"\"\"\n        client = MockDatabaseClient()\n        \n        result = client.create_database(\"test-db\", \"postgres\", \"medium\")\n        \n        assert result[\"id\"].startswith(\"db-\")\n        assert result[\"name\"] == \"test-db\"\n        assert result[\"engine\"] == \"postgres\"\n        assert result[\"size\"] == \"medium\"\n        assert \"endpoint\" in result\n        assert result[\"status\"] == \"active\"",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5305,
            "output_tokens": 4096,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "provider-resources-03",
      "task_type": "similar_syntax",
      "target_language": "go",
      "expected_patterns": [
        "resource\\.ParallelTest\\(t",
        "resource\\.TestCase\\{",
        "acctest\\.PreCheck",
        "ProtoV5ProviderFactories",
        "CheckDestroy",
        "ImportState.*true",
        "testAccCheck.*Exists",
        "testAccCheck.*Destroy",
        "ExpectNonEmptyPlan"
      ],
      "anti_patterns": [
        "terraform plan|terraform apply",
        "\\$ terraform",
        "resource\\s+\"\\w+\"\\s+\"\\w+\"",
        "pytest|unittest|describe\\(",
        "go test -run"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/internal/provider/example_resource_test.go",
          "description": "Terraform acceptance testing: resource.Test with resource.TestCase{}, resource.TestStep, PreCheck function, ProtoV6ProviderFactories (note: example uses V6, but V5 pattern is similar), CheckDestroy, ImportState verification, modern state checking with statecheck.ExpectKnownValue()"
        },
        {
          "url": "https://pkg.go.dev/github.com/hashicorp/terraform-plugin-testing/helper/resource",
          "description": "Test helper package: resource.ParallelTest, TestCase, TestStep, ImportState, CheckDestroy patterns, ExpectNonEmptyPlan"
        },
        {
          "url": "https://pkg.go.dev/testing",
          "description": "Go testing package - source of func TestAccFoo(t *testing.T) test function signature pattern for acceptance tests"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "```go\npackage provider\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"testing\"\n\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n\t\"github.com/hashicorp/terraform-plugin-testing/terraform\"\n)\n\nfunc TestAccCloudDatabase_basic(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"mycloud_database.test\"\n\tdatabaseName := fmt.Sprintf(\"tf-test-%s\", acctest.RandString(10))\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t// Create and Read testing\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(databaseName, \"db.small\", 20),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", databaseName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_type\", \"db.small\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_gb\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.0\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Environment\", \"test\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.ManagedBy\", \"terraform\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"id\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"port\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"status\"),\n\t\t\t\t\tresource.TestMatchResourceAttr(resourceName, \"endpoint\", regexp.MustCompile(`^[a-z0-9-]+\\.database\\.cloud\\.example\\.com$`)),\n\t\t\t\t),\n\t\t\t},\n\t\t\t// ImportState testing\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",           // Sensitive field not returned by API\n\t\t\t\t\t\"apply_immediately\",  // Configuration-only field\n\t\t\t\t},\n\t\t\t},\n\t\t\t// Update and Read testing\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(databaseName, \"db.medium\", 30),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", databaseName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_type\", \"db.medium\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_gb\", \"30\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_disappears(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"mycloud_database.test\"\n\tdatabaseName := fmt.Sprintf(\"tf-test-%s\", acctest.RandString(10))\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(databaseName, \"db.small\", 20),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\ttestAccCheckCloudDatabaseDisappears(&database),\n\t\t\t\t),\n\t\t\t\tExpectNonEmptyPlan: true,\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_tags(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"mycloud_database.test\"\n\tdatabaseName := fmt.Sprintf(\"tf-test-%s\", acctest.RandString(10))\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_tags1(databaseName, \"key1\", \"value1\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_tags2(databaseName, \"key1\", \"value1updated\", \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1updated\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_tags1(databaseName, \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_backupRetention(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"mycloud_database.test\"\n\tdatabaseName := fmt.Sprintf(\"tf-test-%s\", acctest.RandString(10))\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_backupRetention(databaseName, 7),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_days\", \"7\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_backupRetention(databaseName, 14),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_days\", \"14\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Helper Functions\n\nfunc testAccCheckCloudDatabaseExists(resourceName string, database *CloudDatabase) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\trs, ok := s.RootModule().Resources[resourceName]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Not found: %s\", resourceName)\n\t\t}\n\n\t\tif rs.Primary.ID == \"\" {\n\t\t\treturn fmt.Errorf(\"No Database ID is set\")\n\t\t}\n\n\t\tclient := testAccProvider.Meta().(*Client)\n\t\tctx := context.Background()\n\n\t\tfoundDatabase, err := client.GetDatabase(ctx, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif foundDatabase.ID != rs.Primary.ID {\n\t\t\treturn fmt.Errorf(\"Database not found: %s\", rs.Primary.ID)\n\t\t}\n\n\t\t*database = *foundDatabase\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckCloudDatabaseDestroy(s *terraform.State) error {\n\tclient := testAccProvider.Meta().(*Client)\n\tctx := context.Background()\n\n\tfor _, rs := range s.RootModule().Resources {\n\t\tif rs.Type != \"mycloud_database\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tdatabase, err := client.GetDatabase(ctx, rs.Primary.ID)\n\t\tif err == nil {\n\t\t\tif database.Status != \"deleted\" {\n\t\t\t\treturn fmt.Errorf(\"Database %s still exists with status: %s\", rs.Primary.ID, database.Status)\n\t\t\t}\n\t\t}\n\n\t\t// Verify the error is a \"not found\" error\n\t\tif !isNotFoundError(err) {\n\t\t\treturn fmt.Errorf(\"Error checking for database deletion: %s\", err)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc testAccCheckCloudDatabaseDisappears(database *CloudDatabase) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tclient := testAccProvider.Meta().(*Client)\n\t\tctx := context.Background()\n\n\t\terr := client.DeleteDatabase(ctx, database.ID)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Error deleting database: %s\", err)\n\t\t}\n\n\t\t// Wait for database to be fully deleted\n\t\treturn waitForDatabaseDeletion(ctx, client, database.ID)\n\t}\n}\n\n// Configuration Functions\n\nfunc testAccCloudDatabaseConfig_basic(name, instanceType string, storageGB int) string {\n\treturn fmt.Sprintf(`\nresource \"mycloud_database\" \"test\" {\n  name          = %[1]q\n  instance_type = %[2]q\n  storage_gb    = %[3]d\n  engine        = \"postgres\"\n  engine_version = \"14.0\"\n  \n  username = \"admin\"\n  password = \"TestPassword123!\"\n  \n  tags = {\n    Environment = \"test\"\n    ManagedBy   = \"terraform\"\n  }\n}\n`, name, instanceType, storageGB)\n}\n\nfunc testAccCloudDatabaseConfig_tags1(name, tagKey1, tagValue1 string) string {\n\treturn fmt.Sprintf(`\nresource \"mycloud_database\" \"test\" {\n  name          = %[1]q\n  instance_type = \"db.small\"\n  storage_gb    = 20\n  engine        = \"postgres\"\n  engine_version = \"14.0\"\n  \n  username = \"admin\"\n  password = \"TestPassword123!\"\n  \n  tags = {\n    %[2]q = %[3]q\n  }\n}\n`, name, tagKey1, tagValue1)\n}\n\nfunc testAccCloudDatabaseConfig_tags2(name, tagKey1, tagValue1, tagKey2, tagValue2 string) string {\n\treturn fmt.Sprintf(`\nresource \"mycloud_database\" \"test\" {\n  name          = %[1]q\n  instance_type = \"db.small\"\n  storage_gb    = 20\n  engine        = \"postgres\"\n  engine_version = \"14.0\"\n  \n  username = \"admin\"\n  password = \"TestPassword123!\"\n  \n  tags = {\n    %[2]q = %[3]q\n    %[4]q = %[5]q\n  }\n}\n`, name, tagKey1, tagValue1, tagKey2, tagValue2)\n}\n\nfunc testAccCloudDatabaseConfig_backupRetention(name string, retentionDays int) string {\n\treturn fmt.Sprintf(`\nresource \"mycloud_database\" \"test\" {\n  name          = %[1]q\n  instance_type = \"db.small\"\n  storage_gb    = 20\n  engine        = \"postgres\"\n  engine_version = \"14.0\"\n  \n  username = \"admin\"\n  password = \"TestPassword123!\"\n  \n  backup_retention_days = %[2]d\n  \n  tags = {\n    Environment = \"test\"\n  }\n}\n`, name, retentionDays)\n}\n\n// Utility Functions\n\nfunc testAccPreCheck(t *testing.T) {\n\t// Add any necessary pre-check validations\n\t// For example, checking for required environment variables\n\tif v := testAccGetEnv(\"MYCLOUD_API_KEY\"); v == \"\" {\n\t\tt.Fatal(\"MYCLOUD_API_KEY must be set for acceptance tests\")\n\t}\n\tif v := testAccGetEnv(\"MYCLOUD_API_URL\"); v == \"\" {\n\t\tt.Fatal(\"MYCLOUD_API_URL must be set for acceptance tests\")\n\t}\n}\n\nfunc testAccGetEnv(key string) string {\n\t// Implementation to get environment variable\n\t// This is a placeholder - implement according to your needs\n\treturn \"\"\n}\n\nfunc isNotFoundError(err error) bool {\n\t// Implement logic to check if error is a \"not found\" error\n\t// This depends on your API client implementation\n\tif err == nil {\n\t\treturn false\n\t}\n\t// Example implementation:\n\t// return strings.Contains(err.Error(), \"not found\") || strings.Contains(err.Error(), \"404\")\n\treturn false\n}\n\nfunc waitForDatabaseDeletion(ctx context.Context, client *Client, databaseID string) error {\n\t// Implement polling logic to wait for database deletion\n\t// This is a simplified example\n\tmaxAttempts := 30\n\tfor i := 0; i < maxAttempts; i++ {\n\t\t_, err := client.GetDatabase(ctx, databaseID)\n\t\tif isNotFoundError(err) {\n\t\t\treturn nil\n\t\t}\n\t\t// Sleep between attempts (use time.Sleep in real implementation)\n\t}\n\treturn fmt.Errorf(\"Timeout waiting for database deletion\")\n}\n\n// Type definitions (these would typically be in your provider package)\n\ntype CloudDatabase struct {\n\tID                  string\n\tName                string\n\tInstanceType        string\n\tStorageGB           int\n\tEngine              string\n\tEngineVersion       string\n\tStatus              string\n\tEndpoint            string\n\tPort                int\n\tBackupRetentionDays int\n\tTags                map[string]string\n}\n\ntype Client struct {\n\t// Client fields\n}\n\nfunc (c *Client) GetDatabase(ctx context.Context, id string) (*CloudDatabase, error) {\n\t// Implementation\n\treturn nil, nil\n}\n\nfunc (c *Client) DeleteDatabase(ctx context.Context, id string) error {\n\t// Implementation\n\treturn nil\n}\n\nvar (\n\ttestAccProvider                  interface{}\n\ttestAccProtoV6ProviderFactories map[string]func() (interface{}, error)\n)\n```\n\nThis comprehensive acceptance test suite includes:\n\n1. **Basic Test**: Creates, reads, updates, and imports a database resource\n2. **Disappears Test**: Verifies the provider handles out-of-band resource deletion\n3. **Tags Test**: Tests tag creation, updates, and removal\n4. **Backup Retention Test**: Tests updating configuration parameters\n5. **Helper Functions**:\n   - `testAccCheckCloudDatabaseExists`: Verifies resource exists in the API\n   - `testAccCheckCloudDatabaseDestroy`: Verifies all resources are destroyed\n   - `testAccCheckCloudDatabaseDisappears`: Manually deletes a resource\n6. **Configuration Functions**: Generate HCL configurations for different test scenarios\n7. **Utility Functions**: Pre-checks, error handling, and wait functions\n\nThe tests follow Terraform's standard patterns and use `resource.ParallelTest` for concurrent execution.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 66,
            "output_tokens": 4036,
            "cached": false
          },
          "with_skill": {
            "output": "# Terraform Provider Database Resource Acceptance Tests\n\nHere's a comprehensive acceptance test suite for a cloud database resource following Terraform provider testing best practices:\n\n```go\n// internal/service/database/database_test.go\npackage database_test\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"testing\"\n\n    \"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n    \"github.com/hashicorp/terraform-plugin-testing/terraform\"\n    sdkacctest \"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n    \"github.com/provider/internal/acctest\"\n    \"github.com/provider/internal/conns\"\n    \"github.com/provider/internal/service/database\"\n    tfdatabase \"github.com/provider/internal/service/database\"\n    \"github.com/provider/internal/tfresource\"\n)\n\nfunc TestAccDatabaseInstance_basic(t *testing.T) {\n    ctx := acctest.Context(t)\n    var dbInstance database.DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_basic(rName),\n                Check: resource.ComposeAggregateTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    resource.TestCheckResourceAttr(resourceName, \"name\", rName),\n                    resource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n                    resource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.7\"),\n                    resource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n                    resource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n                    resource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp2\"),\n                    resource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n                    resource.TestCheckResourceAttr(resourceName, \"multi_az\", \"false\"),\n                    resource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.Environment\", \"test\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"port\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"status\"),\n                    acctest.CheckResourceAttrRegionalARN(resourceName, \"arn\", \"database\", fmt.Sprintf(\"db:%s\", rName)),\n                ),\n            },\n            {\n                ResourceName:      resourceName,\n                ImportState:       true,\n                ImportStateVerify: true,\n                ImportStateVerifyIgnore: []string{\n                    \"password\",\n                    \"skip_final_snapshot\",\n                    \"final_snapshot_identifier\",\n                },\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_disappears(t *testing.T) {\n    ctx := acctest.Context(t)\n    var dbInstance database.DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_basic(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    acctest.CheckResourceDisappears(ctx, acctest.Provider, tfdatabase.ResourceDatabaseInstance(), resourceName),\n                ),\n                ExpectNonEmptyPlan: true,\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_tags(t *testing.T) {\n    ctx := acctest.Context(t)\n    var dbInstance database.DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_tags1(rName, \"key1\", \"value1\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1\"),\n                ),\n            },\n            {\n                ResourceName:      resourceName,\n                ImportState:       true,\n                ImportStateVerify: true,\n                ImportStateVerifyIgnore: []string{\n                    \"password\",\n                    \"skip_final_snapshot\",\n                },\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_tags2(rName, \"key1\", \"value1updated\", \"key2\", \"value2\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1updated\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n                ),\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_tags1(rName, \"key2\", \"value2\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n                ),\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_update(t *testing.T) {\n    ctx := acctest.Context(t)\n    var dbInstance1, dbInstance2, dbInstance3 database.DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_basic(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance1),\n                    resource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n                    resource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n                ),\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_updated(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance2),\n                    testAccCheckDatabaseInstanceNotRecreated(&dbInstance1, &dbInstance2),\n                    resource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n                    resource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"14\"),\n                ),\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_instanceClass(rName, \"db.t3.small\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance3),\n                    testAccCheckDatabaseInstanceNotRecreated(&dbInstance2, &dbInstance3),\n                    resource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.small\"),\n                ),\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_multiAZ(t *testing.T) {\n    ctx := acctest.Context(t)\n    var dbInstance database.DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_multiAZ(rName, true),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    resource.TestCheckResourceAttr(resourceName, \"multi_az\", \"true\"),\n                ),\n            },\n            {\n                ResourceName:      resourceName,\n                ImportState:       true,\n                ImportStateVerify: true,\n                ImportStateVerifyIgnore: []string{\n                    \"password\",\n                    \"skip_final_snapshot\",\n                },\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_storageEncryption(t *testing.T) {\n    ctx := acctest.Context(t)\n    var dbInstance database.DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_storageEncryption(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    resource.TestCheckResourceAttr(resourceName, \"storage_encrypted\", \"true\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"kms_key_id\"),\n                ),\n            },\n            {\n                ResourceName:      resourceName,\n                ImportState:       true,\n                ImportStateVerify: true,\n                ImportStateVerifyIgnore: []string{\n                    \"password\",\n                    \"skip_final_snapshot\",\n                },\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_backupWindow(t *testing.T) {\n    ctx := acctest.Context(t)\n    var dbInstance database.DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"provider_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_backupWindow(rName, \"03:00-04:00\", \"mon:04:00-mon:05:00\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n                    resource.TestCheckResourceAttr(resourceName, \"backup_window\", \"03:00-04:00\"),\n                    resource.TestCheckResourceAttr(resourceName, \"maintenance_window\", \"mon:04:00-mon:05:00\"),\n                ),\n            },\n            {\n                ResourceName:      resourceName,\n                ImportState:       true,\n                ImportStateVerify: true,\n                ImportStateVerifyIgnore: []string{\n                    \"password\",\n                    \"skip_final_snapshot\",\n                },\n            },\n        },\n    })\n}\n\n// Test helper functions\n\nfunc testAccCheckDatabaseInstanceExists(ctx context.Context, n string, v *database.DatabaseInstance) resource.TestCheckFunc {\n    return func(s *terraform.State) error {\n        rs, ok := s.RootModule().Resources[n]\n        if !ok {\n            return fmt.Errorf(\"Not found: %s\", n)\n        }\n\n        if rs.Primary.ID == \"\" {\n            return fmt.Errorf(\"No Database Instance ID is set\")\n        }\n\n        conn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n        output, err := tfdatabase.FindDatabaseInstanceByID(ctx, conn, rs.Primary.ID)\n        if err != nil {\n            return err\n        }\n\n        *v = *output\n\n        return nil\n    }\n}\n\nfunc testAccCheckDatabaseInstanceDestroy(ctx context.Context) resource.TestCheckFunc {\n    return func(s *terraform.State) error {\n        conn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n        for _, rs := range s.RootModule().Resources {\n            if rs.Type != \"provider_database_instance\" {\n                continue\n            }\n\n            _, err := tfdatabase.FindDatabaseInstanceByID(ctx, conn, rs.Primary.ID)\n\n            if tfresource.NotFound(err) {\n                continue\n            }\n\n            if err != nil {\n                return err\n            }\n\n            return fmt.Errorf(\"Database Instance %s still exists\", rs.Primary.ID)\n        }\n\n        return nil\n    }\n}\n\nfunc testAccCheckDatabaseInstanceNotRecreated(i, j *database.DatabaseInstance) resource.TestCheckFunc {\n    return func(s *terraform.State) error {\n        if i.ID != j.ID {\n            return fmt.Errorf(\"Database Instance was recreated. Before: %s, After: %s\", i.ID, j.ID)\n        }\n\n        return nil\n    }\n}\n\n// Configuration functions\n\nfunc testAccDatabaseInstanceConfig_basic(rName string) string {\n    return fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                   = %[1]q\n  engine                 = \"postgres\"\n  engine_version         = \"14.7\"\n  instance_class         = \"db.t3.micro\"\n  allocated_storage      = 20\n  storage_type           = \"gp2\"\n  username               = \"admin\"\n  password               = \"avoid-plaintext-passwords\"\n  publicly_accessible    = false\n  skip_final_snapshot    = true\n  backup_retention_period = 7\n\n  tags = {\n    Environment = \"test\"",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4785,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive Terraform provider acceptance test for a cloud database resource following the standard patterns.\n\n```go\n// internal/service/database/database_test.go\npackage database_test\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n\t\"github.com/hashicorp/terraform-plugin-testing/terraform\"\n\tsdkacctest \"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n\t\n\t\"github.com/yourorg/terraform-provider/internal/acctest\"\n\t\"github.com/yourorg/terraform-provider/internal/conns\"\n\t\"github.com/yourorg/terraform-provider/internal/service/database\"\n\ttfresource \"github.com/yourorg/terraform-provider/internal/tfresource\"\n)\n\nfunc TestAccDatabaseInstance_basic(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"15.0\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp3\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"status\"),\n\t\t\t\t\tacctest.CheckResourceAttrRegionalARN(resourceName, \"arn\", \"database\", fmt.Sprintf(\"db:%s\", rName)),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",           // Sensitive, not returned by API\n\t\t\t\t\t\"apply_immediately\",  // Not stored in state\n\t\t\t\t\t\"final_snapshot_identifier\", // Only used during deletion\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_disappears(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tacctest.CheckResourceDisappears(ctx, acctest.Provider, database.ResourceInstance(), resourceName),\n\t\t\t\t),\n\t\t\t\tExpectNonEmptyPlan: true,\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_tags(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key1\", \"value1\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t\t\"final_snapshot_identifier\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags2(rName, \"key1\", \"value1updated\", \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1updated\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_update(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_updated(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.small\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_storageEncryption(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_storageEncryption(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_encrypted\", \"true\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"kms_key_id\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t\t\"final_snapshot_identifier\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Test helper functions\n\nfunc testAccCheckDatabaseInstanceExists(ctx context.Context, name string) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\trs, ok := s.RootModule().Resources[name]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Not found: %s\", name)\n\t\t}\n\n\t\tif rs.Primary.ID == \"\" {\n\t\t\treturn fmt.Errorf(\"No Database Instance ID is set\")\n\t\t}\n\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n\t\t_, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Database Instance (%s) not found: %w\", rs.Primary.ID, err)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckDatabaseInstanceDestroy(ctx context.Context) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n\t\tfor _, rs := range s.RootModule().Resources {\n\t\t\tif rs.Type != \"provider_database_instance\" {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t_, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\n\t\t\tif tfresource.NotFound(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn fmt.Errorf(\"Database Instance %s still exists\", rs.Primary.ID)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// Test configuration functions\n\nfunc testAccDatabaseInstanceConfig_basic(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"15.0\"\n  instance_class       = \"db.t3.micro\"\n  allocated_storage    = 20\n  storage_type         = \"gp3\"\n  username             = \"admin\"\n  password             = \"avoid-plaintext-passwords\"\n  publicly_accessible  = false\n  skip_final_snapshot  = true\n}\n`, rName)\n}\n\nfunc testAccDatabaseInstanceConfig_updated(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                    = %[1]q\n  engine                  = \"postgres\"\n  engine_version          = \"15.0\"\n  instance_class          = \"db.t3.small\"\n  allocated_storage       = 30\n  storage_type            = \"gp3\"\n  username                = \"admin\"\n  password                = \"avoid-plaintext-passwords\"\n  publicly_accessible     = false\n  backup_retention_period = 7\n  skip_final_snapshot     = true\n  apply_immediately       = true\n}\n`, rName)\n}\n\nfunc testAccDatabaseInstanceConfig_tags1(rName, tagKey1, tagValue1 string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                = %[1]q\n  engine              = \"postgres\"\n  engine_version      = \"15.0\"\n  instance_class      = \"db.t3.micro\"\n  allocated_storage   = 20\n  storage_type        = \"gp3\"\n  username            = \"admin\"\n  password            = \"avoid-plaintext-passwords\"\n  publicly_accessible = false\n  skip_final_snapshot = true\n\n  tags = {\n    %[2]q = %[3]q\n  }\n}\n`, rName, tagKey1, tagValue1)\n}\n\nfunc testAccDatabaseInstanceConfig_tags2(rName, tagKey1, tagValue1, tagKey2, tagValue2 string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                = %[1]q\n  engine              = \"postgres\"\n  engine_version      = \"15.0\"\n  instance_class      = \"db.t3.micro\"\n  allocated_storage   = 20\n  storage_type        = \"gp3\"\n  username            = \"admin\"\n  password            = \"avoid-plaintext-passwords\"\n  publicly_accessible = false\n  skip_final_snapshot = true\n\n  tags = {\n    %[2]q = %[3]q\n    %[4]q = %[5]q\n  }\n}\n`, rName, tagKey1, tagValue1, tagKey2, tagValue2)\n}\n\nfunc testAccDatabaseInstanceConfig_storageEncryption(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_kms_key\" \"test\" {\n  description = %[1]q\n}\n\nresource \"provider_database_instance\" \"test\" {\n  name                = %[1]q\n  engine              = \"postgres\"\n  engine_version      = \"15.0\"\n  instance_class      = \"db.t3.micro\"\n  allocated_storage   = 20\n  storage_type        = \"gp3\"\n  username            = \"admin\"\n  password            = \"avoid-plaintext-passwords\"\n  publicly_accessible = false\n  skip_final_snapshot = true\n  storage_encrypted   = true\n  kms_key_id          = provider_kms_key.test.arn\n}\n`, rName)\n}\n```\n\nNow let's create the finder function that the tests depend on:\n\n```go\n// internal/service/database/find.go\npackage database\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n\t\"github.com/yourorg/database-sdk/types\"\n\t\n\ttfresource \"github.com/yourorg/terraform-provider/internal/tfresource\"\n)\n\nfunc FindInstanceByID(ctx context.Context, conn *Client, id string) (*types.DatabaseInstance, error) {\n\tinput := &DescribeDatabaseInstanceInput{\n\t\tInstanceID: &id,\n\t}\n\n\toutput, err := conn.DescribeDatabaseInstance(ctx, input)\n\tif err != nil {\n\t\tvar notFound *types.ResourceNotFoundException\n\t\tif errors.As(err, &notFound) {\n\t\t\treturn nil, &retry.NotFoundError{\n\t\t\t\tLastError:   err,\n\t\t\t\tLastRequest: input,\n\t\t\t}\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tif output == nil || output.Instance == nil {\n\t\treturn nil, tfresource.NewEmptyResultError(input)\n\t}\n\n\t// Check if instance is in a \"deleted\" state\n\tif status := output.Instance.Status; status != nil {\n\t\tif *status == \"deleting\" || *status == \"deleted\" {\n\t\t\treturn nil, &retry.NotFoundError{\n\t\t\t\tMessage:     \"Instance is being deleted or has been deleted\",\n\t\t\t\tLastRequest: input,\n\t\t\t}\n\t\t}\n\t}\n\n\treturn output",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5269,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "```go\npackage provider\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"testing\"\n\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n\t\"github.com/hashicorp/terraform-plugin-testing/terraform\"\n)\n\nfunc TestAccCloudDatabase_basic(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.5\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"username\", \"admin\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Environment\", \"test\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"id\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"port\"),\n\t\t\t\t\tresource.TestMatchResourceAttr(resourceName, \"endpoint\", regexp.MustCompile(`^[a-z0-9.-]+$`)),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:            resourceName,\n\t\t\t\tImportState:             true,\n\t\t\t\tImportStateVerify:       true,\n\t\t\t\tImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\"},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_disappears(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\ttestAccCheckCloudDatabaseDisappears(&database),\n\t\t\t\t),\n\t\t\t\tExpectNonEmptyPlan: true,\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_update(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_updated(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.small\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"3\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Environment\", \"production\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Updated\", \"true\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:            resourceName,\n\t\t\t\tImportState:             true,\n\t\t\t\tImportStateVerify:       true,\n\t\t\t\tImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\"},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_multipleAZ(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_multiAZ(rName, true),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"multi_az\", \"true\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_multiAZ(rName, false),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"multi_az\", \"false\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_backupRetention(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { testAccPreCheck(t) },\n\t\tProtoV6ProviderFactories: testAccProtoV6ProviderFactories,\n\t\tCheckDestroy:             testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_backupRetention(rName, 7),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_window\", \"03:00-04:00\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_backupRetention(rName, 14),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"14\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Helper Functions\n\nfunc testAccCheckCloudDatabaseExists(resourceName string, database *CloudDatabase) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\trs, ok := s.RootModule().Resources[resourceName]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Not found: %s\", resourceName)\n\t\t}\n\n\t\tif rs.Primary.ID == \"\" {\n\t\t\treturn fmt.Errorf(\"No Database ID is set\")\n\t\t}\n\n\t\tclient := testAccProvider.Meta().(*Client)\n\t\tctx := context.Background()\n\n\t\tfound, err := client.GetDatabase(ctx, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\tif found.ID != rs.Primary.ID {\n\t\t\treturn fmt.Errorf(\"Database not found\")\n\t\t}\n\n\t\t*database = *found\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckCloudDatabaseDestroy(s *terraform.State) error {\n\tclient := testAccProvider.Meta().(*Client)\n\tctx := context.Background()\n\n\tfor _, rs := range s.RootModule().Resources {\n\t\tif rs.Type != \"cloudprovider_database\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tdatabase, err := client.GetDatabase(ctx, rs.Primary.ID)\n\t\tif err == nil {\n\t\t\tif database.Status != \"deleted\" && database.Status != \"deleting\" {\n\t\t\t\treturn fmt.Errorf(\"Database %s still exists with status: %s\", rs.Primary.ID, database.Status)\n\t\t\t}\n\t\t}\n\n\t\t// Verify the error is a \"not found\" error\n\t\tif !isNotFoundError(err) {\n\t\t\treturn err\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc testAccCheckCloudDatabaseDisappears(database *CloudDatabase) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tclient := testAccProvider.Meta().(*Client)\n\t\tctx := context.Background()\n\n\t\terr := client.DeleteDatabase(ctx, database.ID, true)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"error deleting Database: %w\", err)\n\t\t}\n\n\t\t// Wait for the database to be deleted\n\t\treturn waitForDatabaseDeletion(ctx, client, database.ID)\n\t}\n}\n\n// Configuration Functions\n\nfunc testAccCloudDatabaseConfig_basic(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"14.5\"\n  instance_class       = \"db.t3.micro\"\n  allocated_storage    = 20\n  storage_type         = \"gp2\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  publicly_accessible  = false\n  skip_final_snapshot  = true\n\n  tags = {\n    Name        = %[1]q\n    Environment = \"test\"\n  }\n}\n`, rName)\n}\n\nfunc testAccCloudDatabaseConfig_updated(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"14.5\"\n  instance_class       = \"db.t3.small\"\n  allocated_storage    = 30\n  storage_type         = \"gp2\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  publicly_accessible  = false\n  skip_final_snapshot  = true\n\n  tags = {\n    Name        = %[1]q\n    Environment = \"production\"\n    Updated     = \"true\"\n  }\n}\n`, rName)\n}\n\nfunc testAccCloudDatabaseConfig_multiAZ(rName string, multiAZ bool) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"14.5\"\n  instance_class       = \"db.t3.micro\"\n  allocated_storage    = 20\n  storage_type         = \"gp2\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  multi_az             = %[2]t\n  skip_final_snapshot  = true\n\n  tags = {\n    Name = %[1]q\n  }\n}\n`, rName, multiAZ)\n}\n\nfunc testAccCloudDatabaseConfig_backupRetention(rName string, retentionPeriod int) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name                    = %[1]q\n  engine                  = \"postgres\"\n  engine_version          = \"14.5\"\n  instance_class          = \"db.t3.micro\"\n  allocated_storage       = 20\n  storage_type            = \"gp2\"\n  username                = \"admin\"\n  password                = \"TestPassword123!\"\n  backup_retention_period = %[2]d\n  backup_window           = \"03:00-04:00\"\n  skip_final_snapshot     = true\n\n  tags = {\n    Name = %[1]q\n  }\n}\n`, rName, retentionPeriod)\n}\n\n// Utility Functions\n\nfunc waitForDatabaseDeletion(ctx context.Context, client *Client, id string) error {\n\t// Implementation would use a waiter pattern\n\t// This is a simplified version\n\tfor i := 0; i < 60; i++ {\n\t\t_, err := client.GetDatabase(ctx, id)\n\t\tif isNotFoundError(err) {\n\t\t\treturn nil\n\t\t}\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\t\t// Sleep between checks (would use time.Sleep in real implementation)\n\t}\n\treturn fmt.Errorf(\"timeout waiting for database deletion\")\n}\n\nfunc isNotFoundError(err error) bool {\n\t// Implementation depends on your API client\n\t// This would check if the error indicates a 404 or similar\n\tif err == nil {\n\t\treturn false\n\t}\n\t// Example check - adjust based on your actual error types\n\treturn regexp.MustCompile(`not found|does not exist|404`).MatchString(err.Error())\n}\n\n// CloudDatabase represents the database resource structure\ntype CloudDatabase struct {\n\tID                   string\n\tName                 string\n\tEngine               string\n\tEngineVersion        string\n\tInstanceClass        string\n\tAllocatedStorage     int\n\tStorageType          string\n\tUsername             string\n\tEndpoint             string\n\tPort                 int\n\tStatus               string\n\tMultiAZ              bool\n\tBackupRetentionPeriod int\n\tARN                  string\n}\n```\n\nThis comprehensive test suite includes:\n\n1. **Basic Test**: Tests resource creation with standard attributes and import verification\n2. **Disappears Test**: Ensures Terraform handles out-of-band resource deletion\n3. **Update Test**: Verifies in-place updates work correctly\n4. **Multi-AZ Test**: Tests toggling boolean attributes\n5. **Backup Retention Test**: Tests updating numeric attributes\n\n**Key Testing Patterns Used**:\n- `resource.ParallelTest` for concurrent test execution\n- `testAccCheckExists` helper to verify resource existence\n- `testAccCheckDestroy` helper to verify cleanup\n- `testAccCheckDisappears` helper for disappears testing\n- Import state verification with ignored sensitive fields\n- Proper use of `ComposeAggregateTestCheckFunc` for multiple checks\n- Random name generation with `acctest.RandomWithPrefix`\n- Configuration functions using `fmt.Sprintf` for templating",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 66,
            "output_tokens": 3979,
            "cached": false
          },
          "with_skill": {
            "output": "# Terraform Provider Acceptance Test for Cloud Database Resource\n\nI'll create a comprehensive acceptance test suite for a cloud database resource following Terraform provider testing best practices.\n\n## Complete Test Implementation\n\n```go\n// internal/service/database/database_test.go\npackage database_test\n\nimport (\n    \"context\"\n    \"fmt\"\n    \"testing\"\n\n    \"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n    \"github.com/hashicorp/terraform-plugin-testing/terraform\"\n    sdkacctest \"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n    \"github.com/example/terraform-provider-cloud/internal/acctest\"\n    \"github.com/example/terraform-provider-cloud/internal/conns\"\n    tfdatabase \"github.com/example/terraform-provider-cloud/internal/service/database\"\n    \"github.com/example/terraform-provider-cloud/internal/tfresource\"\n)\n\nfunc TestAccDatabaseInstance_basic(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_basic(rName),\n                Check: resource.ComposeAggregateTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttr(resourceName, \"name\", rName),\n                    resource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n                    resource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.5\"),\n                    resource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n                    resource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n                    resource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp3\"),\n                    resource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n                    resource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n                    resource.TestCheckResourceAttr(resourceName, \"multi_az\", \"false\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.Environment\", \"test\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"port\"),\n                    resource.TestCheckResourceAttrSet(resourceName, \"status\"),\n                    acctest.CheckResourceAttrRegionalARN(resourceName, \"arn\", \"database\", fmt.Sprintf(\"db:%s\", rName)),\n                ),\n            },\n            {\n                ResourceName:            resourceName,\n                ImportState:             true,\n                ImportStateVerify:       true,\n                ImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_disappears(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_basic(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    acctest.CheckResourceDisappears(ctx, acctest.Provider, tfdatabase.ResourceDatabaseInstance(), resourceName),\n                ),\n                ExpectNonEmptyPlan: true,\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_tags(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_tags1(rName, \"key1\", \"value1\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1\"),\n                ),\n            },\n            {\n                ResourceName:            resourceName,\n                ImportState:             true,\n                ImportStateVerify:       true,\n                ImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_tags2(rName, \"key1\", \"value1updated\", \"key2\", \"value2\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1updated\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n                ),\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_tags1(rName, \"key2\", \"value2\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n                    resource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n                ),\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_update(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database1, database2, database3 DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_basic(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database1),\n                    resource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n                    resource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n                ),\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_updated(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database2),\n                    testAccCheckDatabaseInstanceNotRecreated(&database1, &database2),\n                    resource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n                    resource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"14\"),\n                    resource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.small\"),\n                ),\n            },\n            {\n                Config: testAccDatabaseInstanceConfig_multiAZ(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database3),\n                    testAccCheckDatabaseInstanceNotRecreated(&database2, &database3),\n                    resource.TestCheckResourceAttr(resourceName, \"multi_az\", \"true\"),\n                ),\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_storageType(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_storageType(rName, \"gp2\"),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp2\"),\n                ),\n            },\n            {\n                ResourceName:            resourceName,\n                ImportState:             true,\n                ImportStateVerify:       true,\n                ImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_securityGroups(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_securityGroups(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttr(resourceName, \"vpc_security_group_ids.#\", \"1\"),\n                ),\n            },\n            {\n                ResourceName:            resourceName,\n                ImportState:             true,\n                ImportStateVerify:       true,\n                ImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_parameterGroup(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_parameterGroup(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttrPair(resourceName, \"parameter_group_name\", \"cloud_database_parameter_group.test\", \"name\"),\n                ),\n            },\n            {\n                ResourceName:            resourceName,\n                ImportState:             true,\n                ImportStateVerify:       true,\n                ImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n            },\n        },\n    })\n}\n\nfunc TestAccDatabaseInstance_optionGroup(t *testing.T) {\n    ctx := acctest.Context(t)\n    var database DatabaseInstance\n    rName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n    resourceName := \"cloud_database_instance.test\"\n\n    resource.ParallelTest(t, resource.TestCase{\n        PreCheck:                 func() { acctest.PreCheck(ctx, t) },\n        ErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n        ProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n        CheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n        Steps: []resource.TestStep{\n            {\n                Config: testAccDatabaseInstanceConfig_optionGroup(rName),\n                Check: resource.ComposeTestCheckFunc(\n                    testAccCheckDatabaseInstanceExists(ctx, resourceName, &database),\n                    resource.TestCheckResourceAttrPair(resourceName, \"option_group_name\", \"cloud_database_option_group.test\", \"name\"),\n                ),\n            },\n            {\n                ResourceName:            resourceName,\n                ImportState:             true,\n                ImportStateVerify:       true,\n                ImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n            },\n        },\n    })\n}\n\n// Test helper functions\n\nfunc testAccCheckDatabaseInstanceExists(ctx context.Context, name string, database *DatabaseInstance) resource.TestCheckFunc {\n    return func(s *terraform.State) error {\n        rs, ok := s.RootModule().Resources[name]\n        if !ok {\n            return fmt.Errorf(\"Not found: %s\", name)\n        }\n\n        if rs.Primary.ID == \"\" {\n            return fmt.Errorf(\"No Database Instance ID is set\")\n        }\n\n        conn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n        output, err := tfdatabase.FindDatabaseInstanceByID(ctx, conn, rs.Primary.ID)\n        if err != nil {\n            return err\n        }\n\n        *database = *output\n\n        return nil\n    }\n}\n\nfunc testAccCheckDatabaseInstanceDestroy(ctx context.Context) resource.TestCheckFunc {\n    return func(s *terraform.State) error {\n        conn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n        for _, rs := range s.RootModule().Resources {\n            if rs.Type != \"cloud_database_instance\" {\n                continue\n            }\n\n            _, err := tfdatabase.FindDatabaseInstanceByID(ctx, conn, rs.Primary.ID)\n\n            if tfresource.NotFound(err) {\n                continue\n            }\n\n            if err != nil {\n                return err\n            }\n\n            return fmt.Errorf(\"Database Instance %s still exists\", rs.Primary.ID)\n        }\n\n        return nil\n    }\n}\n\nfunc testAccCheckDatabaseInstanceNotRecreated(before, after *DatabaseInstance) resource.TestCheckFunc {\n    ",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4785,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive Terraform provider acceptance test for a cloud database resource following the standard patterns.\n\n```go\n// internal/service/database/database_test.go\npackage database_test\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n\t\"github.com/hashicorp/terraform-plugin-testing/terraform\"\n\tsdkacctest \"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n\t\"github.com/yourorg/terraform-provider/internal/acctest\"\n\t\"github.com/yourorg/terraform-provider/internal/conns\"\n\t\"github.com/yourorg/terraform-provider/internal/service/database\"\n\t\"github.com/yourorg/terraform-provider/internal/tfresource\"\n)\n\nfunc TestAccDatabaseInstance_basic(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"15.0\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp3\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"status\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",           // Sensitive, not returned by API\n\t\t\t\t\t\"apply_immediately\",  // Not stored in state\n\t\t\t\t\t\"skip_final_snapshot\", // Not stored in state\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_disappears(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tacctest.CheckResourceDisappears(ctx, acctest.Provider, database.ResourceInstance(), resourceName),\n\t\t\t\t),\n\t\t\t\tExpectNonEmptyPlan: true,\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_tags(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key1\", \"value1\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags2(rName, \"key1\", \"value1updated\", \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1updated\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_update(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance1, dbInstance2 database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance1),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_updated(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance2),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.small\"),\n\t\t\t\t\ttestAccCheckDatabaseInstanceNotRecreated(&dbInstance1, &dbInstance2),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_backupRetention(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_backupRetention(rName, 7),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_window\", \"03:00-04:00\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_backupRetention(rName, 14),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"14\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Test helper functions\n\nfunc testAccCheckDatabaseInstanceExists(ctx context.Context, name string, dbInstance *database.Instance) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\trs, ok := s.RootModule().Resources[name]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Not found: %s\", name)\n\t\t}\n\n\t\tif rs.Primary.ID == \"\" {\n\t\t\treturn fmt.Errorf(\"No Database Instance ID is set\")\n\t\t}\n\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n\t\toutput, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t*dbInstance = *output\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckDatabaseInstanceDestroy(ctx context.Context) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n\t\tfor _, rs := range s.RootModule().Resources {\n\t\t\tif rs.Type != \"provider_database_instance\" {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t_, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\n\t\t\tif tfresource.NotFound(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn fmt.Errorf(\"Database Instance %s still exists\", rs.Primary.ID)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckDatabaseInstanceNotRecreated(before, after *database.Instance) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tif before.ID != after.ID {\n\t\t\treturn fmt.Errorf(\"Database Instance was recreated. Before ID: %s, After ID: %s\", before.ID, after.ID)\n\t\t}\n\t\treturn nil\n\t}\n}\n\n// Test configuration functions\n\nfunc testAccDatabaseInstanceConfig_basic(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"15.0\"\n  instance_class       = \"db.t3.micro\"\n  allocated_storage    = 20\n  storage_type         = \"gp3\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  publicly_accessible  = false\n  skip_final_snapshot  = true\n}\n`, rName)\n}\n\nfunc testAccDatabaseInstanceConfig_updated(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"15.0\"\n  instance_class       = \"db.t3.small\"\n  allocated_storage    = 30\n  storage_type         = \"gp3\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  publicly_accessible  = false\n  skip_final_snapshot  = true\n  apply_immediately    = true\n}\n`, rName)\n}\n\nfunc testAccDatabaseInstanceConfig_tags1(rName, tagKey1, tagValue1 string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"15.0\"\n  instance_class       = \"db.t3.micro\"\n  allocated_storage    = 20\n  storage_type         = \"gp3\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  publicly_accessible  = false\n  skip_final_snapshot  = true\n\n  tags = {\n    %[2]q = %[3]q\n  }\n}\n`, rName, tagKey1, tagValue1)\n}\n\nfunc testAccDatabaseInstanceConfig_tags2(rName, tagKey1, tagValue1, tagKey2, tagValue2 string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"15.0\"\n  instance_class       = \"db.t3.micro\"\n  allocated_storage    = 20\n  storage_type         = \"gp3\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  publicly_accessible  = false\n  skip_final_snapshot  = true\n\n  tags = {\n    %[2]q = %[3]q\n    %[4]q = %[5]q\n  }\n}\n`, rName, tagKey1, tagValue1, tagKey2, tagValue2)\n}\n\nfunc testAccDatabaseInstanceConfig_backupRetention(rName string, retentionPeriod int) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                    = %[1]q\n  engine                  = \"postgres\"\n  engine_version          = \"15.0\"\n  instance_class          = \"db.t3.micro\"\n  allocated_storage       = 20\n  storage_type            = \"gp3\"\n  username                = \"admin\"\n  password                = \"TestPassword123!\"\n  publicly_accessible     = false\n  skip_final_snapshot     = true\n  backup_retention_period = %[2]d\n  backup_window           = \"03:00-04:00\"\n}\n`, rName, retentionPeriod)\n}\n```\n\nNow let me create the complementary find.go file with the finder function:\n\n```go\n// internal/service/database/find.go\npackage database\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/yourorg/terraform-provider/internal/tfresource\"\n\t\"github.com/yourorg/database-sdk-go/types\"\n)\n\n// FindInstanceByID retrieves a database instance by its ID\nfunc FindInstanceByID(ctx context.Context, conn *Client, id string) (*Instance, error) {\n\tinput := &GetInstanceInput{\n\t\tInstanceID: &id,\n\t}\n\n\toutput, err := conn.GetInstance(ctx, input)\n\tif err != nil {\n\t\tvar notFound *types.ResourceNotFoundException\n\t\tif errors.As(err, &",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5269,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "```go\npackage provider\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"regexp\"\n\t\"testing\"\n\n\t\"github.com/hashicorp/terraform-plugin-sdk/v2/helper/acctest\"\n\t\"github.com/hashicorp/terraform-plugin-sdk/v2/helper/resource\"\n\t\"github.com/hashicorp/terraform-plugin-sdk/v2/terraform\"\n)\n\nfunc TestAccCloudDatabase_basic(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:          func() { testAccPreCheck(t) },\n\t\tProviderFactories: testAccProviderFactories,\n\t\tCheckDestroy:      testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.5\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Environment\", \"test\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"id\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"status\"),\n\t\t\t\t\tresource.TestMatchResourceAttr(resourceName, \"endpoint\", regexp.MustCompile(`^[a-z0-9-]+\\.[a-z0-9-]+\\.[a-z0-9-]+\\.rds\\.amazonaws\\.com$`)),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:            resourceName,\n\t\t\t\tImportState:             true,\n\t\t\t\tImportStateVerify:       true,\n\t\t\t\tImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_disappears(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:          func() { testAccPreCheck(t) },\n\t\tProviderFactories: testAccProviderFactories,\n\t\tCheckDestroy:      testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\ttestAccCheckCloudDatabaseDisappears(&database),\n\t\t\t\t),\n\t\t\t\tExpectNonEmptyPlan: true,\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_update(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:          func() { testAccPreCheck(t) },\n\t\tProviderFactories: testAccProviderFactories,\n\t\tCheckDestroy:      testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_updated(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.small\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"3\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Environment\", \"production\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.Updated\", \"true\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:            resourceName,\n\t\t\t\tImportState:             true,\n\t\t\t\tImportStateVerify:       true,\n\t\t\t\tImportStateVerifyIgnore: []string{\"password\", \"skip_final_snapshot\", \"final_snapshot_identifier\"},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_backupRetention(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:          func() { testAccPreCheck(t) },\n\t\tProviderFactories: testAccProviderFactories,\n\t\tCheckDestroy:      testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_backupRetention(rName, 7),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_window\", \"03:00-04:00\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_backupRetention(rName, 14),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"14\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccCloudDatabase_multiAZ(t *testing.T) {\n\tvar database CloudDatabase\n\tresourceName := \"cloudprovider_database.test\"\n\trName := acctest.RandomWithPrefix(\"tf-acc-test\")\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:          func() { testAccPreCheck(t) },\n\t\tProviderFactories: testAccProviderFactories,\n\t\tCheckDestroy:      testAccCheckCloudDatabaseDestroy,\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_multiAZ(rName, false),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"multi_az\", \"false\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccCloudDatabaseConfig_multiAZ(rName, true),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckCloudDatabaseExists(resourceName, &database),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"multi_az\", \"true\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Helper Functions\n\nfunc testAccCheckCloudDatabaseExists(resourceName string, database *CloudDatabase) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\trs, ok := s.RootModule().Resources[resourceName]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Not found: %s\", resourceName)\n\t\t}\n\n\t\tif rs.Primary.ID == \"\" {\n\t\t\treturn fmt.Errorf(\"No Database ID is set\")\n\t\t}\n\n\t\tclient := testAccProvider.Meta().(*Client)\n\t\tctx := context.Background()\n\n\t\tresp, err := client.GetDatabase(ctx, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Error retrieving database: %w\", err)\n\t\t}\n\n\t\tif resp == nil {\n\t\t\treturn fmt.Errorf(\"Database not found\")\n\t\t}\n\n\t\t*database = *resp\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckCloudDatabaseDestroy(s *terraform.State) error {\n\tclient := testAccProvider.Meta().(*Client)\n\tctx := context.Background()\n\n\tfor _, rs := range s.RootModule().Resources {\n\t\tif rs.Type != \"cloudprovider_database\" {\n\t\t\tcontinue\n\t\t}\n\n\t\tresp, err := client.GetDatabase(ctx, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\t// If the error is a \"not found\" error, the resource was successfully destroyed\n\t\t\tif isNotFoundError(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\t\t\treturn fmt.Errorf(\"Error checking database destruction: %w\", err)\n\t\t}\n\n\t\tif resp != nil && resp.Status != \"deleted\" {\n\t\t\treturn fmt.Errorf(\"Database %s still exists with status: %s\", rs.Primary.ID, resp.Status)\n\t\t}\n\t}\n\n\treturn nil\n}\n\nfunc testAccCheckCloudDatabaseDisappears(database *CloudDatabase) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tclient := testAccProvider.Meta().(*Client)\n\t\tctx := context.Background()\n\n\t\terr := client.DeleteDatabase(ctx, database.ID, true)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Error deleting database: %w\", err)\n\t\t}\n\n\t\t// Wait for the database to be deleted\n\t\treturn waitForDatabaseDeletion(ctx, client, database.ID)\n\t}\n}\n\nfunc waitForDatabaseDeletion(ctx context.Context, client *Client, id string) error {\n\t// In a real implementation, this would use a waiter or polling mechanism\n\t// For example, using terraform-plugin-sdk's resource.RetryContext\n\treturn resource.RetryContext(ctx, 10*time.Minute, func() *resource.RetryError {\n\t\tresp, err := client.GetDatabase(ctx, id)\n\t\tif err != nil {\n\t\t\tif isNotFoundError(err) {\n\t\t\t\treturn nil\n\t\t\t}\n\t\t\treturn resource.NonRetryableError(err)\n\t\t}\n\n\t\tif resp.Status == \"deleting\" || resp.Status == \"deleted\" {\n\t\t\treturn resource.RetryableError(fmt.Errorf(\"Database still deleting\"))\n\t\t}\n\n\t\treturn resource.NonRetryableError(fmt.Errorf(\"Database in unexpected state: %s\", resp.Status))\n\t})\n}\n\n// Test Configuration Functions\n\nfunc testAccCloudDatabaseConfig_basic(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name              = %[1]q\n  engine            = \"postgres\"\n  engine_version    = \"14.5\"\n  instance_class    = \"db.t3.micro\"\n  allocated_storage = 20\n  storage_type      = \"gp2\"\n  username          = \"admin\"\n  password          = \"TestPassword123!\"\n  \n  publicly_accessible    = false\n  skip_final_snapshot    = true\n  \n  tags = {\n    Name        = %[1]q\n    Environment = \"test\"\n  }\n}\n`, rName)\n}\n\nfunc testAccCloudDatabaseConfig_updated(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name              = %[1]q\n  engine            = \"postgres\"\n  engine_version    = \"14.5\"\n  instance_class    = \"db.t3.small\"\n  allocated_storage = 30\n  storage_type      = \"gp2\"\n  username          = \"admin\"\n  password          = \"TestPassword123!\"\n  \n  publicly_accessible    = false\n  skip_final_snapshot    = true\n  \n  tags = {\n    Name        = %[1]q\n    Environment = \"production\"\n    Updated     = \"true\"\n  }\n}\n`, rName)\n}\n\nfunc testAccCloudDatabaseConfig_backupRetention(rName string, retentionPeriod int) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name              = %[1]q\n  engine            = \"postgres\"\n  engine_version    = \"14.5\"\n  instance_class    = \"db.t3.micro\"\n  allocated_storage = 20\n  storage_type      = \"gp2\"\n  username          = \"admin\"\n  password          = \"TestPassword123!\"\n  \n  backup_retention_period = %[2]d\n  backup_window          = \"03:00-04:00\"\n  \n  publicly_accessible = false\n  skip_final_snapshot = true\n  \n  tags = {\n    Name        = %[1]q\n    Environment = \"test\"\n  }\n}\n`, rName, retentionPeriod)\n}\n\nfunc testAccCloudDatabaseConfig_multiAZ(rName string, multiAZ bool) string {\n\treturn fmt.Sprintf(`\nresource \"cloudprovider_database\" \"test\" {\n  name              = %[1]q\n  engine            = \"postgres\"\n  engine_version    = \"14.5\"\n  instance_class    = \"db.t3.small\"\n  allocated_storage = 20\n  storage_type      = \"gp2\"\n  username          = \"admin\"\n  password          = \"TestPassword123!\"\n  \n  multi_az            = %[2]t\n  publicly_accessible = false\n  skip_final_snapshot = true\n  \n  tags = {\n    Name        = %[1]q\n    Environment = \"test\"\n  }\n}\n`, rName, multiAZ)\n}\n\n// Utility Functions\n\nfunc isNotFoundError(err error) bool {\n\t// Implementation depends on your API client\n\t// Example for AWS SDK v2:\n\t// var notFoundErr *types.ResourceNotFoundException\n\t// return errors.As(err, &notFoundErr)\n\t\n\t// Generic implementation:\n\tif err == nil {\n\t\treturn false\n\t}\n\treturn strings.Contains(err.Error(), \"not found\") || \n\t       strings.Contains(err.Error(), \"NotFound\") ||\n\t       strings.Contains(err.Error(), \"404\")\n}\n\n// CloudDatabase represents the database resource structure\ntype CloudDatabase struct {\n\tID                    string\n\tName                  string\n\tEngine                string\n\tEngineVersion         string\n\tInstanceClass         string\n\tAllocatedStorage      int\n\tStorageType           string\n\tStatus                string\n\tEndpoint              string\n\tARN                   string\n\tBackupRetentionPeriod int\n\tMultiAZ               bool\n\tPubliclyAccessible    bool\n\tTags                  map[string]string\n}\n\n// Client represents the API client\ntype Client struct {\n\t// Add your client fields here\n}\n\nfunc (c *Client) GetDatabase(ctx context.Context, id string) (*CloudDatabase, error) {\n\t// Implementation for getting database\n\treturn nil, nil\n}\n\nfunc (c *Client) DeleteDatabase(ctx context.Context, id string, skipFinalSnapshot bool) error {\n\t// Implementation for deleting database\n\treturn nil\n}\n```\n\nThis comprehensive test suite includes:\n\n1. **Basic Test**: Tests resource creation with standard attributes and verifies all computed values\n2. **Disappears Test**: Ensures Terraform properly handles resources deleted outside of Terraform\n3. **Import Test**: Verifies state can be",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 66,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# Terraform Provider Acceptance Test for Cloud Database Resource\n\nI'll create a comprehensive acceptance test suite for a cloud database resource following Terraform provider testing best practices.\n\n```go\n// internal/service/database/database_test.go\npackage database_test\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n\t\"github.com/hashicorp/terraform-plugin-testing/terraform\"\n\tsdkacctest \"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n\t\"github.com/example/terraform-provider-cloud/internal/acctest\"\n\t\"github.com/example/terraform-provider-cloud/internal/conns\"\n\t\"github.com/example/terraform-provider-cloud/internal/service/database\"\n\t\"github.com/example/terraform-provider-cloud/internal/tfresource\"\n)\n\nfunc TestAccDatabaseInstance_basic(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.5\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp3\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"multi_az\", \"false\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"status\"),\n\t\t\t\t\tacctest.CheckResourceAttrRegionalARN(resourceName, \"arn\", \"database\", fmt.Sprintf(\"db:%s\", rName)),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"master_password\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t\t\"final_snapshot_identifier\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_disappears(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tacctest.CheckResourceDisappears(ctx, acctest.Provider, database.ResourceInstance(), resourceName),\n\t\t\t\t),\n\t\t\t\tExpectNonEmptyPlan: true,\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_tags(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key1\", \"value1\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"master_password\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t\t\"final_snapshot_identifier\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags2(rName, \"key1\", \"value1updated\", \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1updated\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_storageUpdate(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance1, dbInstance2 database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_storage(rName, 20),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance1),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_storage(rName, 30),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance2),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n\t\t\t\t\ttestAccCheckDatabaseInstanceNotRecreated(&dbInstance1, &dbInstance2),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_multiAZ(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_multiAZ(rName, true),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"multi_az\", \"true\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"availability_zone\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"master_password\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t\t\"final_snapshot_identifier\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_backupRetention(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance1, dbInstance2 database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_backupRetention(rName, 7),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance1),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_backupRetention(rName, 14),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance2),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"14\"),\n\t\t\t\t\ttestAccCheckDatabaseInstanceNotRecreated(&dbInstance1, &dbInstance2),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_engineVersion(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance1, dbInstance2 database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_engineVersion(rName, \"14.5\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance1),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.5\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_engineVersion(rName, \"14.6\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance2),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"14.6\"),\n\t\t\t\t\ttestAccCheckDatabaseInstanceNotRecreated(&dbInstance1, &dbInstance2),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_parameterGroup(t *testing.T) {\n\tctx := acctest.Context(t)\n\tvar dbInstance database.Instance\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"cloud_database_instance.test\"\n\tparameterGroupResourceName := \"cloud_database_parameter_group.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, database.ServiceID),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_parameterGroup(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName, &dbInstance),\n\t\t\t\t\tresource.TestCheckResourceAttrPair(resourceName, \"parameter_group_name\", parameterGroupResourceName, \"name\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"master_password\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t\t\"final_snapshot_identifier\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Test helper functions\n\nfunc testAccCheckDatabaseInstanceExists(ctx context.Context, n string, v *database.Instance) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\trs, ok := s.RootModule().Resources[n]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Not found: %s\", n)\n\t\t}\n\n\t\tif rs.Primary.ID == \"\" {\n\t\t\treturn fmt.Errorf(\"No Database Instance ID is set\")\n\t\t}\n\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n\t\toutput, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\treturn err\n\t\t}\n\n\t\t*v = *output\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckDatabaseInstanceDestroy(ctx context.Context) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n\t\tfor _, rs := range s.RootModule().Resources {\n\t\t\tif rs.Type != \"cloud_database_instance\" {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t_, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\n\t\t\tif tfresource.NotFound(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn fmt.Errorf(\"Database Instance %s still exists\", rs.Primary.ID)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckDatabaseInstanceNotRecreated(i, j *database.Instance) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tif i.ID != j.ID {\n\t\t\treturn fmt.Errorf(\"Database Instance was recreated. Before: %s, After: %s\", i.ID, j.ID)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// Configuration functions\n\nfunc testAccD",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4785,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive Terraform provider acceptance test for a cloud database resource following the standard patterns.\n\n```go\n// internal/service/database/database_test.go\npackage database_test\n\nimport (\n\t\"context\"\n\t\"fmt\"\n\t\"testing\"\n\n\t\"github.com/hashicorp/terraform-plugin-testing/helper/resource\"\n\t\"github.com/hashicorp/terraform-plugin-testing/terraform\"\n\tsdkacctest \"github.com/hashicorp/terraform-plugin-testing/helper/acctest\"\n\t\n\t\"github.com/yourorg/terraform-provider/internal/acctest\"\n\t\"github.com/yourorg/terraform-provider/internal/conns\"\n\t\"github.com/yourorg/terraform-provider/internal/service/database\"\n\ttfresource \"github.com/yourorg/terraform-provider/internal/tfresource\"\n)\n\nfunc TestAccDatabaseInstance_basic(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeAggregateTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"name\", rName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine\", \"postgres\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"engine_version\", \"15.0\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp3\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"publicly_accessible\", \"false\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"arn\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"endpoint\"),\n\t\t\t\t\tresource.TestCheckResourceAttrSet(resourceName, \"status\"),\n\t\t\t\t\tacctest.CheckResourceAttrRegionalARN(resourceName, \"arn\", \"database\", fmt.Sprintf(\"db:%s\", rName)),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t},\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_disappears(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tacctest.CheckResourceDisappears(ctx, acctest.Provider, database.ResourceInstance(), resourceName),\n\t\t\t\t),\n\t\t\t\tExpectNonEmptyPlan: true,\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_tags(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key1\", \"value1\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags2(rName, \"key1\", \"value1updated\", \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"2\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key1\", \"value1updated\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_tags1(rName, \"key2\", \"value2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.%\", \"1\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"tags.key2\", \"value2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_update(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_basic(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"20\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.micro\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_updated(rName),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"allocated_storage\", \"30\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"instance_class\", \"db.t3.small\"),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"backup_retention_period\", \"7\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\nfunc TestAccDatabaseInstance_storageType(t *testing.T) {\n\tctx := acctest.Context(t)\n\trName := sdkacctest.RandomWithPrefix(acctest.ResourcePrefix)\n\tresourceName := \"provider_database_instance.test\"\n\n\tresource.ParallelTest(t, resource.TestCase{\n\t\tPreCheck:                 func() { acctest.PreCheck(ctx, t) },\n\t\tErrorCheck:               acctest.ErrorCheck(t, \"database\"),\n\t\tProtoV5ProviderFactories: acctest.ProtoV5ProviderFactories,\n\t\tCheckDestroy:             testAccCheckDatabaseInstanceDestroy(ctx),\n\t\tSteps: []resource.TestStep{\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_storageType(rName, \"gp2\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp2\"),\n\t\t\t\t),\n\t\t\t},\n\t\t\t{\n\t\t\t\tResourceName:      resourceName,\n\t\t\t\tImportState:       true,\n\t\t\t\tImportStateVerify: true,\n\t\t\t\tImportStateVerifyIgnore: []string{\n\t\t\t\t\t\"password\",\n\t\t\t\t\t\"skip_final_snapshot\",\n\t\t\t\t\t\"apply_immediately\",\n\t\t\t\t},\n\t\t\t},\n\t\t\t{\n\t\t\t\tConfig: testAccDatabaseInstanceConfig_storageType(rName, \"gp3\"),\n\t\t\t\tCheck: resource.ComposeTestCheckFunc(\n\t\t\t\t\ttestAccCheckDatabaseInstanceExists(ctx, resourceName),\n\t\t\t\t\tresource.TestCheckResourceAttr(resourceName, \"storage_type\", \"gp3\"),\n\t\t\t\t),\n\t\t\t},\n\t\t},\n\t})\n}\n\n// Helper Functions\n\nfunc testAccCheckDatabaseInstanceExists(ctx context.Context, name string) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\trs, ok := s.RootModule().Resources[name]\n\t\tif !ok {\n\t\t\treturn fmt.Errorf(\"Not found: %s\", name)\n\t\t}\n\n\t\tif rs.Primary.ID == \"\" {\n\t\t\treturn fmt.Errorf(\"No Database Instance ID is set\")\n\t\t}\n\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\t\t\n\t\t_, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\t\tif err != nil {\n\t\t\treturn fmt.Errorf(\"Database Instance (%s) not found: %w\", rs.Primary.ID, err)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\nfunc testAccCheckDatabaseInstanceDestroy(ctx context.Context) resource.TestCheckFunc {\n\treturn func(s *terraform.State) error {\n\t\tconn := acctest.Provider.Meta().(*conns.Client).DatabaseClient(ctx)\n\n\t\tfor _, rs := range s.RootModule().Resources {\n\t\t\tif rs.Type != \"provider_database_instance\" {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\t_, err := database.FindInstanceByID(ctx, conn, rs.Primary.ID)\n\t\t\t\n\t\t\tif tfresource.NotFound(err) {\n\t\t\t\tcontinue\n\t\t\t}\n\n\t\t\tif err != nil {\n\t\t\t\treturn err\n\t\t\t}\n\n\t\t\treturn fmt.Errorf(\"Database Instance %s still exists\", rs.Primary.ID)\n\t\t}\n\n\t\treturn nil\n\t}\n}\n\n// Test Configuration Functions\n\nfunc testAccDatabaseInstanceConfig_basic(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                 = %[1]q\n  engine               = \"postgres\"\n  engine_version       = \"15.0\"\n  instance_class       = \"db.t3.micro\"\n  allocated_storage    = 20\n  storage_type         = \"gp3\"\n  username             = \"admin\"\n  password             = \"TestPassword123!\"\n  skip_final_snapshot  = true\n  publicly_accessible  = false\n}\n`, rName)\n}\n\nfunc testAccDatabaseInstanceConfig_updated(rName string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                    = %[1]q\n  engine                  = \"postgres\"\n  engine_version          = \"15.0\"\n  instance_class          = \"db.t3.small\"\n  allocated_storage       = 30\n  storage_type            = \"gp3\"\n  username                = \"admin\"\n  password                = \"TestPassword123!\"\n  skip_final_snapshot     = true\n  publicly_accessible     = false\n  backup_retention_period = 7\n  apply_immediately       = true\n}\n`, rName)\n}\n\nfunc testAccDatabaseInstanceConfig_tags1(rName, tagKey1, tagValue1 string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                = %[1]q\n  engine              = \"postgres\"\n  engine_version      = \"15.0\"\n  instance_class      = \"db.t3.micro\"\n  allocated_storage   = 20\n  storage_type        = \"gp3\"\n  username            = \"admin\"\n  password            = \"TestPassword123!\"\n  skip_final_snapshot = true\n\n  tags = {\n    %[2]q = %[3]q\n  }\n}\n`, rName, tagKey1, tagValue1)\n}\n\nfunc testAccDatabaseInstanceConfig_tags2(rName, tagKey1, tagValue1, tagKey2, tagValue2 string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                = %[1]q\n  engine              = \"postgres\"\n  engine_version      = \"15.0\"\n  instance_class      = \"db.t3.micro\"\n  allocated_storage   = 20\n  storage_type        = \"gp3\"\n  username            = \"admin\"\n  password            = \"TestPassword123!\"\n  skip_final_snapshot = true\n\n  tags = {\n    %[2]q = %[3]q\n    %[4]q = %[5]q\n  }\n}\n`, rName, tagKey1, tagValue1, tagKey2, tagValue2)\n}\n\nfunc testAccDatabaseInstanceConfig_storageType(rName, storageType string) string {\n\treturn fmt.Sprintf(`\nresource \"provider_database_instance\" \"test\" {\n  name                = %[1]q\n  engine              = \"postgres\"\n  engine_version      = \"15.0\"\n  instance_class      = \"db.t3.micro\"\n  allocated_storage   = 20\n  storage_type        = %[2]q\n  username            = \"admin\"\n  password            = \"TestPassword123!\"\n  skip_final_snapshot = true\n  apply_immediately   = true\n}\n`, rName, storageType)\n}\n```\n\nNow let me create the corresponding finder function that the tests depend on:\n\n```go\n// internal/service/database/find.go\npackage database\n\nimport (\n\t\"context\"\n\t\"errors\"\n\n\t\"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n\t\"github.com/yourorg/database-sdk/types\"\n)\n\n// FindInstanceByID retrieves a database instance by its ID\nfunc FindInstanceByID(ctx context.Context, conn *Client, id string) (*types.DBInstance, error) {\n\tinput := &GetDBInstanceInput{\n\t\tDBInstanceIdentifier: &id,\n\t}\n\n\toutput, err := conn.GetDBInstance(ctx, input)\n\tif err != nil {\n\t\tvar notFound *types.DBInstanceNotFoundFault\n\t\tif errors.As(err, &notFound) {\n\t\t\treturn nil, &retry.NotFoundError{\n\t\t\t\tLastError:   err,\n\t\t\t\tLastRequest: input,\n\t\t\t}\n\t\t}\n\t\treturn nil, err\n\t}\n\n\tif output == nil || output.DBInstance == nil {\n\t\treturn nil, &retry.NotFoundError{\n\t\t\tMessage:     \"Empty result\",\n\t\t\tLastRequest: input,\n\t\t}\n\t}\n\n\tdbInstance := output.DBInstance\n\t\n\t// Check if instance is in a deleted state\n\tif dbInstance.DBInstanceStatus != nil {\n\t\tstatus := *dbInstance.DBInstanceStatus\n\t\tif status == \"deleting\" || status == \"deleted\" {\n\t\t\treturn nil, &retry.NotFoundError{\n\t\t\t\tMessage:     \"Instance is being deleted or has been deleted\",\n\t\t\t\tLastRequest: input,\n\t\t\t}\n\t\t}\n\t}\n\n\treturn dbInstance, nil\n}\n```\n\nAnd here's",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5269,
            "output_tokens": 4096,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "provider-resources-04",
      "task_type": "grounded",
      "target_language": "go",
      "expected_patterns": [
        "func \\(r \\*resourceDatabase\\) Read",
        "func \\(r \\*resourceDatabase\\) Update",
        "req\\.State\\.Get\\(ctx",
        "req\\.Plan\\.Get\\(ctx",
        "tfresource\\.NotFound|ResourceNotFound",
        "resp\\.State\\.RemoveResource\\(ctx\\)",
        "resp\\.Diagnostics\\.Append"
      ],
      "anti_patterns": [
        "d\\.Set\\(",
        "d\\.Get\\(",
        "schema\\.Resource\\{",
        "ResourceData",
        "CreateWithoutTimeout"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/internal/provider/example_resource.go",
          "description": "Plugin Framework CRUD operations: func (r *resourceType) Read/Update methods, req.State.Get(ctx) to get current state, req.Plan.Get(ctx) for desired state in Update, resp.State.Set(ctx) to save state, resp.Diagnostics.Append for error handling, resp.State.RemoveResource(ctx) for not found handling"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "```go\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\ntype resourceDatabaseModel struct {\n    ID          types.String `tfsdk:\"id\"`\n    Name        types.String `tfsdk:\"name\"`\n    Engine      types.String `tfsdk:\"engine\"`\n    Size        types.Int64  `tfsdk:\"size\"`\n    Status      types.String `tfsdk:\"status\"`\n}\n\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() { return }\n    // ... create logic ...\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Call the finder function to get the database\n    database, err := r.findDatabaseByID(ctx, data.ID.ValueString())\n    if err != nil {\n        // Check if resource was not found\n        if isResourceNotFoundError(err) {\n            // Remove from state if resource no longer exists\n            resp.State.RemoveResource(ctx)\n            return\n        }\n        \n        // Handle other errors\n        resp.Diagnostics.AddError(\n            \"Error Reading Database\",\n            fmt.Sprintf(\"Could not read database ID %s: %s\", data.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Update the state with the retrieved data\n    data.ID = types.StringValue(database.ID)\n    data.Name = types.StringValue(database.Name)\n    data.Engine = types.StringValue(database.Engine)\n    data.Size = types.Int64Value(database.Size)\n    data.Status = types.StringValue(database.Status)\n    \n    // Save updated data into Terraform state\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    \n    // Get current plan\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Check if resource still exists before updating\n    _, err := r.findDatabaseByID(ctx, state.ID.ValueString())\n    if err != nil {\n        if isResourceNotFoundError(err) {\n            resp.Diagnostics.AddError(\n                \"Database Not Found\",\n                fmt.Sprintf(\"Database ID %s no longer exists and cannot be updated\", state.ID.ValueString()),\n            )\n            resp.State.RemoveResource(ctx)\n            return\n        }\n        \n        resp.Diagnostics.AddError(\n            \"Error Reading Database\",\n            fmt.Sprintf(\"Could not read database ID %s before update: %s\", state.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Perform the update operation\n    updateInput := &DatabaseUpdateInput{\n        ID:     plan.ID.ValueString(),\n        Name:   plan.Name.ValueString(),\n        Engine: plan.Engine.ValueString(),\n        Size:   plan.Size.ValueInt64(),\n    }\n    \n    updatedDatabase, err := r.updateDatabase(ctx, updateInput)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Updating Database\",\n            fmt.Sprintf(\"Could not update database ID %s: %s\", plan.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Update the plan with the response data\n    plan.ID = types.StringValue(updatedDatabase.ID)\n    plan.Name = types.StringValue(updatedDatabase.Name)\n    plan.Engine = types.StringValue(updatedDatabase.Engine)\n    plan.Size = types.Int64Value(updatedDatabase.Size)\n    plan.Status = types.StringValue(updatedDatabase.Status)\n    \n    // Save updated data into Terraform state\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\n// Finder pattern implementation\nfunc (r *resourceDatabase) findDatabaseByID(ctx context.Context, id string) (*Database, error) {\n    // Call your API client to retrieve the database\n    client := r.Meta().Client // Assuming client is available via Meta()\n    \n    database, err := client.GetDatabase(ctx, id)\n    if err != nil {\n        return nil, err\n    }\n    \n    return database, nil\n}\n\n// Helper function to check if error is a \"not found\" error\nfunc isResourceNotFoundError(err error) bool {\n    // Adjust this based on your API client's error types\n    // Common patterns:\n    if err == nil {\n        return false\n    }\n    \n    // Check for specific error types\n    var notFoundErr *ResourceNotFoundError\n    if errors.As(err, &notFoundErr) {\n        return true\n    }\n    \n    // Check for HTTP 404 status\n    var apiErr *APIError\n    if errors.As(err, &apiErr) && apiErr.StatusCode == 404 {\n        return true\n    }\n    \n    // Check error message as fallback\n    errMsg := strings.ToLower(err.Error())\n    return strings.Contains(errMsg, \"not found\") || \n           strings.Contains(errMsg, \"does not exist\") ||\n           strings.Contains(errMsg, \"404\")\n}\n\n// Supporting types (adjust based on your actual API client)\ntype Database struct {\n    ID     string\n    Name   string\n    Engine string\n    Size   int64\n    Status string\n}\n\ntype DatabaseUpdateInput struct {\n    ID     string\n    Name   string\n    Engine string\n    Size   int64\n}\n\ntype ResourceNotFoundError struct {\n    ResourceID string\n}\n\nfunc (e *ResourceNotFoundError) Error() string {\n    return fmt.Sprintf(\"resource %s not found\", e.ResourceID)\n}\n\ntype APIError struct {\n    StatusCode int\n    Message    string\n}\n\nfunc (e *APIError) Error() string {\n    return fmt.Sprintf(\"API error %d: %s\", e.StatusCode, e.Message)\n}\n```\n\nThis implementation includes:\n\n1. **Read Operation**: Fetches current state, uses finder pattern, handles not found errors by removing from state, and updates state with fresh data\n2. **Update Operation**: Validates resource exists before updating, performs update, handles errors appropriately, and saves updated state\n3. **Finder Pattern**: Centralized `findDatabaseByID` function for consistent resource retrieval\n4. **Error Handling**: Proper detection of \"not found\" errors with multiple fallback mechanisms\n5. **State Management**: Correct use of `RemoveResource` when resource is deleted externally",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 254,
            "output_tokens": 1832,
            "cached": false
          },
          "with_skill": {
            "output": "# Complete Terraform Provider Resource Implementation\n\nHere's the complete implementation with Read, Update operations, and the finder pattern:\n\n```go\npackage service\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/hashicorp/terraform-plugin-framework/path\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource\"\n    \"github.com/hashicorp/terraform-plugin-framework/types\"\n    \"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n    \"github.com/provider/internal/conns\"\n    \"github.com/provider/internal/framework\"\n    \"github.com/provider/internal/tfresource\"\n    \"github.com/provider/sdk/database\"\n    dbtypes \"github.com/provider/sdk/database/types\"\n)\n\n// Resource Model\ntype resourceDatabaseModel struct {\n    ID          types.String `tfsdk:\"id\"`\n    Name        types.String `tfsdk:\"name\"`\n    Engine      types.String `tfsdk:\"engine\"`\n    Size        types.Int64  `tfsdk:\"size\"`\n    Status      types.String `tfsdk:\"status\"`\n    ARN         types.String `tfsdk:\"arn\"`\n    Endpoint    types.String `tfsdk:\"endpoint\"`\n    LastUpdated types.String `tfsdk:\"last_updated\"`\n}\n\n// Resource Implementation\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\nfunc (r *resourceDatabase) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = req.ProviderTypeName + \"_database\"\n}\n\n// Create Operation\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.CreateDatabaseInput{\n        Name:   data.Name.ValueStringPointer(),\n        Engine: data.Engine.ValueStringPointer(),\n        Size:   data.Size.ValueInt64Pointer(),\n    }\n\n    output, err := conn.CreateDatabase(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error creating Database\",\n            fmt.Sprintf(\"Could not create database %s: %s\", data.Name.ValueString(), err),\n        )\n        return\n    }\n\n    // Set initial values\n    data.ID = types.StringPointerValue(output.Id)\n    data.ARN = types.StringPointerValue(output.Arn)\n    data.Status = types.StringValue(\"creating\")\n\n    // Wait for database to be available\n    createTimeout := 30 * time.Minute\n    db, err := waitDatabaseCreated(ctx, conn, data.ID.ValueString(), createTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database creation\",\n            fmt.Sprintf(\"Database %s did not become available: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update model with final values\n    data.Status = types.StringPointerValue(db.Status)\n    data.Endpoint = types.StringPointerValue(db.Endpoint)\n    data.LastUpdated = types.StringValue(time.Now().Format(time.RFC3339))\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\n// Read Operation\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Use finder pattern to handle not found\n    db, err := findDatabaseByID(ctx, conn, data.ID.ValueString())\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource not found\",\n            fmt.Sprintf(\"Database %s not found, removing from state\", data.ID.ValueString()),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error reading Database\",\n            fmt.Sprintf(\"Could not read database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update model with current values from API\n    data.Name = types.StringPointerValue(db.Name)\n    data.Engine = types.StringPointerValue(db.Engine)\n    data.Size = types.Int64PointerValue(db.Size)\n    data.Status = types.StringPointerValue(db.Status)\n    data.ARN = types.StringPointerValue(db.Arn)\n    data.Endpoint = types.StringPointerValue(db.Endpoint)\n\n    // Preserve last_updated if it exists in state\n    if data.LastUpdated.IsNull() {\n        data.LastUpdated = types.StringValue(time.Now().Format(time.RFC3339))\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\n// Update Operation\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Check if size needs to be updated\n    if !plan.Size.Equal(state.Size) {\n        input := &database.ModifyDatabaseInput{\n            Id:   plan.ID.ValueStringPointer(),\n            Size: plan.Size.ValueInt64Pointer(),\n        }\n\n        _, err := conn.ModifyDatabase(ctx, input)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error updating Database size\",\n                fmt.Sprintf(\"Could not update database %s size: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        // Wait for modification to complete\n        updateTimeout := 30 * time.Minute\n        db, err := waitDatabaseUpdated(ctx, conn, plan.ID.ValueString(), updateTimeout)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error waiting for Database update\",\n                fmt.Sprintf(\"Database %s update did not complete: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        // Update status from API response\n        plan.Status = types.StringPointerValue(db.Status)\n    }\n\n    // Update last_updated timestamp\n    plan.LastUpdated = types.StringValue(time.Now().Format(time.RFC3339))\n\n    // Preserve computed values from state if not changed\n    if plan.ARN.IsNull() {\n        plan.ARN = state.ARN\n    }\n    if plan.Endpoint.IsNull() {\n        plan.Endpoint = state.Endpoint\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\n// Delete Operation\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.DeleteDatabaseInput{\n        Id: data.ID.ValueStringPointer(),\n    }\n\n    _, err := conn.DeleteDatabase(ctx, input)\n    if err != nil {\n        // If resource is already deleted, that's okay\n        if tfresource.NotFound(err) {\n            return\n        }\n\n        resp.Diagnostics.AddError(\n            \"Error deleting Database\",\n            fmt.Sprintf(\"Could not delete database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Wait for deletion to complete\n    deleteTimeout := 30 * time.Minute\n    _, err = waitDatabaseDeleted(ctx, conn, data.ID.ValueString(), deleteTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database deletion\",\n            fmt.Sprintf(\"Database %s deletion did not complete: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n}\n\n// Finder Pattern Implementation\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*dbtypes.Database, error) {\n    input := &database.DescribeDatabaseInput{\n        Id: &id,\n    }\n\n    output, err := conn.DescribeDatabase(ctx, input)\n    if err != nil {\n        // Handle specific not found errors\n        var notFound *dbtypes.ResourceNotFoundException\n        if errors.As(err, &notFound) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n\n        // Handle access denied as not found (common pattern)\n        var accessDenied *dbtypes.AccessDeniedException\n        if errors.As(err, &accessDenied) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n\n        return nil, err\n    }\n\n    // Validate output\n    if output == nil || output.Database == nil {\n        return nil, tfresource.NewEmptyResultError(input)\n    }\n\n    // Check for terminal states that should be treated as not found\n    if output.Database.Status != nil {\n        status := *output.Database.Status\n        if status == \"deleted\" || status == \"deleting\" {\n            return nil, &retry.NotFoundError{\n                LastError:   fmt.Errorf(\"database in terminal state: %s\", status),\n                LastRequest: input,\n            }\n        }\n    }\n\n    return output.Database, nil\n}\n\n// Status Refresh Function\nfunc statusDatabase(ctx context.Context, conn *database.Client, id string) retry.StateRefreshFunc {\n    return func() (interface{}, string, error) {\n        output, err := findDatabaseByID(ctx, conn, id)\n        if tfresource.NotFound(err) {\n            return nil, \"\", nil\n        }\n        if err != nil {\n            return nil, \"\", err\n        }\n\n        return output, *output.Status, nil\n    }\n}\n\n// Wait for Database Created\nfunc waitDatabaseCreated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*dbtypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"creating\", \"pending\", \"configuring\"},\n        Target:  []string{\"available\", \"active\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   30 * time.Second,\n        MinTimeout: 10 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*dbtypes.Database); ok {\n        // Include additional error details if available\n        if output.StatusMessage != nil {\n            err = fmt.Errorf(\"%w: %s\", err, *output.StatusMessage)\n        }\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for Database Updated\nfunc waitDatabaseUpdated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*dbtypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"modifying\", \"updating\", \"configuring\"},\n        Target:  []string{\"available\", \"active\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   30 * time.Second,\n        MinTimeout: 10 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*dbtypes.Database); ok {\n        if output.StatusMessage != nil {\n            err = fmt.Errorf(\"%w: %s\", err, *output.StatusMessage)\n        }\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for Database Deleted\nfunc waitDatabaseDeleted(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*dbtypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"deleting\", \"available\", \"active\"},\n        Target:  []string{},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   30 * time.Second,\n        MinTimeout: 10 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*dbtypes.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\n// ImportState Implementation\nfunc (r *resourceDatabase) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {\n    resource.ImportStatePassthroughID(ctx, path.Root(\"id\"), req, resp)\n}\n```\n\n## Key Implementation Details\n\n### 1. **Read Operation Features**\n- Uses finder pattern for consistent not found handling\n- Removes resource from state when not found\n- Updates all attributes from API response\n- Preserves `last_updated` timestamp from state\n\n### 2. **Update Operation Features**\n- Compares plan vs state to detect changes\n- Only updates changed attributes\n- Waits for modification to complete\n- Updates `last_updated` timestamp\n- Preserves computed values\n\n### 3. **Finder Pattern**\n- Handles multiple not found scenarios\n- Converts API errors to `retry.NotFoundError`\n- Validates output is not nil\n- Checks for terminal states\n\n### 4. **State Management**\n- Proper waiter functions for async operations\n- Status refresh with error details\n- Configurable timeouts and delays\n- Handles terminal states correctly\n\n### 5. **Error Handling**\n- Clear, actionable error messages\n- Includes resource identifier in errors\n- Preserves error context\n- Handles edge cases (access denied, etc.)\n\nThis implementation follows Terraform Plugin Framework best practices and provides robust resource lifecycle management.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4973,
            "output_tokens": 3741,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "Here's the complete implementation with Read and Update operations, including proper error handling and the finder pattern:\n\n```go\npackage database\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/hashicorp/terraform-plugin-framework/resource\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/types\"\n    \"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n    \n    \"github.com/yourorg/provider/internal/framework\"\n    \"github.com/yourorg/provider/internal/tfresource\"\n    databasetypes \"github.com/yourorg/sdk/service/database/types\"\n)\n\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\ntype resourceDatabaseModel struct {\n    ID     types.String `tfsdk:\"id\"`\n    Name   types.String `tfsdk:\"name\"`\n    Engine types.String `tfsdk:\"engine\"`\n    Size   types.Int64  `tfsdk:\"size\"`\n    Status types.String `tfsdk:\"status\"`\n}\n\nfunc (r *resourceDatabase) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = req.ProviderTypeName + \"_database\"\n}\n\nfunc (r *resourceDatabase) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Description: \"Manages a database instance.\",\n        Attributes: map[string]schema.Attribute{\n            \"id\": framework.IDAttribute(),\n            \"name\": schema.StringAttribute{\n                Description: \"Name of the database.\",\n                Required:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"engine\": schema.StringAttribute{\n                Description: \"Database engine type (e.g., postgres, mysql).\",\n                Required:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"size\": schema.Int64Attribute{\n                Description: \"Size of the database in GB.\",\n                Required:    true,\n                PlanModifiers: []planmodifier.Int64{\n                    int64planmodifier.RequiresReplace(),\n                },\n            },\n            \"status\": schema.StringAttribute{\n                Description: \"Current status of the database.\",\n                Computed:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n        },\n    }\n}\n\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.CreateDatabaseInput{\n        Name:   data.Name.ValueStringPointer(),\n        Engine: data.Engine.ValueStringPointer(),\n        Size:   data.Size.ValueInt64Pointer(),\n    }\n\n    output, err := conn.CreateDatabase(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error creating Database\",\n            fmt.Sprintf(\"Could not create database %s: %s\", data.Name.ValueString(), err),\n        )\n        return\n    }\n\n    data.ID = types.StringPointerValue(output.Id)\n    data.Status = types.StringPointerValue(output.Status)\n\n    // Wait for database to become available\n    createTimeout := 30 * time.Minute\n    db, err := waitDatabaseCreated(ctx, conn, data.ID.ValueString(), createTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database creation\",\n            fmt.Sprintf(\"Database %s did not become available: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    data.Status = types.StringPointerValue(db.Status)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    output, err := findDatabaseByID(ctx, conn, data.ID.ValueString())\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource not found\",\n            fmt.Sprintf(\"Database %s not found, removing from state\", data.ID.ValueString()),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error reading Database\",\n            fmt.Sprintf(\"Could not read database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update state with values from API\n    data.Name = types.StringPointerValue(output.Name)\n    data.Engine = types.StringPointerValue(output.Engine)\n    data.Size = types.Int64PointerValue(output.Size)\n    data.Status = types.StringPointerValue(output.Status)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Check if size needs to be updated\n    if !plan.Size.Equal(state.Size) {\n        input := &database.UpdateDatabaseInput{\n            Id:   plan.ID.ValueStringPointer(),\n            Size: plan.Size.ValueInt64Pointer(),\n        }\n\n        _, err := conn.UpdateDatabase(ctx, input)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error updating Database\",\n                fmt.Sprintf(\"Could not update database %s: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        // Wait for update to complete\n        updateTimeout := 30 * time.Minute\n        db, err := waitDatabaseUpdated(ctx, conn, plan.ID.ValueString(), updateTimeout)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error waiting for Database update\",\n                fmt.Sprintf(\"Database %s update did not complete: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        plan.Status = types.StringPointerValue(db.Status)\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    _, err := conn.DeleteDatabase(ctx, &database.DeleteDatabaseInput{\n        Id: data.ID.ValueStringPointer(),\n    })\n\n    if tfresource.NotFound(err) {\n        return\n    }\n\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error deleting Database\",\n            fmt.Sprintf(\"Could not delete database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Wait for deletion to complete\n    deleteTimeout := 30 * time.Minute\n    _, err = waitDatabaseDeleted(ctx, conn, data.ID.ValueString(), deleteTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database deletion\",\n            fmt.Sprintf(\"Database %s was not deleted: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n}\n\n// Finder function - implements the finder pattern for handling resource not found\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*databasetypes.Database, error) {\n    input := &database.GetDatabaseInput{\n        Id: &id,\n    }\n\n    output, err := conn.GetDatabase(ctx, input)\n    if err != nil {\n        // Handle specific API error for resource not found\n        var notFound *databasetypes.ResourceNotFoundException\n        if errors.As(err, &notFound) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n        return nil, err\n    }\n\n    if output == nil || output.Database == nil {\n        return nil, tfresource.NewEmptyResultError(input)\n    }\n\n    return output.Database, nil\n}\n\n// Status function for state refresh\nfunc statusDatabase(ctx context.Context, conn *database.Client, id string) retry.StateRefreshFunc {\n    return func() (interface{}, string, error) {\n        output, err := findDatabaseByID(ctx, conn, id)\n        if tfresource.NotFound(err) {\n            return nil, \"\", nil\n        }\n        if err != nil {\n            return nil, \"\", err\n        }\n\n        return output, *output.Status, nil\n    }\n}\n\n// Wait for database creation\nfunc waitDatabaseCreated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*databasetypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"CREATING\", \"PENDING\"},\n        Target:  []string{\"AVAILABLE\", \"ACTIVE\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*databasetypes.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database update\nfunc waitDatabaseUpdated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*databasetypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"UPDATING\", \"MODIFYING\"},\n        Target:  []string{\"AVAILABLE\", \"ACTIVE\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*databasetypes.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database deletion\nfunc waitDatabaseDeleted(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*databasetypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"DELETING\", \"AVAILABLE\", \"ACTIVE\"},\n        Target:  []string{},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*databasetypes.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n```\n\n## Key Implementation Details:\n\n1. **Read Operation**:\n   - Uses `findDatabaseByID` to fetch current state\n   - Handles `NotFound` error by removing resource from state\n   - Updates all attributes from API response\n   - Proper error diagnostics for other errors\n\n2. **Update Operation**:\n   - Compares plan vs state to detect changes\n   - Only updates changed attributes (size in this case)\n   - Waits for update to complete before returning\n   - Updates status after successful modification\n\n3. **Finder Pattern**:\n   - `findDatabaseByID` centralizes resource lookup logic\n   - Converts API-specific errors to `retry.NotFoundError`\n   - Handles empty response cases\n   - Used by all operations and waiters\n\n4. **State Management**:\n   - Proper use of `StateChangeConf` for async operations\n   - Status refresh function for polling\n   - Appropriate timeouts and delays\n   - Handles intermediate states (CREATING, UPDATING, DELETING)\n\n5. **Error Handling**:\n   - Clear, actionable error messages\n   - Proper error type checking with `errors.As`\n   - Distinguishes between not found and other errors\n   - Warnings for expected conditions (resource not found)\n\nThis implementation follows Terraform provider best practices for resource lifecycle management.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5457,
            "output_tokens": 3504,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "```go\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\ntype resourceDatabaseModel struct {\n    ID          types.String `tfsdk:\"id\"`\n    Name        types.String `tfsdk:\"name\"`\n    Engine      types.String `tfsdk:\"engine\"`\n    Size        types.Int64  `tfsdk:\"size\"`\n    Status      types.String `tfsdk:\"status\"`\n}\n\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() { return }\n    // ... create logic ...\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Call API to get database using finder pattern\n    database, err := r.findDatabaseByID(ctx, data.ID.ValueString())\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Reading Database\",\n            fmt.Sprintf(\"Could not read database ID %s: %s\", data.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Handle resource not found - remove from state\n    if database == nil {\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    \n    // Update state with refreshed values\n    data.ID = types.StringValue(database.ID)\n    data.Name = types.StringValue(database.Name)\n    data.Engine = types.StringValue(database.Engine)\n    data.Size = types.Int64Value(database.Size)\n    data.Status = types.StringValue(database.Status)\n    \n    // Set refreshed state\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    \n    // Get current plan\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Verify resource still exists before updating\n    database, err := r.findDatabaseByID(ctx, state.ID.ValueString())\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Reading Database\",\n            fmt.Sprintf(\"Could not read database ID %s before update: %s\", state.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    if database == nil {\n        resp.Diagnostics.AddError(\n            \"Database Not Found\",\n            fmt.Sprintf(\"Database ID %s not found, cannot update\", state.ID.ValueString()),\n        )\n        return\n    }\n    \n    // Prepare update request\n    updateReq := &DatabaseUpdateRequest{\n        ID:     plan.ID.ValueString(),\n        Name:   plan.Name.ValueString(),\n        Engine: plan.Engine.ValueString(),\n        Size:   plan.Size.ValueInt64(),\n    }\n    \n    // Call API to update database\n    updatedDatabase, err := r.client.UpdateDatabase(ctx, updateReq)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Updating Database\",\n            fmt.Sprintf(\"Could not update database ID %s: %s\", plan.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Update plan with computed values from API response\n    plan.Status = types.StringValue(updatedDatabase.Status)\n    \n    // Set updated state\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Call API to delete database\n    err := r.client.DeleteDatabase(ctx, data.ID.ValueString())\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Deleting Database\",\n            fmt.Sprintf(\"Could not delete database ID %s: %s\", data.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Resource is automatically removed from state after successful delete\n}\n\n// findDatabaseByID implements the finder pattern for handling resource not found\n// Returns (nil, nil) when resource is not found\n// Returns (nil, error) when an error occurs\n// Returns (*Database, nil) when resource is found\nfunc (r *resourceDatabase) findDatabaseByID(ctx context.Context, id string) (*Database, error) {\n    database, err := r.client.GetDatabase(ctx, id)\n    if err != nil {\n        // Check if error is a \"not found\" error\n        if isNotFoundError(err) {\n            return nil, nil\n        }\n        return nil, err\n    }\n    \n    return database, nil\n}\n\n// Helper function to determine if error is a \"not found\" error\nfunc isNotFoundError(err error) bool {\n    // Adjust based on your API client's error types\n    var apiErr *APIError\n    if errors.As(err, &apiErr) {\n        return apiErr.StatusCode == 404\n    }\n    return false\n}\n\n// Supporting types (adjust based on your actual API client)\ntype Database struct {\n    ID     string\n    Name   string\n    Engine string\n    Size   int64\n    Status string\n}\n\ntype DatabaseUpdateRequest struct {\n    ID     string\n    Name   string\n    Engine string\n    Size   int64\n}\n\ntype APIError struct {\n    StatusCode int\n    Message    string\n}\n\nfunc (e *APIError) Error() string {\n    return e.Message\n}\n```\n\n**Key Implementation Details:**\n\n1. **Read Operation:**\n   - Uses finder pattern to handle not found gracefully\n   - Removes resource from state when not found\n   - Refreshes all attributes from API\n\n2. **Update Operation:**\n   - Verifies resource exists before updating\n   - Handles computed attributes (Status)\n   - Proper error handling with context\n\n3. **Finder Pattern:**\n   - Returns `(nil, nil)` for not found\n   - Returns `(nil, error)` for actual errors\n   - Returns `(*Database, nil)` for success\n\n4. **Error Handling:**\n   - Descriptive error messages with context\n   - Proper diagnostic reporting\n   - Early returns on errors",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 254,
            "output_tokens": 1796,
            "cached": false
          },
          "with_skill": {
            "output": "# Complete Terraform Provider Resource Implementation\n\nHere's the complete implementation with Read, Update, Delete operations, and the finder pattern:\n\n```go\npackage service\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/hashicorp/terraform-plugin-framework/path\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/types\"\n    \"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n    \n    \"github.com/terraform-providers/terraform-provider-example/internal/conns\"\n    \"github.com/terraform-providers/terraform-provider-example/internal/framework\"\n    \"github.com/terraform-providers/terraform-provider-example/internal/tfresource\"\n    \n    \"github.com/example/sdk/database\"\n    sdktypes \"github.com/example/sdk/types\"\n)\n\n// Resource type definition\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\n// Resource model\ntype resourceDatabaseModel struct {\n    ID          types.String `tfsdk:\"id\"`\n    Name        types.String `tfsdk:\"name\"`\n    Engine      types.String `tfsdk:\"engine\"`\n    Size        types.Int64  `tfsdk:\"size\"`\n    Status      types.String `tfsdk:\"status\"`\n    Description types.String `tfsdk:\"description\"`\n    ARN         types.String `tfsdk:\"arn\"`\n    Endpoint    types.String `tfsdk:\"endpoint\"`\n}\n\n// Metadata returns the resource type name\nfunc (r *resourceDatabase) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = req.ProviderTypeName + \"_database\"\n}\n\n// Schema defines the resource schema\nfunc (r *resourceDatabase) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Description: \"Manages a Database instance.\",\n        Attributes: map[string]schema.Attribute{\n            \"id\": framework.IDAttribute(),\n            \"name\": schema.StringAttribute{\n                Description: \"Name of the database.\",\n                Required:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"engine\": schema.StringAttribute{\n                Description: \"Database engine type (e.g., postgres, mysql).\",\n                Required:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"size\": schema.Int64Attribute{\n                Description: \"Size of the database in GB.\",\n                Required:    true,\n                PlanModifiers: []planmodifier.Int64{\n                    int64planmodifier.RequiresReplace(),\n                },\n            },\n            \"description\": schema.StringAttribute{\n                Description: \"Description of the database.\",\n                Optional:    true,\n            },\n            \"status\": schema.StringAttribute{\n                Description: \"Current status of the database.\",\n                Computed:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n            \"arn\": schema.StringAttribute{\n                Description: \"ARN of the database.\",\n                Computed:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n            \"endpoint\": schema.StringAttribute{\n                Description: \"Connection endpoint for the database.\",\n                Computed:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n        },\n    }\n}\n\n// Create creates a new database resource\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.CreateDatabaseInput{\n        Name:        data.Name.ValueStringPointer(),\n        Engine:      data.Engine.ValueStringPointer(),\n        Size:        data.Size.ValueInt64Pointer(),\n        Description: data.Description.ValueStringPointer(),\n    }\n\n    output, err := conn.CreateDatabase(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error creating Database\",\n            fmt.Sprintf(\"Could not create database %s: %s\", data.Name.ValueString(), err),\n        )\n        return\n    }\n\n    // Set the ID immediately\n    data.ID = types.StringPointerValue(output.Id)\n\n    // Wait for the database to become available\n    createTimeout := 30 * time.Minute\n    db, err := waitDatabaseCreated(ctx, conn, data.ID.ValueString(), createTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database creation\",\n            fmt.Sprintf(\"Database %s did not reach available state: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update model with computed attributes\n    data.Status = types.StringPointerValue(db.Status)\n    data.ARN = types.StringPointerValue(db.Arn)\n    data.Endpoint = types.StringPointerValue(db.Endpoint)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\n// Read reads the current state of the database resource\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Use finder pattern to handle not found\n    db, err := findDatabaseByID(ctx, conn, data.ID.ValueString())\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource not found\",\n            fmt.Sprintf(\"Database %s not found, removing from state\", data.ID.ValueString()),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error reading Database\",\n            fmt.Sprintf(\"Could not read database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update model with current values from API\n    data.Name = types.StringPointerValue(db.Name)\n    data.Engine = types.StringPointerValue(db.Engine)\n    data.Size = types.Int64PointerValue(db.Size)\n    data.Description = types.StringPointerValue(db.Description)\n    data.Status = types.StringPointerValue(db.Status)\n    data.ARN = types.StringPointerValue(db.Arn)\n    data.Endpoint = types.StringPointerValue(db.Endpoint)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\n// Update updates the database resource\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Check if description changed (only updatable field)\n    if !plan.Description.Equal(state.Description) {\n        input := &database.UpdateDatabaseInput{\n            Id:          plan.ID.ValueStringPointer(),\n            Description: plan.Description.ValueStringPointer(),\n        }\n\n        _, err := conn.UpdateDatabase(ctx, input)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error updating Database\",\n                fmt.Sprintf(\"Could not update database %s: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        // Wait for update to complete\n        updateTimeout := 20 * time.Minute\n        db, err := waitDatabaseUpdated(ctx, conn, plan.ID.ValueString(), updateTimeout)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error waiting for Database update\",\n                fmt.Sprintf(\"Database %s update did not complete: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        // Update computed attributes that may have changed\n        plan.Status = types.StringPointerValue(db.Status)\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\n// Delete deletes the database resource\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.DeleteDatabaseInput{\n        Id: data.ID.ValueStringPointer(),\n    }\n\n    _, err := conn.DeleteDatabase(ctx, input)\n    if err != nil {\n        // If resource is already gone, that's okay\n        if tfresource.NotFound(err) {\n            return\n        }\n\n        resp.Diagnostics.AddError(\n            \"Error deleting Database\",\n            fmt.Sprintf(\"Could not delete database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Wait for deletion to complete\n    deleteTimeout := 30 * time.Minute\n    _, err = waitDatabaseDeleted(ctx, conn, data.ID.ValueString(), deleteTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database deletion\",\n            fmt.Sprintf(\"Database %s deletion did not complete: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n}\n\n// ImportState handles resource import\nfunc (r *resourceDatabase) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {\n    resource.ImportStatePassthroughID(ctx, path.Root(\"id\"), req, resp)\n}\n\n// Finder function - handles resource not found pattern\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*sdktypes.Database, error) {\n    input := &database.GetDatabaseInput{\n        Id: &id,\n    }\n\n    output, err := conn.GetDatabase(ctx, input)\n    if err != nil {\n        // Handle specific not found error types\n        var notFound *sdktypes.ResourceNotFoundException\n        if errors.As(err, &notFound) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n        return nil, err\n    }\n\n    // Handle empty response\n    if output == nil || output.Database == nil {\n        return nil, tfresource.NewEmptyResultError(input)\n    }\n\n    return output.Database, nil\n}\n\n// Status refresh function for state waiters\nfunc statusDatabase(ctx context.Context, conn *database.Client, id string) retry.StateRefreshFunc {\n    return func() (interface{}, string, error) {\n        output, err := findDatabaseByID(ctx, conn, id)\n        if tfresource.NotFound(err) {\n            return nil, \"\", nil\n        }\n        if err != nil {\n            return nil, \"\", err\n        }\n\n        return output, *output.Status, nil\n    }\n}\n\n// Wait for database creation\nfunc waitDatabaseCreated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*sdktypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"creating\", \"pending\", \"initializing\"},\n        Target:  []string{\"available\", \"active\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   30 * time.Second,\n        MinTimeout: 10 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*sdktypes.Database); ok {\n        // Include additional error details if available\n        if output.StatusMessage != nil {\n            err = fmt.Errorf(\"%w: %s\", err, *output.StatusMessage)\n        }\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database update\nfunc waitDatabaseUpdated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*sdktypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"updating\", \"modifying\"},\n        Target:  []string{\"available\", \"active\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*sdktypes.Database); ok {\n        if output.StatusMessage != nil {\n            err = fmt.Errorf(\"%w: %s\", err, *output.StatusMessage)\n        }\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database deletion\nfunc waitDatabaseDeleted(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*sdktypes.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"deleting\", \"available\", \"active\"},\n        Target:  []string{},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   30 * time.Second,\n        MinTimeout: 10 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*sdktypes.Database); ok {\n        if output.StatusMessage != nil {\n            err = fmt.Errorf(\"%w: %s\", err, *output.StatusMessage)\n        }\n        return output, err\n    }\n\n    return nil, err\n}\n```\n\n## Key Implementation Details\n\n### 1. **Read Operation**\n- Uses `findDatabaseByID` finder pattern\n- Handles `NotFound` error by removing resource from state\n- Updates all attributes from API response\n- Proper error handling with descriptive messages\n\n### 2. **Update Operation**\n- Compares plan vs state to detect changes\n- Only updates changed attributes (description in this case)\n- Waits for update to complete before returning\n- Updates computed attributes after successful update\n\n### 3. **Finder Pattern**\n```go\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*sdktypes.Database, error) {\n    // Handles:\n    // - API call\n    // - ResourceNotFoundException -> NotFoundError\n    // - Empty response -> EmptyResultError\n    // - Other errors passed through\n}\n```\n\n### 4. **State Management**\n- Uses `StateChangeConf` for async operations\n- Proper timeout handling\n- Status messages included in errors\n- Different delays for different operations\n\n### 5. **Error Handling**",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4973,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "Here's the complete implementation with Read and Update operations, following Terraform provider best practices:\n\n```go\npackage service\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/hashicorp/terraform-plugin-framework/resource\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/types\"\n    \"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n    \n    \"github.com/yourorg/provider/internal/framework\"\n    \"github.com/yourorg/provider/internal/tfresource\"\n)\n\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\ntype resourceDatabaseModel struct {\n    ID     types.String `tfsdk:\"id\"`\n    Name   types.String `tfsdk:\"name\"`\n    Engine types.String `tfsdk:\"engine\"`\n    Size   types.Int64  `tfsdk:\"size\"`\n    Status types.String `tfsdk:\"status\"`\n}\n\nfunc (r *resourceDatabase) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = req.ProviderTypeName + \"_database\"\n}\n\nfunc (r *resourceDatabase) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Description: \"Manages a Database resource.\",\n        Attributes: map[string]schema.Attribute{\n            \"id\": framework.IDAttribute(),\n            \"name\": schema.StringAttribute{\n                Required:    true,\n                Description: \"Name of the database.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"engine\": schema.StringAttribute{\n                Required:    true,\n                Description: \"Database engine type.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"size\": schema.Int64Attribute{\n                Required:    true,\n                Description: \"Size of the database in GB.\",\n                PlanModifiers: []planmodifier.Int64{\n                    int64planmodifier.RequiresReplace(),\n                },\n            },\n            \"status\": schema.StringAttribute{\n                Computed:    true,\n                Description: \"Current status of the database.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n        },\n    }\n}\n\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.CreateDatabaseInput{\n        Name:   data.Name.ValueStringPointer(),\n        Engine: data.Engine.ValueStringPointer(),\n        Size:   data.Size.ValueInt64Pointer(),\n    }\n\n    output, err := conn.CreateDatabase(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error creating Database\",\n            fmt.Sprintf(\"Could not create database %s: %s\", data.Name.ValueString(), err),\n        )\n        return\n    }\n\n    data.ID = types.StringPointerValue(output.Id)\n    data.Status = types.StringPointerValue(output.Status)\n\n    // Wait for database to become available\n    createTimeout := 30 * time.Minute\n    db, err := waitDatabaseCreated(ctx, conn, data.ID.ValueString(), createTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database creation\",\n            fmt.Sprintf(\"Database %s did not become available: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    data.Status = types.StringPointerValue(db.Status)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    output, err := findDatabaseByID(ctx, conn, data.ID.ValueString())\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource not found\",\n            fmt.Sprintf(\"Database %s not found, removing from state\", data.ID.ValueString()),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error reading Database\",\n            fmt.Sprintf(\"Could not read database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update state with values from API\n    data.Name = types.StringPointerValue(output.Name)\n    data.Engine = types.StringPointerValue(output.Engine)\n    data.Size = types.Int64PointerValue(output.Size)\n    data.Status = types.StringPointerValue(output.Status)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Check if size changed (only updatable attribute in this example)\n    if !plan.Size.Equal(state.Size) {\n        input := &database.UpdateDatabaseInput{\n            Id:   plan.ID.ValueStringPointer(),\n            Size: plan.Size.ValueInt64Pointer(),\n        }\n\n        _, err := conn.UpdateDatabase(ctx, input)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error updating Database\",\n                fmt.Sprintf(\"Could not update database %s: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        // Wait for update to complete\n        updateTimeout := 30 * time.Minute\n        db, err := waitDatabaseUpdated(ctx, conn, plan.ID.ValueString(), updateTimeout)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error waiting for Database update\",\n                fmt.Sprintf(\"Database %s update did not complete: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        plan.Status = types.StringPointerValue(db.Status)\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    _, err := conn.DeleteDatabase(ctx, &database.DeleteDatabaseInput{\n        Id: data.ID.ValueStringPointer(),\n    })\n\n    if tfresource.NotFound(err) {\n        return\n    }\n\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error deleting Database\",\n            fmt.Sprintf(\"Could not delete database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Wait for deletion to complete\n    deleteTimeout := 30 * time.Minute\n    _, err = waitDatabaseDeleted(ctx, conn, data.ID.ValueString(), deleteTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database deletion\",\n            fmt.Sprintf(\"Database %s deletion did not complete: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n}\n\n// Finder function following the pattern\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*database.Database, error) {\n    input := &database.GetDatabaseInput{\n        Id: &id,\n    }\n\n    output, err := conn.GetDatabase(ctx, input)\n    if err != nil {\n        var notFound *types.ResourceNotFoundException\n        if errors.As(err, &notFound) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n        return nil, err\n    }\n\n    if output == nil || output.Database == nil {\n        return nil, tfresource.NewEmptyResultError(input)\n    }\n\n    return output.Database, nil\n}\n\n// Status function for state refresh\nfunc statusDatabase(ctx context.Context, conn *database.Client, id string) retry.StateRefreshFunc {\n    return func() (interface{}, string, error) {\n        output, err := findDatabaseByID(ctx, conn, id)\n        if tfresource.NotFound(err) {\n            return nil, \"\", nil\n        }\n        if err != nil {\n            return nil, \"\", err\n        }\n        return output, *output.Status, nil\n    }\n}\n\n// Wait functions for async operations\nfunc waitDatabaseCreated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"CREATING\", \"PENDING\"},\n        Target:  []string{\"AVAILABLE\", \"ACTIVE\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\nfunc waitDatabaseUpdated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"UPDATING\", \"MODIFYING\"},\n        Target:  []string{\"AVAILABLE\", \"ACTIVE\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\nfunc waitDatabaseDeleted(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"DELETING\", \"AVAILABLE\", \"ACTIVE\"},\n        Target:  []string{},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n```\n\n## Key Implementation Details:\n\n1. **Read Operation**:\n   - Uses `findDatabaseByID` finder pattern\n   - Handles `NotFound` by removing from state with warning\n   - Updates all attributes from API response\n   - Proper error handling with context\n\n2. **Update Operation**:\n   - Compares plan vs state to detect changes\n   - Only updates changed attributes\n   - Waits for async operations to complete\n   - Updates status after operation\n\n3. **Finder Pattern**:\n   - Wraps API errors in `retry.NotFoundError`\n   - Handles empty results\n   - Consistent error handling\n\n4. **State Management**:\n   - Proper use of `UseStateForUnknown` for computed values\n   - `RequiresReplace` for immutable attributes\n   - Waits for resource states before updating Terraform state\n\n5. **Error Handling**:\n   - Clear, actionable error messages\n   - Proper error type checking with `errors.As`\n   - Context included in all error messages",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5457,
            "output_tokens": 3358,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "```go\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\ntype resourceDatabaseModel struct {\n    ID          types.String `tfsdk:\"id\"`\n    Name        types.String `tfsdk:\"name\"`\n    Engine      types.String `tfsdk:\"engine\"`\n    Size        types.Int64  `tfsdk:\"size\"`\n    Status      types.String `tfsdk:\"status\"`\n}\n\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() { return }\n    // ... create logic ...\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Get database from API using finder pattern\n    database, err := r.findDatabaseByID(ctx, data.ID.ValueString())\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Reading Database\",\n            fmt.Sprintf(\"Could not read database ID %s: %s\", data.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Handle resource not found - remove from state\n    if database == nil {\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    \n    // Update state with refreshed values\n    data.ID = types.StringValue(database.ID)\n    data.Name = types.StringValue(database.Name)\n    data.Engine = types.StringValue(database.Engine)\n    data.Size = types.Int64Value(database.Size)\n    data.Status = types.StringValue(database.Status)\n    \n    // Set refreshed state\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    \n    // Get plan values\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Check if resource exists before updating\n    existing, err := r.findDatabaseByID(ctx, state.ID.ValueString())\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Reading Database\",\n            fmt.Sprintf(\"Could not read database ID %s before update: %s\", state.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    if existing == nil {\n        resp.Diagnostics.AddError(\n            \"Database Not Found\",\n            fmt.Sprintf(\"Database ID %s not found, cannot update\", state.ID.ValueString()),\n        )\n        return\n    }\n    \n    // Prepare update request\n    updateReq := &DatabaseUpdateRequest{\n        ID:     plan.ID.ValueString(),\n        Name:   plan.Name.ValueString(),\n        Engine: plan.Engine.ValueString(),\n        Size:   plan.Size.ValueInt64(),\n    }\n    \n    // Call API to update database\n    updatedDatabase, err := r.client.UpdateDatabase(ctx, updateReq)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Updating Database\",\n            fmt.Sprintf(\"Could not update database ID %s: %s\", plan.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Update plan with computed values from API response\n    plan.Status = types.StringValue(updatedDatabase.Status)\n    \n    // Set updated state\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    \n    // Get current state\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n    \n    // Delete database via API\n    err := r.client.DeleteDatabase(ctx, data.ID.ValueString())\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error Deleting Database\",\n            fmt.Sprintf(\"Could not delete database ID %s: %s\", data.ID.ValueString(), err.Error()),\n        )\n        return\n    }\n    \n    // Resource is automatically removed from state after successful delete\n}\n\n// findDatabaseByID implements the finder pattern for handling resource not found\n// Returns (nil, nil) when resource is not found (not an error condition)\n// Returns (nil, error) when an actual error occurs\n// Returns (database, nil) when resource is found\nfunc (r *resourceDatabase) findDatabaseByID(ctx context.Context, id string) (*Database, error) {\n    database, err := r.client.GetDatabase(ctx, id)\n    if err != nil {\n        // Check if error is \"not found\" - this is not an error condition\n        if isNotFoundError(err) {\n            return nil, nil\n        }\n        // Actual error occurred\n        return nil, err\n    }\n    \n    return database, nil\n}\n\n// Helper function to determine if error is a \"not found\" error\nfunc isNotFoundError(err error) bool {\n    // Adjust based on your API client's error types\n    var notFoundErr *NotFoundError\n    return errors.As(err, &notFoundErr) || \n           strings.Contains(err.Error(), \"not found\") ||\n           strings.Contains(err.Error(), \"404\")\n}\n\n// Example API types (adjust to match your actual API client)\ntype Database struct {\n    ID     string\n    Name   string\n    Engine string\n    Size   int64\n    Status string\n}\n\ntype DatabaseUpdateRequest struct {\n    ID     string\n    Name   string\n    Engine string\n    Size   int64\n}\n\ntype NotFoundError struct {\n    error\n}\n```\n\n**Key Features:**\n\n1. **Read Operation**: Properly handles resource not found by removing from state\n2. **Update Operation**: Validates resource exists before updating\n3. **Finder Pattern**: `findDatabaseByID` returns `(nil, nil)` for not found vs `(nil, error)` for actual errors\n4. **Error Handling**: Comprehensive error messages with context\n5. **State Management**: Proper state refresh and computed attribute handling",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 254,
            "output_tokens": 1739,
            "cached": false
          },
          "with_skill": {
            "output": "# Complete Terraform Provider Resource Implementation\n\nHere's the complete implementation with Read, Update operations, and proper finder pattern:\n\n```go\npackage service\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/hashicorp/terraform-plugin-framework/path\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/types\"\n    \"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n    \n    \"github.com/yourorg/terraform-provider/internal/conns\"\n    \"github.com/yourorg/terraform-provider/internal/framework\"\n    \"github.com/yourorg/terraform-provider/internal/tfresource\"\n    \"github.com/yourorg/api-client/database\"\n    apitypes \"github.com/yourorg/api-client/types\"\n)\n\n// Resource definition\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\ntype resourceDatabaseModel struct {\n    ID          types.String `tfsdk:\"id\"`\n    Name        types.String `tfsdk:\"name\"`\n    Engine      types.String `tfsdk:\"engine\"`\n    Size        types.Int64  `tfsdk:\"size\"`\n    Status      types.String `tfsdk:\"status\"`\n    Endpoint    types.String `tfsdk:\"endpoint\"`\n    CreatedAt   types.String `tfsdk:\"created_at\"`\n}\n\n// Metadata sets the resource type name\nfunc (r *resourceDatabase) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = req.ProviderTypeName + \"_database\"\n}\n\n// Schema defines the resource schema\nfunc (r *resourceDatabase) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Description: \"Manages a database instance.\",\n        Attributes: map[string]schema.Attribute{\n            \"id\": framework.IDAttribute(),\n            \"name\": schema.StringAttribute{\n                Description: \"Name of the database instance.\",\n                Required:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"engine\": schema.StringAttribute{\n                Description: \"Database engine type (e.g., postgres, mysql).\",\n                Required:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"size\": schema.Int64Attribute{\n                Description: \"Size of the database in GB.\",\n                Required:    true,\n                PlanModifiers: []planmodifier.Int64{\n                    int64planmodifier.RequiresReplace(),\n                },\n            },\n            \"status\": schema.StringAttribute{\n                Description: \"Current status of the database.\",\n                Computed:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n            \"endpoint\": schema.StringAttribute{\n                Description: \"Connection endpoint for the database.\",\n                Computed:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n            \"created_at\": schema.StringAttribute{\n                Description: \"Timestamp when the database was created.\",\n                Computed:    true,\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n        },\n    }\n}\n\n// Create implements the resource Create operation\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.CreateDatabaseInput{\n        Name:   data.Name.ValueStringPointer(),\n        Engine: data.Engine.ValueStringPointer(),\n        Size:   data.Size.ValueInt64Pointer(),\n    }\n\n    output, err := conn.CreateDatabase(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error creating Database\",\n            fmt.Sprintf(\"Could not create database %s: %s\", data.Name.ValueString(), err),\n        )\n        return\n    }\n\n    data.ID = types.StringPointerValue(output.Id)\n\n    // Wait for database to become available\n    createTimeout := 30 * time.Minute\n    db, err := waitDatabaseCreated(ctx, conn, data.ID.ValueString(), createTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database creation\",\n            fmt.Sprintf(\"Database %s did not become available: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Set computed attributes\n    data.Status = types.StringPointerValue(db.Status)\n    data.Endpoint = types.StringPointerValue(db.Endpoint)\n    data.CreatedAt = types.StringPointerValue(db.CreatedAt)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\n// Read implements the resource Read operation\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Use finder pattern to handle not found\n    db, err := findDatabaseByID(ctx, conn, data.ID.ValueString())\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource not found\",\n            fmt.Sprintf(\"Database %s not found, removing from state\", data.ID.ValueString()),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error reading Database\",\n            fmt.Sprintf(\"Could not read database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update state with API response\n    data.Name = types.StringPointerValue(db.Name)\n    data.Engine = types.StringPointerValue(db.Engine)\n    data.Size = types.Int64PointerValue(db.Size)\n    data.Status = types.StringPointerValue(db.Status)\n    data.Endpoint = types.StringPointerValue(db.Endpoint)\n    data.CreatedAt = types.StringPointerValue(db.CreatedAt)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\n// Update implements the resource Update operation\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Check if any updatable attributes have changed\n    // Note: name, engine, and size require replacement (RequiresReplace modifier)\n    // This update would handle other attributes if they existed\n    \n    // For this example, we'll demonstrate checking for changes\n    // even though current schema has no updatable attributes\n    hasChanges := false\n\n    // Example: If we had an updatable description field\n    // if !plan.Description.Equal(state.Description) {\n    //     hasChanges = true\n    // }\n\n    if !hasChanges {\n        // No changes to apply, just refresh state\n        db, err := findDatabaseByID(ctx, conn, plan.ID.ValueString())\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error reading Database\",\n                fmt.Sprintf(\"Could not read database %s: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        plan.Status = types.StringPointerValue(db.Status)\n        plan.Endpoint = types.StringPointerValue(db.Endpoint)\n        resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n        return\n    }\n\n    // If there were updatable attributes, we would update them here\n    // Example update logic:\n    /*\n    input := &database.UpdateDatabaseInput{\n        Id:          plan.ID.ValueStringPointer(),\n        Description: plan.Description.ValueStringPointer(),\n    }\n\n    _, err := conn.UpdateDatabase(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error updating Database\",\n            fmt.Sprintf(\"Could not update database %s: %s\", plan.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Wait for update to complete\n    updateTimeout := 20 * time.Minute\n    db, err := waitDatabaseUpdated(ctx, conn, plan.ID.ValueString(), updateTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database update\",\n            fmt.Sprintf(\"Database %s update did not complete: %s\", plan.ID.ValueString(), err),\n        )\n        return\n    }\n\n    plan.Status = types.StringPointerValue(db.Status)\n    */\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\n// Delete implements the resource Delete operation\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.DeleteDatabaseInput{\n        Id: data.ID.ValueStringPointer(),\n    }\n\n    _, err := conn.DeleteDatabase(ctx, input)\n    if err != nil {\n        // Check if resource is already deleted\n        if tfresource.NotFound(err) {\n            return\n        }\n\n        resp.Diagnostics.AddError(\n            \"Error deleting Database\",\n            fmt.Sprintf(\"Could not delete database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Wait for deletion to complete\n    deleteTimeout := 30 * time.Minute\n    _, err = waitDatabaseDeleted(ctx, conn, data.ID.ValueString(), deleteTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database deletion\",\n            fmt.Sprintf(\"Database %s deletion did not complete: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n}\n\n// ImportState implements the resource ImportState operation\nfunc (r *resourceDatabase) ImportState(ctx context.Context, req resource.ImportStateRequest, resp *resource.ImportStateResponse) {\n    resource.ImportStatePassthroughID(ctx, path.Root(\"id\"), req, resp)\n}\n\n// Finder pattern implementation\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*database.Database, error) {\n    input := &database.GetDatabaseInput{\n        Id: &id,\n    }\n\n    output, err := conn.GetDatabase(ctx, input)\n    if err != nil {\n        // Handle specific API error types\n        var notFound *apitypes.ResourceNotFoundException\n        if errors.As(err, &notFound) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n        return nil, err\n    }\n\n    if output == nil || output.Database == nil {\n        return nil, tfresource.NewEmptyResultError(input)\n    }\n\n    return output.Database, nil\n}\n\n// Status refresh function for state waiters\nfunc statusDatabase(ctx context.Context, conn *database.Client, id string) retry.StateRefreshFunc {\n    return func() (interface{}, string, error) {\n        db, err := findDatabaseByID(ctx, conn, id)\n        if tfresource.NotFound(err) {\n            return nil, \"\", nil\n        }\n        if err != nil {\n            return nil, \"\", err\n        }\n\n        return db, *db.Status, nil\n    }\n}\n\n// Wait for database creation\nfunc waitDatabaseCreated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"creating\", \"pending\", \"initializing\"},\n        Target:  []string{\"available\", \"active\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   30 * time.Second,\n        MinTimeout: 10 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database update\nfunc waitDatabaseUpdated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"updating\", \"modifying\"},\n        Target:  []string{\"available\", \"active\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database deletion\nfunc waitDatabaseDeleted(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"deleting\", \"available\", \"active\"},\n        Target:  []string{},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n```\n\n## Key Implementation Details\n\n### 1. **Read Operation**\n- Uses finder pattern to handle resource not found\n- Removes resource from state if not found (with warning)\n- Updates all attributes from API response\n- Proper error handling with diagnostics\n\n### 2. **Update Operation**\n- Compares plan vs state to detect changes\n- Handles case where no updatable attributes exist\n- Demonstrates pattern for future updatable attributes\n- Refreshes computed attributes after update\n- Includes waiter for async operations\n\n### 3. **Finder Pattern**\n```go\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*database.Database, error) {\n    // Returns *retry.NotFoundError for not found\n    // Returns nil for empty results\n    // Returns actual error for API failures\n}\n```\n\n### 4. **State Waiters**\n- `waitDatabaseCreated`: Wa",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4973,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "Here's the complete implementation with Read and Update operations, including proper error handling and the finder pattern:\n\n```go\npackage service\n\nimport (\n    \"context\"\n    \"errors\"\n    \"fmt\"\n    \"time\"\n\n    \"github.com/hashicorp/terraform-plugin-framework/resource\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/int64planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/planmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/resource/schema/stringplanmodifier\"\n    \"github.com/hashicorp/terraform-plugin-framework/types\"\n    \"github.com/hashicorp/terraform-plugin-sdk/v2/helper/retry\"\n    \n    \"github.com/yourorg/provider/internal/framework\"\n    \"github.com/yourorg/provider/internal/tfresource\"\n)\n\ntype resourceDatabase struct {\n    framework.ResourceWithConfigure\n}\n\ntype resourceDatabaseModel struct {\n    ID     types.String `tfsdk:\"id\"`\n    Name   types.String `tfsdk:\"name\"`\n    Engine types.String `tfsdk:\"engine\"`\n    Size   types.Int64  `tfsdk:\"size\"`\n    Status types.String `tfsdk:\"status\"`\n}\n\nfunc (r *resourceDatabase) Metadata(_ context.Context, req resource.MetadataRequest, resp *resource.MetadataResponse) {\n    resp.TypeName = req.ProviderTypeName + \"_database\"\n}\n\nfunc (r *resourceDatabase) Schema(ctx context.Context, req resource.SchemaRequest, resp *resource.SchemaResponse) {\n    resp.Schema = schema.Schema{\n        Description: \"Manages a database instance.\",\n        Attributes: map[string]schema.Attribute{\n            \"id\": framework.IDAttribute(),\n            \"name\": schema.StringAttribute{\n                Required:    true,\n                Description: \"Name of the database.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"engine\": schema.StringAttribute{\n                Required:    true,\n                Description: \"Database engine type (e.g., postgres, mysql).\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.RequiresReplace(),\n                },\n            },\n            \"size\": schema.Int64Attribute{\n                Required:    true,\n                Description: \"Size of the database in GB.\",\n                PlanModifiers: []planmodifier.Int64{\n                    int64planmodifier.UseStateForUnknown(),\n                },\n            },\n            \"status\": schema.StringAttribute{\n                Computed:    true,\n                Description: \"Current status of the database.\",\n                PlanModifiers: []planmodifier.String{\n                    stringplanmodifier.UseStateForUnknown(),\n                },\n            },\n        },\n    }\n}\n\nfunc (r *resourceDatabase) Create(ctx context.Context, req resource.CreateRequest, resp *resource.CreateResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    input := &database.CreateDatabaseInput{\n        Name:   data.Name.ValueStringPointer(),\n        Engine: data.Engine.ValueStringPointer(),\n        Size:   data.Size.ValueInt64Pointer(),\n    }\n\n    output, err := conn.CreateDatabase(ctx, input)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error creating Database\",\n            fmt.Sprintf(\"Could not create database %s: %s\", data.Name.ValueString(), err),\n        )\n        return\n    }\n\n    data.ID = types.StringPointerValue(output.Id)\n\n    // Wait for database to become available\n    createTimeout := 30 * time.Minute\n    db, err := waitDatabaseCreated(ctx, conn, data.ID.ValueString(), createTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database creation\",\n            fmt.Sprintf(\"Database %s did not become available: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    data.Status = types.StringPointerValue(db.Status)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Read(ctx context.Context, req resource.ReadRequest, resp *resource.ReadResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    output, err := findDatabaseByID(ctx, conn, data.ID.ValueString())\n    if tfresource.NotFound(err) {\n        resp.Diagnostics.AddWarning(\n            \"Resource not found\",\n            fmt.Sprintf(\"Database %s not found, removing from state\", data.ID.ValueString()),\n        )\n        resp.State.RemoveResource(ctx)\n        return\n    }\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error reading Database\",\n            fmt.Sprintf(\"Could not read database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Update state with values from API\n    data.Name = types.StringPointerValue(output.Name)\n    data.Engine = types.StringPointerValue(output.Engine)\n    data.Size = types.Int64PointerValue(output.Size)\n    data.Status = types.StringPointerValue(output.Status)\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &data)...)\n}\n\nfunc (r *resourceDatabase) Update(ctx context.Context, req resource.UpdateRequest, resp *resource.UpdateResponse) {\n    var plan, state resourceDatabaseModel\n    resp.Diagnostics.Append(req.Plan.Get(ctx, &plan)...)\n    resp.Diagnostics.Append(req.State.Get(ctx, &state)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    // Check if size needs to be updated\n    if !plan.Size.Equal(state.Size) {\n        input := &database.UpdateDatabaseInput{\n            Id:   plan.ID.ValueStringPointer(),\n            Size: plan.Size.ValueInt64Pointer(),\n        }\n\n        _, err := conn.UpdateDatabase(ctx, input)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error updating Database\",\n                fmt.Sprintf(\"Could not update database %s: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        // Wait for update to complete\n        updateTimeout := 30 * time.Minute\n        db, err := waitDatabaseUpdated(ctx, conn, plan.ID.ValueString(), updateTimeout)\n        if err != nil {\n            resp.Diagnostics.AddError(\n                \"Error waiting for Database update\",\n                fmt.Sprintf(\"Database %s update did not complete: %s\", plan.ID.ValueString(), err),\n            )\n            return\n        }\n\n        plan.Status = types.StringPointerValue(db.Status)\n    }\n\n    resp.Diagnostics.Append(resp.State.Set(ctx, &plan)...)\n}\n\nfunc (r *resourceDatabase) Delete(ctx context.Context, req resource.DeleteRequest, resp *resource.DeleteResponse) {\n    var data resourceDatabaseModel\n    resp.Diagnostics.Append(req.State.Get(ctx, &data)...)\n    if resp.Diagnostics.HasError() {\n        return\n    }\n\n    conn := r.Meta().DatabaseClient(ctx)\n\n    _, err := conn.DeleteDatabase(ctx, &database.DeleteDatabaseInput{\n        Id: data.ID.ValueStringPointer(),\n    })\n\n    if tfresource.NotFound(err) {\n        return\n    }\n\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error deleting Database\",\n            fmt.Sprintf(\"Could not delete database %s: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n\n    // Wait for deletion to complete\n    deleteTimeout := 30 * time.Minute\n    _, err = waitDatabaseDeleted(ctx, conn, data.ID.ValueString(), deleteTimeout)\n    if err != nil {\n        resp.Diagnostics.AddError(\n            \"Error waiting for Database deletion\",\n            fmt.Sprintf(\"Database %s deletion did not complete: %s\", data.ID.ValueString(), err),\n        )\n        return\n    }\n}\n\n// Finder function following the pattern\nfunc findDatabaseByID(ctx context.Context, conn *database.Client, id string) (*database.Database, error) {\n    input := &database.GetDatabaseInput{\n        Id: &id,\n    }\n\n    output, err := conn.GetDatabase(ctx, input)\n    if err != nil {\n        var notFound *types.ResourceNotFoundException\n        if errors.As(err, &notFound) {\n            return nil, &retry.NotFoundError{\n                LastError:   err,\n                LastRequest: input,\n            }\n        }\n        return nil, err\n    }\n\n    if output == nil || output.Database == nil {\n        return nil, tfresource.NewEmptyResultError(input)\n    }\n\n    return output.Database, nil\n}\n\n// Status function for state refresh\nfunc statusDatabase(ctx context.Context, conn *database.Client, id string) retry.StateRefreshFunc {\n    return func() (interface{}, string, error) {\n        output, err := findDatabaseByID(ctx, conn, id)\n        if tfresource.NotFound(err) {\n            return nil, \"\", nil\n        }\n        if err != nil {\n            return nil, \"\", err\n        }\n\n        return output, *output.Status, nil\n    }\n}\n\n// Wait for database creation\nfunc waitDatabaseCreated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"CREATING\", \"PENDING\"},\n        Target:  []string{\"AVAILABLE\", \"ACTIVE\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database update\nfunc waitDatabaseUpdated(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"UPDATING\", \"MODIFYING\"},\n        Target:  []string{\"AVAILABLE\", \"ACTIVE\"},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n\n// Wait for database deletion\nfunc waitDatabaseDeleted(ctx context.Context, conn *database.Client, id string, timeout time.Duration) (*database.Database, error) {\n    stateConf := &retry.StateChangeConf{\n        Pending: []string{\"DELETING\", \"AVAILABLE\", \"ACTIVE\"},\n        Target:  []string{},\n        Refresh: statusDatabase(ctx, conn, id),\n        Timeout: timeout,\n        Delay:   10 * time.Second,\n        MinTimeout: 5 * time.Second,\n    }\n\n    outputRaw, err := stateConf.WaitForStateContext(ctx)\n    if output, ok := outputRaw.(*database.Database); ok {\n        return output, err\n    }\n\n    return nil, err\n}\n```\n\n## Key Implementation Details\n\n### Read Operation\n- Uses `findDatabaseByID` to fetch current state\n- Handles `NotFound` error by removing resource from state with a warning\n- Updates all computed and mutable attributes from API response\n- Proper error diagnostics for API failures\n\n### Update Operation\n- Compares plan vs state to detect changes\n- Only updates changed attributes (size in this case)\n- Waits for update to complete before returning\n- Updates status after successful modification\n\n### Finder Pattern\n- Returns `retry.NotFoundError` for 404s\n- Returns `tfresource.NewEmptyResultError` for nil responses\n- Properly wraps API errors for retry logic\n\n### State Management\n- Uses `StateChangeConf` for polling resource status\n- Separate wait functions for create, update, delete\n- Configurable timeouts with sensible defaults\n- Proper state transitions for each operation\n\nThis implementation follows Terraform provider best practices for resource lifecycle management.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5457,
            "output_tokens": 3336,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "provider-resources-05",
      "task_type": "adjacent_domain",
      "target_language": "hcl",
      "expected_patterns": [
        "resource\\s+\"\\w+\"\\s+\"\\w+\"\\s*\\{",
        "data\\s+\"\\w+\"\\s+\"\\w+\"\\s*\\{",
        "provider\\s+\"\\w+\"\\s*\\{"
      ],
      "anti_patterns": [
        "func\\s+\\w+\\(",
        "schema\\.StringAttribute",
        "resource\\.CreateRequest",
        "resp\\.Diagnostics",
        "framework\\.ResourceWithConfigure"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/examples/resources/scaffolding_example/resource.tf",
          "description": "HCL resource block syntax example: resource \"type\" \"name\" {} configuration pattern"
        },
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/examples/data-sources/scaffolding_example/data-source.tf",
          "description": "HCL data source block syntax example: data \"type\" \"name\" {} configuration pattern for data source lookups"
        },
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/examples/provider/provider.tf",
          "description": "HCL provider block syntax example: provider \"name\" {} configuration pattern"
        },
        {
          "url": "https://raw.githubusercontent.com/hashicorp/terraform-provider-scaffolding-framework/refs/heads/main/internal/provider/example_resource.go",
          "description": "Anti-patterns: Go Plugin Framework provider code (func definitions, schema.StringAttribute, resource.CreateRequest, resp.Diagnostics, framework.ResourceWithConfigure) that should not appear in HCL configuration"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "```hcl\n# variables.tf\nvariable \"region\" {\n  description = \"The cloud region where resources will be created\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]$\", var.region))\n    error_message = \"Region must be in the format: us-east-1, eu-west-2, etc.\"\n  }\n}\n\nvariable \"db_instance_class\" {\n  description = \"The instance class for the database\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z0-9]+$\", var.db_instance_class))\n    error_message = \"Instance class must be a valid RDS instance type (e.g., db.t3.micro, db.m5.large).\"\n  }\n}\n\nvariable \"db_name\" {\n  description = \"The name of the database to create\"\n  type        = string\n  default     = \"myappdb\"\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{0,62}$\", var.db_name))\n    error_message = \"Database name must start with a letter and contain only alphanumeric characters and underscores, max 63 characters.\"\n  }\n}\n\nvariable \"db_username\" {\n  description = \"Master username for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_username) >= 1 && length(var.db_username) <= 16\n    error_message = \"Username must be between 1 and 16 characters.\"\n  }\n}\n\nvariable \"db_password\" {\n  description = \"Master password for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_password) >= 8 && can(regex(\"[A-Z]\", var.db_password)) && can(regex(\"[a-z]\", var.db_password)) && can(regex(\"[0-9]\", var.db_password))\n    error_message = \"Password must be at least 8 characters and contain uppercase, lowercase, and numeric characters.\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"The allocated storage in gigabytes\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"engine_version\" {\n  description = \"The database engine version\"\n  type        = string\n  default     = \"14.7\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+$\", var.engine_version))\n    error_message = \"Engine version must be in the format X.Y (e.g., 14.7).\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"The number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Whether the database should be publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"existing_db_identifier\" {\n  description = \"The identifier of an existing database to look up\"\n  type        = string\n  default     = \"existing-database\"\n\n  validation {\n    condition     = can(regex(\"^[a-z][a-z0-9-]{0,62}$\", var.existing_db_identifier))\n    error_message = \"Database identifier must start with a letter, contain only lowercase alphanumeric characters and hyphens, max 63 characters.\"\n  }\n}\n\nvariable \"environment\" {\n  description = \"The environment name (dev, staging, prod)\"\n  type        = string\n  default     = \"dev\"\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be one of: dev, staging, prod.\"\n  }\n}\n\nvariable \"tags\" {\n  description = \"A map of tags to assign to resources\"\n  type        = map(string)\n  default = {\n    Terraform   = \"true\"\n    Environment = \"dev\"\n  }\n\n  validation {\n    condition     = length(var.tags) > 0\n    error_message = \"At least one tag must be specified.\"\n  }\n}\n\n# main.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\n# Provider Configuration\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = {\n      ManagedBy   = \"Terraform\"\n      Environment = var.environment\n      Project     = \"CloudDatabase\"\n    }\n  }\n}\n\n# Data source to get the default VPC\ndata \"aws_vpc\" \"default\" {\n  default = true\n}\n\n# Data source to get subnets in the default VPC\ndata \"aws_subnets\" \"default\" {\n  filter {\n    name   = \"vpc-id\"\n    values = [data.aws_vpc.default.id]\n  }\n}\n\n# Security Group for the database\nresource \"aws_security_group\" \"db_security_group\" {\n  name_prefix = \"${var.environment}-db-sg-\"\n  description = \"Security group for RDS database instance\"\n  vpc_id      = data.aws_vpc.default.id\n\n  ingress {\n    description = \"PostgreSQL access\"\n    from_port   = 5432\n    to_port     = 5432\n    protocol    = \"tcp\"\n    cidr_blocks = var.publicly_accessible ? [\"0.0.0.0/0\"] : [data.aws_vpc.default.cidr_block]\n  }\n\n  egress {\n    description = \"Allow all outbound traffic\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.environment}-db-security-group\"\n    }\n  )\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# DB Subnet Group\nresource \"aws_db_subnet_group\" \"db_subnet_group\" {\n  name_prefix = \"${var.environment}-db-subnet-group-\"\n  description = \"Subnet group for RDS database instance\"\n  subnet_ids  = data.aws_subnets.default.ids\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.environment}-db-subnet-group\"\n    }\n  )\n}\n\n# RDS Database Instance Resource\nresource \"aws_db_instance\" \"main\" {\n  # Required arguments\n  identifier     = \"${var.environment}-${var.db_name}-instance\"\n  engine         = \"postgres\"\n  engine_version = var.engine_version\n  instance_class = var.db_instance_class\n\n  # Storage configuration\n  allocated_storage     = var.allocated_storage\n  storage_type          = \"gp3\"\n  storage_encrypted     = true\n  max_allocated_storage = var.allocated_storage * 2\n\n  # Database configuration\n  db_name  = var.db_name\n  username = var.db_username\n  password = var.db_password\n  port     = 5432\n\n  # Network configuration\n  db_subnet_group_name   = aws_db_subnet_group.db_subnet_group.name\n  vpc_security_group_ids = [aws_security_group.db_security_group.id]\n  publicly_accessible    = var.publicly_accessible\n\n  # High availability\n  multi_az = var.multi_az\n\n  # Backup configuration\n  backup_retention_period = var.backup_retention_period\n  backup_window           = \"03:00-04:00\"\n  maintenance_window      = \"mon:04:00-mon:05:00\"\n\n  # Monitoring and logging\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n  monitoring_interval             = 60\n  monitoring_role_arn             = aws_iam_role.rds_monitoring_role.arn\n\n  # Performance Insights\n  performance_insights_enabled    = true\n  performance_insights_retention_period = 7\n\n  # Additional settings\n  auto_minor_version_upgrade = true\n  deletion_protection        = var.environment == \"prod\" ? true : false\n  skip_final_snapshot        = var.environment == \"prod\" ? false : true\n  final_snapshot_identifier  = var.environment == \"prod\" ? \"${var.environment}-${var.db_name}-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\" : null\n  copy_tags_to_snapshot      = true\n\n  # Parameter group\n  parameter_group_name = aws_db_parameter_group.main.name\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.environment}-${var.db_name}-database\"\n    }\n  )\n\n  depends_on = [\n    aws_db_subnet_group.db_subnet_group,\n    aws_security_group.db_security_group\n  ]\n}\n\n# DB Parameter Group\nresource \"aws_db_parameter_group\" \"main\" {\n  name_prefix = \"${var.environment}-postgres-params-\"\n  family      = \"postgres14\"\n  description = \"Custom parameter group for PostgreSQL\"\n\n  parameter {\n    name  = \"log_connections\"\n    value = \"1\"\n  }\n\n  parameter {\n    name  = \"log_disconnections\"\n    value = \"1\"\n  }\n\n  parameter {\n    name  = \"log_duration\"\n    value = \"1\"\n  }\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.environment}-postgres-parameter-group\"\n    }\n  )\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# IAM Role for RDS Enhanced Monitoring\nresource \"aws_iam_role\" \"rds_monitoring_role\" {\n  name_prefix = \"${var.environment}-rds-monitoring-\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = var.tags\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring_policy\" {\n  role       = aws_iam_role.rds_monitoring_role.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# Data Source - Look up existing database by identifier\ndata \"aws_db_instance\" \"existing\" {\n  db_instance_identifier = var.existing_db_identifier\n}\n\n# outputs.tf\noutput \"database_endpoint\" {\n  description = \"The connection endpoint for the newly created database\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"database_address\" {\n  description = \"The hostname of the database\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"database_port\" {\n  description = \"The port of the database\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"database_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"database_id\" {\n  description = \"The identifier of the RDS instance\"\n  value       = aws_db_instance.main.id\n}\n\noutput \"database_resource_id\" {\n  description = \"The resource ID of the RDS instance\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"database_status\" {\n  description = \"The status of the RDS instance\"\n  value       = aws_db_instance.main.status\n}\n\noutput \"existing_database_endpoint\" {\n  description = \"The connection endpoint for the existing database\"\n  value       = data.aws_db_instance.existing.endpoint\n}\n\noutput \"existing_database_address\" {\n  description = \"The hostname of the existing database\"\n  value       = data.aws_db_instance.existing.address\n}\n\noutput \"existing_database_engine\" {\n  description = \"The database engine of the existing database\"\n  value       = data.aws_db_instance.existing.engine\n}\n\noutput \"existing_database_engine_version\" {\n  description = \"The database engine version of the existing database\"\n  value       = data.aws_db_instance.existing.engine_version\n}\n\noutput \"connection_string\" {\n  description = \"Database connection string (without password)\"\n  value       = \"postgresql://${var.db_username}@${aws_db_instance.main.endpoint}/${var.db_name}\"\n  sensitive   = true\n}\n\noutput \"security_group_id\" {\n  description = \"The ID of the database security group\"\n  value       = aws_security_group.db_security_group.id\n}\n\noutput \"subnet_group_name\" {\n  description = \"The name of the DB subnet group\"\n  value       = aws_db_subnet_group.db_subnet_group.name\n}\n\n# terraform.tfvars.example\n# region                  = \"us-east-1\"\n# db_instance_class       = \"db.t3.micro\"\n# db_name                 = \"myappdb\"\n# db_username             = \"dbadmin\"\n# db_password             = \"ChangeMe123!\"\n# allocated_storage       = 20\n# engine_version          = \"14.7\"\n# backup_retention_period = 7\n# multi_az                = false\n# publicly_accessible     = false\n# existing_db_identifier  = \"existing-database\"\n# environment             = \"dev\"\n# tags = {\n#   Terraform   = \"true\"\n#   Environment = \"dev\"\n#   Project     = \"MyApp\"\n# }\n```\n\nThis comprehensive Terraform configuration includes:\n\n## Key Features:\n\n1. **Provider Block**: AWS provider with region configuration and default tags\n\n2. **Resource (RDS Database)**: Complete PostgreSQL RDS instance with:\n   - All required arguments (identifier, engine, instance_class, etc.)\n   - Storage configuration with encryption\n   - Network configuration with security groups\n   - Backup and maintenance windows\n   - Enhanced monitoring and Performance Insights\n   - Environment-specific settings (deletion protection for prod)\n\n3. **Data Source**: Looks up an existing database by identifier\n\n4. **Outputs**: Multiple output blocks showing:\n   - Database endpoint and connection details\n   - Existing database information\n   - Security group and subnet group details\n\n5. **Variables with Validation**:\n   - Region format validation\n   - Instance class format validation\n   - Database name character restrictions\n   - Password complexity requirements\n   - Storage size limits\n   - Environment enumeration\n   - Tag requirements\n\n6. **Additional Resources**:\n   - Security group with proper ingress/egress rules\n   - DB subnet group\n   - Parameter group for custom settings\n   - IAM role for enhanced monitoring\n\nTo use this configuration:\n\n```bash\nterraform init\nterraform plan -var=\"db_username=admin\" -var=\"db_password=SecurePass123!\"\nterraform apply -var=\"db_username=admin\" -var=\"db_password=SecurePass123!\"\n```",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 59,
            "output_tokens": 4000,
            "cached": false
          },
          "with_skill": {
            "output": "# Terraform Configuration for Cloud Database\n\nHere's a complete HCL configuration with provider, resource, data source, and outputs:\n\n## variables.tf\n\n```hcl\nvariable \"region\" {\n  description = \"AWS region where resources will be created\"\n  type        = string\n  default     = \"us-west-2\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]$\", var.region))\n    error_message = \"Region must be a valid AWS region format (e.g., us-west-2).\"\n  }\n}\n\nvariable \"environment\" {\n  description = \"Environment name for resource tagging\"\n  type        = string\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be one of: dev, staging, prod.\"\n  }\n}\n\nvariable \"db_name\" {\n  description = \"Name of the database instance\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-z][a-z0-9-]{0,62}[a-z0-9]$\", var.db_name))\n    error_message = \"Database name must start with a letter, contain only lowercase letters, numbers, and hyphens, and be 1-64 characters long.\"\n  }\n}\n\nvariable \"db_username\" {\n  description = \"Master username for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_username) >= 1 && length(var.db_username) <= 16\n    error_message = \"Username must be between 1 and 16 characters.\"\n  }\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]*$\", var.db_username))\n    error_message = \"Username must start with a letter and contain only alphanumeric characters and underscores.\"\n  }\n}\n\nvariable \"db_password\" {\n  description = \"Master password for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_password) >= 8 && length(var.db_password) <= 128\n    error_message = \"Password must be between 8 and 128 characters.\"\n  }\n\n  validation {\n    condition     = can(regex(\"[A-Z]\", var.db_password)) && can(regex(\"[a-z]\", var.db_password)) && can(regex(\"[0-9]\", var.db_password))\n    error_message = \"Password must contain at least one uppercase letter, one lowercase letter, and one number.\"\n  }\n}\n\nvariable \"db_instance_class\" {\n  description = \"Instance class for the database\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z0-9]+$\", var.db_instance_class))\n    error_message = \"Instance class must be a valid RDS instance type (e.g., db.t3.micro).\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"engine_version\" {\n  description = \"Database engine version\"\n  type        = string\n  default     = \"14.7\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+$\", var.engine_version))\n    error_message = \"Engine version must be in format X.Y (e.g., 14.7).\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Whether the database should be publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"vpc_security_group_ids\" {\n  description = \"List of VPC security group IDs\"\n  type        = list(string)\n\n  validation {\n    condition     = length(var.vpc_security_group_ids) > 0\n    error_message = \"At least one security group ID must be provided.\"\n  }\n\n  validation {\n    condition     = alltrue([for sg in var.vpc_security_group_ids : can(regex(\"^sg-[a-f0-9]{8,}$\", sg))])\n    error_message = \"All security group IDs must be valid (format: sg-xxxxxxxx).\"\n  }\n}\n\nvariable \"db_subnet_group_name\" {\n  description = \"Name of DB subnet group\"\n  type        = string\n\n  validation {\n    condition     = length(var.db_subnet_group_name) > 0\n    error_message = \"DB subnet group name cannot be empty.\"\n  }\n}\n\nvariable \"existing_db_name\" {\n  description = \"Name of existing database to look up via data source\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"tags\" {\n  description = \"Additional tags for resources\"\n  type        = map(string)\n  default     = {}\n\n  validation {\n    condition     = alltrue([for k, v in var.tags : can(regex(\"^[a-zA-Z0-9+\\\\-=._:/@]{1,128}$\", k))])\n    error_message = \"Tag keys must be valid AWS tag format (1-128 characters).\"\n  }\n}\n```\n\n## provider.tf\n\n```hcl\nterraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~> 3.5\"\n    }\n  }\n\n  # Optional: Configure backend for state storage\n  # backend \"s3\" {\n  #   bucket         = \"my-terraform-state\"\n  #   key            = \"database/terraform.tfstate\"\n  #   region         = \"us-west-2\"\n  #   encrypt        = true\n  #   dynamodb_table = \"terraform-state-lock\"\n  # }\n}\n\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = {\n      Environment = var.environment\n      ManagedBy   = \"Terraform\"\n      Project     = \"CloudDatabase\"\n    }\n  }\n}\n```\n\n## main.tf\n\n```hcl\n# Generate a random suffix for unique naming\nresource \"random_id\" \"db_suffix\" {\n  byte_length = 4\n}\n\n# Create a parameter group for database configuration\nresource \"aws_db_parameter_group\" \"main\" {\n  name_prefix = \"${var.db_name}-params-\"\n  family      = \"postgres14\"\n  description = \"Custom parameter group for ${var.db_name}\"\n\n  parameter {\n    name  = \"log_connections\"\n    value = \"1\"\n  }\n\n  parameter {\n    name  = \"log_disconnections\"\n    value = \"1\"\n  }\n\n  parameter {\n    name  = \"log_duration\"\n    value = \"1\"\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.db_name}-parameter-group\"\n    }\n  )\n}\n\n# Create the RDS database instance\nresource \"aws_db_instance\" \"main\" {\n  identifier = \"${var.db_name}-${random_id.db_suffix.hex}\"\n\n  # Engine configuration\n  engine               = \"postgres\"\n  engine_version       = var.engine_version\n  instance_class       = var.db_instance_class\n  allocated_storage    = var.allocated_storage\n  storage_type         = \"gp3\"\n  storage_encrypted    = true\n  \n  # Database configuration\n  db_name  = replace(var.db_name, \"-\", \"_\")\n  username = var.db_username\n  password = var.db_password\n  port     = 5432\n\n  # Network configuration\n  db_subnet_group_name   = var.db_subnet_group_name\n  vpc_security_group_ids = var.vpc_security_group_ids\n  publicly_accessible    = var.publicly_accessible\n  multi_az              = var.multi_az\n\n  # Backup configuration\n  backup_retention_period   = var.backup_retention_period\n  backup_window            = \"03:00-04:00\"\n  maintenance_window       = \"mon:04:00-mon:05:00\"\n  copy_tags_to_snapshot    = true\n  skip_final_snapshot      = var.environment != \"prod\"\n  final_snapshot_identifier = var.environment == \"prod\" ? \"${var.db_name}-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\" : null\n\n  # Performance and monitoring\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n  monitoring_interval             = 60\n  monitoring_role_arn            = aws_iam_role.rds_monitoring.arn\n  performance_insights_enabled    = true\n  performance_insights_retention_period = 7\n\n  # Parameter and option groups\n  parameter_group_name = aws_db_parameter_group.main.name\n\n  # Deletion protection\n  deletion_protection = var.environment == \"prod\"\n\n  # Auto minor version upgrade\n  auto_minor_version_upgrade = true\n  apply_immediately         = var.environment != \"prod\"\n\n  tags = merge(\n    var.tags,\n    {\n      Name = var.db_name\n    }\n  )\n\n  lifecycle {\n    ignore_changes = [\n      password,\n      final_snapshot_identifier,\n    ]\n  }\n}\n\n# IAM role for enhanced monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name_prefix = \"${var.db_name}-rds-monitoring-\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = merge(\n    var.tags,\n    {\n      Name = \"${var.db_name}-rds-monitoring-role\"\n    }\n  )\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# CloudWatch alarm for high CPU\nresource \"aws_cloudwatch_metric_alarm\" \"database_cpu\" {\n  alarm_name          = \"${var.db_name}-high-cpu\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 2\n  metric_name         = \"CPUUtilization\"\n  namespace           = \"AWS/RDS\"\n  period              = 300\n  statistic           = \"Average\"\n  threshold           = 80\n  alarm_description   = \"This metric monitors RDS CPU utilization\"\n  alarm_actions       = [] # Add SNS topic ARN for notifications\n\n  dimensions = {\n    DBInstanceIdentifier = aws_db_instance.main.identifier\n  }\n\n  tags = var.tags\n}\n\n# CloudWatch alarm for low storage\nresource \"aws_cloudwatch_metric_alarm\" \"database_storage\" {\n  alarm_name          = \"${var.db_name}-low-storage\"\n  comparison_operator = \"LessThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"FreeStorageSpace\"\n  namespace           = \"AWS/RDS\"\n  period              = 300\n  statistic           = \"Average\"\n  threshold           = 10737418240 # 10 GB in bytes\n  alarm_description   = \"This metric monitors RDS free storage space\"\n  alarm_actions       = [] # Add SNS topic ARN for notifications\n\n  dimensions = {\n    DBInstanceIdentifier = aws_db_instance.main.identifier\n  }\n\n  tags = var.tags\n}\n```\n\n## data.tf\n\n```hcl\n# Data source to look up existing database by identifier\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_db_name != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_db_name\n}\n\n# Data source to get current AWS account information\ndata \"aws_caller_identity\" \"current\" {}\n\n# Data source to get current AWS region\ndata \"aws_region\" \"current\" {}\n\n# Data source to look up available engine versions\ndata \"aws_rds_engine_version\" \"postgres\" {\n  engine  = \"postgres\"\n  version = var.engine_version\n}\n\n# Data source to get DB subnet group information\ndata \"aws_db_subnet_group\" \"selected\" {\n  name = var.db_subnet_group_name\n}\n```\n\n## outputs.tf\n\n```hcl\n# Primary database outputs\noutput \"db_instance_id\" {\n  description = \"The RDS instance identifier\"\n  value       = aws_db_instance.main.identifier\n}\n\noutput \"db_instance_arn\" {\n  description = \"The ARN of the RDS instance\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"db_instance_endpoint\" {\n  description = \"The connection endpoint for the database\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"db_instance_address\" {\n  description = \"The hostname of the RDS instance\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"db_instance_port\" {\n  description = \"The port the database is listening on\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"db_instance_name\" {\n  description = \"The database name\"\n  value       = aws_db_instance.main.db_name\n}\n\noutput \"db_instance_username\" {\n  description = \"The master username for the database\"\n  value       = aws_db_instance.main.username\n  sensitive   = true\n}\n\noutput \"db_instance_resource_id\" {\n  description = \"The RDS Resource ID of this instance\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"db_instance_status\" {\n  description = \"The RDS instance status\"\n  value       = aws_db_instance.main.status\n}\n\noutput \"db_instance_availability_zone\" {\n  description = \"The availability zone of the instance\"\n  value       = aws_db_instance.main.availability_zone\n}\n\n# Connection string output\noutput \"db_connection_string\" {\n  description = \"PostgreSQL connection string (without password)\"\n  value       = \"postgresql://${aws_db_instance.main.username}@${aws_db_instance.main.endpoint}/${aws_db_instance.main.db_name}\"\n  sensitive   = true\n}\n\n# Existing database outputs (from data source)\noutput \"existing_db_endpoint\" {\n  description = \"Endpoint of the existing database (if queried)\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].endpoint : null\n}\n\noutput \"existing_db_address\" {\n  description = \"Address of the existing database (if queried)\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].address : null\n}\n\noutput \"existing_db_port\" {\n  description = \"Port of the existing database (if queried)\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].port : null\n}\n\noutput \"existing_db",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4778,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a complete Terraform configuration with provider, resource, data source, variables, and outputs.\n\n```hcl\n# variables.tf\nvariable \"region\" {\n  description = \"Cloud region for resources\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]$\", var.region))\n    error_message = \"Region must be in format: us-east-1, eu-west-2, etc.\"\n  }\n}\n\nvariable \"database_name\" {\n  description = \"Name of the database instance\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-z0-9-]{1,63}$\", var.database_name))\n    error_message = \"Database name must be lowercase alphanumeric with hyphens, 1-63 characters.\"\n  }\n}\n\nvariable \"database_engine\" {\n  description = \"Database engine type\"\n  type        = string\n  default     = \"postgres\"\n\n  validation {\n    condition     = contains([\"postgres\", \"mysql\", \"mariadb\"], var.database_engine)\n    error_message = \"Database engine must be one of: postgres, mysql, mariadb.\"\n  }\n}\n\nvariable \"database_version\" {\n  description = \"Database engine version\"\n  type        = string\n  default     = \"14.5\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+$\", var.database_version))\n    error_message = \"Database version must be in format: major.minor (e.g., 14.5).\"\n  }\n}\n\nvariable \"instance_class\" {\n  description = \"Database instance class\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z]+$\", var.instance_class))\n    error_message = \"Instance class must be in format: db.t3.micro, db.m5.large, etc.\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"database_username\" {\n  description = \"Master username for database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{0,15}$\", var.database_username))\n    error_message = \"Username must start with a letter, contain only alphanumeric and underscore, max 16 characters.\"\n  }\n}\n\nvariable \"database_password\" {\n  description = \"Master password for database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.database_password) >= 8 && length(var.database_password) <= 128\n    error_message = \"Password must be between 8 and 128 characters.\"\n  }\n}\n\nvariable \"backup_retention_days\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_days >= 0 && var.backup_retention_days <= 35\n    error_message = \"Backup retention must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Allow public access to database\"\n  type        = bool\n  default     = false\n}\n\nvariable \"vpc_security_group_ids\" {\n  description = \"List of VPC security group IDs\"\n  type        = list(string)\n  default     = []\n\n  validation {\n    condition     = alltrue([for sg in var.vpc_security_group_ids : can(regex(\"^sg-[a-f0-9]{8,}$\", sg))])\n    error_message = \"Security group IDs must be in format: sg-xxxxxxxx.\"\n  }\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to resources\"\n  type        = map(string)\n  default     = {}\n\n  validation {\n    condition     = alltrue([for k, v in var.tags : can(regex(\"^[a-zA-Z0-9_-]+$\", k))])\n    error_message = \"Tag keys must contain only alphanumeric, underscore, and hyphen characters.\"\n  }\n}\n\nvariable \"existing_database_name\" {\n  description = \"Name of existing database to look up\"\n  type        = string\n  default     = \"\"\n}\n```\n\n```hcl\n# main.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = merge(\n      var.tags,\n      {\n        ManagedBy   = \"Terraform\"\n        Environment = terraform.workspace\n      }\n    )\n  }\n}\n\n# Database resource\nresource \"aws_db_instance\" \"main\" {\n  identifier = var.database_name\n\n  # Engine configuration\n  engine         = var.database_engine\n  engine_version = var.database_version\n\n  # Instance configuration\n  instance_class    = var.instance_class\n  allocated_storage = var.allocated_storage\n  storage_type      = \"gp3\"\n  storage_encrypted = true\n\n  # Database credentials\n  username = var.database_username\n  password = var.database_password\n\n  # Database name (initial database to create)\n  db_name = replace(var.database_name, \"-\", \"_\")\n\n  # Network configuration\n  publicly_accessible    = var.publicly_accessible\n  vpc_security_group_ids = var.vpc_security_group_ids\n\n  # High availability\n  multi_az = var.multi_az\n\n  # Backup configuration\n  backup_retention_period = var.backup_retention_days\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"mon:04:00-mon:05:00\"\n\n  # Monitoring\n  enabled_cloudwatch_logs_exports = var.database_engine == \"postgres\" ? [\"postgresql\"] : [\"error\", \"general\", \"slowquery\"]\n  monitoring_interval             = 60\n  monitoring_role_arn            = aws_iam_role.rds_monitoring.arn\n\n  # Performance Insights\n  performance_insights_enabled    = true\n  performance_insights_retention_period = 7\n\n  # Deletion protection\n  deletion_protection = true\n  skip_final_snapshot = false\n  final_snapshot_identifier = \"${var.database_name}-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n\n  # Auto minor version upgrade\n  auto_minor_version_upgrade = true\n\n  # Parameter group\n  parameter_group_name = aws_db_parameter_group.main.name\n\n  tags = {\n    Name = var.database_name\n  }\n\n  lifecycle {\n    ignore_changes = [\n      final_snapshot_identifier,\n      password,\n    ]\n  }\n}\n\n# Parameter group for database configuration\nresource \"aws_db_parameter_group\" \"main\" {\n  name   = \"${var.database_name}-params\"\n  family = var.database_engine == \"postgres\" ? \"postgres14\" : \"mysql8.0\"\n\n  dynamic \"parameter\" {\n    for_each = var.database_engine == \"postgres\" ? {\n      \"shared_preload_libraries\" = \"pg_stat_statements\"\n      \"log_statement\"            = \"all\"\n      \"log_min_duration_statement\" = \"1000\"\n    } : {\n      \"slow_query_log\"           = \"1\"\n      \"long_query_time\"          = \"2\"\n      \"log_queries_not_using_indexes\" = \"1\"\n    }\n\n    content {\n      name  = parameter.key\n      value = parameter.value\n    }\n  }\n\n  tags = {\n    Name = \"${var.database_name}-params\"\n  }\n}\n\n# IAM role for enhanced monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name = \"${var.database_name}-rds-monitoring\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = {\n    Name = \"${var.database_name}-rds-monitoring\"\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# Data source to look up existing database\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_database_name != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_database_name\n}\n```\n\n```hcl\n# outputs.tf\noutput \"database_id\" {\n  description = \"Database instance identifier\"\n  value       = aws_db_instance.main.id\n}\n\noutput \"database_endpoint\" {\n  description = \"Database connection endpoint\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"database_address\" {\n  description = \"Database hostname\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"database_port\" {\n  description = \"Database port\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"database_arn\" {\n  description = \"Database ARN\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"database_resource_id\" {\n  description = \"Database resource ID\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"database_status\" {\n  description = \"Database instance status\"\n  value       = aws_db_instance.main.status\n}\n\noutput \"database_engine\" {\n  description = \"Database engine type\"\n  value       = aws_db_instance.main.engine\n}\n\noutput \"database_engine_version\" {\n  description = \"Database engine version\"\n  value       = aws_db_instance.main.engine_version_actual\n}\n\noutput \"database_connection_string\" {\n  description = \"Database connection string (without password)\"\n  value       = \"${var.database_engine}://${var.database_username}@${aws_db_instance.main.endpoint}/${aws_db_instance.main.db_name}\"\n  sensitive   = true\n}\n\n# Outputs for existing database lookup\noutput \"existing_database_endpoint\" {\n  description = \"Endpoint of existing database (if looked up)\"\n  value       = var.existing_database_name != \"\" ? data.aws_db_instance.existing[0].endpoint : null\n}\n\noutput \"existing_database_address\" {\n  description = \"Address of existing database (if looked up)\"\n  value       = var.existing_database_name != \"\" ? data.aws_db_instance.existing[0].address : null\n}\n\noutput \"existing_database_port\" {\n  description = \"Port of existing database (if looked up)\"\n  value       = var.existing_database_name != \"\" ? data.aws_db_instance.existing[0].port : null\n}\n\noutput \"existing_database_engine\" {\n  description = \"Engine of existing database (if looked up)\"\n  value       = var.existing_database_name != \"\" ? data.aws_db_instance.existing[0].engine : null\n}\n\noutput \"existing_database_status\" {\n  description = \"Status of existing database (if looked up)\"\n  value       = var.existing_database_name != \"\" ? data.aws_db_instance.existing[0].db_instance_status : null\n}\n```\n\n```hcl\n# terraform.tfvars.example\n# Copy this file to terraform.tfvars and fill in your values\n\nregion                 = \"us-east-1\"\ndatabase_name          = \"myapp-db\"\ndatabase_engine        = \"postgres\"\ndatabase_version       = \"14.5\"\ninstance_class         = \"db.t3.micro\"\nallocated_storage      = 20\ndatabase_username      = \"dbadmin\"\ndatabase_password      = \"ChangeMe123!\"  # Use a secure password\nbackup_retention_days  = 7\nmulti_az               = false\npublicly_accessible    = false\nvpc_security_group_ids = [\"sg-0123456789abcdef0\"]\n\ntags = {\n  Project     = \"MyApp\"\n  Environment = \"Development\"\n  Owner       = \"DevOps Team\"\n}\n\n# Optional: Look up an existing database\nexisting_database_name = \"\"\n```\n\nThis configuration includes:\n\n1. **Provider Block**: AWS provider with region and default tags\n2. **Resource**: `aws_db_instance` with all required arguments including:\n   - Engine configuration\n   - Instance sizing\n   - Storage settings\n   - Network configuration\n   - Backup and monitoring\n   - Security features\n3. **Data Source**: Looks up existing database by name (conditional)\n4. **Variables**: Comprehensive variable definitions with validation for:\n   - Region format\n   - Database naming conventions\n   - Engine types\n   - Storage limits\n   - Security group IDs\n   - Username/password requirements\n5. **Outputs**: Database endpoint and other connection details\n6. **Additional Resources**: Parameter group and IAM role for monitoring\n\nThe configuration follows best practices with proper validation, sensitive value handling, and lifecycle management.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5063,
            "output_tokens": 3491,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "```hcl\n# variables.tf\nvariable \"region\" {\n  description = \"The cloud region where resources will be created\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]$\", var.region))\n    error_message = \"Region must be in the format: us-east-1, eu-west-2, etc.\"\n  }\n}\n\nvariable \"database_name\" {\n  description = \"The name of the database instance\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-z][a-z0-9-]{2,62}[a-z0-9]$\", var.database_name))\n    error_message = \"Database name must start with a letter, contain only lowercase letters, numbers, and hyphens, and be between 4-64 characters.\"\n  }\n}\n\nvariable \"database_engine\" {\n  description = \"The database engine to use\"\n  type        = string\n  default     = \"postgres\"\n\n  validation {\n    condition     = contains([\"postgres\", \"mysql\", \"mariadb\"], var.database_engine)\n    error_message = \"Database engine must be one of: postgres, mysql, mariadb.\"\n  }\n}\n\nvariable \"database_engine_version\" {\n  description = \"The version of the database engine\"\n  type        = string\n  default     = \"14.7\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+$\", var.database_engine_version))\n    error_message = \"Engine version must be in format X.Y (e.g., 14.7).\"\n  }\n}\n\nvariable \"instance_class\" {\n  description = \"The instance type for the database\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z]+$\", var.instance_class))\n    error_message = \"Instance class must be in format db.type.size (e.g., db.t3.micro).\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"The allocated storage in gigabytes\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"database_username\" {\n  description = \"Master username for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.database_username) >= 4 && length(var.database_username) <= 16\n    error_message = \"Database username must be between 4 and 16 characters.\"\n  }\n}\n\nvariable \"database_password\" {\n  description = \"Master password for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.database_password) >= 8 && can(regex(\"[A-Z]\", var.database_password)) && can(regex(\"[a-z]\", var.database_password)) && can(regex(\"[0-9]\", var.database_password))\n    error_message = \"Password must be at least 8 characters and contain uppercase, lowercase, and numeric characters.\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Whether the database should be publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"existing_database_name\" {\n  description = \"Name of an existing database to look up\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to resources\"\n  type        = map(string)\n  default = {\n    Environment = \"development\"\n    ManagedBy   = \"terraform\"\n  }\n\n  validation {\n    condition     = length(var.tags) > 0\n    error_message = \"At least one tag must be specified.\"\n  }\n}\n\n# provider.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = var.tags\n  }\n}\n\n# main.tf\n# VPC and Security Group for the database\nresource \"aws_security_group\" \"database\" {\n  name_prefix = \"${var.database_name}-sg\"\n  description = \"Security group for ${var.database_name} database\"\n\n  ingress {\n    from_port   = 5432\n    to_port     = 5432\n    protocol    = \"tcp\"\n    cidr_blocks = var.publicly_accessible ? [\"0.0.0.0/0\"] : [\"10.0.0.0/8\"]\n    description = \"PostgreSQL access\"\n  }\n\n  egress {\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n    description = \"Allow all outbound traffic\"\n  }\n\n  tags = {\n    Name = \"${var.database_name}-security-group\"\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# DB Subnet Group\nresource \"aws_db_subnet_group\" \"database\" {\n  name_prefix = \"${var.database_name}-subnet-group\"\n  description = \"Subnet group for ${var.database_name}\"\n  subnet_ids  = data.aws_subnets.default.ids\n\n  tags = {\n    Name = \"${var.database_name}-subnet-group\"\n  }\n}\n\n# RDS Database Instance\nresource \"aws_db_instance\" \"main\" {\n  identifier     = var.database_name\n  engine         = var.database_engine\n  engine_version = var.database_engine_version\n  instance_class = var.instance_class\n\n  # Storage configuration\n  allocated_storage     = var.allocated_storage\n  storage_type          = \"gp3\"\n  storage_encrypted     = true\n  max_allocated_storage = var.allocated_storage * 2\n\n  # Database configuration\n  db_name  = replace(var.database_name, \"-\", \"_\")\n  username = var.database_username\n  password = var.database_password\n  port     = 5432\n\n  # Network configuration\n  db_subnet_group_name   = aws_db_subnet_group.database.name\n  vpc_security_group_ids = [aws_security_group.database.id]\n  publicly_accessible    = var.publicly_accessible\n  multi_az               = var.multi_az\n\n  # Backup configuration\n  backup_retention_period = var.backup_retention_period\n  backup_window           = \"03:00-04:00\"\n  maintenance_window      = \"mon:04:00-mon:05:00\"\n\n  # Additional settings\n  skip_final_snapshot       = true\n  final_snapshot_identifier = \"${var.database_name}-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n  deletion_protection       = false\n  auto_minor_version_upgrade = true\n\n  # Performance Insights\n  performance_insights_enabled    = true\n  performance_insights_retention_period = 7\n\n  # Monitoring\n  enabled_cloudwatch_logs_exports = [\"postgresql\", \"upgrade\"]\n  monitoring_interval             = 60\n  monitoring_role_arn            = aws_iam_role.rds_monitoring.arn\n\n  tags = {\n    Name = var.database_name\n  }\n\n  lifecycle {\n    ignore_changes = [\n      password,\n      final_snapshot_identifier\n    ]\n  }\n}\n\n# IAM Role for Enhanced Monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name_prefix = \"${var.database_name}-rds-monitoring\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = {\n    Name = \"${var.database_name}-monitoring-role\"\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# data.tf\n# Data source to get default VPC\ndata \"aws_vpc\" \"default\" {\n  default = true\n}\n\n# Data source to get default subnets\ndata \"aws_subnets\" \"default\" {\n  filter {\n    name   = \"vpc-id\"\n    values = [data.aws_vpc.default.id]\n  }\n}\n\n# Data source to look up an existing database by name\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_database_name != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_database_name\n}\n\n# outputs.tf\noutput \"database_endpoint\" {\n  description = \"The connection endpoint for the database\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"database_address\" {\n  description = \"The hostname of the database\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"database_port\" {\n  description = \"The port the database is listening on\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"database_arn\" {\n  description = \"The ARN of the database instance\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"database_id\" {\n  description = \"The identifier of the database instance\"\n  value       = aws_db_instance.main.id\n}\n\noutput \"database_resource_id\" {\n  description = \"The resource ID of the database instance\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"database_status\" {\n  description = \"The status of the database instance\"\n  value       = aws_db_instance.main.status\n}\n\noutput \"security_group_id\" {\n  description = \"The ID of the security group\"\n  value       = aws_security_group.database.id\n}\n\noutput \"existing_database_endpoint\" {\n  description = \"The endpoint of the existing database (if looked up)\"\n  value       = var.existing_database_name != \"\" ? data.aws_db_instance.existing[0].endpoint : null\n}\n\noutput \"existing_database_address\" {\n  description = \"The address of the existing database (if looked up)\"\n  value       = var.existing_database_name != \"\" ? data.aws_db_instance.existing[0].address : null\n}\n\noutput \"connection_string\" {\n  description = \"Database connection string (without password)\"\n  value       = \"postgresql://${var.database_username}@${aws_db_instance.main.endpoint}/${aws_db_instance.main.db_name}\"\n  sensitive   = true\n}\n\n# terraform.tfvars.example\n# region                  = \"us-east-1\"\n# database_name           = \"myapp-db-prod\"\n# database_engine         = \"postgres\"\n# database_engine_version = \"14.7\"\n# instance_class          = \"db.t3.micro\"\n# allocated_storage       = 20\n# database_username       = \"dbadmin\"\n# database_password       = \"SecurePassword123!\"\n# backup_retention_period = 7\n# multi_az                = false\n# publicly_accessible     = false\n# existing_database_name  = \"\"\n# \n# tags = {\n#   Environment = \"production\"\n#   Project     = \"myapp\"\n#   ManagedBy   = \"terraform\"\n# }\n\n```\n\nThis comprehensive Terraform configuration includes:\n\n## Key Features:\n\n1. **Provider Block**: AWS provider with version constraints and default tags\n\n2. **Resource Block**: `aws_db_instance` with all required arguments:\n   - Engine configuration\n   - Storage settings\n   - Network configuration\n   - Backup settings\n   - Monitoring and logging\n\n3. **Data Source**: Looks up existing database by identifier\n\n4. **Output Blocks**: Multiple outputs including database endpoint\n\n5. **Variable Validations**:\n   - Region format validation\n   - Database name pattern validation\n   - Engine type validation\n   - Storage size range validation\n   - Password complexity validation\n   - Backup retention validation\n\n6. **Additional Resources**:\n   - Security group for database access\n   - DB subnet group\n   - IAM role for enhanced monitoring\n\n## Usage:\n\n```bash\n# Initialize Terraform\nterraform init\n\n# Create terraform.tfvars from example\ncp terraform.tfvars.example terraform.tfvars\n\n# Edit terraform.tfvars with your values\n# Then plan and apply\nterraform plan\nterraform apply\n\n# To look up an existing database, set:\n# existing_database_name = \"my-existing-db\"\n```",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 59,
            "output_tokens": 3412,
            "cached": false
          },
          "with_skill": {
            "output": "# Terraform Configuration for Cloud Database\n\nHere's a complete HCL configuration with provider, resource, data source, variables, and outputs:\n\n## File Structure\n\n```\n.\n\u251c\u2500\u2500 main.tf           # Main configuration\n\u251c\u2500\u2500 variables.tf      # Variable definitions\n\u251c\u2500\u2500 outputs.tf        # Output definitions\n\u251c\u2500\u2500 versions.tf       # Provider version constraints\n\u2514\u2500\u2500 terraform.tfvars  # Variable values (example)\n```\n\n## versions.tf\n\n```hcl\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n```\n\n## variables.tf\n\n```hcl\nvariable \"region\" {\n  description = \"AWS region where resources will be created\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]$\", var.region))\n    error_message = \"Region must be a valid AWS region format (e.g., us-east-1).\"\n  }\n}\n\nvariable \"environment\" {\n  description = \"Environment name (dev, staging, prod)\"\n  type        = string\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be one of: dev, staging, prod.\"\n  }\n}\n\nvariable \"db_name\" {\n  description = \"Name of the database to create\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{0,62}$\", var.db_name))\n    error_message = \"Database name must start with a letter, contain only alphanumeric characters and underscores, and be 1-63 characters long.\"\n  }\n}\n\nvariable \"db_username\" {\n  description = \"Master username for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{0,15}$\", var.db_username))\n    error_message = \"Username must start with a letter, contain only alphanumeric characters and underscores, and be 1-16 characters long.\"\n  }\n}\n\nvariable \"db_password\" {\n  description = \"Master password for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_password) >= 8 && length(var.db_password) <= 128\n    error_message = \"Password must be between 8 and 128 characters long.\"\n  }\n\n  validation {\n    condition     = can(regex(\"[A-Z]\", var.db_password)) && can(regex(\"[a-z]\", var.db_password)) && can(regex(\"[0-9]\", var.db_password))\n    error_message = \"Password must contain at least one uppercase letter, one lowercase letter, and one number.\"\n  }\n}\n\nvariable \"db_instance_class\" {\n  description = \"Instance class for the database\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z0-9]+$\", var.db_instance_class))\n    error_message = \"Instance class must be a valid RDS instance type (e.g., db.t3.micro).\"\n  }\n}\n\nvariable \"db_allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.db_allocated_storage >= 20 && var.db_allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"db_engine\" {\n  description = \"Database engine type\"\n  type        = string\n  default     = \"postgres\"\n\n  validation {\n    condition     = contains([\"postgres\", \"mysql\", \"mariadb\", \"oracle-ee\", \"sqlserver-ee\"], var.db_engine)\n    error_message = \"Engine must be one of: postgres, mysql, mariadb, oracle-ee, sqlserver-ee.\"\n  }\n}\n\nvariable \"db_engine_version\" {\n  description = \"Database engine version\"\n  type        = string\n  default     = \"15.4\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+\", var.db_engine_version))\n    error_message = \"Engine version must be in format X.Y (e.g., 15.4).\"\n  }\n}\n\nvariable \"db_port\" {\n  description = \"Port for database connections\"\n  type        = number\n  default     = 5432\n\n  validation {\n    condition     = var.db_port >= 1024 && var.db_port <= 65535\n    error_message = \"Port must be between 1024 and 65535.\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Make database publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"skip_final_snapshot\" {\n  description = \"Skip final snapshot when destroying database\"\n  type        = bool\n  default     = false\n}\n\nvariable \"vpc_security_group_ids\" {\n  description = \"List of VPC security group IDs\"\n  type        = list(string)\n  default     = []\n\n  validation {\n    condition     = alltrue([for sg in var.vpc_security_group_ids : can(regex(\"^sg-[a-f0-9]{8,}$\", sg))])\n    error_message = \"All security group IDs must be valid (format: sg-xxxxxxxx).\"\n  }\n}\n\nvariable \"db_subnet_group_name\" {\n  description = \"Name of DB subnet group\"\n  type        = string\n  default     = null\n\n  validation {\n    condition     = var.db_subnet_group_name == null || can(regex(\"^[a-zA-Z][a-zA-Z0-9-]{0,254}$\", var.db_subnet_group_name))\n    error_message = \"Subnet group name must start with a letter and contain only alphanumeric characters and hyphens.\"\n  }\n}\n\nvariable \"parameter_group_family\" {\n  description = \"Database parameter group family\"\n  type        = string\n  default     = \"postgres15\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]+[0-9]+$\", var.parameter_group_family))\n    error_message = \"Parameter group family must be in format: engine-name + version (e.g., postgres15).\"\n  }\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to all resources\"\n  type        = map(string)\n  default     = {}\n\n  validation {\n    condition     = alltrue([for k, v in var.tags : can(regex(\"^[\\\\w\\\\s.:/=+@-]{1,128}$\", k)) && can(regex(\"^[\\\\w\\\\s.:/=+@-]{0,256}$\", v))])\n    error_message = \"Tag keys must be 1-128 characters and values must be 0-256 characters.\"\n  }\n}\n\nvariable \"existing_db_name\" {\n  description = \"Name of existing database to look up via data source\"\n  type        = string\n  default     = \"\"\n\n  validation {\n    condition     = var.existing_db_name == \"\" || can(regex(\"^[a-zA-Z][a-zA-Z0-9-]{0,62}$\", var.existing_db_name))\n    error_message = \"Database identifier must start with a letter and contain only alphanumeric characters and hyphens.\"\n  }\n}\n```\n\n## main.tf\n\n```hcl\n# Provider Configuration\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = merge(\n      {\n        Environment = var.environment\n        ManagedBy   = \"Terraform\"\n        Project     = \"CloudDatabase\"\n      },\n      var.tags\n    )\n  }\n}\n\n# Local values for computed configurations\nlocals {\n  db_identifier = \"${var.environment}-${var.db_name}\"\n  \n  final_snapshot_identifier = var.skip_final_snapshot ? null : \"${local.db_identifier}-final-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n  \n  common_tags = {\n    Name        = local.db_identifier\n    Environment = var.environment\n    Database    = var.db_name\n  }\n}\n\n# DB Parameter Group\nresource \"aws_db_parameter_group\" \"main\" {\n  name        = \"${local.db_identifier}-params\"\n  family      = var.parameter_group_family\n  description = \"Parameter group for ${local.db_identifier}\"\n\n  # Example parameters for PostgreSQL\n  dynamic \"parameter\" {\n    for_each = var.db_engine == \"postgres\" ? {\n      \"shared_preload_libraries\" = \"pg_stat_statements\"\n      \"log_statement\"            = \"all\"\n      \"log_min_duration_statement\" = \"1000\"\n    } : {}\n\n    content {\n      name  = parameter.key\n      value = parameter.value\n    }\n  }\n\n  tags = merge(\n    local.common_tags,\n    {\n      Type = \"ParameterGroup\"\n    }\n  )\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# DB Subnet Group (if specified)\nresource \"aws_db_subnet_group\" \"main\" {\n  count = var.db_subnet_group_name != null ? 0 : 1\n\n  name        = \"${local.db_identifier}-subnet-group\"\n  description = \"Subnet group for ${local.db_identifier}\"\n  subnet_ids  = [] # Would be populated from variables or data sources\n\n  tags = merge(\n    local.common_tags,\n    {\n      Type = \"SubnetGroup\"\n    }\n  )\n}\n\n# RDS Database Instance\nresource \"aws_db_instance\" \"main\" {\n  # Required Arguments\n  identifier     = local.db_identifier\n  engine         = var.db_engine\n  engine_version = var.db_engine_version\n  instance_class = var.db_instance_class\n\n  # Database Configuration\n  db_name  = var.db_name\n  username = var.db_username\n  password = var.db_password\n  port     = var.db_port\n\n  # Storage Configuration\n  allocated_storage     = var.db_allocated_storage\n  storage_type          = \"gp3\"\n  storage_encrypted     = true\n  max_allocated_storage = var.db_allocated_storage * 2 # Enable storage autoscaling\n\n  # Network Configuration\n  publicly_accessible    = var.publicly_accessible\n  vpc_security_group_ids = var.vpc_security_group_ids\n  db_subnet_group_name   = var.db_subnet_group_name != null ? var.db_subnet_group_name : try(aws_db_subnet_group.main[0].name, null)\n\n  # High Availability\n  multi_az               = var.multi_az\n  availability_zone      = var.multi_az ? null : data.aws_availability_zones.available.names[0]\n\n  # Backup Configuration\n  backup_retention_period   = var.backup_retention_period\n  backup_window            = \"03:00-04:00\"\n  maintenance_window       = \"mon:04:00-mon:05:00\"\n  copy_tags_to_snapshot    = true\n  skip_final_snapshot      = var.skip_final_snapshot\n  final_snapshot_identifier = local.final_snapshot_identifier\n\n  # Parameter and Option Groups\n  parameter_group_name = aws_db_parameter_group.main.name\n\n  # Monitoring and Logging\n  enabled_cloudwatch_logs_exports = var.db_engine == \"postgres\" ? [\"postgresql\", \"upgrade\"] : []\n  monitoring_interval             = 60\n  monitoring_role_arn            = aws_iam_role.rds_monitoring.arn\n  performance_insights_enabled    = true\n  performance_insights_retention_period = 7\n\n  # Deletion Protection\n  deletion_protection = var.environment == \"prod\" ? true : false\n\n  # Auto Minor Version Upgrade\n  auto_minor_version_upgrade = true\n\n  # Apply changes immediately (use with caution in production)\n  apply_immediately = var.environment != \"prod\"\n\n  tags = merge(\n    local.common_tags,\n    {\n      Type = \"RDSInstance\"\n    }\n  )\n\n  lifecycle {\n    ignore_changes = [\n      password, # Ignore password changes after creation\n    ]\n  }\n\n  depends_on = [\n    aws_db_parameter_group.main,\n    aws_iam_role_policy_attachment.rds_monitoring\n  ]\n}\n\n# IAM Role for Enhanced Monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name = \"${local.db_identifier}-monitoring-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = merge(\n    local.common_tags,\n    {\n      Type = \"IAMRole\"\n    }\n  )\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# Data source for availability zones\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\n# Data Source: Look up existing database by identifier\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_db_name != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_db_name\n}\n\n# CloudWatch Alarms for Database Monitoring\nresource \"aws_cloudwatch_metric_alarm\" \"database_cpu\" {\n  alarm_name          = \"${local.db_identifier}-high-cpu\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 2\n  metric_name         = \"CPUUtilization\"\n  namespace           = \"AWS/RDS\"\n  period              = 300\n  statistic           = \"Average\"\n  threshold           = 80\n  alarm_description   = \"This metric monitors RDS CPU utilization\"\n  alarm_actions       = [] # Add SNS topic ARN for notifications\n\n  dimensions = {\n    DBInstanceIdentifier = aws_db_instance.main.identifier\n  }\n\n  tags = local.common_tags\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"database_storage\" {\n  alarm_name          = \"${local.db_identifier}-low-storage\"\n  comparison_operator = \"LessThanThreshold\"\n  evaluation_periods  = 1\n  metric_name         = \"FreeStorageSpace\"\n  namespace           = \"AWS/RDS\"\n  period              = 300\n  statistic           = \"Average\"\n  threshold           = 10737418240 # 10 GB in bytes\n  alarm_description   = \"This metric monitors RDS free storage space\"\n  alarm_actions       = [] # Add SNS topic ARN for notifications\n\n  dimensions = {\n    DBInstanceIdentifier = aws_db_instance.main.identifier\n  }\n\n  tags = local.common_tags\n}\n\nresource \"aws_cloudwatch_metric_alarm\" \"database_connections\" {\n  alarm_name          = \"${local.db_identifier}-high-connections\"\n  comparison_operator = \"GreaterThanThreshold\"\n  evaluation_periods  = 2",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4778,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive Terraform configuration with provider, resource, data source, variables, and outputs. I'll use AWS RDS as an example cloud database.\n\n```hcl\n# variables.tf\nvariable \"aws_region\" {\n  description = \"AWS region where resources will be created\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]{1}$\", var.aws_region))\n    error_message = \"AWS region must be in the format: us-east-1, eu-west-2, etc.\"\n  }\n}\n\nvariable \"db_name\" {\n  description = \"Name of the database to create\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{0,62}$\", var.db_name))\n    error_message = \"Database name must start with a letter and contain only alphanumeric characters and underscores, max 63 characters.\"\n  }\n}\n\nvariable \"db_username\" {\n  description = \"Master username for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_username) >= 1 && length(var.db_username) <= 16\n    error_message = \"Database username must be between 1 and 16 characters.\"\n  }\n}\n\nvariable \"db_password\" {\n  description = \"Master password for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_password) >= 8 && can(regex(\"[A-Z]\", var.db_password)) && can(regex(\"[a-z]\", var.db_password)) && can(regex(\"[0-9]\", var.db_password))\n    error_message = \"Password must be at least 8 characters and contain uppercase, lowercase, and numeric characters.\"\n  }\n}\n\nvariable \"db_instance_class\" {\n  description = \"Instance class for the RDS database\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z0-9]+$\", var.db_instance_class))\n    error_message = \"Instance class must be a valid RDS instance type (e.g., db.t3.micro, db.m5.large).\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"engine_version\" {\n  description = \"Database engine version\"\n  type        = string\n  default     = \"8.0.35\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+\\\\.[0-9]+$\", var.engine_version))\n    error_message = \"Engine version must be in semantic version format (e.g., 8.0.35).\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Whether the database should be publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"vpc_security_group_ids\" {\n  description = \"List of VPC security group IDs\"\n  type        = list(string)\n\n  validation {\n    condition     = length(var.vpc_security_group_ids) > 0\n    error_message = \"At least one security group ID must be provided.\"\n  }\n}\n\nvariable \"db_subnet_group_name\" {\n  description = \"Name of DB subnet group\"\n  type        = string\n\n  validation {\n    condition     = length(var.db_subnet_group_name) > 0\n    error_message = \"DB subnet group name cannot be empty.\"\n  }\n}\n\nvariable \"existing_db_name\" {\n  description = \"Name of existing database to look up via data source\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to resources\"\n  type        = map(string)\n  default = {\n    Environment = \"development\"\n    ManagedBy   = \"terraform\"\n  }\n\n  validation {\n    condition     = length(var.tags) > 0\n    error_message = \"At least one tag must be provided.\"\n  }\n}\n```\n\n```hcl\n# main.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\n# Provider configuration\nprovider \"aws\" {\n  region = var.aws_region\n\n  default_tags {\n    tags = var.tags\n  }\n}\n\n# Resource: Create a new RDS database instance\nresource \"aws_db_instance\" \"main\" {\n  identifier = \"${var.db_name}-instance\"\n\n  # Engine configuration\n  engine               = \"mysql\"\n  engine_version       = var.engine_version\n  instance_class       = var.db_instance_class\n  allocated_storage    = var.allocated_storage\n  storage_type         = \"gp3\"\n  storage_encrypted    = true\n\n  # Database configuration\n  db_name  = var.db_name\n  username = var.db_username\n  password = var.db_password\n  port     = 3306\n\n  # Network configuration\n  db_subnet_group_name   = var.db_subnet_group_name\n  vpc_security_group_ids = var.vpc_security_group_ids\n  publicly_accessible    = var.publicly_accessible\n  multi_az               = var.multi_az\n\n  # Backup configuration\n  backup_retention_period = var.backup_retention_period\n  backup_window          = \"03:00-04:00\"\n  maintenance_window     = \"mon:04:00-mon:05:00\"\n\n  # Additional settings\n  skip_final_snapshot       = true\n  final_snapshot_identifier = \"${var.db_name}-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n  deletion_protection       = false\n  \n  # Performance insights\n  enabled_cloudwatch_logs_exports = [\"error\", \"general\", \"slowquery\"]\n  performance_insights_enabled    = true\n  performance_insights_retention_period = 7\n\n  # Monitoring\n  monitoring_interval = 60\n  monitoring_role_arn = aws_iam_role.rds_monitoring.arn\n\n  tags = {\n    Name = \"${var.db_name}-database\"\n  }\n\n  lifecycle {\n    prevent_destroy = false\n    ignore_changes  = [password]\n  }\n}\n\n# IAM role for enhanced monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name = \"${var.db_name}-rds-monitoring-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = {\n    Name = \"${var.db_name}-monitoring-role\"\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# Data source: Look up an existing database by identifier\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_db_name != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_db_name\n}\n\n# Data source: Get current AWS account information\ndata \"aws_caller_identity\" \"current\" {}\n\n# Data source: Get available engine versions\ndata \"aws_rds_engine_version\" \"mysql\" {\n  engine  = \"mysql\"\n  version = var.engine_version\n}\n```\n\n```hcl\n# outputs.tf\n# Outputs for the created database\noutput \"db_instance_id\" {\n  description = \"ID of the created RDS instance\"\n  value       = aws_db_instance.main.id\n}\n\noutput \"db_instance_arn\" {\n  description = \"ARN of the created RDS instance\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"db_endpoint\" {\n  description = \"Connection endpoint for the database\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"db_address\" {\n  description = \"Hostname of the RDS instance\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"db_port\" {\n  description = \"Port the database is listening on\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"db_name\" {\n  description = \"Name of the database\"\n  value       = aws_db_instance.main.db_name\n}\n\noutput \"db_resource_id\" {\n  description = \"Resource ID of the RDS instance\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"db_availability_zone\" {\n  description = \"Availability zone of the RDS instance\"\n  value       = aws_db_instance.main.availability_zone\n}\n\noutput \"db_status\" {\n  description = \"Status of the RDS instance\"\n  value       = aws_db_instance.main.status\n}\n\n# Outputs for the existing database (from data source)\noutput \"existing_db_endpoint\" {\n  description = \"Connection endpoint for the existing database\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].endpoint : null\n}\n\noutput \"existing_db_address\" {\n  description = \"Hostname of the existing RDS instance\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].address : null\n}\n\noutput \"existing_db_port\" {\n  description = \"Port the existing database is listening on\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].port : null\n}\n\noutput \"existing_db_arn\" {\n  description = \"ARN of the existing RDS instance\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].db_instance_arn : null\n}\n\n# Connection string output\noutput \"db_connection_string\" {\n  description = \"Connection string for the database (without password)\"\n  value       = \"mysql://${var.db_username}@${aws_db_instance.main.endpoint}/${var.db_name}\"\n  sensitive   = true\n}\n\n# Monitoring outputs\noutput \"monitoring_role_arn\" {\n  description = \"ARN of the monitoring IAM role\"\n  value       = aws_iam_role.rds_monitoring.arn\n}\n\n# Account information\noutput \"aws_account_id\" {\n  description = \"AWS account ID\"\n  value       = data.aws_caller_identity.current.account_id\n}\n\noutput \"engine_version_info\" {\n  description = \"Information about the MySQL engine version\"\n  value = {\n    version                       = data.aws_rds_engine_version.mysql.version\n    parameter_group_family        = data.aws_rds_engine_version.mysql.parameter_group_family\n    supported_feature_names       = data.aws_rds_engine_version.mysql.supported_feature_names\n  }\n}\n```\n\n```hcl\n# terraform.tfvars.example\n# Copy this file to terraform.tfvars and fill in your values\n\naws_region              = \"us-east-1\"\ndb_name                 = \"myapplication\"\ndb_username             = \"admin\"\ndb_password             = \"ChangeMe123!\"  # Use a secure password\ndb_instance_class       = \"db.t3.micro\"\nallocated_storage       = 20\nengine_version          = \"8.0.35\"\nbackup_retention_period = 7\nmulti_az                = false\npublicly_accessible     = false\n\n# Replace with your actual security group and subnet group\nvpc_security_group_ids  = [\"sg-0123456789abcdef0\"]\ndb_subnet_group_name    = \"my-db-subnet-group\"\n\n# Optional: specify an existing database to look up\nexisting_db_name = \"\"\n\ntags = {\n  Environment = \"development\"\n  Project     = \"my-application\"\n  ManagedBy   = \"terraform\"\n}\n```\n\n```hcl\n# versions.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n\n  # Optional: Configure backend for state storage\n  # backend \"s3\" {\n  #   bucket         = \"my-terraform-state\"\n  #   key            = \"rds/terraform.tfstate\"\n  #   region         = \"us-east-1\"\n  #   encrypt        = true\n  #   dynamodb_table = \"terraform-state-lock\"\n  # }\n}\n```\n\nThis configuration includes:\n\n1. **Provider Block**: AWS provider with region configuration and default tags\n2. **Resource**: `aws_db_instance` with all required arguments including engine, storage, networking, backups, and monitoring\n3. **Data Sources**: \n   - Lookup existing database by identifier\n   - Get AWS account info\n   - Get RDS engine version details\n4. **Variables**: Comprehensive variable definitions with validation rules for:\n   - Region format\n   - Database name constraints\n   - Password complexity\n   - Storage limits\n   - Instance class format\n5. **Outputs**: Multiple outputs showing endpoints, connection info, and metadata\n6. **Additional Features**:\n   - IAM role for enhanced monitoring\n   - Encryption enabled\n   - Performance insights\n   - CloudWatch logs\n   - Lifecycle rules\n\nTo use this configuration:\n\n```bash\n# Initialize Terraform\nterraform init\n\n# Validate configuration\nterraform validate\n\n# Plan changes\nterraform plan\n\n# Apply configuration\nterraform apply\n\n# View outputs\nterraform output db_endpoint\n```",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5063,
            "output_tokens": 3721,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "```hcl\n# variables.tf\nvariable \"region\" {\n  description = \"AWS region for resources\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]{1}$\", var.region))\n    error_message = \"Region must be a valid AWS region format (e.g., us-east-1).\"\n  }\n}\n\nvariable \"db_instance_class\" {\n  description = \"Database instance class\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z0-9]+$\", var.db_instance_class))\n    error_message = \"Instance class must be a valid RDS instance type (e.g., db.t3.micro).\"\n  }\n}\n\nvariable \"db_name\" {\n  description = \"Name of the database\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{0,62}$\", var.db_name))\n    error_message = \"Database name must start with a letter and contain only alphanumeric characters and underscores, max 63 characters.\"\n  }\n}\n\nvariable \"db_username\" {\n  description = \"Master username for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_username) >= 1 && length(var.db_username) <= 16\n    error_message = \"Username must be between 1 and 16 characters.\"\n  }\n}\n\nvariable \"db_password\" {\n  description = \"Master password for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_password) >= 8 && can(regex(\"[A-Z]\", var.db_password)) && can(regex(\"[a-z]\", var.db_password)) && can(regex(\"[0-9]\", var.db_password))\n    error_message = \"Password must be at least 8 characters and contain uppercase, lowercase, and numeric characters.\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"engine_version\" {\n  description = \"Database engine version\"\n  type        = string\n  default     = \"8.0.35\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+\\\\.[0-9]+$\", var.engine_version))\n    error_message = \"Engine version must be in semantic version format (e.g., 8.0.35).\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Make database publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"existing_db_identifier\" {\n  description = \"Identifier of existing database to lookup\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"environment\" {\n  description = \"Environment name\"\n  type        = string\n  default     = \"development\"\n\n  validation {\n    condition     = contains([\"development\", \"staging\", \"production\"], var.environment)\n    error_message = \"Environment must be one of: development, staging, production.\"\n  }\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to resources\"\n  type        = map(string)\n  default     = {}\n\n  validation {\n    condition     = alltrue([for k, v in var.tags : can(regex(\"^[a-zA-Z0-9_-]+$\", k))])\n    error_message = \"Tag keys must contain only alphanumeric characters, hyphens, and underscores.\"\n  }\n}\n\n# main.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\n# Provider Configuration\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = merge(\n      {\n        Environment = var.environment\n        ManagedBy   = \"Terraform\"\n        Project     = \"CloudDatabase\"\n      },\n      var.tags\n    )\n  }\n}\n\n# VPC and Networking (required for RDS)\nresource \"aws_vpc\" \"main\" {\n  cidr_block           = \"10.0.0.0/16\"\n  enable_dns_hostnames = true\n  enable_dns_support   = true\n\n  tags = {\n    Name = \"${var.db_name}-vpc\"\n  }\n}\n\nresource \"aws_subnet\" \"private_1\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.1.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[0]\n\n  tags = {\n    Name = \"${var.db_name}-private-subnet-1\"\n  }\n}\n\nresource \"aws_subnet\" \"private_2\" {\n  vpc_id            = aws_vpc.main.id\n  cidr_block        = \"10.0.2.0/24\"\n  availability_zone = data.aws_availability_zones.available.names[1]\n\n  tags = {\n    Name = \"${var.db_name}-private-subnet-2\"\n  }\n}\n\nresource \"aws_db_subnet_group\" \"main\" {\n  name       = \"${var.db_name}-subnet-group\"\n  subnet_ids = [aws_subnet.private_1.id, aws_subnet.private_2.id]\n\n  tags = {\n    Name = \"${var.db_name}-subnet-group\"\n  }\n}\n\n# Security Group for Database\nresource \"aws_security_group\" \"db\" {\n  name        = \"${var.db_name}-db-sg\"\n  description = \"Security group for RDS database\"\n  vpc_id      = aws_vpc.main.id\n\n  ingress {\n    description = \"MySQL/Aurora access\"\n    from_port   = 3306\n    to_port     = 3306\n    protocol    = \"tcp\"\n    cidr_blocks = [\"10.0.0.0/16\"]\n  }\n\n  egress {\n    description = \"Allow all outbound traffic\"\n    from_port   = 0\n    to_port     = 0\n    protocol    = \"-1\"\n    cidr_blocks = [\"0.0.0.0/0\"]\n  }\n\n  tags = {\n    Name = \"${var.db_name}-db-sg\"\n  }\n}\n\n# RDS Database Instance Resource\nresource \"aws_db_instance\" \"main\" {\n  identifier     = var.db_name\n  engine         = \"mysql\"\n  engine_version = var.engine_version\n\n  # Instance specifications\n  instance_class    = var.db_instance_class\n  allocated_storage = var.allocated_storage\n  storage_type      = \"gp3\"\n  storage_encrypted = true\n\n  # Database configuration\n  db_name  = var.db_name\n  username = var.db_username\n  password = var.db_password\n  port     = 3306\n\n  # Network configuration\n  db_subnet_group_name   = aws_db_subnet_group.main.name\n  vpc_security_group_ids = [aws_security_group.db.id]\n  publicly_accessible    = var.publicly_accessible\n  multi_az               = var.multi_az\n\n  # Backup configuration\n  backup_retention_period = var.backup_retention_period\n  backup_window           = \"03:00-04:00\"\n  maintenance_window      = \"mon:04:00-mon:05:00\"\n\n  # Additional settings\n  skip_final_snapshot       = true # Set to false in production\n  final_snapshot_identifier = \"${var.db_name}-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n  deletion_protection       = false # Set to true in production\n\n  # Performance and monitoring\n  enabled_cloudwatch_logs_exports = [\"error\", \"general\", \"slowquery\"]\n  monitoring_interval             = 60\n  monitoring_role_arn             = aws_iam_role.rds_monitoring.arn\n  performance_insights_enabled    = true\n\n  # Parameter and option groups\n  parameter_group_name = aws_db_parameter_group.main.name\n\n  tags = {\n    Name = var.db_name\n  }\n\n  lifecycle {\n    ignore_changes = [\n      password,\n      final_snapshot_identifier\n    ]\n  }\n}\n\n# DB Parameter Group\nresource \"aws_db_parameter_group\" \"main\" {\n  name   = \"${var.db_name}-params\"\n  family = \"mysql8.0\"\n\n  parameter {\n    name  = \"character_set_server\"\n    value = \"utf8mb4\"\n  }\n\n  parameter {\n    name  = \"max_connections\"\n    value = \"100\"\n  }\n\n  tags = {\n    Name = \"${var.db_name}-params\"\n  }\n}\n\n# IAM Role for Enhanced Monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name = \"${var.db_name}-rds-monitoring-role\"\n\n  assume_role_policy = jsonencode({\n    Version = \"2012-10-17\"\n    Statement = [\n      {\n        Action = \"sts:AssumeRole\"\n        Effect = \"Allow\"\n        Principal = {\n          Service = \"monitoring.rds.amazonaws.com\"\n        }\n      }\n    ]\n  })\n\n  tags = {\n    Name = \"${var.db_name}-rds-monitoring-role\"\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# Data Sources\ndata \"aws_availability_zones\" \"available\" {\n  state = \"available\"\n}\n\n# Data source to look up existing database by identifier\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_db_identifier != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_db_identifier\n}\n\n# outputs.tf\noutput \"database_endpoint\" {\n  description = \"Connection endpoint for the created database\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"database_address\" {\n  description = \"Hostname of the database\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"database_port\" {\n  description = \"Port of the database\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"database_arn\" {\n  description = \"ARN of the database instance\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"database_id\" {\n  description = \"Database instance identifier\"\n  value       = aws_db_instance.main.id\n}\n\noutput \"database_name\" {\n  description = \"Name of the database\"\n  value       = aws_db_instance.main.db_name\n}\n\noutput \"database_resource_id\" {\n  description = \"Resource ID of the database\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"existing_database_endpoint\" {\n  description = \"Connection endpoint for the existing database (if lookup was performed)\"\n  value       = var.existing_db_identifier != \"\" ? data.aws_db_instance.existing[0].endpoint : null\n}\n\noutput \"existing_database_address\" {\n  description = \"Hostname of the existing database (if lookup was performed)\"\n  value       = var.existing_db_identifier != \"\" ? data.aws_db_instance.existing[0].address : null\n}\n\noutput \"existing_database_engine\" {\n  description = \"Database engine of the existing database (if lookup was performed)\"\n  value       = var.existing_db_identifier != \"\" ? data.aws_db_instance.existing[0].engine : null\n}\n\noutput \"connection_string\" {\n  description = \"Full connection string for the database (without password)\"\n  value       = \"mysql://${var.db_username}@${aws_db_instance.main.endpoint}/${var.db_name}\"\n  sensitive   = true\n}\n\noutput \"security_group_id\" {\n  description = \"ID of the database security group\"\n  value       = aws_security_group.db.id\n}\n\noutput \"subnet_group_name\" {\n  description = \"Name of the database subnet group\"\n  value       = aws_db_subnet_group.main.name\n}\n\n# terraform.tfvars.example\n# region                  = \"us-east-1\"\n# db_name                 = \"myappdatabase\"\n# db_username             = \"admin\"\n# db_password             = \"SecurePassword123!\"\n# db_instance_class       = \"db.t3.micro\"\n# allocated_storage       = 20\n# engine_version          = \"8.0.35\"\n# backup_retention_period = 7\n# multi_az                = false\n# publicly_accessible     = false\n# environment             = \"development\"\n# existing_db_identifier  = \"\" # Set to lookup an existing database\n# tags = {\n#   Owner = \"DevOps Team\"\n#   CostCenter = \"Engineering\"\n# }\n```\n\nThis comprehensive Terraform configuration includes:\n\n**Provider Block:**\n- AWS provider with version constraints\n- Default tags configuration\n- Region specification\n\n**Resource (RDS Database):**\n- Complete RDS instance with all required arguments\n- VPC, subnets, and security groups\n- DB parameter group for customization\n- IAM role for enhanced monitoring\n- Encryption, backups, and monitoring enabled\n\n**Data Source:**\n- Lookup existing database by identifier\n- Conditional execution based on variable\n\n**Output Blocks:**\n- Database endpoint and connection details\n- Both created and existing database outputs\n- Sensitive output handling\n\n**Variable Definitions with Validation:**\n- Region format validation\n- Instance class format validation\n- Database name constraints\n- Password complexity requirements\n- Storage limits\n- Environment restrictions\n- Tag key format validation\n\n**Additional Features:**\n- Lifecycle rules for sensitive data\n- CloudWatch logs integration\n- Performance Insights\n- Multi-AZ support\n- Backup configuration\n- Security best practices\n\nTo use this configuration:\n\n```bash\nterraform init\nterraform plan -var=\"db_name=mydb\" -var=\"db_username=admin\" -var=\"db_password=SecurePass123!\"\nterraform apply\n```",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 59,
            "output_tokens": 3799,
            "cached": false
          },
          "with_skill": {
            "output": "# Terraform Configuration for Cloud Database\n\nHere's a complete HCL configuration demonstrating provider setup, resource creation, data source lookup, and outputs with proper variable validation:\n\n```hcl\n# variables.tf\n# Variable definitions with validation rules\n\nvariable \"region\" {\n  description = \"The cloud region where resources will be created\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]$\", var.region))\n    error_message = \"Region must be in format: us-east-1, eu-west-2, etc.\"\n  }\n}\n\nvariable \"environment\" {\n  description = \"Environment name for resource tagging\"\n  type        = string\n\n  validation {\n    condition     = contains([\"dev\", \"staging\", \"prod\"], var.environment)\n    error_message = \"Environment must be one of: dev, staging, prod.\"\n  }\n}\n\nvariable \"database_name\" {\n  description = \"Name of the database instance\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-z][a-z0-9-]{2,62}[a-z0-9]$\", var.database_name))\n    error_message = \"Database name must be 4-64 characters, start with a letter, and contain only lowercase letters, numbers, and hyphens.\"\n  }\n}\n\nvariable \"database_engine\" {\n  description = \"Database engine type\"\n  type        = string\n  default     = \"postgres\"\n\n  validation {\n    condition     = contains([\"postgres\", \"mysql\", \"mariadb\"], var.database_engine)\n    error_message = \"Database engine must be one of: postgres, mysql, mariadb.\"\n  }\n}\n\nvariable \"database_version\" {\n  description = \"Database engine version\"\n  type        = string\n  default     = \"14.5\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+$\", var.database_version))\n    error_message = \"Database version must be in format: major.minor (e.g., 14.5).\"\n  }\n}\n\nvariable \"instance_class\" {\n  description = \"Database instance class/size\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = can(regex(\"^db\\\\.[a-z0-9]+\\\\.[a-z0-9]+$\", var.instance_class))\n    error_message = \"Instance class must be in format: db.type.size (e.g., db.t3.micro).\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"storage_type\" {\n  description = \"Storage type for the database\"\n  type        = string\n  default     = \"gp3\"\n\n  validation {\n    condition     = contains([\"gp2\", \"gp3\", \"io1\", \"io2\"], var.storage_type)\n    error_message = \"Storage type must be one of: gp2, gp3, io1, io2.\"\n  }\n}\n\nvariable \"master_username\" {\n  description = \"Master username for database access\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{2,15}$\", var.master_username))\n    error_message = \"Master username must be 3-16 characters, start with a letter, and contain only letters, numbers, and underscores.\"\n  }\n}\n\nvariable \"master_password\" {\n  description = \"Master password for database access\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z0-9!@#$%^&*()_+=-]{8,}$\", var.master_password))\n    error_message = \"Master password must be at least 8 characters and contain letters, numbers, and special characters.\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Allow public access to the database\"\n  type        = bool\n  default     = false\n}\n\nvariable \"vpc_security_group_ids\" {\n  description = \"List of VPC security group IDs\"\n  type        = list(string)\n\n  validation {\n    condition     = length(var.vpc_security_group_ids) > 0\n    error_message = \"At least one security group ID must be provided.\"\n  }\n}\n\nvariable \"db_subnet_group_name\" {\n  description = \"Name of DB subnet group\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-z][a-z0-9-]{0,254}$\", var.db_subnet_group_name))\n    error_message = \"DB subnet group name must start with a letter and contain only lowercase letters, numbers, and hyphens.\"\n  }\n}\n\nvariable \"parameter_group_family\" {\n  description = \"Database parameter group family\"\n  type        = string\n  default     = \"postgres14\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]+[0-9]+$\", var.parameter_group_family))\n    error_message = \"Parameter group family must be in format: enginename + version (e.g., postgres14).\"\n  }\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to resources\"\n  type        = map(string)\n  default     = {}\n\n  validation {\n    condition     = alltrue([for k, v in var.tags : can(regex(\"^[a-zA-Z0-9_.-]{1,128}$\", k))])\n    error_message = \"Tag keys must be 1-128 characters and contain only letters, numbers, underscores, periods, and hyphens.\"\n  }\n}\n\nvariable \"existing_database_name\" {\n  description = \"Name of existing database to lookup via data source\"\n  type        = string\n  default     = \"\"\n\n  validation {\n    condition     = var.existing_database_name == \"\" || can(regex(\"^[a-z][a-z0-9-]{2,62}[a-z0-9]$\", var.existing_database_name))\n    error_message = \"Existing database name must be empty or follow naming conventions.\"\n  }\n}\n\nvariable \"enable_performance_insights\" {\n  description = \"Enable Performance Insights\"\n  type        = bool\n  default     = false\n}\n\nvariable \"performance_insights_retention_period\" {\n  description = \"Performance Insights retention period in days\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = contains([7, 731], var.performance_insights_retention_period)\n    error_message = \"Performance Insights retention period must be 7 or 731 days.\"\n  }\n}\n```\n\n```hcl\n# main.tf\n# Main Terraform configuration\n\nterraform {\n  required_version = \">= 1.5.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n    random = {\n      source  = \"hashicorp/random\"\n      version = \"~> 3.5\"\n    }\n  }\n}\n\n# Provider configuration\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = merge(\n      var.tags,\n      {\n        Environment = var.environment\n        ManagedBy   = \"Terraform\"\n        Service     = \"Database\"\n      }\n    )\n  }\n}\n\n# Generate random identifier for unique naming\nresource \"random_id\" \"db_identifier\" {\n  byte_length = 4\n  prefix      = \"${var.database_name}-\"\n\n  keepers = {\n    database_name = var.database_name\n    environment   = var.environment\n  }\n}\n\n# DB Parameter Group\nresource \"aws_db_parameter_group\" \"main\" {\n  name        = \"${var.database_name}-${var.environment}-params\"\n  family      = var.parameter_group_family\n  description = \"Custom parameter group for ${var.database_name}\"\n\n  # Example parameters for PostgreSQL\n  dynamic \"parameter\" {\n    for_each = var.database_engine == \"postgres\" ? {\n      \"shared_preload_libraries\" = \"pg_stat_statements\"\n      \"log_statement\"            = \"all\"\n      \"log_min_duration_statement\" = \"1000\"\n    } : {}\n\n    content {\n      name  = parameter.key\n      value = parameter.value\n    }\n  }\n\n  tags = {\n    Name = \"${var.database_name}-${var.environment}-params\"\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# DB Option Group (for MySQL/MariaDB)\nresource \"aws_db_option_group\" \"main\" {\n  count = contains([\"mysql\", \"mariadb\"], var.database_engine) ? 1 : 0\n\n  name                     = \"${var.database_name}-${var.environment}-options\"\n  option_group_description = \"Option group for ${var.database_name}\"\n  engine_name              = var.database_engine\n  major_engine_version     = split(\".\", var.database_version)[0]\n\n  tags = {\n    Name = \"${var.database_name}-${var.environment}-options\"\n  }\n\n  lifecycle {\n    create_before_destroy = true\n  }\n}\n\n# Main Database Resource\nresource \"aws_db_instance\" \"main\" {\n  # Basic Configuration\n  identifier     = random_id.db_identifier.hex\n  engine         = var.database_engine\n  engine_version = var.database_version\n  instance_class = var.instance_class\n\n  # Storage Configuration\n  allocated_storage     = var.allocated_storage\n  storage_type          = var.storage_type\n  storage_encrypted     = true\n  max_allocated_storage = var.allocated_storage * 2 # Enable storage autoscaling\n\n  # Database Configuration\n  db_name  = replace(var.database_name, \"-\", \"_\") # Database names can't have hyphens\n  username = var.master_username\n  password = var.master_password\n  port     = var.database_engine == \"postgres\" ? 5432 : 3306\n\n  # Network Configuration\n  db_subnet_group_name   = var.db_subnet_group_name\n  vpc_security_group_ids = var.vpc_security_group_ids\n  publicly_accessible    = var.publicly_accessible\n  multi_az               = var.multi_az\n\n  # Parameter and Option Groups\n  parameter_group_name = aws_db_parameter_group.main.name\n  option_group_name    = var.database_engine != \"postgres\" ? aws_db_option_group.main[0].name : null\n\n  # Backup Configuration\n  backup_retention_period   = var.backup_retention_period\n  backup_window             = \"03:00-04:00\"\n  maintenance_window        = \"mon:04:00-mon:05:00\"\n  copy_tags_to_snapshot     = true\n  skip_final_snapshot       = var.environment != \"prod\"\n  final_snapshot_identifier = var.environment == \"prod\" ? \"${random_id.db_identifier.hex}-final-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\" : null\n\n  # Monitoring and Logging\n  enabled_cloudwatch_logs_exports = var.database_engine == \"postgres\" ? [\"postgresql\", \"upgrade\"] : [\"error\", \"general\", \"slowquery\"]\n  monitoring_interval             = 60\n  monitoring_role_arn             = aws_iam_role.rds_monitoring.arn\n\n  # Performance Insights\n  performance_insights_enabled          = var.enable_performance_insights\n  performance_insights_retention_period = var.enable_performance_insights ? var.performance_insights_retention_period : null\n\n  # Security\n  deletion_protection = var.environment == \"prod\"\n  auto_minor_version_upgrade = true\n\n  # Lifecycle\n  apply_immediately = var.environment != \"prod\"\n\n  lifecycle {\n    ignore_changes = [\n      password, # Prevent password changes from triggering updates\n    ]\n  }\n\n  tags = {\n    Name        = var.database_name\n    Environment = var.environment\n    Engine      = var.database_engine\n    Version     = var.database_version\n  }\n\n  depends_on = [\n    aws_db_parameter_group.main,\n    aws_iam_role_policy_attachment.rds_monitoring\n  ]\n}\n\n# IAM Role for Enhanced Monitoring\nresource \"aws_iam_role\" \"rds_monitoring\" {\n  name               = \"${var.database_name}-${var.environment}-rds-monitoring\"\n  assume_role_policy = data.aws_iam_policy_document.rds_monitoring_assume.json\n\n  tags = {\n    Name = \"${var.database_name}-${var.environment}-rds-monitoring\"\n  }\n}\n\ndata \"aws_iam_policy_document\" \"rds_monitoring_assume\" {\n  statement {\n    actions = [\"sts:AssumeRole\"]\n\n    principals {\n      type        = \"Service\"\n      identifiers = [\"monitoring.rds.amazonaws.com\"]\n    }\n  }\n}\n\nresource \"aws_iam_role_policy_attachment\" \"rds_monitoring\" {\n  role       = aws_iam_role.rds_monitoring.name\n  policy_arn = \"arn:aws:iam::aws:policy/service-role/AmazonRDSEnhancedMonitoringRole\"\n}\n\n# Data Source: Lookup existing database by name\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_database_name != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_database_name\n}\n\n# Data Source: Get current AWS account ID\ndata \"aws_caller_identity\" \"current\" {}\n\n# Data Source: Get current AWS region\ndata \"aws_region\" \"current\" {}\n```\n\n```hcl\n# outputs.tf\n# Output definitions\n\n# Primary Database Outputs\noutput \"database_id\" {\n  description = \"The database instance identifier\"\n  value       = aws_db_instance.main.id\n}\n\noutput \"database_arn\" {\n  description = \"The ARN of the database instance\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"database_endpoint\" {\n  description = \"The connection endpoint for the database\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"database_address\" {\n  description = \"The hostname of the database instance\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"database_port\" {\n  description = \"The port the database is listening on\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"database_name\" {\n  description = \"The name of the database\"\n  value       = aws_db_instance.main.db_name\n}\n\noutput \"database_engine\" {\n  description = \"The database engine\"\n  value       = aws_db_instance.main.engine\n}\n\noutput \"database_engine_version\" {\n  description = \"The database engine version\"\n  value       = aws_db_instance.main.engine_version\n}\n\n# Connection String Output\noutput \"database_connection_string\" {\n  description = \"Database connection string (without password)\"\n  value       = \"${var.database_engine}://${var.master_username}@${aws_db_instance.main.endpoint}/${aws_db_instance.main.db_name}\"\n  sensitive   = true\n}\n\n# Resource Configuration Outputs\noutput \"database_resource_id\" {\n  description = \"The RDS Resource ID of the instance\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"database_",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 4778,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive Terraform configuration with provider, resource, data source, variables, and outputs.\n\n```hcl\n# variables.tf\nvariable \"region\" {\n  description = \"The region where resources will be created\"\n  type        = string\n  default     = \"us-east-1\"\n\n  validation {\n    condition     = can(regex(\"^[a-z]{2}-[a-z]+-[0-9]{1}$\", var.region))\n    error_message = \"Region must be in the format: us-east-1, eu-west-2, etc.\"\n  }\n}\n\nvariable \"db_name\" {\n  description = \"Name of the database instance\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-z][a-z0-9-]{0,62}[a-z0-9]$\", var.db_name))\n    error_message = \"Database name must start with a letter, contain only lowercase letters, numbers, and hyphens, and be between 1-63 characters.\"\n  }\n}\n\nvariable \"db_instance_class\" {\n  description = \"The instance type for the database\"\n  type        = string\n  default     = \"db.t3.micro\"\n\n  validation {\n    condition     = contains([\"db.t3.micro\", \"db.t3.small\", \"db.t3.medium\", \"db.t3.large\"], var.db_instance_class)\n    error_message = \"Instance class must be one of: db.t3.micro, db.t3.small, db.t3.medium, db.t3.large.\"\n  }\n}\n\nvariable \"db_engine\" {\n  description = \"Database engine type\"\n  type        = string\n  default     = \"postgres\"\n\n  validation {\n    condition     = contains([\"postgres\", \"mysql\", \"mariadb\"], var.db_engine)\n    error_message = \"Engine must be one of: postgres, mysql, mariadb.\"\n  }\n}\n\nvariable \"db_engine_version\" {\n  description = \"Database engine version\"\n  type        = string\n  default     = \"14.7\"\n\n  validation {\n    condition     = can(regex(\"^[0-9]+\\\\.[0-9]+$\", var.db_engine_version))\n    error_message = \"Engine version must be in format: major.minor (e.g., 14.7).\"\n  }\n}\n\nvariable \"db_username\" {\n  description = \"Master username for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = can(regex(\"^[a-zA-Z][a-zA-Z0-9_]{0,15}$\", var.db_username))\n    error_message = \"Username must start with a letter, contain only alphanumeric characters and underscores, and be 1-16 characters.\"\n  }\n}\n\nvariable \"db_password\" {\n  description = \"Master password for the database\"\n  type        = string\n  sensitive   = true\n\n  validation {\n    condition     = length(var.db_password) >= 8 && can(regex(\"[A-Z]\", var.db_password)) && can(regex(\"[a-z]\", var.db_password)) && can(regex(\"[0-9]\", var.db_password))\n    error_message = \"Password must be at least 8 characters and contain uppercase, lowercase, and numeric characters.\"\n  }\n}\n\nvariable \"allocated_storage\" {\n  description = \"Allocated storage in GB\"\n  type        = number\n  default     = 20\n\n  validation {\n    condition     = var.allocated_storage >= 20 && var.allocated_storage <= 65536\n    error_message = \"Allocated storage must be between 20 and 65536 GB.\"\n  }\n}\n\nvariable \"backup_retention_period\" {\n  description = \"Number of days to retain backups\"\n  type        = number\n  default     = 7\n\n  validation {\n    condition     = var.backup_retention_period >= 0 && var.backup_retention_period <= 35\n    error_message = \"Backup retention period must be between 0 and 35 days.\"\n  }\n}\n\nvariable \"multi_az\" {\n  description = \"Enable Multi-AZ deployment for high availability\"\n  type        = bool\n  default     = false\n}\n\nvariable \"publicly_accessible\" {\n  description = \"Whether the database is publicly accessible\"\n  type        = bool\n  default     = false\n}\n\nvariable \"vpc_security_group_ids\" {\n  description = \"List of VPC security group IDs\"\n  type        = list(string)\n\n  validation {\n    condition     = length(var.vpc_security_group_ids) > 0\n    error_message = \"At least one security group ID must be provided.\"\n  }\n}\n\nvariable \"db_subnet_group_name\" {\n  description = \"Name of DB subnet group\"\n  type        = string\n\n  validation {\n    condition     = can(regex(\"^[a-z][a-z0-9-]{0,254}$\", var.db_subnet_group_name))\n    error_message = \"Subnet group name must start with a letter and contain only lowercase letters, numbers, and hyphens.\"\n  }\n}\n\nvariable \"existing_db_name\" {\n  description = \"Name of existing database to lookup via data source\"\n  type        = string\n  default     = \"\"\n}\n\nvariable \"tags\" {\n  description = \"Tags to apply to resources\"\n  type        = map(string)\n  default     = {}\n\n  validation {\n    condition     = alltrue([for k, v in var.tags : can(regex(\"^[a-zA-Z0-9+\\\\-=._:/@]{1,128}$\", k))])\n    error_message = \"Tag keys must be 1-128 characters and contain only alphanumeric characters and +-=._:/@.\"\n  }\n}\n```\n\n```hcl\n# main.tf\nterraform {\n  required_version = \">= 1.0\"\n\n  required_providers {\n    aws = {\n      source  = \"hashicorp/aws\"\n      version = \"~> 5.0\"\n    }\n  }\n}\n\n# Provider configuration\nprovider \"aws\" {\n  region = var.region\n\n  default_tags {\n    tags = merge(\n      var.tags,\n      {\n        ManagedBy   = \"Terraform\"\n        Environment = terraform.workspace\n      }\n    )\n  }\n}\n\n# Resource: Cloud Database Instance\nresource \"aws_db_instance\" \"main\" {\n  identifier     = var.db_name\n  engine         = var.db_engine\n  engine_version = var.db_engine_version\n  instance_class = var.db_instance_class\n\n  # Storage configuration\n  allocated_storage     = var.allocated_storage\n  storage_type          = \"gp3\"\n  storage_encrypted     = true\n  max_allocated_storage = var.allocated_storage * 2\n\n  # Database configuration\n  db_name  = replace(var.db_name, \"-\", \"_\")\n  username = var.db_username\n  password = var.db_password\n  port     = var.db_engine == \"postgres\" ? 5432 : 3306\n\n  # Network configuration\n  db_subnet_group_name   = var.db_subnet_group_name\n  vpc_security_group_ids = var.vpc_security_group_ids\n  publicly_accessible    = var.publicly_accessible\n  multi_az               = var.multi_az\n\n  # Backup configuration\n  backup_retention_period = var.backup_retention_period\n  backup_window           = \"03:00-04:00\"\n  maintenance_window      = \"mon:04:00-mon:05:00\"\n  skip_final_snapshot     = false\n  final_snapshot_identifier = \"${var.db_name}-final-snapshot-${formatdate(\"YYYY-MM-DD-hhmm\", timestamp())}\"\n\n  # Monitoring and logging\n  enabled_cloudwatch_logs_exports = var.db_engine == \"postgres\" ? [\"postgresql\", \"upgrade\"] : [\"error\", \"general\", \"slowquery\"]\n  performance_insights_enabled    = true\n  performance_insights_retention_period = 7\n\n  # Additional settings\n  auto_minor_version_upgrade = true\n  deletion_protection        = true\n  copy_tags_to_snapshot      = true\n\n  tags = {\n    Name = var.db_name\n  }\n\n  lifecycle {\n    prevent_destroy = true\n    ignore_changes = [\n      password,\n      final_snapshot_identifier,\n    ]\n  }\n}\n\n# Data Source: Lookup existing database by name\ndata \"aws_db_instance\" \"existing\" {\n  count = var.existing_db_name != \"\" ? 1 : 0\n\n  db_instance_identifier = var.existing_db_name\n}\n```\n\n```hcl\n# outputs.tf\noutput \"db_instance_id\" {\n  description = \"The identifier of the database instance\"\n  value       = aws_db_instance.main.id\n}\n\noutput \"db_instance_endpoint\" {\n  description = \"The connection endpoint for the database\"\n  value       = aws_db_instance.main.endpoint\n}\n\noutput \"db_instance_address\" {\n  description = \"The hostname of the database instance\"\n  value       = aws_db_instance.main.address\n}\n\noutput \"db_instance_port\" {\n  description = \"The port the database is listening on\"\n  value       = aws_db_instance.main.port\n}\n\noutput \"db_instance_arn\" {\n  description = \"The ARN of the database instance\"\n  value       = aws_db_instance.main.arn\n}\n\noutput \"db_instance_status\" {\n  description = \"The status of the database instance\"\n  value       = aws_db_instance.main.status\n}\n\noutput \"db_instance_resource_id\" {\n  description = \"The resource ID of the database instance\"\n  value       = aws_db_instance.main.resource_id\n}\n\noutput \"existing_db_endpoint\" {\n  description = \"The endpoint of the existing database (if lookup was performed)\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].endpoint : null\n}\n\noutput \"existing_db_address\" {\n  description = \"The address of the existing database (if lookup was performed)\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].address : null\n}\n\noutput \"existing_db_port\" {\n  description = \"The port of the existing database (if lookup was performed)\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].port : null\n}\n\noutput \"existing_db_engine\" {\n  description = \"The engine of the existing database (if lookup was performed)\"\n  value       = var.existing_db_name != \"\" ? data.aws_db_instance.existing[0].engine : null\n}\n\noutput \"connection_string\" {\n  description = \"Connection string for the database (without password)\"\n  value       = \"${var.db_engine}://${var.db_username}@${aws_db_instance.main.endpoint}/${replace(var.db_name, \"-\", \"_\")}\"\n  sensitive   = true\n}\n```\n\n```hcl\n# terraform.tfvars.example\nregion                 = \"us-east-1\"\ndb_name                = \"my-database\"\ndb_instance_class      = \"db.t3.micro\"\ndb_engine              = \"postgres\"\ndb_engine_version      = \"14.7\"\ndb_username            = \"dbadmin\"\n# db_password should be set via environment variable: TF_VAR_db_password\nallocated_storage      = 20\nbackup_retention_period = 7\nmulti_az               = false\npublicly_accessible    = false\nvpc_security_group_ids = [\"sg-0123456789abcdef0\"]\ndb_subnet_group_name   = \"my-db-subnet-group\"\nexisting_db_name       = \"\"  # Set to lookup an existing database\n\ntags = {\n  Project     = \"MyProject\"\n  Environment = \"Development\"\n  Owner       = \"DevOps Team\"\n}\n```\n\nThis Terraform configuration includes:\n\n1. **Provider Block**: AWS provider with region configuration and default tags\n2. **Resource**: `aws_db_instance` with all required and recommended arguments including:\n   - Storage configuration with encryption\n   - Network settings (VPC, security groups)\n   - Backup and maintenance windows\n   - Performance insights and CloudWatch logs\n   - Lifecycle rules for protection\n\n3. **Data Source**: `aws_db_instance` to lookup existing databases by name (conditional based on variable)\n\n4. **Variables**: Comprehensive variable definitions with:\n   - Type constraints\n   - Default values\n   - Validation rules for format, length, and allowed values\n   - Sensitive marking for credentials\n\n5. **Outputs**: Multiple output blocks showing:\n   - Database endpoint and connection details\n   - Both new and existing database information\n   - Connection string (marked sensitive)\n\nThe configuration follows best practices including encryption, deletion protection, proper tagging, and secure credential handling.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5063,
            "output_tokens": 3194,
            "cached": false
          }
        }
      ]
    }
  ]
}