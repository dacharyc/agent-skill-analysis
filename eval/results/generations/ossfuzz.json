{
  "skill_name": "ossfuzz",
  "generated_at": "2026-02-16T08:36:13.986308+00:00",
  "model": "claude-sonnet-4-5-20250929",
  "temperature": 0.3,
  "runs_per_condition": 3,
  "contamination_score": 0.53,
  "risk_level": "high",
  "test_category": "app_to_app_and_aux",
  "tasks": [
    {
      "task_id": "ossfuzz-01",
      "task_type": "direct_target",
      "target_language": "cpp",
      "expected_patterns": [
        "LLVMFuzzerTestOneInput",
        "gcr\\.io/oss-fuzz-base/base-builder",
        "\\$CXX.*\\$CXXFLAGS",
        "\\$LIB_FUZZING_ENGINE",
        "\\$OUT/",
        "libfuzzer",
        "address",
        "project\\.yaml"
      ],
      "anti_patterns": [
        "atheris",
        "FuzzedDataProvider\\(data\\)",
        "compile_python_fuzzer",
        "cargo fuzz",
        "import sys"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new_project_guide.md",
          "description": "OSS-Fuzz build patterns: $CXX, $CXXFLAGS, $LIB_FUZZING_ENGINE, $OUT directory, gcr.io/oss-fuzz-base/base-builder Docker image, project.yaml structure with libfuzzer and address sanitizer"
        },
        {
          "url": "https://llvm.org/docs/LibFuzzer.html",
          "description": "LibFuzzer documentation - source of LLVMFuzzerTestOneInput(const uint8_t *Data, size_t Size) fuzz target entry point function signature"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/further-reading/fuzzer_environment.md",
          "description": "OSS-Fuzz build environment: $OUT and $SRC environment variables, static linking requirements"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/ujson_fuzzer.py",
          "description": "Anti-patterns: Python Atheris fuzzer example showing atheris.Setup, atheris.Fuzz, FuzzedDataProvider patterns that should not appear in C++"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "# Complete OSS-Fuzz Project Enrollment for fastjson\n\nI'll create a complete OSS-Fuzz integration for a C++ JSON parsing library called 'fastjson'.\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/fastjson/fastjson\"\nlanguage: c++\nprimary_contact: \"security@fastjson.example.com\"\nauto_ccs:\n  - \"dev@fastjson.example.com\"\n  - \"maintainer@fastjson.example.com\"\n\nsanitizers:\n  - address\n  - undefined\n  - memory\n\narchitectures:\n  - x86_64\n\nfuzzing_engines:\n  - libfuzzer\n  - afl\n\nmain_repo: \"https://github.com/fastjson/fastjson.git\"\n\nfile_github_issue: true\n\nvendor_ccs:\n  - \"vendor-security@example.com\"\n\nview_restrictions: none\n\n# Build configuration\nbuild_type: release\n\n# Coverage reports\ncoverage_extra_args: \"\"\n\n# Experimental features\nexperimental: false\n```\n\n## 2. Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder\n\n# Install dependencies\nRUN apt-get update && apt-get install -y \\\n    make \\\n    cmake \\\n    ninja-build \\\n    autoconf \\\n    automake \\\n    libtool \\\n    pkg-config \\\n    wget \\\n    git\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/fastjson/fastjson.git fastjson\n\n# Set working directory\nWORKDIR fastjson\n\n# Copy build script and fuzzer harnesses\nCOPY build.sh $SRC/\nCOPY *.cpp $SRC/\nCOPY *.dict $SRC/ 2>/dev/null || true\nCOPY *.options $SRC/ 2>/dev/null || true\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Build the library with OSS-Fuzz flags\ncd $SRC/fastjson\n\n# Create build directory\nmkdir -p build\ncd build\n\n# Configure with CMake\ncmake .. \\\n    -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=$CC \\\n    -DCMAKE_CXX_COMPILER=$CXX \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DBUILD_TESTING=OFF \\\n    -DENABLE_FUZZING=ON\n\n# Build the library\nninja -j$(nproc)\n\n# Install the library\nninja install\n\n# Build fuzz targets\nFUZZ_TARGETS=(\n    \"json_parse_fuzzer\"\n    \"json_parse_streaming_fuzzer\"\n    \"json_parse_with_validation_fuzzer\"\n)\n\nfor target in \"${FUZZ_TARGETS[@]}\"; do\n    if [ -f \"$SRC/${target}.cpp\" ]; then\n        echo \"Building fuzzer: $target\"\n        \n        $CXX $CXXFLAGS $LIB_FUZZING_ENGINE \\\n            \"$SRC/${target}.cpp\" \\\n            -o \"$OUT/${target}\" \\\n            -I$SRC/fastjson/include \\\n            -L$SRC/fastjson/build \\\n            -lfastjson \\\n            -Wl,-Bstatic -lstdc++ -Wl,-Bdynamic\n        \n        # Copy dictionary if exists\n        if [ -f \"$SRC/${target}.dict\" ]; then\n            cp \"$SRC/${target}.dict\" \"$OUT/\"\n        fi\n        \n        # Copy options if exists\n        if [ -f \"$SRC/${target}.options\" ]; then\n            cp \"$SRC/${target}.options\" \"$OUT/\"\n        fi\n    fi\ndone\n\n# Create seed corpus directories\nmkdir -p $OUT/json_parse_fuzzer_seed_corpus\nmkdir -p $OUT/json_parse_streaming_fuzzer_seed_corpus\nmkdir -p $OUT/json_parse_with_validation_fuzzer_seed_corpus\n\n# Add sample JSON files to seed corpus\ncat > $OUT/json_parse_fuzzer_seed_corpus/simple.json << 'EOF'\n{\"key\": \"value\"}\nEOF\n\ncat > $OUT/json_parse_fuzzer_seed_corpus/array.json << 'EOF'\n[1, 2, 3, 4, 5]\nEOF\n\ncat > $OUT/json_parse_fuzzer_seed_corpus/nested.json << 'EOF'\n{\"name\": \"test\", \"data\": {\"nested\": true, \"count\": 42}}\nEOF\n\ncat > $OUT/json_parse_fuzzer_seed_corpus/complex.json << 'EOF'\n{\n  \"string\": \"hello\",\n  \"number\": 123.456,\n  \"boolean\": true,\n  \"null\": null,\n  \"array\": [1, \"two\", 3.0, false],\n  \"object\": {\"nested\": \"value\"}\n}\nEOF\n\n# Copy seed corpus for other fuzzers\ncp -r $OUT/json_parse_fuzzer_seed_corpus/* $OUT/json_parse_streaming_fuzzer_seed_corpus/\ncp -r $OUT/json_parse_fuzzer_seed_corpus/* $OUT/json_parse_with_validation_fuzzer_seed_corpus/\n\necho \"Build completed successfully\"\n```\n\n## 4. json_parse_fuzzer.cpp\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <memory>\n\n// Include fastjson headers\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Limit input size to prevent timeouts\n    if (size > 1024 * 1024) {  // 1MB limit\n        return 0;\n    }\n\n    // Create a string from the input data\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse the JSON input\n        fastjson::Parser parser;\n        auto result = parser.parse(json_input);\n\n        if (result) {\n            // If parsing succeeded, perform additional operations\n            \n            // Serialize back to string\n            std::string serialized = result->toString();\n            \n            // Try to access various methods\n            if (result->isObject()) {\n                auto obj = result->asObject();\n                // Iterate through keys\n                for (const auto& key : obj->keys()) {\n                    auto value = obj->get(key);\n                    if (value) {\n                        value->toString();\n                    }\n                }\n            } else if (result->isArray()) {\n                auto arr = result->asArray();\n                // Iterate through elements\n                for (size_t i = 0; i < arr->size(); ++i) {\n                    auto element = arr->get(i);\n                    if (element) {\n                        element->toString();\n                    }\n                }\n            }\n            \n            // Test type checking\n            result->isString();\n            result->isNumber();\n            result->isBoolean();\n            result->isNull();\n        }\n    } catch (const std::exception& e) {\n        // Catch any exceptions to prevent crashes\n        // This is expected for invalid JSON\n    } catch (...) {\n        // Catch all other exceptions\n    }\n\n    return 0;\n}\n```\n\n## 5. json_parse_streaming_fuzzer.cpp\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <sstream>\n\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n#include \"fastjson/stream_parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 512 * 1024) {  // 512KB limit for streaming\n        return 0;\n    }\n\n    try {\n        // Test streaming parser\n        fastjson::StreamParser stream_parser;\n        \n        // Feed data in chunks to test streaming behavior\n        size_t chunk_size = 64;\n        for (size_t i = 0; i < size; i += chunk_size) {\n            size_t current_chunk = std::min(chunk_size, size - i);\n            stream_parser.feed(\n                reinterpret_cast<const char*>(data + i), \n                current_chunk\n            );\n            \n            // Try to get parsed objects\n            while (auto obj = stream_parser.getNext()) {\n                obj->toString();\n            }\n        }\n        \n        // Finalize the stream\n        stream_parser.finalize();\n        \n        // Get any remaining objects\n        while (auto obj = stream_parser.getNext()) {\n            obj->toString();\n        }\n        \n    } catch (const std::exception& e) {\n        // Expected for invalid input\n    } catch (...) {\n        // Catch all\n    }\n\n    return 0;\n}\n```\n\n## 6. json_parse_with_validation_fuzzer.cpp\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n#include \"fastjson/validator.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 1024 * 1024) {\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse with strict validation\n        fastjson::Parser parser;\n        parser.setStrictMode(true);\n        parser.setMaxDepth(100);\n        parser.setMaxStringLength(10000);\n        \n        auto result = parser.parse(json_input);\n\n        if (result) {\n            // Validate the parsed JSON\n            fastjson::Validator validator;\n            bool is_valid = validator.validate(result.get());\n            \n            if (is_valid) {\n                // Perform deep copy\n                auto copy = result->clone();\n                \n                // Compare original and copy\n                if (copy) {\n                    std::string original_str = result->toString();\n                    std::string copy_str = copy->toString();\n                    \n                    // Test equality\n                    bool equal = (original_str == copy_str);\n                    (void)equal;  // Suppress unused variable warning\n                }\n                \n                // Test pretty printing\n                std::string pretty = result->toPrettyString();\n                \n                // Test minified output\n                std::string minified = result->toMinifiedString();\n            }\n        }\n    } catch (const std::exception& e) {\n        // Expected for invalid input\n    } catch (...) {\n        // Catch all\n    }\n\n    return 0;\n}\n```\n\n## 7. json_parse_fuzzer.dict\n\n```\n# JSON fuzzing dictionary\n# Keywords\n\"true\"\n\"false\"\n\"null\"\n\n# Delimiters\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\n# Quotes\n\"\\\"\"\n\"'\"\n\n# Escape sequences\n\"\\\\\\\\\"\n\"\\\\n\"\n\"\\\\r\"\n\"\\\\t\"\n\"\\\\b\"\n\"\\\\f\"\n\"\\\\/\"\n\"\\\\u0000\"\n\"\\\\u001f\"\n\"\\\\uffff\"\n\n# Numbers\n\"0\"\n\"1\"\n\"-1\"\n\"1.0\"\n\"-1.0\"\n\"1e10\"\n\"1E10\"\n\"1e+10\"\n\"1e-10\"\n\n# Common patterns\n\"{\\\"key\\\":\\\"value\\\"}\"\n\"[1,2,3]\"\n\"{}\"\n\"[]\"\n\"[{}]\"\n\"{\\\"a\\\":[]}\"\n\n# Edge cases\n\"\\\"\\\\u0000\\\"\"\n\"\\\"\\\\\\\"\\\"\"\n\"1e308\"\n\"-1e308\"\n\"9999999999999999999999\"\n```\n\n## 8. json_parse_fuzzer.options\n\n```\n[libfuzzer]\nmax_len = 1048576\ntimeout = 25\nrss_limit_mb = 2048\n```\n\n## 9. json_parse_streaming_fuzzer.options\n\n```\n[libfuzzer]\nmax_len = 524288\ntimeout = 30\nrss_limit_mb = 2048\n```\n\n## 10. json_parse_with_validation_fuzzer.options\n\n```\n[libfuzzer]\nmax_len = 1048576\ntimeout = 30\nrss_limit_mb = 2048\n```\n\n---\n\n## Usage Instructions\n\n1. **Place all files in the OSS-Fuzz repository structure:**\n   ```\n   oss-fuzz/projects/fastjson/\n   \u251c\u2500\u2500 project.yaml\n   \u251c\u2500\u2500 Dockerfile\n   \u251c\u2500\u2500 build.sh\n   \u251c\u2500\u2500 json_parse_fuzzer.cpp\n   \u251c\u2500\u2500 json_parse_streaming_fuzzer.cpp\n   \u251c\u2500\u2500 json_parse_with_validation_fuzzer.cpp\n   \u251c\u2500\u2500 json_parse_fuzzer.dict\n   \u251c\u2500\u2500 json_parse_fuzzer.options\n   \u251c\u2500\u2500 json_parse_streaming_fuzzer.options\n   \u2514\u2500\u2500 json_parse_with_validation_fuzzer.options\n   ```\n\n2. **Build the project:**",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 105,
            "output_tokens": 4096,
            "cached": false
          },
          "with_skill": {
            "output": "# Complete OSS-Fuzz Enrollment for fastjson\n\nHere's a complete OSS-Fuzz project enrollment for the fastjson C++ JSON parsing library.\n\n## Project Structure\n\n```\noss-fuzz/projects/fastjson/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 build.sh\n\u2514\u2500\u2500 fuzz_parser.cc\n```\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/fastjson/fastjson\"\nlanguage: c++\nprimary_contact: \"security@fastjson.org\"\nauto_ccs:\n  - \"maintainer@fastjson.org\"\n  - \"fuzzing-team@fastjson.org\"\n\n# Main repository\nmain_repo: \"https://github.com/fastjson/fastjson\"\n\n# Fuzzing engines to use\nfuzzing_engines:\n  - libfuzzer\n  - afl\n\n# Sanitizers to test with\nsanitizers:\n  - address\n  - undefined\n  - memory  # Optional: if you want MemorySanitizer coverage\n\n# Architectures (optional, defaults to x86_64)\narchitectures:\n  - x86_64\n\n# File issue automatically when bugs are found\nfile_github_issue: true\n\n# Vendor CCS (optional - notify other stakeholders)\nvendor_ccs:\n  - \"oss-security@lists.openwall.com\"\n\n# Help URL for project-specific fuzzing documentation\nhelp_url: \"https://github.com/fastjson/fastjson/blob/main/docs/FUZZING.md\"\n\n# View restrictions (optional)\nview_restrictions: none\n\n# Experimental features (optional)\nexperimental: false\n```\n\n## 2. Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/fastjson/fastjson.git fastjson\n\n# Clone the fuzzing harnesses repository (if separate)\n# Alternatively, harnesses can be in the main repo under fuzz/ directory\n# RUN git clone --depth 1 https://github.com/fastjson/fastjson-fuzzers.git fuzzers\n\n# Set working directory\nWORKDIR fastjson\n\n# Copy build script\nCOPY build.sh $SRC/\nCOPY fuzz_*.cc $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Build the fastjson library\ncd $SRC/fastjson\n\n# Create build directory\nmkdir -p build\ncd build\n\n# Configure with CMake\n# Note: We build a static library for fuzzing\ncmake .. \\\n    -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DCMAKE_C_COMPILER=\"$CC\" \\\n    -DCMAKE_CXX_COMPILER=\"$CXX\" \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_TESTING=OFF \\\n    -DBUILD_EXAMPLES=OFF \\\n    -DBUILD_BENCHMARKS=OFF\n\n# Build the library\nninja -j$(nproc)\n\n# The library should now be at: build/libfastjson.a\nFASTJSON_LIB=\"$SRC/fastjson/build/libfastjson.a\"\n\n# Verify library was built\nif [ ! -f \"$FASTJSON_LIB\" ]; then\n    echo \"Error: libfastjson.a not found at $FASTJSON_LIB\"\n    exit 1\nfi\n\n# Build fuzz targets\ncd $SRC\n\n# List of fuzz targets to build\nFUZZ_TARGETS=(\n    \"fuzz_parser\"\n    \"fuzz_parser_strict\"\n    \"fuzz_serializer\"\n    \"fuzz_roundtrip\"\n)\n\n# Build each fuzzer\nfor target in \"${FUZZ_TARGETS[@]}\"; do\n    if [ -f \"$SRC/${target}.cc\" ]; then\n        echo \"Building $target\"\n        \n        $CXX $CXXFLAGS \\\n            -std=c++17 \\\n            -I$SRC/fastjson/include \\\n            $SRC/${target}.cc \\\n            -o $OUT/$target \\\n            $LIB_FUZZING_ENGINE \\\n            $FASTJSON_LIB\n        \n        # Copy seed corpus if it exists\n        if [ -d \"$SRC/fastjson/fuzz/corpus/${target}\" ]; then\n            zip -j $OUT/${target}_seed_corpus.zip \\\n                $SRC/fastjson/fuzz/corpus/${target}/*\n        fi\n        \n        # Copy dictionary if it exists\n        if [ -f \"$SRC/fastjson/fuzz/${target}.dict\" ]; then\n            cp $SRC/fastjson/fuzz/${target}.dict $OUT/${target}.dict\n        fi\n        \n        # Copy options file if it exists\n        if [ -f \"$SRC/fastjson/fuzz/${target}.options\" ]; then\n            cp $SRC/fastjson/fuzz/${target}.options $OUT/${target}.options\n        fi\n    fi\ndone\n\necho \"Build completed successfully\"\n```\n\n## 4. fuzz_parser.cc\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <vector>\n\n// Include fastjson headers\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n#include \"fastjson/value.h\"\n\n// Fuzz target for basic JSON parsing\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Reject inputs that are too large to avoid timeouts\n    if (size > 1024 * 1024) {  // 1MB limit\n        return 0;\n    }\n\n    // Reject empty inputs\n    if (size == 0) {\n        return 0;\n    }\n\n    // Create a string from the input data\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse the JSON input\n        fastjson::Document doc;\n        doc.Parse(json_input);\n\n        // If parsing succeeded, perform additional operations\n        if (!doc.HasParseError()) {\n            // Test various accessor methods\n            if (doc.IsObject()) {\n                // Iterate through object members\n                for (auto it = doc.MemberBegin(); it != doc.MemberEnd(); ++it) {\n                    // Access key and value\n                    const char* key = it->name.GetString();\n                    const fastjson::Value& value = it->value;\n                    \n                    // Test different value types\n                    if (value.IsString()) {\n                        value.GetString();\n                    } else if (value.IsNumber()) {\n                        if (value.IsInt()) {\n                            value.GetInt();\n                        } else if (value.IsDouble()) {\n                            value.GetDouble();\n                        }\n                    } else if (value.IsBool()) {\n                        value.GetBool();\n                    } else if (value.IsArray()) {\n                        for (size_t i = 0; i < value.Size(); ++i) {\n                            // Access array elements\n                            const fastjson::Value& elem = value[i];\n                        }\n                    }\n                }\n            } else if (doc.IsArray()) {\n                // Iterate through array elements\n                for (size_t i = 0; i < doc.Size(); ++i) {\n                    const fastjson::Value& elem = doc[i];\n                }\n            }\n\n            // Test serialization back to string\n            std::string serialized = doc.ToString();\n\n            // Test deep copy\n            fastjson::Document copy;\n            copy.CopyFrom(doc);\n        }\n    } catch (const std::exception& e) {\n        // Catch any exceptions to prevent crashes\n        // This is expected for invalid JSON\n    } catch (...) {\n        // Catch all other exceptions\n    }\n\n    return 0;\n}\n```\n\n## 5. Additional Fuzz Harnesses\n\n### fuzz_parser_strict.cc\n\n```cpp\n// Strict parsing mode - rejects any non-standard JSON\n#include <cstddef>\n#include <cstdint>\n#include <string>\n\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 512 * 1024 || size == 0) {\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        fastjson::Document doc;\n        // Enable strict parsing mode\n        doc.Parse(json_input, fastjson::kParseStrictMode);\n\n        if (!doc.HasParseError()) {\n            // Validate the document structure\n            doc.Validate();\n        }\n    } catch (...) {\n        // Expected for invalid JSON\n    }\n\n    return 0;\n}\n```\n\n### fuzz_serializer.cc\n\n```cpp\n// Test JSON serialization with various options\n#include <cstddef>\n#include <cstdint>\n#include <string>\n\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n#include \"fastjson/writer.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 256 * 1024 || size == 0) {\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        fastjson::Document doc;\n        doc.Parse(json_input);\n\n        if (!doc.HasParseError()) {\n            // Test different serialization modes\n            std::string compact = doc.ToString(fastjson::kCompact);\n            std::string pretty = doc.ToString(fastjson::kPretty);\n            std::string minimal = doc.ToString(fastjson::kMinimal);\n        }\n    } catch (...) {\n        // Expected for invalid JSON\n    }\n\n    return 0;\n}\n```\n\n### fuzz_roundtrip.cc\n\n```cpp\n// Test parse -> serialize -> parse roundtrip\n#include <cstddef>\n#include <cstdint>\n#include <string>\n\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 128 * 1024 || size == 0) {\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // First parse\n        fastjson::Document doc1;\n        doc1.Parse(json_input);\n\n        if (!doc1.HasParseError()) {\n            // Serialize\n            std::string serialized = doc1.ToString();\n\n            // Second parse\n            fastjson::Document doc2;\n            doc2.Parse(serialized);\n\n            // Both should be valid and equivalent\n            if (!doc2.HasParseError()) {\n                // Compare documents (if library supports comparison)\n                // doc1 == doc2\n            }\n        }\n    } catch (...) {\n        // Expected for invalid JSON\n    }\n\n    return 0;\n}\n```\n\n## 6. Optional: Seed Corpus\n\nCreate a seed corpus directory structure:\n\n```\nfastjson/fuzz/corpus/fuzz_parser/\n\u251c\u2500\u2500 empty_object.json\n\u251c\u2500\u2500 empty_array.json\n\u251c\u2500\u2500 simple_string.json\n\u251c\u2500\u2500 numbers.json\n\u251c\u2500\u2500 nested.json\n\u2514\u2500\u2500 unicode.json\n```\n\n**Example seed files:**\n\n**empty_object.json:**\n```json\n{}\n```\n\n**empty_array.json:**\n```json\n[]\n```\n\n**simple_string.json:**\n```json\n{\"key\": \"value\"}\n```\n\n**numbers.json:**\n```json\n{\"int\": 42, \"float\": 3.14, \"negative\": -100, \"exp\": 1e10}\n```\n\n**nested.json:**\n```json\n{\n  \"object\": {\n    \"array\": [1, 2, 3],\n    \"nested\": {\n      \"deep\": true\n    }\n  }\n}\n```\n\n**unicode.json:**\n```json\n{\"emoji\": \"\ud83d\ude80\", \"chinese\": \"\u4f60\u597d\", \"escape\": \"\\u0041\"}\n```\n\n## 7. Optional: Dictionary File\n\n**fastjson/fuzz/fuzz_parser.dict:**\n```\n# JSON structural tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\n# JSON keywords\n\"true\"\n\"false\"\n\"null\"\n\n# Common keys\n\"\\\"name\\\"\"\n\"\\\"value\\\"\"\n\"\\\"data\\\"\"\n\"\\\"id\\\"\"\n\"\\\"type\\\"\"\n\n# Number patterns\n\"0\"\n\"1\"\n\"-1\"\n\"0.0\"\n\"1e10\"\n\"-1.5e-10\"\n\n# String patterns\n\"\\\"\\\"\"\n\"\\\"a\\\"\"\n\"\\\"test\\\"\"\n\n# Escape sequences\n\"\\\\\\\"\"\n\"\\\\\\\\\"\n\"\\\\/\"\n\"\\\\b\"\n\"\\\\f\"\n\"\\\\n\"\n\"\\\\r\"\n\"\\\\t\"\n\"\\\\u0000\"\n```\n\n## 8. Optional: Options File\n\n**fastjson/fuzz/fuzz_parser.options:**\n```\n[libfuzzer]\nmax_len = 1048576\ntimeout = 25\nrss_limit_mb = 2560\ndict = fuzz_parser.dict\n\n[asan]\ndetect_leaks = 1\n```\n\n## Testing Locally\n\nBefore submitting the PR, test locally:\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Copy your project files\nmkdir -p projects/fastjson\ncp /path/to/your/files/* projects/fastjson/\n\n# Build the project image\npython3 infra/helper.py build_image fastjson\n\n# Build fuzzers with AddressSanitizer\npython3 inf",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5051,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a complete OSS-Fuzz enrollment for the fastjson library. This will include all necessary files and a basic fuzzing harness.\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/yourorg/fastjson\"\nlanguage: c++\nprimary_contact: \"security@yourorg.com\"\nmain_repo: \"https://github.com/yourorg/fastjson\"\nfuzzing_engines:\n  - libfuzzer\n  - afl\nsanitizers:\n  - address\n  - undefined\n```\n\n## 2. Dockerfile\n\n```dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config\n\n# Clone the fastjson repository\nRUN git clone --depth 1 https://github.com/yourorg/fastjson fastjson\n\nWORKDIR fastjson\nCOPY build.sh $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Build the fastjson library\nmkdir -p build\ncd build\n\n# Configure with CMake\ncmake .. \\\n    -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=\"$CC\" \\\n    -DCMAKE_CXX_COMPILER=\"$CXX\" \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DBUILD_TESTING=OFF\n\n# Build the library\nninja\n\n# Return to source directory for fuzzer compilation\ncd ..\n\n# Build the fuzz harness\n$CXX $CXXFLAGS -std=c++17 \\\n    -I./include \\\n    $SRC/fastjson/fuzz/fuzz_parser.cc \\\n    -o $OUT/fuzz_parser \\\n    $LIB_FUZZING_ENGINE \\\n    ./build/libfastjson.a\n\n# Copy seed corpus if it exists\nif [ -f \"$SRC/fastjson/fuzz/corpus.zip\" ]; then\n    cp $SRC/fastjson/fuzz/corpus.zip $OUT/fuzz_parser_seed_corpus.zip\nfi\n\n# Copy dictionary if it exists\nif [ -f \"$SRC/fastjson/fuzz/json.dict\" ]; then\n    cp $SRC/fastjson/fuzz/json.dict $OUT/fuzz_parser.dict\nfi\n```\n\n## 4. Fuzz Harness (fuzz/fuzz_parser.cc)\n\n```cpp\n#include <cstdint>\n#include <cstddef>\n#include <string>\n#include <vector>\n\n// Include your JSON parser header\n// Adjust this path based on your actual library structure\n#include \"fastjson/parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Ignore empty inputs\n    if (size == 0) {\n        return 0;\n    }\n\n    // Convert input to string\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse the JSON input\n        // Adjust this based on your actual API\n        fastjson::Parser parser;\n        auto result = parser.parse(json_input);\n        \n        // If parsing succeeded, try to serialize it back\n        // This exercises both parsing and serialization code paths\n        if (result.has_value()) {\n            auto serialized = result.value().to_string();\n            // Optionally parse again to test round-trip\n            parser.parse(serialized);\n        }\n    } catch (const std::exception& e) {\n        // Catch expected exceptions (parse errors, etc.)\n        // These are not bugs, just invalid input\n    } catch (...) {\n        // Catch any other exceptions\n        // Unexpected exceptions might indicate bugs\n    }\n\n    return 0;\n}\n```\n\n## 5. JSON Dictionary (fuzz/json.dict)\n\n```\n# JSON structural tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\n# JSON literals\n\"true\"\n\"false\"\n\"null\"\n\n# Common JSON patterns\n\"{\\\"key\\\":\\\"value\\\"}\"\n\"[1,2,3]\"\n\"{\\\"nested\\\":{\\\"key\\\":\\\"value\\\"}}\"\n\"[{\\\"id\\\":1},{\\\"id\\\":2}]\"\n\n# Edge cases\n\"0\"\n\"-1\"\n\"1.5\"\n\"1e10\"\n\"1.5e-10\"\n\"\\\"\\\"\"\n\"\\\"\\\\n\\\"\"\n\"\\\"\\\\t\\\"\"\n\"\\\"\\\\u0000\\\"\"\n\n# Whitespace variations\n\" \"\n\"\\n\"\n\"\\t\"\n\"\\r\"\n```\n\n## 6. Seed Corpus Structure (fuzz/corpus/)\n\nCreate a directory with sample JSON files:\n\n**corpus/simple.json:**\n```json\n{\"key\": \"value\"}\n```\n\n**corpus/array.json:**\n```json\n[1, 2, 3, 4, 5]\n```\n\n**corpus/nested.json:**\n```json\n{\n  \"user\": {\n    \"name\": \"John\",\n    \"age\": 30,\n    \"active\": true\n  }\n}\n```\n\n**corpus/mixed.json:**\n```json\n{\n  \"string\": \"hello\",\n  \"number\": 42,\n  \"float\": 3.14,\n  \"bool\": true,\n  \"null\": null,\n  \"array\": [1, 2, 3],\n  \"object\": {\"nested\": \"value\"}\n}\n```\n\n**corpus/unicode.json:**\n```json\n{\"text\": \"Hello \u4e16\u754c \ud83c\udf0d\"}\n```\n\n**corpus/empty.json:**\n```json\n{}\n```\n\nThen create the corpus zip:\n```bash\ncd fuzz\nzip -r corpus.zip corpus/\n```\n\n## Project Structure\n\nYour fastjson repository should have this structure:\n\n```\nfastjson/\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 include/\n\u2502   \u2514\u2500\u2500 fastjson/\n\u2502       \u2514\u2500\u2500 parser.h\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 parser.cpp\n\u251c\u2500\u2500 fuzz/\n\u2502   \u251c\u2500\u2500 fuzz_parser.cc\n\u2502   \u251c\u2500\u2500 json.dict\n\u2502   \u251c\u2500\u2500 corpus.zip\n\u2502   \u2514\u2500\u2500 corpus/\n\u2502       \u251c\u2500\u2500 simple.json\n\u2502       \u251c\u2500\u2500 array.json\n\u2502       \u251c\u2500\u2500 nested.json\n\u2502       \u251c\u2500\u2500 mixed.json\n\u2502       \u251c\u2500\u2500 unicode.json\n\u2502       \u2514\u2500\u2500 empty.json\n\u2514\u2500\u2500 README.md\n```\n\n## Testing Locally\n\nTo test this setup locally with OSS-Fuzz:\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Create the project directory\nmkdir -p projects/fastjson\n\n# Copy the files\ncp /path/to/project.yaml projects/fastjson/\ncp /path/to/Dockerfile projects/fastjson/\ncp /path/to/build.sh projects/fastjson/\n\n# Build the project image\npython3 infra/helper.py build_image fastjson\n\n# Build fuzzers with AddressSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=address fastjson\n\n# Run the fuzzer\npython3 infra/helper.py run_fuzzer fastjson fuzz_parser\n\n# Test with UndefinedBehaviorSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=undefined fastjson\npython3 infra/helper.py run_fuzzer fastjson fuzz_parser\n\n# Generate coverage report\npython3 infra/helper.py build_fuzzers --sanitizer=coverage fastjson\npython3 infra/helper.py coverage fastjson\n```\n\n## Key Features\n\nThis enrollment includes:\n\n\u2705 **Both fuzzing engines** (libFuzzer and AFL++)\n\u2705 **Multiple sanitizers** (AddressSanitizer and UndefinedBehaviorSanitizer)\n\u2705 **Comprehensive harness** that tests parsing and serialization\n\u2705 **JSON dictionary** with common tokens and edge cases\n\u2705 **Seed corpus** with diverse JSON examples\n\u2705 **Static linking** for better performance\n\u2705 **Exception handling** to distinguish bugs from invalid input\n\u2705 **CMake integration** with proper compiler flags\n\nThe harness is designed to catch common JSON parsing bugs like buffer overflows, use-after-free, integer overflows, and undefined behavior.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5581,
            "output_tokens": 2128,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "# OSS-Fuzz Project Enrollment for fastjson\n\nI'll create a complete OSS-Fuzz integration for the fastjson C++ JSON parsing library.\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/fastjson/fastjson\"\nlanguage: c++\nprimary_contact: \"security@fastjson.example.com\"\nauto_ccs:\n  - \"dev@fastjson.example.com\"\n  - \"maintainer@fastjson.example.com\"\n\nsanitizers:\n  - address\n  - undefined\n  - memory\n\narchitectures:\n  - x86_64\n\nfuzzing_engines:\n  - libfuzzer\n  - afl\n\nmain_repo: \"https://github.com/fastjson/fastjson.git\"\n\nfile_github_issue: true\n\nvendor_ccs:\n  - \"vendor-security@example.com\"\n\nview_restrictions: none\n\n# Optional: Specify if the project needs special build configuration\nexperimental: false\n\n# Coverage report settings\ncoverage_extra_args: \"\"\n\n# Continuous fuzzing\nrun_tests: true\n```\n\n## 2. Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder\n\n# Install dependencies\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config \\\n    git \\\n    wget\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/fastjson/fastjson.git fastjson\n\n# Set working directory\nWORKDIR fastjson\n\n# Copy build script and fuzzer harnesses\nCOPY build.sh $SRC/\nCOPY fuzzer/*.cpp $SRC/\n\n# Set the working directory back to $SRC for the build\nWORKDIR $SRC\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Build the fastjson library\ncd $SRC/fastjson\n\n# Create build directory\nmkdir -p build\ncd build\n\n# Configure with CMake\n# Note: We use the OSS-Fuzz provided compiler flags\ncmake -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=$CC \\\n    -DCMAKE_CXX_COMPILER=$CXX \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DBUILD_TESTING=OFF \\\n    -DFASTJSON_BUILD_EXAMPLES=OFF \\\n    -DFASTJSON_BUILD_TESTS=OFF \\\n    ..\n\n# Build the library\nninja\n\n# The library should now be available as libfastjson.a\nFASTJSON_LIB=\"$SRC/fastjson/build/libfastjson.a\"\n\n# Verify the library was built\nif [ ! -f \"$FASTJSON_LIB\" ]; then\n    echo \"Error: fastjson library not found at $FASTJSON_LIB\"\n    # Try to find it\n    find $SRC/fastjson/build -name \"*.a\" -o -name \"*.so\"\n    exit 1\nfi\n\n# Build fuzzers\nFUZZERS=(\n    \"json_parse_fuzzer\"\n    \"json_parse_streaming_fuzzer\"\n    \"json_serialize_fuzzer\"\n)\n\nfor fuzzer in \"${FUZZERS[@]}\"; do\n    if [ -f \"$SRC/${fuzzer}.cpp\" ]; then\n        echo \"Building $fuzzer\"\n        \n        $CXX $CXXFLAGS \\\n            -I$SRC/fastjson/include \\\n            -std=c++17 \\\n            $LIB_FUZZING_ENGINE \\\n            $SRC/${fuzzer}.cpp \\\n            $FASTJSON_LIB \\\n            -o $OUT/${fuzzer}\n        \n        # Create seed corpus if it doesn't exist\n        if [ ! -d \"$SRC/${fuzzer}_seed_corpus\" ]; then\n            mkdir -p \"$SRC/${fuzzer}_seed_corpus\"\n        fi\n        \n        # Zip the seed corpus\n        if [ -d \"$SRC/${fuzzer}_seed_corpus\" ] && [ \"$(ls -A $SRC/${fuzzer}_seed_corpus)\" ]; then\n            zip -j $OUT/${fuzzer}_seed_corpus.zip $SRC/${fuzzer}_seed_corpus/*\n        fi\n        \n        # Copy dictionary if it exists\n        if [ -f \"$SRC/${fuzzer}.dict\" ]; then\n            cp $SRC/${fuzzer}.dict $OUT/\n        fi\n    fi\ndone\n\n# Create a generic JSON dictionary for all fuzzers\ncat > $OUT/json.dict << EOF\n# JSON tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\"true\"\n\"false\"\n\"null\"\n\"0\"\n\"1\"\n\"-1\"\n\"0.0\"\n\"1.0\"\n\"-1.0\"\n\"e\"\n\"E\"\n\"\\\\\"\n\"\\\\n\"\n\"\\\\r\"\n\"\\\\t\"\n\"\\\\u0000\"\nEOF\n\n# Link the dictionary to all fuzzers\nfor fuzzer in \"${FUZZERS[@]}\"; do\n    if [ -f \"$OUT/${fuzzer}\" ]; then\n        cp $OUT/json.dict $OUT/${fuzzer}.dict\n    fi\ndone\n\necho \"Build completed successfully\"\n```\n\n## 4. Fuzzer Harnesses\n\n### fuzzer/json_parse_fuzzer.cpp\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <stdexcept>\n\n// Include fastjson headers\n// Adjust these includes based on actual fastjson API\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Limit input size to prevent timeouts\n    if (size > 1024 * 1024) {  // 1MB limit\n        return 0;\n    }\n\n    // Create a string from the input data\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Attempt to parse the JSON input\n        // Adjust API calls based on actual fastjson implementation\n        fastjson::Parser parser;\n        auto result = parser.parse(json_input);\n\n        // If parsing succeeded, try to access the parsed data\n        if (result) {\n            // Try various operations on the parsed JSON\n            result->type();\n            \n            if (result->is_object()) {\n                auto obj = result->as_object();\n                for (const auto& pair : obj) {\n                    // Access keys and values\n                    pair.first.c_str();\n                    pair.second.type();\n                }\n            } else if (result->is_array()) {\n                auto arr = result->as_array();\n                for (const auto& item : arr) {\n                    item.type();\n                }\n            } else if (result->is_string()) {\n                result->as_string();\n            } else if (result->is_number()) {\n                result->as_number();\n            } else if (result->is_bool()) {\n                result->as_bool();\n            }\n            \n            // Try to serialize back to string\n            result->to_string();\n        }\n    } catch (const std::exception& e) {\n        // Catch parsing exceptions - this is expected for invalid JSON\n        // We don't want to report these as crashes\n    } catch (...) {\n        // Catch any other exceptions\n    }\n\n    return 0;\n}\n```\n\n### fuzzer/json_parse_streaming_fuzzer.cpp\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <sstream>\n#include <stdexcept>\n\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 1024 * 1024) {\n        return 0;\n    }\n\n    try {\n        // Test streaming parser if available\n        fastjson::Parser parser;\n        \n        // Feed data in chunks to test streaming capabilities\n        size_t chunk_size = 64;\n        for (size_t i = 0; i < size; i += chunk_size) {\n            size_t current_chunk = std::min(chunk_size, size - i);\n            std::string chunk(reinterpret_cast<const char*>(data + i), current_chunk);\n            \n            // Feed chunk to parser\n            parser.feed(chunk);\n        }\n        \n        // Finalize parsing\n        auto result = parser.finalize();\n        \n        if (result) {\n            result->to_string();\n        }\n    } catch (const std::exception& e) {\n        // Expected for invalid input\n    } catch (...) {\n        // Catch all\n    }\n\n    return 0;\n}\n```\n\n### fuzzer/json_serialize_fuzzer.cpp\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <stdexcept>\n\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n#include \"fastjson/serializer.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 512 * 1024) {\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse JSON\n        fastjson::Parser parser;\n        auto result = parser.parse(json_input);\n\n        if (result) {\n            // Test different serialization options\n            fastjson::Serializer serializer;\n            \n            // Compact serialization\n            serializer.set_pretty(false);\n            std::string compact = serializer.serialize(result);\n            \n            // Pretty serialization\n            serializer.set_pretty(true);\n            serializer.set_indent(2);\n            std::string pretty = serializer.serialize(result);\n            \n            // Try to parse the serialized output\n            auto reparsed_compact = parser.parse(compact);\n            auto reparsed_pretty = parser.parse(pretty);\n            \n            // Verify round-trip consistency\n            if (reparsed_compact && reparsed_pretty) {\n                std::string compact2 = serializer.serialize(reparsed_compact);\n                std::string pretty2 = serializer.serialize(reparsed_pretty);\n            }\n        }\n    } catch (const std::exception& e) {\n        // Expected for invalid input\n    } catch (...) {\n        // Catch all\n    }\n\n    return 0;\n}\n```\n\n## 5. Seed Corpus Examples\n\nCreate a directory structure for seed corpus:\n\n### fuzzer/json_parse_fuzzer_seed_corpus/\n\n```bash\n# Create seed corpus directory and add sample files\nmkdir -p fuzzer/json_parse_fuzzer_seed_corpus\n```\n\n**fuzzer/json_parse_fuzzer_seed_corpus/simple_object.json:**\n```json\n{\"key\": \"value\"}\n```\n\n**fuzzer/json_parse_fuzzer_seed_corpus/simple_array.json:**\n```json\n[1, 2, 3, 4, 5]\n```\n\n**fuzzer/json_parse_fuzzer_seed_corpus/nested.json:**\n```json\n{\"users\": [{\"name\": \"Alice\", \"age\": 30}, {\"name\": \"Bob\", \"age\": 25}]}\n```\n\n**fuzzer/json_parse_fuzzer_seed_corpus/types.json:**\n```json\n{\"string\": \"hello\", \"number\": 42, \"float\": 3.14, \"bool\": true, \"null\": null}\n```\n\n**fuzzer/json_parse_fuzzer_seed_corpus/unicode.json:**\n```json\n{\"emoji\": \"\ud83d\ude80\", \"chinese\": \"\u4f60\u597d\", \"escape\": \"\\u0048\\u0065\\u006c\\u006c\\u006f\"}\n```\n\n## 6. Additional Configuration Files\n\n### .gitignore (for the OSS-Fuzz integration directory)\n\n```gitignore\nbuild/\n*.o\n*.a\n*.so\n*.dylib\n*.zip\ncorpus/\ncrashes/\n```\n\n## Summary\n\nThis complete OSS-Fuzz integration includes:\n\n1. **project.yaml**: Defines project metadata, sanitizers (ASan, UBSan, MSan), fuzzing engines (libFuzzer, AFL++), and contact information.\n\n2. **Dockerfile**: Sets up the build environment with all necessary dependencies and clones the repository.\n\n3. **build.sh**: Builds the fastjson library using CMake and compiles multiple fuzzer harnesses with proper linking.\n\n4. **Fuzzer Harnesses**: Three different fuzzers testing:\n   - Basic JSON parsing\n   - Streaming parser functionality\n   - Serialization and round-trip consistency\n\n5. **Seed Corpus**: Sample JSON files to kickstart fuzzing with valid inputs.\n\nThe integration supports both libFuzzer and AFL++, uses AddressSanitizer and UndefinedBehaviorSanitizer, and includes proper error handling to avoid false positives from expected parsing exceptions.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 105,
            "output_tokens": 4063,
            "cached": false
          },
          "with_skill": {
            "output": "# Complete OSS-Fuzz Enrollment for fastjson\n\nHere's a complete OSS-Fuzz project enrollment with all required files and a fuzz harness.\n\n## Project Structure\n\n```\noss-fuzz/projects/fastjson/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 build.sh\n\u2514\u2500\u2500 fuzz_json_parser.cc\n```\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/fastjson/fastjson\"\nlanguage: c++\nprimary_contact: \"security@fastjson.example.com\"\nauto_ccs:\n  - \"maintainer@fastjson.example.com\"\n  - \"devteam@fastjson.example.com\"\n\nmain_repo: \"https://github.com/fastjson/fastjson\"\n\n# Fuzzing configuration\nfuzzing_engines:\n  - libfuzzer\n  - afl\n\nsanitizers:\n  - address\n  - undefined\n  - memory\n\n# Build configuration\narchitectures:\n  - x86_64\n\n# Optional: Specify file extensions for coverage\nfile_github_issue_for_crashes: true\n```\n\n## 2. Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/fastjson/fastjson fastjson\n\n# Set working directory\nWORKDIR fastjson\n\n# Copy build script and fuzz harness\nCOPY build.sh fuzz_*.cc $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Build the fastjson library\ncd $SRC/fastjson\n\n# Create build directory\nmkdir -p build\ncd build\n\n# Configure with CMake\n# Note: We build static libraries for fuzzing\ncmake .. \\\n    -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DCMAKE_C_COMPILER=\"$CC\" \\\n    -DCMAKE_CXX_COMPILER=\"$CXX\" \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_TESTING=OFF \\\n    -DBUILD_EXAMPLES=OFF\n\n# Build the library\nninja -j$(nproc)\n\n# Build fuzz targets\nFUZZ_TARGETS=(\n    \"fuzz_json_parser\"\n)\n\nfor target in \"${FUZZ_TARGETS[@]}\"; do\n    echo \"Building fuzzer: $target\"\n    \n    $CXX $CXXFLAGS \\\n        -std=c++17 \\\n        -I$SRC/fastjson/include \\\n        $SRC/${target}.cc \\\n        -o $OUT/${target} \\\n        $LIB_FUZZING_ENGINE \\\n        $SRC/fastjson/build/libfastjson.a\ndone\n\n# Create seed corpus for JSON parser\n# This provides initial interesting inputs for the fuzzer\nmkdir -p $OUT/fuzz_json_parser_seed_corpus\n\n# Create various JSON test cases\ncat > $OUT/fuzz_json_parser_seed_corpus/empty_object.json << 'EOF'\n{}\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/empty_array.json << 'EOF'\n[]\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/simple_object.json << 'EOF'\n{\"key\": \"value\"}\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/nested_object.json << 'EOF'\n{\"outer\": {\"inner\": {\"deep\": \"value\"}}}\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/array_of_objects.json << 'EOF'\n[{\"id\": 1}, {\"id\": 2}, {\"id\": 3}]\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/mixed_types.json << 'EOF'\n{\n  \"string\": \"text\",\n  \"number\": 42,\n  \"float\": 3.14,\n  \"bool\": true,\n  \"null\": null,\n  \"array\": [1, 2, 3],\n  \"object\": {\"nested\": \"value\"}\n}\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/unicode.json << 'EOF'\n{\"unicode\": \"Hello \u4e16\u754c \ud83c\udf0d\"}\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/escaped_chars.json << 'EOF'\n{\"escaped\": \"line1\\nline2\\ttab\\\"quote\"}\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/large_number.json << 'EOF'\n{\"large\": 9223372036854775807}\nEOF\n\ncat > $OUT/fuzz_json_parser_seed_corpus/scientific_notation.json << 'EOF'\n{\"scientific\": 1.23e-10}\nEOF\n\n# Zip the corpus\ncd $OUT\nzip -q -r fuzz_json_parser_seed_corpus.zip fuzz_json_parser_seed_corpus\nrm -rf fuzz_json_parser_seed_corpus\n\n# Create dictionary for JSON fuzzing\n# Dictionaries help the fuzzer generate more valid inputs\ncat > $OUT/fuzz_json_parser.dict << 'EOF'\n# JSON structural tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\n# JSON keywords\n\"true\"\n\"false\"\n\"null\"\n\n# Common JSON keys\n\"\\\"id\\\"\"\n\"\\\"name\\\"\"\n\"\\\"value\\\"\"\n\"\\\"data\\\"\"\n\"\\\"type\\\"\"\n\"\\\"items\\\"\"\n\"\\\"count\\\"\"\n\"\\\"status\\\"\"\n\n# Escape sequences\n\"\\\\n\"\n\"\\\\r\"\n\"\\\\t\"\n\"\\\\\\\\\"\n\"\\\\\\\"\"\n\"\\\\/\"\n\"\\\\b\"\n\"\\\\f\"\n\"\\\\u0000\"\n\n# Number patterns\n\"0\"\n\"1\"\n\"-1\"\n\"0.0\"\n\"1e10\"\n\"-1.5e-10\"\n\n# Edge case strings\n\"\\\"\\\"\"\n\"\\\" \\\"\"\n\"\\\"\\\\u0000\\\"\"\nEOF\n\necho \"Build completed successfully!\"\n```\n\n## 4. fuzz_json_parser.cc\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n//\n////////////////////////////////////////////////////////////////////////////////\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <vector>\n\n// Include fastjson headers\n// Adjust these includes based on actual fastjson API\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n#include \"fastjson/value.h\"\n\n// Fuzzer entry point\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Ignore empty inputs\n    if (size == 0) {\n        return 0;\n    }\n\n    // Limit input size to prevent timeouts\n    // Adjust based on performance testing\n    const size_t kMaxSize = 1024 * 1024; // 1MB\n    if (size > kMaxSize) {\n        return 0;\n    }\n\n    // Convert input to string\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    // Test 1: Basic parsing\n    try {\n        fastjson::Parser parser;\n        fastjson::Document doc = parser.parse(json_input);\n        \n        // If parsing succeeds, exercise the parsed document\n        if (doc.isValid()) {\n            // Test various document operations\n            doc.isObject();\n            doc.isArray();\n            doc.isString();\n            doc.isNumber();\n            doc.isBool();\n            doc.isNull();\n            \n            // Try to access as different types (should handle gracefully)\n            if (doc.isObject()) {\n                auto obj = doc.asObject();\n                // Iterate through keys if possible\n                for (const auto& key : obj.keys()) {\n                    obj.get(key);\n                }\n            }\n            \n            if (doc.isArray()) {\n                auto arr = doc.asArray();\n                size_t len = arr.size();\n                // Access elements (with bounds checking)\n                for (size_t i = 0; i < std::min(len, size_t(100)); ++i) {\n                    arr.at(i);\n                }\n            }\n            \n            // Test serialization (round-trip)\n            std::string serialized = doc.toString();\n            \n            // Test pretty printing\n            std::string pretty = doc.toPrettyString();\n        }\n    } catch (const fastjson::ParseException& e) {\n        // Expected for invalid JSON - not a bug\n    } catch (const std::exception& e) {\n        // Other exceptions might indicate bugs\n        // But we don't want to crash the fuzzer\n    }\n\n    // Test 2: Streaming parser (if available)\n    try {\n        fastjson::StreamParser stream_parser;\n        stream_parser.feed(json_input);\n        stream_parser.finish();\n    } catch (...) {\n        // Ignore exceptions\n    }\n\n    // Test 3: Parse with different options (if available)\n    try {\n        fastjson::ParserOptions options;\n        options.allowComments = true;\n        options.allowTrailingCommas = true;\n        options.allowNaN = true;\n        options.allowInfinity = true;\n        \n        fastjson::Parser parser_with_options(options);\n        parser_with_options.parse(json_input);\n    } catch (...) {\n        // Ignore exceptions\n    }\n\n    // Test 4: Validate without full parsing (if available)\n    try {\n        fastjson::Validator validator;\n        validator.validate(json_input);\n    } catch (...) {\n        // Ignore exceptions\n    }\n\n    return 0;\n}\n\n// Optional: Custom initialization\nextern \"C\" int LLVMFuzzerInitialize(int *argc, char ***argv) {\n    // Perform any one-time initialization here\n    // For example, setting up global state or configuration\n    return 0;\n}\n```\n\n## Additional Files (Optional but Recommended)\n\n### 5. fuzz_json_serializer.cc\n\nAdditional harness to test serialization:\n\n```cpp\n// Copyright 2024 Google LLC\n// Licensed under the Apache License, Version 2.0\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n#include \"fastjson/builder.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size == 0 || size > 1024 * 1024) {\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse JSON\n        fastjson::Parser parser;\n        fastjson::Document doc = parser.parse(json_input);\n        \n        if (doc.isValid()) {\n            // Test serialization\n            std::string output1 = doc.toString();\n            std::string output2 = doc.toPrettyString();\n            \n            // Test builder API\n            fastjson::Builder builder;\n            builder.fromDocument(doc);\n            std::string output3 = builder.build();\n            \n            // Round-trip test: parse serialized output\n            fastjson::Document doc2 = parser.parse(output1);\n            \n            // Verify equivalence (if API supports it)\n            if (doc2.isValid()) {\n                doc.equals(doc2);\n            }\n        }\n    } catch (...) {\n        // Ignore exceptions\n    }\n\n    return 0;\n}\n```\n\n### 6. fuzz_json_query.cc\n\nHarness to test JSON querying/path operations:\n\n```cpp\n// Copyright 2024 Google LLC\n// Licensed under the Apache License, Version 2.0\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <vector>\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n#include \"fastjson/query.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size < 2 || size > 1024 * 1024) {\n        return 0;\n    }\n\n    // Split input: first byte determines split point\n    size_t split = data[0] % size;\n    \n    std::string json_input(reinterpret_cast<const char*>(data + 1), split);\n    std::string query_path(reinterpret_cast<const char*>(data + 1 + split), \n                          size - split - 1);\n\n    try {\n        fastjson::Parser parser;\n        fastjson::Document doc = parser.parse(json_input);\n        \n        if (doc.isValid()) {\n            // Test JSON path queries\n            fastjson::Query query(query_path);\n            auto results = query.execute(doc);\n            \n            // Test various query operations\n            doc.get(query_path);\n            doc.has(query_path);\n            doc.set(query_path, fastjson::Value(\"fuzz\"));\n            doc.remove(query_path);\n        }\n    } catch (...) {\n        // Ignore exceptions\n    }\n\n    return 0;\n}\n```\n\n## Testing Locally\n\nBefore submitting, test the integration locally:\n\n```bash\n# Navigate to OSS-Fuzz directory\ncd /path/to/oss-fuzz\n\n# Build the project image\npython3 infra/helper.py build_image fastjson\n\n# Build fuzzers with AddressSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=address fastjson\n\n# Run the main fuzzer for 60 seconds\npython3 infra/helper.py run_fuzzer fastjson fuzz_json_parser -- -max_total_time=60\n\n# Build with UndefinedBehaviorSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=undefined fastjson\n\n# Run with UBSan\npython3 infra/helper.py run_fuzzer fastjson fuzz_json_parser -- -max_total_time=60\n\n# Generate coverage report\npython3",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5051,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a complete OSS-Fuzz enrollment for the fastjson library. This will include all necessary files and a basic fuzzing harness.\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/yourorg/fastjson\"\nlanguage: c++\nprimary_contact: \"security@fastjson.example.com\"\nmain_repo: \"https://github.com/yourorg/fastjson\"\nfuzzing_engines:\n  - libfuzzer\n  - afl\nsanitizers:\n  - address\n  - undefined\n```\n\n## 2. Dockerfile\n\n```dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/yourorg/fastjson fastjson\n\nWORKDIR fastjson\nCOPY build.sh $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Build the library with fuzzing instrumentation\nmkdir -p build\ncd build\n\n# Configure with CMake\ncmake .. \\\n    -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=$CC \\\n    -DCMAKE_CXX_COMPILER=$CXX \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DBUILD_TESTING=OFF\n\n# Build the library\nninja\n\n# Build the fuzz harness\n$CXX $CXXFLAGS -std=c++17 \\\n    -I$SRC/fastjson/include \\\n    $SRC/fastjson/fuzz/fuzz_parser.cpp \\\n    -o $OUT/fuzz_parser \\\n    $LIB_FUZZING_ENGINE \\\n    libfastjson.a\n\n# Copy seed corpus if it exists\nif [ -f $SRC/fastjson/fuzz/corpus.zip ]; then\n    cp $SRC/fastjson/fuzz/corpus.zip $OUT/fuzz_parser_seed_corpus.zip\nfi\n\n# Copy dictionary if it exists\nif [ -f $SRC/fastjson/fuzz/json.dict ]; then\n    cp $SRC/fastjson/fuzz/json.dict $OUT/fuzz_parser.dict\nfi\n```\n\n## 4. Fuzz Harness (fuzz/fuzz_parser.cpp)\n\n```cpp\n#include <cstdint>\n#include <cstddef>\n#include <string>\n#include <vector>\n\n// Include your JSON library headers\n// Adjust these includes based on your actual library structure\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Reject inputs that are too small or too large\n    if (size == 0 || size > 1024 * 1024) {\n        return 0;\n    }\n\n    // Convert input to string\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse the JSON input\n        fastjson::Parser parser;\n        auto document = parser.parse(json_input);\n\n        // If parsing succeeded, try to access the document\n        if (document) {\n            // Exercise various document operations\n            document->is_object();\n            document->is_array();\n            document->is_string();\n            document->is_number();\n            document->is_bool();\n            document->is_null();\n\n            // Try to serialize back to string\n            auto serialized = document->to_string();\n\n            // If it's an object, try to access members\n            if (document->is_object()) {\n                auto obj = document->as_object();\n                for (const auto& [key, value] : obj) {\n                    // Access each key-value pair\n                    (void)key;\n                    (void)value;\n                }\n            }\n\n            // If it's an array, try to access elements\n            if (document->is_array()) {\n                auto arr = document->as_array();\n                for (const auto& element : arr) {\n                    // Access each element\n                    (void)element;\n                }\n            }\n        }\n    } catch (const fastjson::ParseError& e) {\n        // Expected exception for invalid JSON\n        // Don't report this as a bug\n    } catch (const std::exception& e) {\n        // Other exceptions might indicate bugs\n        // Let the fuzzer catch these\n    }\n\n    return 0;\n}\n```\n\n## 5. JSON Dictionary (fuzz/json.dict)\n\n```\n# JSON structural tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\n# JSON values\n\"true\"\n\"false\"\n\"null\"\n\n# Numbers\n\"0\"\n\"1\"\n\"-1\"\n\"1.0\"\n\"-1.0\"\n\"1e10\"\n\"1E10\"\n\"1e-10\"\n\n# Strings\n\"\\\"\\\"\"\n\"\\\"a\\\"\"\n\"\\\"test\\\"\"\n\n# Escape sequences\n\"\\\\\\\\\"\n\"\\\\\\\"\"\n\"\\\\n\"\n\"\\\\r\"\n\"\\\\t\"\n\"\\\\/\"\n\"\\\\b\"\n\"\\\\f\"\n\"\\\\u0000\"\n\"\\\\u0020\"\n\"\\\\uFFFF\"\n\n# Common JSON patterns\n\"{\\\"key\\\":\\\"value\\\"}\"\n\"[1,2,3]\"\n\"{\\\"a\\\":1,\\\"b\\\":2}\"\n\"[{\\\"x\\\":1},{\\\"y\\\":2}]\"\n```\n\n## 6. Sample Seed Corpus Files\n\nCreate these files in `fuzz/corpus/`:\n\n**fuzz/corpus/empty_object.json:**\n```json\n{}\n```\n\n**fuzz/corpus/empty_array.json:**\n```json\n[]\n```\n\n**fuzz/corpus/simple_object.json:**\n```json\n{\"name\":\"test\",\"value\":42}\n```\n\n**fuzz/corpus/nested.json:**\n```json\n{\"users\":[{\"id\":1,\"name\":\"Alice\"},{\"id\":2,\"name\":\"Bob\"}]}\n```\n\n**fuzz/corpus/types.json:**\n```json\n{\"string\":\"hello\",\"number\":123,\"bool\":true,\"null\":null,\"array\":[1,2,3]}\n```\n\nThen zip them:\n```bash\ncd fuzz/corpus\nzip ../corpus.zip *.json\n```\n\n## Testing Locally\n\nTo test this setup locally before submitting to OSS-Fuzz:\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Create the project directory\nmkdir -p projects/fastjson\n\n# Copy your files\ncp /path/to/project.yaml projects/fastjson/\ncp /path/to/Dockerfile projects/fastjson/\ncp /path/to/build.sh projects/fastjson/\n\n# Build the project image\npython3 infra/helper.py build_image fastjson\n\n# Build fuzzers with AddressSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=address fastjson\n\n# Run the fuzzer\npython3 infra/helper.py run_fuzzer fastjson fuzz_parser\n\n# Test with UndefinedBehaviorSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=undefined fastjson\npython3 infra/helper.py run_fuzzer fastjson fuzz_parser\n\n# Generate coverage report (requires gsutil)\npython3 infra/helper.py build_fuzzers --sanitizer=coverage fastjson\npython3 infra/helper.py coverage fastjson\n```\n\n## Key Features of This Setup\n\n1. **Multiple Fuzzing Engines**: Supports both libFuzzer and AFL++\n2. **Multiple Sanitizers**: Tests with AddressSanitizer and UndefinedBehaviorSanitizer\n3. **Proper Input Validation**: Harness rejects empty and oversized inputs\n4. **Exception Handling**: Distinguishes between expected parse errors and actual bugs\n5. **Comprehensive Testing**: Exercises various JSON operations (parsing, serialization, traversal)\n6. **Dictionary**: Provides JSON-specific tokens to guide fuzzing\n7. **Seed Corpus**: Includes valid JSON examples to bootstrap fuzzing\n\nThis setup follows OSS-Fuzz best practices and should provide effective continuous fuzzing for the fastjson library.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5581,
            "output_tokens": 2131,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "# Complete OSS-Fuzz Project Enrollment for fastjson\n\nI'll create a complete OSS-Fuzz integration for a C++ JSON parsing library called 'fastjson'.\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/fastjson/fastjson\"\nlanguage: c++\nprimary_contact: \"security@fastjson.example.com\"\nauto_ccs:\n  - \"dev@fastjson.example.com\"\n  - \"maintainer@fastjson.example.com\"\n\nsanitizers:\n  - address\n  - undefined\n  - memory\n\narchitectures:\n  - x86_64\n\nfuzzing_engines:\n  - libfuzzer\n  - afl\n\nmain_repo: \"https://github.com/fastjson/fastjson.git\"\n\nfile_github_issue: true\n\nhelp_url: \"https://github.com/fastjson/fastjson/blob/main/FUZZING.md\"\n\nview_restrictions: none\n\nvendor_ccs:\n  - \"oss-fuzz-reports@fastjson.example.com\"\n```\n\n## 2. Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder\n\n# Install dependencies\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config \\\n    git\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/fastjson/fastjson.git fastjson\n\n# Set working directory\nWORKDIR fastjson\n\n# Copy build script and fuzzer harnesses\nCOPY build.sh $SRC/\nCOPY *.cc $SRC/\nCOPY *.cpp $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Build the library\ncd $SRC/fastjson\n\n# Create build directory\nmkdir -p build\ncd build\n\n# Configure with CMake\ncmake .. \\\n    -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=$CC \\\n    -DCMAKE_CXX_COMPILER=$CXX \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DBUILD_TESTING=OFF \\\n    -DFASTJSON_BUILD_EXAMPLES=OFF \\\n    -DFASTJSON_BUILD_TESTS=OFF\n\n# Build the library\nninja\n\n# Find the library\nFASTJSON_LIB=$(find . -name \"libfastjson*.a\" | head -n 1)\n\nif [ -z \"$FASTJSON_LIB\" ]; then\n    echo \"Error: fastjson library not found\"\n    exit 1\nfi\n\necho \"Found fastjson library: $FASTJSON_LIB\"\n\n# Build fuzzers\nFUZZERS=(\n    \"json_parse_fuzzer\"\n    \"json_parse_strict_fuzzer\"\n    \"json_parse_streaming_fuzzer\"\n)\n\nfor fuzzer in \"${FUZZERS[@]}\"; do\n    if [ -f \"$SRC/${fuzzer}.cc\" ] || [ -f \"$SRC/${fuzzer}.cpp\" ]; then\n        echo \"Building $fuzzer\"\n        \n        # Determine file extension\n        if [ -f \"$SRC/${fuzzer}.cc\" ]; then\n            FUZZER_SRC=\"$SRC/${fuzzer}.cc\"\n        else\n            FUZZER_SRC=\"$SRC/${fuzzer}.cpp\"\n        fi\n        \n        # Compile the fuzzer\n        $CXX $CXXFLAGS \\\n            -I$SRC/fastjson/include \\\n            -I$SRC/fastjson/src \\\n            $FUZZER_SRC \\\n            $LIB_FUZZING_ENGINE \\\n            $FASTJSON_LIB \\\n            -o $OUT/$fuzzer\n        \n        # Create seed corpus if it doesn't exist\n        if [ ! -d \"$OUT/${fuzzer}_seed_corpus\" ]; then\n            mkdir -p \"$OUT/${fuzzer}_seed_corpus\"\n            \n            # Create some basic JSON samples\n            echo '{}' > \"$OUT/${fuzzer}_seed_corpus/empty_object.json\"\n            echo '[]' > \"$OUT/${fuzzer}_seed_corpus/empty_array.json\"\n            echo '{\"key\":\"value\"}' > \"$OUT/${fuzzer}_seed_corpus/simple_object.json\"\n            echo '[1,2,3]' > \"$OUT/${fuzzer}_seed_corpus/simple_array.json\"\n            echo '{\"nested\":{\"key\":\"value\"}}' > \"$OUT/${fuzzer}_seed_corpus/nested.json\"\n            echo '{\"string\":\"test\",\"number\":123,\"bool\":true,\"null\":null}' > \"$OUT/${fuzzer}_seed_corpus/types.json\"\n            echo '{\"array\":[1,2,3],\"object\":{\"a\":\"b\"}}' > \"$OUT/${fuzzer}_seed_corpus/mixed.json\"\n        fi\n    fi\ndone\n\n# Copy dictionary if it exists\nif [ -f \"$SRC/fastjson/fuzzing/json.dict\" ]; then\n    cp \"$SRC/fastjson/fuzzing/json.dict\" \"$OUT/\"\nelif [ -f \"$SRC/json.dict\" ]; then\n    cp \"$SRC/json.dict\" \"$OUT/\"\nelse\n    # Create a basic JSON dictionary\n    cat > \"$OUT/json.dict\" << 'EOF'\n# JSON dictionary for fuzzing\n\"{}\"\n\"[]\"\n\":\"\n\",\"\n\"true\"\n\"false\"\n\"null\"\n\"\\\"\"\n\"\\\\\"\n\"\\/\"\n\"\\b\"\n\"\\f\"\n\"\\n\"\n\"\\r\"\n\"\\t\"\n\"\\u0000\"\n\"0\"\n\"-1\"\n\"1.0\"\n\"1e10\"\n\"1E-10\"\nEOF\nfi\n\necho \"Build completed successfully\"\n```\n\n## 4. json_parse_fuzzer.cc (Basic Fuzzer Harness)\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n\n// Include fastjson headers (adjust based on actual library structure)\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Limit input size to prevent timeouts\n    if (size > 1024 * 1024) {  // 1MB limit\n        return 0;\n    }\n\n    // Create a null-terminated string\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse the JSON input\n        fastjson::Parser parser;\n        auto result = parser.parse(json_input);\n\n        // If parsing succeeded, try to serialize it back\n        if (result) {\n            std::string serialized = result->serialize();\n            \n            // Try to parse the serialized output (round-trip test)\n            auto reparsed = parser.parse(serialized);\n        }\n    } catch (const std::exception& e) {\n        // Catch expected exceptions (invalid JSON, etc.)\n        // These are not bugs, just invalid input\n    } catch (...) {\n        // Catch any other exceptions\n        // This might indicate a bug\n    }\n\n    return 0;\n}\n```\n\n## 5. json_parse_strict_fuzzer.cc (Strict Mode Fuzzer)\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 512 * 1024) {  // 512KB limit for strict mode\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse with strict mode enabled\n        fastjson::Parser parser;\n        parser.setStrictMode(true);\n        parser.setAllowComments(false);\n        parser.setAllowTrailingCommas(false);\n        \n        auto result = parser.parse(json_input);\n\n        if (result) {\n            // Test various operations on the parsed JSON\n            result->size();\n            result->empty();\n            result->type();\n            \n            // Try to access as different types\n            if (result->isObject()) {\n                result->asObject();\n            } else if (result->isArray()) {\n                result->asArray();\n            } else if (result->isString()) {\n                result->asString();\n            } else if (result->isNumber()) {\n                result->asNumber();\n            } else if (result->isBool()) {\n                result->asBool();\n            }\n        }\n    } catch (const std::exception& e) {\n        // Expected exceptions for invalid input\n    } catch (...) {\n        // Unexpected exceptions\n    }\n\n    return 0;\n}\n```\n\n## 6. json_parse_streaming_fuzzer.cc (Streaming Parser Fuzzer)\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <sstream>\n\n#include \"fastjson/json.h\"\n#include \"fastjson/parser.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 1024 * 1024) {\n        return 0;\n    }\n\n    if (size < 2) {\n        return 0;\n    }\n\n    // Use first byte to determine chunk size\n    size_t chunk_size = (data[0] % 32) + 1;\n    \n    std::string json_input(reinterpret_cast<const char*>(data + 1), size - 1);\n\n    try {\n        fastjson::StreamingParser parser;\n        \n        // Feed data in chunks\n        size_t offset = 0;\n        while (offset < json_input.size()) {\n            size_t current_chunk = std::min(chunk_size, json_input.size() - offset);\n            parser.feed(json_input.data() + offset, current_chunk);\n            offset += current_chunk;\n        }\n        \n        // Finalize parsing\n        auto result = parser.finalize();\n        \n        if (result) {\n            // Validate the result\n            result->validate();\n        }\n    } catch (const std::exception& e) {\n        // Expected exceptions\n    } catch (...) {\n        // Unexpected exceptions\n    }\n\n    return 0;\n}\n```\n\n## 7. json.dict (JSON Fuzzing Dictionary)\n\n```\n# JSON fuzzing dictionary\n\"{}\"\n\"[]\"\n\":\"\n\",\"\n\"true\"\n\"false\"\n\"null\"\n\"\\\"\"\n\"\\\\\"\n\"\\/\"\n\"\\b\"\n\"\\f\"\n\"\\n\"\n\"\\r\"\n\"\\t\"\n\"\\u0000\"\n\"\\u001f\"\n\"\\uffff\"\n\"0\"\n\"-0\"\n\"1\"\n\"-1\"\n\"1.0\"\n\"-1.0\"\n\"1e10\"\n\"1E10\"\n\"1e-10\"\n\"1E-10\"\n\"\\\"string\\\"\"\n\"\\\"key\\\"\"\n\"\\\"value\\\"\"\n\"\\\"name\\\"\"\n\"\\\"data\\\"\"\n\"{\\\"key\\\":\\\"value\\\"}\"\n\"[1,2,3]\"\n\"[[]]\"\n\"{\\\"a\\\":{\\\"b\\\":{\\\"c\\\":{}}}}\"\n\"[[[[[[[[[[]]]]]]]]]\"\n```\n\n## Usage Instructions\n\n1. **Place these files in the OSS-Fuzz repository structure:**\n   ```\n   projects/fastjson/\n   \u251c\u2500\u2500 project.yaml\n   \u251c\u2500\u2500 Dockerfile\n   \u251c\u2500\u2500 build.sh\n   \u251c\u2500\u2500 json_parse_fuzzer.cc\n   \u251c\u2500\u2500 json_parse_strict_fuzzer.cc\n   \u251c\u2500\u2500 json_parse_streaming_fuzzer.cc\n   \u2514\u2500\u2500 json.dict\n   ```\n\n2. **Test the build locally:**\n   ```bash\n   python infra/helper.py build_image fastjson\n   python infra/helper.py build_fuzzers fastjson\n   ```\n\n3. **Run the fuzzers:**\n   ```bash\n   python infra/helper.py run_fuzzer fastjson json_parse_fuzzer\n   ```\n\n4. **Check coverage:**\n   ```bash\n   python infra/helper.py coverage fastjson\n   ```\n\nThis complete setup provides comprehensive fuzzing for the fastjson library with multiple sanitizers, fuzzing engines, and different test scenarios.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 105,
            "output_tokens": 3895,
            "cached": false
          },
          "with_skill": {
            "output": "# Complete OSS-Fuzz Enrollment for fastjson\n\nHere's a complete OSS-Fuzz integration for a hypothetical C++ JSON parsing library called 'fastjson'.\n\n## Directory Structure\n\n```\noss-fuzz/projects/fastjson/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 build.sh\n\u2514\u2500\u2500 fuzz_json_parser.cc\n```\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/example/fastjson\"\nlanguage: c++\nprimary_contact: \"security@fastjson.example.com\"\nauto_ccs:\n  - \"maintainer@fastjson.example.com\"\n  - \"dev-team@fastjson.example.com\"\n\n# Main repository for the project\nmain_repo: \"https://github.com/example/fastjson\"\n\n# Fuzzing engines to use\nfuzzing_engines:\n  - libfuzzer\n  - afl\n\n# Sanitizers to apply\nsanitizers:\n  - address\n  - undefined\n  - memory\n\n# Optional: Specify architectures (defaults to x86_64)\narchitectures:\n  - x86_64\n\n# File issue automatically when bugs are found\nfile_github_issue: true\n\n# Help URL for project-specific fuzzing documentation\nhelp_url: \"https://github.com/example/fastjson/blob/main/docs/FUZZING.md\"\n\n# Vendor code review (if needed for dependencies)\nvendor_ccs:\n  - \"vendor-security@example.com\"\n\n# View restrictions (use 'public' for open source)\nview_restrictions: none\n\n# Experimental features\nexperimental: false\n```\n\n## 2. Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/example/fastjson fastjson\n\n# Clone the fuzzing harness repository (if separate)\n# RUN git clone --depth 1 https://github.com/example/fastjson-fuzz fastjson-fuzz\n\n# Set working directory\nWORKDIR fastjson\n\n# Copy build script and harness into the container\nCOPY build.sh fuzz_*.cc $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Navigate to the project directory\ncd $SRC/fastjson\n\n# Create build directory\nmkdir -p build\ncd build\n\n# Configure CMake with OSS-Fuzz flags\n# Note: OSS-Fuzz provides CFLAGS, CXXFLAGS, and LIB_FUZZING_ENGINE\ncmake -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=$CC \\\n    -DCMAKE_CXX_COMPILER=$CXX \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DBUILD_TESTING=OFF \\\n    -DBUILD_EXAMPLES=OFF \\\n    ..\n\n# Build the library\nninja -j$(nproc)\n\n# Build the fuzz targets\n# Link against the static library and fuzzing engine\n$CXX $CXXFLAGS -std=c++17 \\\n    -I$SRC/fastjson/include \\\n    $SRC/fuzz_json_parser.cc \\\n    -o $OUT/fuzz_json_parser \\\n    $LIB_FUZZING_ENGINE \\\n    libfastjson.a\n\n# Optional: Build additional fuzz targets\nif [ -f \"$SRC/fuzz_json_serializer.cc\" ]; then\n    $CXX $CXXFLAGS -std=c++17 \\\n        -I$SRC/fastjson/include \\\n        $SRC/fuzz_json_serializer.cc \\\n        -o $OUT/fuzz_json_serializer \\\n        $LIB_FUZZING_ENGINE \\\n        libfastjson.a\nfi\n\n# Copy seed corpus if available\nif [ -d \"$SRC/fastjson/fuzz/corpus\" ]; then\n    zip -j $OUT/fuzz_json_parser_seed_corpus.zip $SRC/fastjson/fuzz/corpus/*\nfi\n\n# Copy dictionary if available\nif [ -f \"$SRC/fastjson/fuzz/json.dict\" ]; then\n    cp $SRC/fastjson/fuzz/json.dict $OUT/fuzz_json_parser.dict\nfi\n\n# Create a basic JSON dictionary if none exists\nif [ ! -f \"$OUT/fuzz_json_parser.dict\" ]; then\n    cat > $OUT/fuzz_json_parser.dict << EOF\n# JSON syntax tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\"true\"\n\"false\"\n\"null\"\n\"0\"\n\"1\"\n\"-1\"\n\"0.0\"\n\"1.0\"\n\"-1.0\"\n\"e\"\n\"E\"\n\"\\\\\\\\\"\n\"\\\\/\"\n\"\\\\b\"\n\"\\\\f\"\n\"\\\\n\"\n\"\\\\r\"\n\"\\\\t\"\n\"\\\\u0000\"\nEOF\nfi\n\n# Create a minimal seed corpus if none exists\nif [ ! -f \"$OUT/fuzz_json_parser_seed_corpus.zip\" ]; then\n    mkdir -p $SRC/corpus_temp\n    \n    # Create basic JSON test cases\n    echo '{}' > $SRC/corpus_temp/empty_object.json\n    echo '[]' > $SRC/corpus_temp/empty_array.json\n    echo 'null' > $SRC/corpus_temp/null.json\n    echo 'true' > $SRC/corpus_temp/true.json\n    echo 'false' > $SRC/corpus_temp/false.json\n    echo '0' > $SRC/corpus_temp/zero.json\n    echo '\"string\"' > $SRC/corpus_temp/string.json\n    echo '{\"key\":\"value\"}' > $SRC/corpus_temp/simple_object.json\n    echo '[1,2,3]' > $SRC/corpus_temp/simple_array.json\n    echo '{\"nested\":{\"key\":\"value\"}}' > $SRC/corpus_temp/nested.json\n    echo '{\"array\":[1,2,3]}' > $SRC/corpus_temp/object_with_array.json\n    echo '{\"number\":123.456}' > $SRC/corpus_temp/number.json\n    echo '{\"bool\":true,\"null\":null}' > $SRC/corpus_temp/mixed.json\n    \n    # Create corpus zip\n    zip -j $OUT/fuzz_json_parser_seed_corpus.zip $SRC/corpus_temp/*\n    rm -rf $SRC/corpus_temp\nfi\n```\n\n## 4. fuzz_json_parser.cc\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n#include <vector>\n\n// Include the fastjson library headers\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n#include \"fastjson/value.h\"\n\n// Fuzzer entry point\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Reject inputs that are too large to avoid timeouts\n    if (size > 1024 * 1024) {  // 1MB limit\n        return 0;\n    }\n\n    // Reject empty inputs\n    if (size == 0) {\n        return 0;\n    }\n\n    // Convert input to string\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Test 1: Basic parsing\n        fastjson::Parser parser;\n        fastjson::Document doc;\n        \n        bool parse_result = parser.parse(json_input, doc);\n        \n        if (parse_result) {\n            // Test 2: Access document root\n            const fastjson::Value& root = doc.root();\n            \n            // Test 3: Type checking\n            if (root.is_object()) {\n                // Iterate over object members\n                for (auto it = root.begin_object(); it != root.end_object(); ++it) {\n                    const std::string& key = it->first;\n                    const fastjson::Value& value = it->second;\n                    \n                    // Access various value types\n                    if (value.is_string()) {\n                        std::string str = value.as_string();\n                    } else if (value.is_number()) {\n                        double num = value.as_number();\n                    } else if (value.is_bool()) {\n                        bool b = value.as_bool();\n                    } else if (value.is_array()) {\n                        size_t array_size = value.size();\n                    }\n                }\n            } else if (root.is_array()) {\n                // Iterate over array elements\n                for (size_t i = 0; i < root.size(); ++i) {\n                    const fastjson::Value& element = root[i];\n                    // Access element (triggers various code paths)\n                    element.type();\n                }\n            }\n            \n            // Test 4: Serialization (round-trip test)\n            std::string serialized = doc.serialize();\n            \n            // Test 5: Query operations (if supported)\n            if (root.is_object()) {\n                // Try to access various keys\n                root.get(\"key\");\n                root.get(\"nested\");\n                root.get(\"array\");\n                root.has(\"key\");\n            }\n            \n            // Test 6: Deep copy (if supported)\n            fastjson::Document doc_copy = doc;\n            \n            // Test 7: Modification operations (if supported)\n            if (root.is_object() && !root.empty()) {\n                fastjson::Document mutable_doc = doc;\n                // Attempt modifications\n                // mutable_doc.root().set(\"new_key\", \"new_value\");\n            }\n        }\n        \n        // Test 8: Error handling with partial parsing\n        parser.parse_partial(json_input);\n        \n    } catch (const fastjson::ParseException& e) {\n        // Expected exception for invalid JSON - not a bug\n        // Access exception details to test exception handling\n        const char* what = e.what();\n        int error_code = e.code();\n        size_t error_pos = e.position();\n    } catch (const std::exception& e) {\n        // Other exceptions might indicate bugs\n        // But we don't crash - just return\n    } catch (...) {\n        // Catch-all for any other exceptions\n    }\n\n    return 0;\n}\n\n// Optional: Custom initialization\nextern \"C\" int LLVMFuzzerInitialize(int *argc, char ***argv) {\n    // Perform any one-time initialization here\n    // For example: set up logging, configure parser options, etc.\n    \n    // Disable verbose error messages to improve fuzzing speed\n    // fastjson::set_error_verbosity(false);\n    \n    return 0;\n}\n```\n\n## 5. Additional Harness: fuzz_json_serializer.cc (Optional)\n\n```cpp\n// Copyright 2024 Google LLC\n//\n// Licensed under the Apache License, Version 2.0 (the \"License\");\n// you may not use this file except in compliance with the License.\n// You may obtain a copy of the License at\n//\n//      http://www.apache.org/licenses/LICENSE-2.0\n//\n// Unless required by applicable law or agreed to in writing, software\n// distributed under the License is distributed on an \"AS IS\" BASIS,\n// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n// See the License for the specific language governing permissions and\n// limitations under the License.\n\n#include <cstddef>\n#include <cstdint>\n#include <string>\n\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n#include \"fastjson/serializer.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    if (size > 512 * 1024 || size == 0) {\n        return 0;\n    }\n\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        fastjson::Parser parser;\n        fastjson::Document doc;\n        \n        if (parser.parse(json_input, doc)) {\n            // Test different serialization formats\n            fastjson::Serializer serializer;\n            \n            // Compact format\n            std::string compact = serializer.serialize(doc, false);\n            \n            // Pretty-printed format\n            std::string pretty = serializer.serialize(doc, true);\n            \n            // Custom indentation\n            serializer.set_indent(2);\n            std::string custom_indent = serializer.serialize(doc, true);\n            \n            // Test serialization options\n            serializer.set_escape_unicode(true);\n            std::string escaped = serializer.serialize(doc, false);\n            \n            // Verify round-trip\n            fastjson::Document doc2;\n            if (parser.parse(compact, doc2)) {\n                std::string compact2 = serializer.serialize(doc2, false);\n            }\n        }\n    } catch (...) {\n        // Ignore exceptions\n    }\n\n    return 0;\n}\n```\n\n## 6. json.dict (Dictionary File)\n\nCreate this file in your project's fuzz directory:\n\n```\n# JSON structural tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\n# JSON values\n\"true\"\n\"false\"\n\"null\"\n\n# Numbers\n\"0\"\n\"1\"\n\"-1\"\n\"123\"\n\"-123\"\n\"0.0\"\n\"1.0\"\n\"-1.0\"\n\"123.456\"\n\"-123.456\"\n\"1e10\"\n\"1E10\"\n\"1e-10\"\n\"1E-10\"\n\n# Escape sequences\n\"\\\\\\\\\"\n\"\\\\/\"\n\"\\\\b\"\n\"\\\\f\"\n\"\\\\n\"\n\"\\\\r\"\n\"\\\\t\"\n\"\\\\u0000\"\n\"\\\\u0020\"\n\"\\\\uFFFF\"\n\n# Common keys\n\"\\\"id\\\"\"\n\"\\\"name\\\"\"\n\"\\\"value\\\"\"\n\"\\\"data\\\"\"\n\"\\\"type\\\"\"\n\"\\\"items\\\"\"\n\"\\\"key\\\"\"\n\"\\\"nested\\",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5051,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a complete OSS-Fuzz enrollment for the fastjson library. This will include all necessary files for continuous fuzzing.\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/yourorg/fastjson\"\nlanguage: c++\nprimary_contact: \"security@yourorg.com\"\nmain_repo: \"https://github.com/yourorg/fastjson\"\nfuzzing_engines:\n  - libfuzzer\n  - afl\nsanitizers:\n  - address\n  - undefined\n```\n\n## 2. Dockerfile\n\n```dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder\nRUN apt-get update && apt-get install -y \\\n    cmake \\\n    ninja-build \\\n    pkg-config\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/yourorg/fastjson\n\nWORKDIR fastjson\nCOPY build.sh $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Build the library with fuzzing instrumentation\nmkdir -p build\ncd build\n\ncmake .. \\\n    -GNinja \\\n    -DCMAKE_BUILD_TYPE=Release \\\n    -DCMAKE_C_COMPILER=$CC \\\n    -DCMAKE_CXX_COMPILER=$CXX \\\n    -DCMAKE_C_FLAGS=\"$CFLAGS\" \\\n    -DCMAKE_CXX_FLAGS=\"$CXXFLAGS\" \\\n    -DBUILD_SHARED_LIBS=OFF \\\n    -DBUILD_TESTING=OFF\n\nninja\n\n# Build the fuzz harness\n$CXX $CXXFLAGS -std=c++17 \\\n    -I../include \\\n    $SRC/fastjson/fuzz/json_parse_fuzzer.cc \\\n    -o $OUT/json_parse_fuzzer \\\n    $LIB_FUZZING_ENGINE \\\n    ./libfastjson.a\n\n# Copy seed corpus if available\nif [ -f \"$SRC/fastjson/fuzz/json_parse_fuzzer_seed_corpus.zip\" ]; then\n    cp $SRC/fastjson/fuzz/json_parse_fuzzer_seed_corpus.zip \\\n       $OUT/json_parse_fuzzer_seed_corpus.zip\nfi\n\n# Copy dictionary if available\nif [ -f \"$SRC/fastjson/fuzz/json.dict\" ]; then\n    cp $SRC/fastjson/fuzz/json.dict $OUT/json_parse_fuzzer.dict\nfi\n```\n\n## 4. Fuzz Harness (fuzz/json_parse_fuzzer.cc)\n\n```cpp\n#include <cstdint>\n#include <cstddef>\n#include <string>\n#include <vector>\n\n// Include your JSON library headers\n#include \"fastjson/parser.h\"\n#include \"fastjson/document.h\"\n\nextern \"C\" int LLVMFuzzerTestOneInput(const uint8_t *data, size_t size) {\n    // Reject inputs that are too large to avoid timeouts\n    if (size > 1024 * 1024) {  // 1MB limit\n        return 0;\n    }\n\n    // Reject empty inputs\n    if (size == 0) {\n        return 0;\n    }\n\n    // Convert to string for parsing\n    std::string json_input(reinterpret_cast<const char*>(data), size);\n\n    try {\n        // Parse the JSON input\n        fastjson::Parser parser;\n        fastjson::Document doc = parser.parse(json_input);\n\n        // Exercise various operations on the parsed document\n        if (doc.is_object()) {\n            // Iterate over object keys\n            for (const auto& key : doc.get_keys()) {\n                auto value = doc.get(key);\n                // Access value to ensure it's processed\n                (void)value;\n            }\n        } else if (doc.is_array()) {\n            // Iterate over array elements\n            size_t array_size = doc.size();\n            for (size_t i = 0; i < array_size && i < 1000; ++i) {\n                auto element = doc[i];\n                (void)element;\n            }\n        }\n\n        // Try to serialize back to JSON\n        std::string serialized = doc.to_string();\n        (void)serialized;\n\n    } catch (const fastjson::ParseException& e) {\n        // Expected for invalid JSON - not a bug\n        return 0;\n    } catch (const std::exception& e) {\n        // Other exceptions might indicate bugs\n        // But we don't crash - let sanitizers catch real issues\n        return 0;\n    }\n\n    return 0;\n}\n```\n\n## 5. Optional: JSON Dictionary (fuzz/json.dict)\n\n```\n# JSON syntax tokens\n\"{\"\n\"}\"\n\"[\"\n\"]\"\n\":\"\n\",\"\n\"\\\"\"\n\"true\"\n\"false\"\n\"null\"\n\n# Common JSON patterns\n\"{\\\"key\\\":\\\"value\\\"}\"\n\"[1,2,3]\"\n\"{\\\"nested\\\":{\\\"key\\\":\\\"value\\\"}}\"\n\"[{\\\"id\\\":1},{\\\"id\\\":2}]\"\n\n# Edge cases\n\"0\"\n\"-1\"\n\"1.5\"\n\"1e10\"\n\"1E-10\"\n\"\\\"\\\"\"\n\"\\\"\\\\n\\\"\"\n\"\\\"\\\\u0000\\\"\"\n```\n\n## 6. Optional: Seed Corpus Creation Script\n\nCreate a script to generate initial corpus:\n\n```bash\n#!/bin/bash\n# create_corpus.sh\n\nmkdir -p corpus\ncd corpus\n\n# Valid JSON examples\necho '{}' > empty_object.json\necho '[]' > empty_array.json\necho '{\"key\":\"value\"}' > simple_object.json\necho '[1,2,3,4,5]' > simple_array.json\necho '{\"nested\":{\"key\":\"value\"}}' > nested_object.json\necho '{\"array\":[1,2,3]}' > object_with_array.json\necho '{\"string\":\"test\",\"number\":42,\"bool\":true,\"null\":null}' > mixed_types.json\necho '[{\"id\":1,\"name\":\"Alice\"},{\"id\":2,\"name\":\"Bob\"}]' > array_of_objects.json\necho '{\"unicode\":\"\\\\u0048\\\\u0065\\\\u006c\\\\u006c\\\\u006f\"}' > unicode.json\necho '{\"escaped\":\"line1\\\\nline2\\\\ttab\"}' > escaped_chars.json\n\n# Edge cases\necho '0' > number_zero.json\necho '-1' > negative_number.json\necho '1.5e10' > scientific_notation.json\necho '\"\"' > empty_string.json\necho 'true' > boolean_true.json\necho 'false' > boolean_false.json\necho 'null' > null_value.json\n\n# Create zip archive\ncd ..\nzip -r json_parse_fuzzer_seed_corpus.zip corpus/\n```\n\n## Testing Locally\n\nBefore submitting to OSS-Fuzz, test locally:\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Create the project directory\nmkdir -p projects/fastjson\n\n# Copy your files\ncp /path/to/project.yaml projects/fastjson/\ncp /path/to/Dockerfile projects/fastjson/\ncp /path/to/build.sh projects/fastjson/\n\n# Build the project image\npython3 infra/helper.py build_image --pull fastjson\n\n# Build fuzzers with AddressSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=address fastjson\n\n# Run the fuzzer\npython3 infra/helper.py run_fuzzer fastjson json_parse_fuzzer\n\n# Test with UndefinedBehaviorSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=undefined fastjson\npython3 infra/helper.py run_fuzzer fastjson json_parse_fuzzer\n\n# Generate coverage report (requires gsutil)\npython3 infra/helper.py build_fuzzers --sanitizer=coverage fastjson\npython3 infra/helper.py coverage fastjson\n```\n\n## Key Features of This Setup\n\n1. **Multiple Fuzzing Engines**: Supports both libFuzzer and AFL++\n2. **Multiple Sanitizers**: Tests with AddressSanitizer and UndefinedBehaviorSanitizer\n3. **CMake Integration**: Uses CMake with proper compiler flags from OSS-Fuzz\n4. **Static Linking**: Builds static library to avoid runtime dependencies\n5. **Input Validation**: Harness includes size limits to prevent timeouts\n6. **Exception Handling**: Properly handles expected parse errors\n7. **Dictionary**: Provides JSON-specific tokens for better fuzzing\n8. **Seed Corpus**: Initial valid inputs to bootstrap fuzzing\n\nThis complete setup is ready for OSS-Fuzz enrollment and will provide continuous fuzzing coverage for the fastjson library.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5581,
            "output_tokens": 2223,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "ossfuzz-02",
      "task_type": "cross_language",
      "target_language": "go",
      "expected_patterns": [
        "func Fuzz\\w+\\(f \\*testing\\.F\\)",
        "f\\.Add\\(",
        "f\\.Fuzz\\(",
        "testing",
        "url\\.Parse|ParseURL"
      ],
      "anti_patterns": [
        "LLVMFuzzerTestOneInput",
        "atheris",
        "helper\\.py",
        "build_fuzzers",
        "gcr\\.io/oss-fuzz-base",
        "\\$LIB_FUZZING_ENGINE"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new-project-guide/go_lang.md",
          "description": "Go fuzzing with testing.F: func FuzzDemo(f *testing.F), f.Fuzz() method for native Go 1.18 fuzzers, f.Add() for seed corpus"
        },
        {
          "url": "https://go.dev/doc/security/fuzz",
          "description": "Go native fuzzing: testing.F, f.Add seed corpus, f.Fuzz function signature"
        },
        {
          "url": "https://pkg.go.dev/testing#F",
          "description": "Go testing.F type: Add, Fuzz methods for fuzz testing"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new_project_guide.md",
          "description": "Anti-patterns: OSS-Fuzz C++ patterns (LLVMFuzzerTestOneInput, $LIB_FUZZING_ENGINE, base-builder) that should not appear in native Go tests"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/ujson_fuzzer.py",
          "description": "Anti-patterns: Python Atheris patterns (atheris, helper.py) that should not appear in Go"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "# Go Fuzz Test for URL Parser\n\nHere's a comprehensive fuzz test for a URL parser library using Go's native fuzzing framework:\n\n```go\npackage urlparser\n\nimport (\n\t\"net/url\"\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\n// FuzzURLParser tests URL parsing with various malformed inputs\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with interesting test cases\n\tf.Add(\"https://example.com\")\n\tf.Add(\"http://user:pass@host:8080/path?query=value#fragment\")\n\tf.Add(\"ftp://ftp.example.com/file.txt\")\n\tf.Add(\"mailto:test@example.com\")\n\tf.Add(\"file:///path/to/file\")\n\tf.Add(\"//example.com/path\")\n\tf.Add(\"/path/to/resource\")\n\tf.Add(\"?query=only\")\n\tf.Add(\"#fragment-only\")\n\tf.Add(\"http://[::1]:8080\")\n\tf.Add(\"http://192.168.1.1:80/path\")\n\tf.Add(\"http://example.com:99999\")\n\tf.Add(\"http://example.com/../../../etc/passwd\")\n\tf.Add(\"http://example.com/%2e%2e%2f\")\n\tf.Add(\"http://example.com/path with spaces\")\n\tf.Add(\"http://example.com/path?key=value&key2=value2\")\n\tf.Add(\"http://user@example.com\")\n\tf.Add(\"http://:password@example.com\")\n\tf.Add(\"http://example.com:abc/path\")\n\tf.Add(\"http://\")\n\tf.Add(\"://example.com\")\n\tf.Add(\"http:///path\")\n\tf.Add(\"http://example..com\")\n\tf.Add(\"http://example.com::\")\n\tf.Add(\"http://[invalid-ipv6]\")\n\tf.Add(\"http://example.com\\x00/path\")\n\tf.Add(strings.Repeat(\"a\", 10000))\n\tf.Add(\"http://\" + strings.Repeat(\"a\", 1000) + \".com\")\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Ensure the fuzzer doesn't panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"URL parsing panicked with input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Test url.Parse\n\t\tparsed, err := url.Parse(input)\n\t\t\n\t\t// If parsing succeeded, perform validation checks\n\t\tif err == nil {\n\t\t\tvalidateParsedURL(t, input, parsed)\n\t\t} else {\n\t\t\t// Ensure error is reasonable\n\t\t\tif err.Error() == \"\" {\n\t\t\t\tt.Errorf(\"url.Parse returned empty error message for input %q\", input)\n\t\t\t}\n\t\t}\n\n\t\t// Test url.ParseRequestURI (stricter parsing)\n\t\tparsedReq, errReq := url.ParseRequestURI(input)\n\t\tif errReq == nil {\n\t\t\tvalidateParsedURL(t, input, parsedReq)\n\t\t\t\n\t\t\t// ParseRequestURI should only succeed for absolute URIs\n\t\t\tif parsedReq.Scheme == \"\" && !strings.HasPrefix(input, \"/\") {\n\t\t\t\tt.Errorf(\"ParseRequestURI accepted relative URL without scheme: %q\", input)\n\t\t\t}\n\t\t}\n\n\t\t// Test roundtrip: parse and re-serialize\n\t\tif err == nil && parsed != nil {\n\t\t\ttestRoundtrip(t, input, parsed)\n\t\t}\n\n\t\t// Test URL methods don't panic\n\t\tif parsed != nil {\n\t\t\ttestURLMethods(t, parsed)\n\t\t}\n\t})\n}\n\n// validateParsedURL checks the parsed URL for consistency\nfunc validateParsedURL(t *testing.T, original string, parsed *url.URL) {\n\tif parsed == nil {\n\t\tt.Error(\"Parsed URL is nil but no error was returned\")\n\t\treturn\n\t}\n\n\t// Check that scheme is lowercase if present\n\tif parsed.Scheme != \"\" && parsed.Scheme != strings.ToLower(parsed.Scheme) {\n\t\tt.Errorf(\"Scheme should be lowercase: got %q\", parsed.Scheme)\n\t}\n\n\t// Check host doesn't contain invalid characters\n\tif parsed.Host != \"\" {\n\t\tif strings.Contains(parsed.Host, \" \") {\n\t\t\tt.Errorf(\"Host contains spaces: %q\", parsed.Host)\n\t\t}\n\t\tif strings.Contains(parsed.Host, \"\\n\") || strings.Contains(parsed.Host, \"\\r\") {\n\t\t\tt.Errorf(\"Host contains newlines: %q\", parsed.Host)\n\t\t}\n\t}\n\n\t// Check port is valid if present\n\tif port := parsed.Port(); port != \"\" {\n\t\t// Port should be numeric\n\t\tfor _, c := range port {\n\t\t\tif c < '0' || c > '9' {\n\t\t\t\tt.Errorf(\"Port contains non-numeric characters: %q\", port)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check path is valid UTF-8\n\tif !utf8.ValidString(parsed.Path) {\n\t\tt.Errorf(\"Path is not valid UTF-8: %q\", parsed.Path)\n\t}\n\n\t// Check that User info doesn't contain invalid characters\n\tif parsed.User != nil {\n\t\tusername := parsed.User.Username()\n\t\tif strings.Contains(username, \"\\x00\") {\n\t\t\tt.Errorf(\"Username contains null bytes: %q\", username)\n\t\t}\n\t\tif password, ok := parsed.User.Password(); ok {\n\t\t\tif strings.Contains(password, \"\\x00\") {\n\t\t\t\tt.Errorf(\"Password contains null bytes: %q\", password)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check query parameters can be parsed\n\tif parsed.RawQuery != \"\" {\n\t\tvalues := parsed.Query()\n\t\t// Ensure Query() doesn't panic and returns valid data\n\t\tfor key, vals := range values {\n\t\t\tif !utf8.ValidString(key) {\n\t\t\t\tt.Errorf(\"Query key is not valid UTF-8: %q\", key)\n\t\t\t}\n\t\t\tfor _, val := range vals {\n\t\t\t\tif !utf8.ValidString(val) {\n\t\t\t\t\tt.Errorf(\"Query value is not valid UTF-8: %q\", val)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check fragment is valid UTF-8\n\tif !utf8.ValidString(parsed.Fragment) {\n\t\tt.Errorf(\"Fragment is not valid UTF-8: %q\", parsed.Fragment)\n\t}\n}\n\n// testRoundtrip tests that parsing and re-serializing produces consistent results\nfunc testRoundtrip(t *testing.T, original string, parsed *url.URL) {\n\t// Convert back to string\n\tserialized := parsed.String()\n\n\t// Parse the serialized version\n\treparsed, err := url.Parse(serialized)\n\tif err != nil {\n\t\tt.Errorf(\"Roundtrip failed: re-parsing serialized URL failed: %v\\nOriginal: %q\\nSerialized: %q\", \n\t\t\terr, original, serialized)\n\t\treturn\n\t}\n\n\t// Check key components match\n\tif parsed.Scheme != reparsed.Scheme {\n\t\tt.Errorf(\"Roundtrip scheme mismatch: %q != %q\", parsed.Scheme, reparsed.Scheme)\n\t}\n\tif parsed.Host != reparsed.Host {\n\t\tt.Errorf(\"Roundtrip host mismatch: %q != %q\", parsed.Host, reparsed.Host)\n\t}\n\tif parsed.Path != reparsed.Path {\n\t\tt.Errorf(\"Roundtrip path mismatch: %q != %q\", parsed.Path, reparsed.Path)\n\t}\n\tif parsed.RawQuery != reparsed.RawQuery {\n\t\tt.Errorf(\"Roundtrip query mismatch: %q != %q\", parsed.RawQuery, reparsed.RawQuery)\n\t}\n\tif parsed.Fragment != reparsed.Fragment {\n\t\tt.Errorf(\"Roundtrip fragment mismatch: %q != %q\", parsed.Fragment, reparsed.Fragment)\n\t}\n}\n\n// testURLMethods ensures URL methods don't panic\nfunc testURLMethods(t *testing.T, parsed *url.URL) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"URL method panicked: %v\\nURL: %+v\", r, parsed)\n\t\t}\n\t}()\n\n\t// Test various methods\n\t_ = parsed.String()\n\t_ = parsed.Hostname()\n\t_ = parsed.Port()\n\t_ = parsed.RequestURI()\n\t_ = parsed.Query()\n\t_ = parsed.IsAbs()\n\t_ = parsed.EscapedPath()\n\t_ = parsed.EscapedFragment()\n\t\n\t// Test Redacted (Go 1.15+)\n\t_ = parsed.Redacted()\n\n\t// Test ResolveReference with a simple reference\n\tref, _ := url.Parse(\"/path\")\n\tif ref != nil {\n\t\t_ = parsed.ResolveReference(ref)\n\t}\n\n\t// Test Parse with relative URL\n\t_, _ = parsed.Parse(\"./relative\")\n\t_, _ = parsed.Parse(\"../parent\")\n\t_, _ = parsed.Parse(\"?query\")\n\t_, _ = parsed.Parse(\"#fragment\")\n\n\t// Test MarshalBinary and UnmarshalBinary\n\tdata, err := parsed.MarshalBinary()\n\tif err == nil && data != nil {\n\t\tnewURL := &url.URL{}\n\t\t_ = newURL.UnmarshalBinary(data)\n\t}\n}\n\n// FuzzURLQueryParsing specifically tests query string parsing\nfunc FuzzURLQueryParsing(f *testing.F) {\n\t// Seed corpus for query strings\n\tf.Add(\"key=value\")\n\tf.Add(\"key1=value1&key2=value2\")\n\tf.Add(\"key=value1&key=value2\")\n\tf.Add(\"key=\")\n\tf.Add(\"=value\")\n\tf.Add(\"key\")\n\tf.Add(\"key1=value1;key2=value2\")\n\tf.Add(\"key=value%20with%20spaces\")\n\tf.Add(\"key=value+with+plus\")\n\tf.Add(\"key=%XX\")\n\tf.Add(\"key=%\")\n\tf.Add(strings.Repeat(\"key=value&\", 1000))\n\tf.Add(\"key=\" + strings.Repeat(\"a\", 10000))\n\n\tf.Fuzz(func(t *testing.T, query string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Query parsing panicked with input %q: %v\", query, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Test url.ParseQuery\n\t\tvalues, err := url.ParseQuery(query)\n\t\t\n\t\tif err == nil {\n\t\t\t// Validate parsed values\n\t\t\tfor key, vals := range values {\n\t\t\t\tif !utf8.ValidString(key) {\n\t\t\t\t\tt.Errorf(\"Query key is not valid UTF-8: %q\", key)\n\t\t\t\t}\n\t\t\t\tfor _, val := range vals {\n\t\t\t\t\tif !utf8.ValidString(val) {\n\t\t\t\t\t\tt.Errorf(\"Query value is not valid UTF-8: %q\", val)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test Encode roundtrip\n\t\t\tencoded := values.Encode()\n\t\t\treparsed, err := url.ParseQuery(encoded)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"Roundtrip failed: %v\\nOriginal: %q\\nEncoded: %q\", err, query, encoded)\n\t\t\t} else {\n\t\t\t\t// Check that values match (order may differ)\n\t\t\t\tif len(values) != len(reparsed) {\n\t\t\t\t\tt.Errorf(\"Roundtrip length mismatch: %d != %d\", len(values), len(reparsed))\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\n// FuzzURLEscaping tests URL escaping and unescaping\nfunc FuzzURLEscaping(f *testing.F) {\n\tf.Add(\"hello world\")\n\tf.Add(\"hello+world\")\n\tf.Add(\"hello%20world\")\n\tf.Add(\"hello%2Bworld\")\n\tf.Add(\"%\")\n\tf.Add(\"%%\")\n\tf.Add(\"%2\")\n\tf.Add(\"%GG\")\n\tf.Add(strings.Repeat(\"%20\", 1000))\n\tf.Add(\"\\x00\\x01\\x02\")\n\tf.Add(\"\u65e5\u672c\u8a9e\")\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"URL escaping panicked with input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Test PathEscape/PathUnescape\n\t\tescaped := url.PathEscape(input)\n\t\tif !utf8.ValidString(escaped) {\n\t\t\tt.Errorf(\"PathEscape produced invalid UTF-8: %q\", escaped)\n\t\t}\n\n\t\tunescaped, err := url.PathUnescape(escaped)\n\t\tif err == nil && unescaped != input {\n\t\t\tt.Errorf(\"PathEscape/PathUnescape roundtrip failed:\\nInput: %q\\nEscaped: %q\\nUnescaped: %q\",\n\t\t\t\tinput, escaped, unescaped)\n\t\t}\n\n\t\t// Test QueryEscape/QueryUnescape\n\t\tqueryEscaped := url.QueryEscape(input)\n\t\tif !utf8.ValidString(queryEscaped) {\n\t\t\tt.Errorf(\"QueryEscape produced invalid UTF-8: %q\", queryEscaped)\n\t\t}\n\n\t\tqueryUnescaped, err := url.QueryUnescape(queryEscaped)\n\t\tif err == nil && queryUnescaped != input {\n\t\t\tt.Errorf(\"QueryEscape/QueryUnescape roundtrip failed:\\nInput: %q\\nEscaped: %q\\nUnescaped: %q\",\n\t\t\t\tinput, queryEscaped, queryUnescaped)\n\t\t}\n\n\t\t// Test unescaping the original input\n\t\t_, _ = url.PathUnescape(input)\n\t\t_, _ = url.QueryUnescape(input)\n\t})\n}\n```\n\n## Running the Fuzz Tests\n\nTo run these fuzz tests, use the following commands:\n\n```bash\n# Run URL parser fuzzing for 30 seconds\ngo test -fuzz=FuzzURLParser -fuzztime=30s\n\n# Run query parsing fuzzing\ngo test -fuzz=FuzzURLQueryParsing -fuzztime=30s\n\n# Run URL escaping fuzzing\ngo test -fuzz=FuzzURLEscaping -fuzztime=30s\n\n# Run with parallel workers\ngo test -fuzz=FuzzURLParser -parallel=8\n\n# Run and save interesting inputs to testdata\ngo test -fuzz=FuzzURLParser -fuzztime=1m\n```\n\n## Key Features\n\n1. **Comprehensive Coverage**: Tests URL parsing, query parsing, and escaping/unescaping\n2. **Panic Detection**: Uses defer/recover to catch panics\n3. **Validation Checks**: Verifies parsed components are valid (UTF-8, proper format, etc.)\n4. **Roundtrip Testing**: Ensures parse\u2192serialize\u2192parse produces consistent results\n5. **Method Testing**: Exercises all URL methods to find edge cases\n6. **Rich Seed Corpus**: Includes malformed, edge case, and valid inputs\n\nThis fuzz test will help discover bugs like buffer overflows, panics, incorrect parsing, and inconsistent behavior in URL parsing code.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 59,
            "output_tokens": 3888,
            "cached": false
          },
          "with_skill": {
            "output": "# Go Native Fuzzing for URL Parser\n\nHere's a comprehensive Go fuzz test for a URL parser library using Go's native `testing.F` framework:\n\n## Complete Example\n\n```go\npackage urlparser_test\n\nimport (\n\t\"net/url\"\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\n// FuzzURLParser tests URL parsing with various malformed inputs\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with interesting URL patterns\n\tf.Add(\"https://example.com/path?query=value#fragment\")\n\tf.Add(\"http://user:pass@host:8080/path\")\n\tf.Add(\"ftp://ftp.example.com/file.txt\")\n\tf.Add(\"mailto:user@example.com\")\n\tf.Add(\"file:///path/to/file\")\n\tf.Add(\"//example.com/path\") // Protocol-relative URL\n\tf.Add(\"http://[::1]:8080/\")  // IPv6\n\tf.Add(\"http://192.168.1.1/\")\n\tf.Add(\"http://example.com:80/\")\n\tf.Add(\"http://example.com/path%20with%20spaces\")\n\tf.Add(\"http://example.com/path?key=value&key2=value2\")\n\tf.Add(\"http://example.com#fragment\")\n\tf.Add(\"relative/path\")\n\tf.Add(\"/absolute/path\")\n\tf.Add(\"?query=only\")\n\tf.Add(\"#fragment-only\")\n\t\n\t// Edge cases and malformed inputs\n\tf.Add(\"\")\n\tf.Add(\":\")\n\tf.Add(\"://\")\n\tf.Add(\"http://\")\n\tf.Add(\"http:///path\")\n\tf.Add(\"http://host:99999/\") // Invalid port\n\tf.Add(\"http://host:-1/\")    // Negative port\n\tf.Add(\"http://host:abc/\")   // Non-numeric port\n\tf.Add(\"http://[invalid-ipv6]/\")\n\tf.Add(\"http://host/path with spaces\")\n\tf.Add(\"http://host/path\\nwith\\nnewlines\")\n\tf.Add(\"http://host/path\\x00with\\x00nulls\")\n\tf.Add(strings.Repeat(\"a\", 10000)) // Very long input\n\tf.Add(\"http://\" + strings.Repeat(\"a\", 1000) + \".com/\")\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Skip invalid UTF-8 to avoid noise\n\t\tif !utf8.ValidString(input) {\n\t\t\tt.Skip(\"invalid UTF-8\")\n\t\t}\n\t\t\n\t\t// Test 1: Parse should not panic\n\t\tvar parsedURL *url.URL\n\t\tvar parseErr error\n\t\t\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"url.Parse panicked on input %q: %v\", input, r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\tparsedURL, parseErr = url.Parse(input)\n\t\t}()\n\t\t\n\t\t// If parsing failed, that's acceptable for malformed input\n\t\tif parseErr != nil {\n\t\t\treturn\n\t\t}\n\t\t\n\t\t// Test 2: Parsed URL should be valid\n\t\tif parsedURL == nil {\n\t\t\tt.Errorf(\"url.Parse returned nil URL without error for input %q\", input)\n\t\t\treturn\n\t\t}\n\t\t\n\t\t// Test 3: String() should not panic and should be idempotent\n\t\tvar urlString string\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"URL.String() panicked: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\turlString = parsedURL.String()\n\t\t}()\n\t\t\n\t\t// Test 4: Re-parsing the stringified URL should work\n\t\treparsed, err := url.Parse(urlString)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"Re-parsing stringified URL failed: %v\\nOriginal: %q\\nStringified: %q\", \n\t\t\t\terr, input, urlString)\n\t\t\treturn\n\t\t}\n\t\t\n\t\t// Test 5: Basic consistency checks\n\t\tif reparsed.String() != urlString {\n\t\t\tt.Errorf(\"URL string representation not stable:\\nFirst:  %q\\nSecond: %q\", \n\t\t\t\turlString, reparsed.String())\n\t\t}\n\t\t\n\t\t// Test 6: Component access should not panic\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"Accessing URL components panicked: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\t\n\t\t\t_ = parsedURL.Scheme\n\t\t\t_ = parsedURL.Opaque\n\t\t\t_ = parsedURL.User\n\t\t\t_ = parsedURL.Host\n\t\t\t_ = parsedURL.Path\n\t\t\t_ = parsedURL.RawPath\n\t\t\t_ = parsedURL.RawQuery\n\t\t\t_ = parsedURL.Fragment\n\t\t\t_ = parsedURL.RawFragment\n\t\t\t\n\t\t\t// These methods should not panic\n\t\t\t_ = parsedURL.Hostname()\n\t\t\t_ = parsedURL.Port()\n\t\t\t_ = parsedURL.RequestURI()\n\t\t\t_ = parsedURL.EscapedPath()\n\t\t\t_ = parsedURL.EscapedFragment()\n\t\t\t_ = parsedURL.Query()\n\t\t}()\n\t\t\n\t\t// Test 7: Validate scheme if present\n\t\tif parsedURL.Scheme != \"\" {\n\t\t\tif strings.Contains(parsedURL.Scheme, \":\") {\n\t\t\t\tt.Errorf(\"Scheme contains colon: %q\", parsedURL.Scheme)\n\t\t\t}\n\t\t\tif strings.Contains(parsedURL.Scheme, \"/\") {\n\t\t\t\tt.Errorf(\"Scheme contains slash: %q\", parsedURL.Scheme)\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Test 8: Validate port if present\n\t\tif port := parsedURL.Port(); port != \"\" {\n\t\t\t// Port should be numeric\n\t\t\tfor _, c := range port {\n\t\t\t\tif c < '0' || c > '9' {\n\t\t\t\t\tt.Errorf(\"Port contains non-numeric character: %q\", port)\n\t\t\t\t\tbreak\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Test 9: ResolveReference should not panic\n\t\tif parsedURL.IsAbs() {\n\t\t\tfunc() {\n\t\t\t\tdefer func() {\n\t\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\t\tt.Errorf(\"ResolveReference panicked: %v\", r)\n\t\t\t\t\t}\n\t\t\t\t}()\n\t\t\t\t\n\t\t\t\tref, _ := url.Parse(\"relative/path\")\n\t\t\t\tif ref != nil {\n\t\t\t\t\t_ = parsedURL.ResolveReference(ref)\n\t\t\t\t}\n\t\t\t}()\n\t\t}\n\t})\n}\n\n// FuzzURLParseRequestURI tests ParseRequestURI specifically\nfunc FuzzURLParseRequestURI(f *testing.F) {\n\t// Seed with valid request URIs\n\tf.Add(\"/path\")\n\tf.Add(\"/path?query=value\")\n\tf.Add(\"http://example.com/path\")\n\tf.Add(\"https://example.com:443/path?q=v#frag\")\n\t\n\t// Invalid request URIs\n\tf.Add(\"\")\n\tf.Add(\"relative/path\")\n\tf.Add(\"//example.com/path\")\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tif !utf8.ValidString(input) {\n\t\t\tt.Skip(\"invalid UTF-8\")\n\t\t}\n\t\t\n\t\t// ParseRequestURI should not panic\n\t\tvar parsedURL *url.URL\n\t\tvar parseErr error\n\t\t\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"url.ParseRequestURI panicked on input %q: %v\", input, r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\tparsedURL, parseErr = url.ParseRequestURI(input)\n\t\t}()\n\t\t\n\t\t// If it succeeded, verify it's a valid request URI\n\t\tif parseErr == nil && parsedURL != nil {\n\t\t\t// Request URIs must be absolute or start with /\n\t\t\tif !parsedURL.IsAbs() && !strings.HasPrefix(input, \"/\") {\n\t\t\t\tt.Errorf(\"ParseRequestURI accepted invalid request URI: %q\", input)\n\t\t\t}\n\t\t}\n\t})\n}\n\n// FuzzURLQueryParsing tests query parameter parsing\nfunc FuzzURLQueryParsing(f *testing.F) {\n\tf.Add(\"key=value\")\n\tf.Add(\"key1=value1&key2=value2\")\n\tf.Add(\"key=value%20with%20spaces\")\n\tf.Add(\"key=\")\n\tf.Add(\"key\")\n\tf.Add(\"=value\")\n\tf.Add(\"&&&\")\n\tf.Add(\"key=value&key=value2\") // Duplicate keys\n\tf.Add(\"key[]=value1&key[]=value2\")\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tif !utf8.ValidString(input) {\n\t\t\tt.Skip(\"invalid UTF-8\")\n\t\t}\n\t\t\n\t\t// ParseQuery should not panic\n\t\tvar values url.Values\n\t\tvar parseErr error\n\t\t\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"url.ParseQuery panicked on input %q: %v\", input, r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\tvalues, parseErr = url.ParseQuery(input)\n\t\t}()\n\t\t\n\t\tif parseErr != nil {\n\t\t\treturn\n\t\t}\n\t\t\n\t\t// Encoding back should not panic\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"Values.Encode() panicked: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\tencoded := values.Encode()\n\t\t\t\n\t\t\t// Re-parsing should work\n\t\t\t_, err := url.ParseQuery(encoded)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"Re-parsing encoded query failed: %v\\nOriginal: %q\\nEncoded: %q\", \n\t\t\t\t\terr, input, encoded)\n\t\t\t}\n\t\t}()\n\t\t\n\t\t// Accessing values should not panic\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"Accessing query values panicked: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\t\n\t\t\tfor key := range values {\n\t\t\t\t_ = values.Get(key)\n\t\t\t\t_ = values[key]\n\t\t\t}\n\t\t}()\n\t})\n}\n\n// FuzzURLEscaping tests URL escaping/unescaping\nfunc FuzzURLEscaping(f *testing.F) {\n\tf.Add(\"hello world\")\n\tf.Add(\"hello%20world\")\n\tf.Add(\"hello+world\")\n\tf.Add(\"special!@#$%^&*()\")\n\tf.Add(\"unicode: \u4f60\u597d\")\n\tf.Add(\"%\")\n\tf.Add(\"%2\")\n\tf.Add(\"%ZZ\")\n\tf.Add(\"%%\")\n\tf.Add(strings.Repeat(\"%\", 100))\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tif !utf8.ValidString(input) {\n\t\t\tt.Skip(\"invalid UTF-8\")\n\t\t}\n\t\t\n\t\t// Test PathEscape/PathUnescape\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"PathEscape panicked: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\t\n\t\t\tescaped := url.PathEscape(input)\n\t\t\tunescaped, err := url.PathUnescape(escaped)\n\t\t\t\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"PathUnescape failed on PathEscape output: %v\", err)\n\t\t\t} else if unescaped != input {\n\t\t\t\tt.Errorf(\"PathEscape/PathUnescape not idempotent:\\nInput:      %q\\nEscaped:    %q\\nUnescaped:  %q\", \n\t\t\t\t\tinput, escaped, unescaped)\n\t\t\t}\n\t\t}()\n\t\t\n\t\t// Test QueryEscape/QueryUnescape\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"QueryEscape panicked: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\t\n\t\t\tescaped := url.QueryEscape(input)\n\t\t\tunescaped, err := url.QueryUnescape(escaped)\n\t\t\t\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"QueryUnescape failed on QueryEscape output: %v\", err)\n\t\t\t} else if unescaped != input {\n\t\t\t\tt.Errorf(\"QueryEscape/QueryUnescape not idempotent:\\nInput:      %q\\nEscaped:    %q\\nUnescaped:  %q\", \n\t\t\t\t\tinput, escaped, unescaped)\n\t\t\t}\n\t\t}()\n\t\t\n\t\t// Test unescaping potentially malformed input\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"PathUnescape panicked on raw input: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\t_, _ = url.PathUnescape(input)\n\t\t}()\n\t\t\n\t\tfunc() {\n\t\t\tdefer func() {\n\t\t\t\tif r := recover(); r != nil {\n\t\t\t\t\tt.Errorf(\"QueryUnescape panicked on raw input: %v\", r)\n\t\t\t\t}\n\t\t\t}()\n\t\t\t_, _ = url.QueryUnescape(input)\n\t\t}()\n\t})\n}\n```\n\n## Running the Fuzz Tests\n\n```bash\n# Run all fuzz tests for 30 seconds each\ngo test -fuzz=FuzzURL -fuzztime=30s\n\n# Run specific fuzz test\ngo test -fuzz=FuzzURLParser -fuzztime=1m\n\n# Run with more memory\ngo test -fuzz=FuzzURLParser -fuzztime=30s -parallel=4\n\n# Continue fuzzing from previous corpus\ngo test -fuzz=FuzzURLParser -fuzztime=10m\n\n# Run with specific seed\ngo test -fuzz=FuzzURLParser -fuzztime=30s -fuzzseed=12345\n```\n\n## Understanding the Output\n\n```bash\n# Successful fuzzing output\nfuzz: elapsed: 0s, gathering baseline coverage: 0/192 completed\nfuzz: elapsed: 0s, gathering baseline coverage: 192/192 completed, now fuzzing with 8 workers\nfuzz: elapsed: 3s, execs: 325017 (108336/sec), new interesting: 11 (total: 203)\nfuzz: elapsed: 6s, execs: 680218 (118402/sec), new interesting: 11 (total: 203)\n\n# If a crash is found\n--- FAIL: FuzzURLParser (0.03s)\n    --- FAIL: FuzzURLParser (0.00s)\n        url_test.go:45: url.Parse panicked on input \"http://\\x00\": parse \"http://\\x00\": net/url: invalid control character in URL\n    \n    Failing input written to testdata/fuzz/FuzzURLParser/[hash]\n    To re-run:\n    go test -run=FuzzURLParser/[hash]\n```\n\n## Key Features\n\n| Feature | Purpose |\n|---------|---------|\n| **Panic Detection** | Wraps all operations in defer/recover to catch panics |\n| **Idempotency Testing** | Verifies parse \u2192 stringify \u2192 parse produces same result |\n| **Component Validation** | Checks scheme, port, and other components for correctness |\n| **UTF-8 Filtering** | Skips invalid UTF-8 to reduce noise |\n| **Comprehensive Seeds** | Includes valid, edge case, and malformed inputs |\n| **Multiple Functions** | Tests different parsing functions separately |\n\n## What This Tests\n\n| Test | What It Catches |\n|------|-----------------|\n| **Parse panics** | Crashes on malformed input |\n| **Nil pointer dereferences** | Missing nil checks |\n| **String instability** | Non-deterministic string representation |\n| **Invalid component values** | Scheme with \":\", port with letters |\n| **Escape/unescape bugs** | Data loss or corruption in encoding |\n| **Query parsing issues** | Crashes or incorrect parsing of parameters |\n| **Memory issues** | Excessive allocations, buffer overflows |\n\n## Analyzing Results\n\n```bash\n# View the corpus that was generated\nls testdata/fuzz/F",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5005,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive Go fuzz test for URL parsing. Since I don't see an existing URL parser library in the project, I'll create one along with the fuzz test.\n\n```go\n// internal/urlparser/parser.go\npackage urlparser\n\nimport (\n\t\"errors\"\n\t\"fmt\"\n\t\"strings\"\n)\n\nvar (\n\tErrEmptyURL      = errors.New(\"empty URL\")\n\tErrInvalidScheme = errors.New(\"invalid scheme\")\n\tErrInvalidPort   = errors.New(\"invalid port\")\n)\n\n// URL represents a parsed URL\ntype URL struct {\n\tScheme   string\n\tHost     string\n\tPort     string\n\tPath     string\n\tQuery    string\n\tFragment string\n}\n\n// Parse parses a URL string into its components\nfunc Parse(rawURL string) (*URL, error) {\n\tif rawURL == \"\" {\n\t\treturn nil, ErrEmptyURL\n\t}\n\n\turl := &URL{}\n\tremaining := rawURL\n\n\t// Extract scheme\n\tif idx := strings.Index(remaining, \"://\"); idx != -1 {\n\t\turl.Scheme = remaining[:idx]\n\t\tif !isValidScheme(url.Scheme) {\n\t\t\treturn nil, ErrInvalidScheme\n\t\t}\n\t\tremaining = remaining[idx+3:]\n\t}\n\n\t// Extract fragment\n\tif idx := strings.Index(remaining, \"#\"); idx != -1 {\n\t\turl.Fragment = remaining[idx+1:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract query\n\tif idx := strings.Index(remaining, \"?\"); idx != -1 {\n\t\turl.Query = remaining[idx+1:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract path\n\tif idx := strings.Index(remaining, \"/\"); idx != -1 {\n\t\turl.Path = remaining[idx:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract host and port\n\tif remaining != \"\" {\n\t\tif idx := strings.LastIndex(remaining, \":\"); idx != -1 {\n\t\t\turl.Host = remaining[:idx]\n\t\t\turl.Port = remaining[idx+1:]\n\t\t\tif !isValidPort(url.Port) {\n\t\t\t\treturn nil, ErrInvalidPort\n\t\t\t}\n\t\t} else {\n\t\t\turl.Host = remaining\n\t\t}\n\t}\n\n\treturn url, nil\n}\n\n// String reconstructs the URL string\nfunc (u *URL) String() string {\n\tvar sb strings.Builder\n\n\tif u.Scheme != \"\" {\n\t\tsb.WriteString(u.Scheme)\n\t\tsb.WriteString(\"://\")\n\t}\n\n\tif u.Host != \"\" {\n\t\tsb.WriteString(u.Host)\n\t}\n\n\tif u.Port != \"\" {\n\t\tsb.WriteString(\":\")\n\t\tsb.WriteString(u.Port)\n\t}\n\n\tif u.Path != \"\" {\n\t\tsb.WriteString(u.Path)\n\t}\n\n\tif u.Query != \"\" {\n\t\tsb.WriteString(\"?\")\n\t\tsb.WriteString(u.Query)\n\t}\n\n\tif u.Fragment != \"\" {\n\t\tsb.WriteString(\"#\")\n\t\tsb.WriteString(u.Fragment)\n\t}\n\n\treturn sb.String()\n}\n\nfunc isValidScheme(scheme string) bool {\n\tif scheme == \"\" {\n\t\treturn false\n\t}\n\tfor i, c := range scheme {\n\t\tif i == 0 && !isAlpha(c) {\n\t\t\treturn false\n\t\t}\n\t\tif !isAlpha(c) && !isDigit(c) && c != '+' && c != '-' && c != '.' {\n\t\t\treturn false\n\t\t}\n\t}\n\treturn true\n}\n\nfunc isValidPort(port string) bool {\n\tif port == \"\" {\n\t\treturn false\n\t}\n\tfor _, c := range port {\n\t\tif !isDigit(c) {\n\t\t\treturn false\n\t\t}\n\t}\n\t// Check port range\n\tvar portNum int\n\tfmt.Sscanf(port, \"%d\", &portNum)\n\treturn portNum > 0 && portNum <= 65535\n}\n\nfunc isAlpha(c rune) bool {\n\treturn (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')\n}\n\nfunc isDigit(c rune) bool {\n\treturn c >= '0' && c <= '9'\n}\n```\n\n```go\n// internal/urlparser/parser_fuzz_test.go\npackage urlparser\n\nimport (\n\t\"strings\"\n\t\"testing\"\n)\n\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with valid and edge case URLs\n\tseeds := []string{\n\t\t\"http://example.com\",\n\t\t\"https://example.com:8080/path\",\n\t\t\"ftp://user@host.com:21/file.txt\",\n\t\t\"http://example.com/path?query=value\",\n\t\t\"https://example.com/path#fragment\",\n\t\t\"http://example.com:8080/path?q=v#frag\",\n\t\t\"//example.com/path\",\n\t\t\"/path/to/resource\",\n\t\t\"example.com\",\n\t\t\"http://192.168.1.1:8080\",\n\t\t\"\",\n\t\t\"://example.com\",\n\t\t\"http://\",\n\t\t\"http://:8080\",\n\t\t\"http://example.com:\",\n\t\t\"http://example.com:99999\",\n\t\t\"ht!tp://example.com\",\n\t\t\"http://example.com:abc\",\n\t\t\"http://example.com/path?query#fragment#extra\",\n\t\t\"http://[::1]:8080/path\",\n\t\t\"http://example.com:0\",\n\t\t\"http://example.com:-1\",\n\t\tstrings.Repeat(\"a\", 10000),\n\t\t\"http://\" + strings.Repeat(\"a\", 1000) + \".com\",\n\t\t\"http://example.com/\" + strings.Repeat(\"p\", 1000),\n\t}\n\n\tfor _, seed := range seeds {\n\t\tf.Add(seed)\n\t}\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// The main goal is to ensure Parse never panics\n\t\t// and maintains invariants\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Parse panicked on input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\turl, err := Parse(input)\n\n\t\t// If parsing succeeded, verify invariants\n\t\tif err == nil {\n\t\t\tif url == nil {\n\t\t\t\tt.Errorf(\"Parse returned nil URL with nil error for input %q\", input)\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Verify scheme validity\n\t\t\tif url.Scheme != \"\" && !isValidScheme(url.Scheme) {\n\t\t\t\tt.Errorf(\"Parse returned invalid scheme %q for input %q\", url.Scheme, input)\n\t\t\t}\n\n\t\t\t// Verify port validity\n\t\t\tif url.Port != \"\" && !isValidPort(url.Port) {\n\t\t\t\tt.Errorf(\"Parse returned invalid port %q for input %q\", url.Port, input)\n\t\t\t}\n\n\t\t\t// Verify String() doesn't panic\n\t\t\treconstructed := url.String()\n\t\t\tif reconstructed == \"\" && input != \"\" {\n\t\t\t\t// Empty reconstruction might be valid for some inputs\n\t\t\t\t// but worth checking\n\t\t\t}\n\n\t\t\t// Verify idempotency: parsing the reconstructed URL should work\n\t\t\turl2, err2 := Parse(reconstructed)\n\t\t\tif err2 != nil {\n\t\t\t\t// It's okay if reconstruction isn't perfect, but it shouldn't\n\t\t\t\t// produce something that can't be parsed\n\t\t\t\tt.Logf(\"Reconstructed URL %q cannot be parsed: %v (original: %q)\", \n\t\t\t\t\treconstructed, err2, input)\n\t\t\t} else if url2 != nil {\n\t\t\t\t// Verify key fields match\n\t\t\t\tif url2.Scheme != url.Scheme {\n\t\t\t\t\tt.Errorf(\"Scheme mismatch after reconstruction: %q != %q (input: %q)\",\n\t\t\t\t\t\turl2.Scheme, url.Scheme, input)\n\t\t\t\t}\n\t\t\t\tif url2.Host != url.Host {\n\t\t\t\t\tt.Errorf(\"Host mismatch after reconstruction: %q != %q (input: %q)\",\n\t\t\t\t\t\turl2.Host, url.Host, input)\n\t\t\t\t}\n\t\t\t\tif url2.Port != url.Port {\n\t\t\t\t\tt.Errorf(\"Port mismatch after reconstruction: %q != %q (input: %q)\",\n\t\t\t\t\t\turl2.Port, url.Port, input)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Check for common issues\n\t\t\tif strings.Contains(url.Scheme, \":\") {\n\t\t\t\tt.Errorf(\"Scheme contains colon: %q (input: %q)\", url.Scheme, input)\n\t\t\t}\n\t\t\tif strings.Contains(url.Host, \"/\") {\n\t\t\t\tt.Errorf(\"Host contains slash: %q (input: %q)\", url.Host, input)\n\t\t\t}\n\t\t\tif strings.Contains(url.Port, \":\") {\n\t\t\t\tt.Errorf(\"Port contains colon: %q (input: %q)\", url.Port, input)\n\t\t\t}\n\n\t\t} else {\n\t\t\t// If parsing failed, verify error is one of the expected types\n\t\t\tif err != ErrEmptyURL && err != ErrInvalidScheme && err != ErrInvalidPort {\n\t\t\t\t// This is fine - there might be other error types\n\t\t\t\t// Just log for awareness\n\t\t\t\tt.Logf(\"Unexpected error type for input %q: %v\", input, err)\n\t\t\t}\n\t\t}\n\n\t\t// Additional safety checks for extreme inputs\n\t\tif len(input) > 100000 {\n\t\t\t// Ensure we're not consuming excessive memory\n\t\t\tt.Logf(\"Processing very long input: %d bytes\", len(input))\n\t\t}\n\n\t\t// Check for null bytes which might cause issues\n\t\tif strings.Contains(input, \"\\x00\") {\n\t\t\tt.Logf(\"Input contains null bytes: %q\", input)\n\t\t}\n\t})\n}\n\n// FuzzURLParserRoundTrip tests that parsing and reconstruction are consistent\nfunc FuzzURLParserRoundTrip(f *testing.F) {\n\tseeds := []string{\n\t\t\"http://example.com\",\n\t\t\"https://example.com:8080/path?query=value#fragment\",\n\t\t\"ftp://example.com:21/file.txt\",\n\t}\n\n\tfor _, seed := range seeds {\n\t\tf.Add(seed)\n\t}\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Panic during round-trip test: %v\", r)\n\t\t\t}\n\t\t}()\n\n\t\turl1, err1 := Parse(input)\n\t\tif err1 != nil {\n\t\t\treturn // Skip invalid inputs\n\t\t}\n\n\t\treconstructed := url1.String()\n\t\turl2, err2 := Parse(reconstructed)\n\t\t\n\t\tif err2 != nil {\n\t\t\tt.Errorf(\"Failed to parse reconstructed URL: %v\\nOriginal: %q\\nReconstructed: %q\",\n\t\t\t\terr2, input, reconstructed)\n\t\t\treturn\n\t\t}\n\n\t\t// Compare all fields\n\t\tif url1.Scheme != url2.Scheme {\n\t\t\tt.Errorf(\"Scheme changed: %q -> %q (input: %q)\",\n\t\t\t\turl1.Scheme, url2.Scheme, input)\n\t\t}\n\t\tif url1.Host != url2.Host {\n\t\t\tt.Errorf(\"Host changed: %q -> %q (input: %q)\",\n\t\t\t\turl1.Host, url2.Host, input)\n\t\t}\n\t\tif url1.Port != url2.Port {\n\t\t\tt.Errorf(\"Port changed: %q -> %q (input: %q)\",\n\t\t\t\turl1.Port, url2.Port, input)\n\t\t}\n\t\tif url1.Path != url2.Path {\n\t\t\tt.Errorf(\"Path changed: %q -> %q (input: %q)\",\n\t\t\t\turl1.Path, url2.Path, input)\n\t\t}\n\t\tif url1.Query != url2.Query {\n\t\t\tt.Errorf(\"Query changed: %q -> %q (input: %q)\",\n\t\t\t\turl1.Query, url2.Query, input)\n\t\t}\n\t\tif url1.Fragment != url2.Fragment {\n\t\t\tt.Errorf(\"Fragment changed: %q -> %q (input: %q)\",\n\t\t\t\turl1.Fragment, url2.Fragment, input)\n\t\t}\n\t})\n}\n```\n\n```go\n// internal/urlparser/parser_test.go\npackage urlparser\n\nimport (\n\t\"testing\"\n)\n\nfunc TestParseValid(t *testing.T) {\n\ttests := []struct {\n\t\tname     string\n\t\tinput    string\n\t\texpected *URL\n\t}{\n\t\t{\n\t\t\tname:  \"simple http\",\n\t\t\tinput: \"http://example.com\",\n\t\t\texpected: &URL{\n\t\t\t\tScheme: \"http\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"with port\",\n\t\t\tinput: \"https://example.com:8080\",\n\t\t\texpected: &URL{\n\t\t\t\tScheme: \"https\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t\tPort:   \"8080\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"with path\",\n\t\t\tinput: \"http://example.com/path/to/resource\",\n\t\t\texpected: &URL{\n\t\t\t\tScheme: \"http\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t\tPath:   \"/path/to/resource\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"full url\",\n\t\t\tinput: \"https://example.com:443/path?query=value#fragment\",\n\t\t\texpected: &URL{\n\t\t\t\tScheme:   \"https\",\n\t\t\t\tHost:     \"example.com\",\n\t\t\t\tPort:     \"443\",\n\t\t\t\tPath:     \"/path\",\n\t\t\t\tQuery:    \"query=value\",\n\t\t\t\tFragment: \"fragment\",\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tgot, err := Parse(tt.input)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t\t}\n\t\t\tif got.Scheme != tt.expected.Scheme {\n\t\t\t\tt.Errorf(\"Scheme: got %q, want %q\", got.Scheme, tt.expected.Scheme)\n\t\t\t}\n\t\t\tif got.Host != tt.expected.Host {\n\t\t\t\tt.Errorf(\"Host: got %q, want %q\", got.Host, tt.expected.Host)\n\t\t\t}\n\t\t\tif got.Port != tt.expected.Port {\n\t\t\t\tt.Errorf(\"Port: got %q, want %q\", got.Port, tt.expected.Port)\n\t\t\t}\n\t\t\tif got.Path != tt.expected.Path {\n\t\t\t\tt.Errorf(\"Path: got %q, want %q\", got.Path, tt.expected.Path)\n\t\t\t}\n\t\t\tif got.Query != tt.expected.Query {\n\t\t\t\tt.Errorf(\"Query: got %q, want %q\", got.Query, tt.expected.Query)\n\t\t\t}\n\t\t\tif got.Fragment != tt.expected.Fragment {\n\t\t\t\tt.Errorf(\"Fragment: got %q, want %q\", got.Fragment, tt.expected.Fragment)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestParseInvalid(t *testing.T) {\n\ttests := []struct {\n\t\tname        string\n\t\tinput       string\n\t\texpectedErr error\n\t}{\n\t\t{\n\t\t\tname:        \"empty string\",\n\t\t\tinput:       \"\",\n\t\t\texpectedErr: ErrEmptyURL,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid scheme\",\n\t\t\tinput:       \"ht!tp://example.com\",\n\t\t\texpectedErr: ErrInvalidScheme,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid port\",\n\t\t\tinput:       \"http://example.com:abc\",\n\t\t\texpectedErr: ErrInvalidPort,\n\t\t},\n\t\t{\n\t\t\tname:        \"port out of range\",\n\t\t\tinput:       \"http://example.com:99999\",\n\t\t\texpectedErr: ErrInvalidPort,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\t_, err := Parse(tt.input)\n\t\t\tif err != tt.expectedErr {\n\t\t\t\tt.Errorf(\"expected error %v, got %v\", tt.expectedErr, err)\n\t\t\t}\n\t\t})\n\t}\n}\n```\n\nNow you can run the fuzz tests:\n\n```bash\n# Run the main fuzz test for 30 seconds\ngo test -fuzz=FuzzURLParser -fuzztime=30s ./internal/urlparser\n\n# Run the round-trip fuzz test\ngo test -fuzz=F",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5489,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "# Go Fuzz Test for URL Parser\n\nHere's a comprehensive fuzz test for a URL parser library using Go's native fuzzing framework:\n\n```go\npackage urlparser\n\nimport (\n\t\"net/url\"\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\n// FuzzURLParser tests URL parsing with various malformed inputs\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with interesting test cases\n\tf.Add(\"https://example.com\")\n\tf.Add(\"http://user:pass@host:8080/path?query=value#fragment\")\n\tf.Add(\"ftp://ftp.example.com/file.txt\")\n\tf.Add(\"mailto:test@example.com\")\n\tf.Add(\"//example.com/path\")\n\tf.Add(\"http://[::1]:8080\")\n\tf.Add(\"http://192.168.1.1:80/path\")\n\tf.Add(\"https://example.com:443/path?a=b&c=d\")\n\tf.Add(\"http://example.com/%2F%2F\")\n\tf.Add(\"http://example.com/path with spaces\")\n\tf.Add(\"http://example.com/path?query=value with spaces\")\n\tf.Add(\"http://example.com/../../../etc/passwd\")\n\tf.Add(\"http://example.com/./path/./to/./resource\")\n\tf.Add(\"http://example.com:99999/path\")\n\tf.Add(\"http://\")\n\tf.Add(\"://example.com\")\n\tf.Add(\"http:///path\")\n\tf.Add(\"http://example.com:abc/path\")\n\tf.Add(\"http://user:@example.com\")\n\tf.Add(\"http://:password@example.com\")\n\tf.Add(\"http://[invalid-ipv6]/path\")\n\tf.Add(\"http://example.com\\x00/path\")\n\tf.Add(strings.Repeat(\"a\", 10000))\n\tf.Add(\"http://example.com?\" + strings.Repeat(\"a=b&\", 1000))\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Test 1: Ensure no panics occur during parsing\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"URL parsing panicked with input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Parse the URL\n\t\tparsedURL, err := url.Parse(input)\n\n\t\t// If parsing succeeded, perform validation checks\n\t\tif err == nil {\n\t\t\t// Test 2: Verify the parsed URL can be converted back to string\n\t\t\turlString := parsedURL.String()\n\t\t\tif urlString == \"\" && input != \"\" {\n\t\t\t\tt.Errorf(\"Parsed URL string is empty for non-empty input: %q\", input)\n\t\t\t}\n\n\t\t\t// Test 3: Verify re-parsing produces consistent results\n\t\t\treparsedURL, reparsErr := url.Parse(urlString)\n\t\t\tif reparsErr != nil {\n\t\t\t\tt.Errorf(\"Re-parsing failed for URL %q (original: %q): %v\", urlString, input, reparsErr)\n\t\t\t} else {\n\t\t\t\t// Check key components match\n\t\t\t\tif reparsedURL.Scheme != parsedURL.Scheme {\n\t\t\t\t\tt.Errorf(\"Scheme mismatch after re-parse: got %q, want %q\", reparsedURL.Scheme, parsedURL.Scheme)\n\t\t\t\t}\n\t\t\t\tif reparsedURL.Host != parsedURL.Host {\n\t\t\t\t\tt.Errorf(\"Host mismatch after re-parse: got %q, want %q\", reparsedURL.Host, parsedURL.Host)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 4: Verify URL components are valid UTF-8\n\t\t\tif !utf8.ValidString(parsedURL.Scheme) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in scheme: %q\", parsedURL.Scheme)\n\t\t\t}\n\t\t\tif !utf8.ValidString(parsedURL.Host) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in host: %q\", parsedURL.Host)\n\t\t\t}\n\t\t\tif !utf8.ValidString(parsedURL.Path) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in path: %q\", parsedURL.Path)\n\t\t\t}\n\n\t\t\t// Test 5: Verify hostname extraction doesn't panic\n\t\t\thostname := parsedURL.Hostname()\n\t\t\tif hostname != \"\" && !utf8.ValidString(hostname) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in hostname: %q\", hostname)\n\t\t\t}\n\n\t\t\t// Test 6: Verify port extraction doesn't panic\n\t\t\tport := parsedURL.Port()\n\t\t\tif port != \"\" {\n\t\t\t\t// Port should be numeric if present\n\t\t\t\tfor _, c := range port {\n\t\t\t\t\tif c < '0' || c > '9' {\n\t\t\t\t\t\tt.Errorf(\"Non-numeric port: %q\", port)\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 7: Verify query parsing doesn't panic\n\t\t\tquery := parsedURL.Query()\n\t\t\tfor key, values := range query {\n\t\t\t\tif !utf8.ValidString(key) {\n\t\t\t\t\tt.Errorf(\"Invalid UTF-8 in query key: %q\", key)\n\t\t\t\t}\n\t\t\t\tfor _, value := range values {\n\t\t\t\t\tif !utf8.ValidString(value) {\n\t\t\t\t\t\tt.Errorf(\"Invalid UTF-8 in query value: %q\", value)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 8: Verify RequestURI doesn't panic\n\t\t\trequestURI := parsedURL.RequestURI()\n\t\t\tif !utf8.ValidString(requestURI) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in RequestURI: %q\", requestURI)\n\t\t\t}\n\n\t\t\t// Test 9: Verify User info doesn't panic\n\t\t\tif parsedURL.User != nil {\n\t\t\t\tusername := parsedURL.User.Username()\n\t\t\t\tif !utf8.ValidString(username) {\n\t\t\t\t\tt.Errorf(\"Invalid UTF-8 in username: %q\", username)\n\t\t\t\t}\n\t\t\t\tpassword, _ := parsedURL.User.Password()\n\t\t\t\tif !utf8.ValidString(password) {\n\t\t\t\t\tt.Errorf(\"Invalid UTF-8 in password: %q\", password)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 10: Verify EscapedPath doesn't panic\n\t\t\tescapedPath := parsedURL.EscapedPath()\n\t\t\tif !utf8.ValidString(escapedPath) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in escaped path: %q\", escapedPath)\n\t\t\t}\n\n\t\t\t// Test 11: Verify IsAbs is consistent\n\t\t\tisAbs := parsedURL.IsAbs()\n\t\t\thasScheme := parsedURL.Scheme != \"\"\n\t\t\tif isAbs && !hasScheme {\n\t\t\t\tt.Errorf(\"URL reported as absolute but has no scheme\")\n\t\t\t}\n\n\t\t\t// Test 12: Test ResolveReference doesn't panic\n\t\t\tbaseURL, baseErr := url.Parse(\"http://example.com/base/path\")\n\t\t\tif baseErr == nil {\n\t\t\t\tresolved := baseURL.ResolveReference(parsedURL)\n\t\t\t\tif resolved == nil {\n\t\t\t\t\tt.Errorf(\"ResolveReference returned nil\")\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 13: Verify Redacted doesn't panic\n\t\t\tredacted := parsedURL.Redacted()\n\t\t\tif !utf8.ValidString(redacted) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in redacted URL: %q\", redacted)\n\t\t\t}\n\t\t}\n\n\t\t// Test 14: Test ParseRequestURI separately (stricter parsing)\n\t\t_, parseReqErr := url.ParseRequestURI(input)\n\t\t// Just ensure it doesn't panic; errors are expected for many inputs\n\n\t\t// Test 15: Test QueryUnescape on the input\n\t\tunescaped, unescapeErr := url.QueryUnescape(input)\n\t\tif unescapeErr == nil && !utf8.ValidString(unescaped) {\n\t\t\tt.Errorf(\"QueryUnescape produced invalid UTF-8: %q\", unescaped)\n\t\t}\n\n\t\t// Test 16: Test PathUnescape on the input\n\t\tpathUnescaped, pathUnescapeErr := url.PathUnescape(input)\n\t\tif pathUnescapeErr == nil && !utf8.ValidString(pathUnescaped) {\n\t\t\tt.Errorf(\"PathUnescape produced invalid UTF-8: %q\", pathUnescaped)\n\t\t}\n\n\t\t// Suppress unused variable warnings\n\t\t_ = parseReqErr\n\t\t_ = pathUnescaped\n\t\t_ = pathUnescapeErr\n\t})\n}\n\n// FuzzURLQueryParsing specifically tests query string parsing\nfunc FuzzURLQueryParsing(f *testing.F) {\n\t// Seed corpus for query strings\n\tf.Add(\"key=value\")\n\tf.Add(\"key1=value1&key2=value2\")\n\tf.Add(\"key=value%20with%20spaces\")\n\tf.Add(\"key=value&key=value2\")\n\tf.Add(\"key=\")\n\tf.Add(\"=value\")\n\tf.Add(\"key\")\n\tf.Add(\"key1=value1&key2=value2&key3=value3\")\n\tf.Add(\"key=%00\")\n\tf.Add(strings.Repeat(\"a=b&\", 100))\n\n\tf.Fuzz(func(t *testing.T, query string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Query parsing panicked with input %q: %v\", query, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Parse query string\n\t\tvalues, err := url.ParseQuery(query)\n\t\tif err == nil {\n\t\t\t// Verify all keys and values are valid UTF-8\n\t\t\tfor key, vals := range values {\n\t\t\t\tif !utf8.ValidString(key) {\n\t\t\t\t\tt.Errorf(\"Invalid UTF-8 in query key: %q\", key)\n\t\t\t\t}\n\t\t\t\tfor _, val := range vals {\n\t\t\t\t\tif !utf8.ValidString(val) {\n\t\t\t\t\t\tt.Errorf(\"Invalid UTF-8 in query value: %q\", val)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Verify encoding back produces valid result\n\t\t\tencoded := values.Encode()\n\t\t\tif !utf8.ValidString(encoded) {\n\t\t\t\tt.Errorf(\"Encoded query string has invalid UTF-8: %q\", encoded)\n\t\t\t}\n\n\t\t\t// Verify re-parsing produces consistent results\n\t\t\treparsed, reparseErr := url.ParseQuery(encoded)\n\t\t\tif reparseErr != nil {\n\t\t\t\tt.Errorf(\"Re-parsing encoded query failed: %v\", reparseErr)\n\t\t\t} else {\n\t\t\t\t// Check that all original keys exist in reparsed\n\t\t\t\tfor key := range values {\n\t\t\t\t\tif _, exists := reparsed[key]; !exists {\n\t\t\t\t\t\tt.Errorf(\"Key %q missing after re-parse\", key)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\n// FuzzURLEscaping tests URL escaping and unescaping\nfunc FuzzURLEscaping(f *testing.F) {\n\tf.Add(\"hello world\")\n\tf.Add(\"hello%20world\")\n\tf.Add(\"hello+world\")\n\tf.Add(\"special!@#$%^&*()\")\n\tf.Add(\"unicode: \u4f60\u597d\")\n\tf.Add(\"%\")\n\tf.Add(\"%2\")\n\tf.Add(\"%ZZ\")\n\tf.Add(strings.Repeat(\"%20\", 100))\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"URL escaping panicked with input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Test QueryEscape/QueryUnescape round trip\n\t\tescaped := url.QueryEscape(input)\n\t\tif !utf8.ValidString(escaped) {\n\t\t\tt.Errorf(\"QueryEscape produced invalid UTF-8: %q\", escaped)\n\t\t}\n\n\t\tunescaped, err := url.QueryUnescape(escaped)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"QueryUnescape failed on QueryEscape output: %v\", err)\n\t\t} else if unescaped != input {\n\t\t\tt.Errorf(\"QueryEscape/QueryUnescape round trip failed: got %q, want %q\", unescaped, input)\n\t\t}\n\n\t\t// Test PathEscape/PathUnescape round trip\n\t\tpathEscaped := url.PathEscape(input)\n\t\tif !utf8.ValidString(pathEscaped) {\n\t\t\tt.Errorf(\"PathEscape produced invalid UTF-8: %q\", pathEscaped)\n\t\t}\n\n\t\tpathUnescaped, pathErr := url.PathUnescape(pathEscaped)\n\t\tif pathErr != nil {\n\t\t\tt.Errorf(\"PathUnescape failed on PathEscape output: %v\", pathErr)\n\t\t} else if pathUnescaped != input {\n\t\t\tt.Errorf(\"PathEscape/PathUnescape round trip failed: got %q, want %q\", pathUnescaped, input)\n\t\t}\n\t})\n}\n```\n\n## Running the Fuzz Tests\n\nTo run these fuzz tests, use the following commands:\n\n```bash\n# Run the main URL parser fuzzer for 30 seconds\ngo test -fuzz=FuzzURLParser -fuzztime=30s\n\n# Run the query parsing fuzzer\ngo test -fuzz=FuzzURLQueryParsing -fuzztime=30s\n\n# Run the escaping fuzzer\ngo test -fuzz=FuzzURLEscaping -fuzztime=30s\n\n# Run with a specific timeout and parallel workers\ngo test -fuzz=FuzzURLParser -fuzztime=1m -parallel=4\n\n# Run until a failure is found\ngo test -fuzz=FuzzURLParser\n```\n\n## Key Features\n\n1. **Panic Detection**: All tests use `defer/recover` to catch panics\n2. **Round-trip Testing**: Verifies that parsing and re-serializing produces consistent results\n3. **UTF-8 Validation**: Ensures all string outputs are valid UTF-8\n4. **Component Validation**: Tests individual URL components (scheme, host, port, path, query, etc.)\n5. **Edge Cases**: Includes seeds for malformed URLs, special characters, and boundary conditions\n6. **Multiple Test Functions**: Separate fuzzers for different aspects of URL handling\n\nThis comprehensive fuzz test suite will help identify bugs, panics, and inconsistencies in URL parsing implementations.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 59,
            "output_tokens": 3593,
            "cached": false
          },
          "with_skill": {
            "output": "# Go Native Fuzzing for URL Parser\n\nHere's a comprehensive fuzz test for a URL parser library using Go's native `testing.F` framework:\n\n## Complete Example\n\n```go\npackage urlparser_test\n\nimport (\n\t\"net/url\"\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\n// FuzzURLParser tests URL parsing with various malformed inputs\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with interesting test cases\n\tf.Add(\"https://example.com\")\n\tf.Add(\"http://user:pass@host:8080/path?query=value#fragment\")\n\tf.Add(\"//example.com/path\")\n\tf.Add(\"mailto:user@example.com\")\n\tf.Add(\"file:///path/to/file\")\n\tf.Add(\"ftp://ftp.example.com\")\n\tf.Add(\"http://[::1]:8080\")\n\tf.Add(\"http://192.168.1.1\")\n\t\n\t// Edge cases and malformed inputs\n\tf.Add(\"\")\n\tf.Add(\":\")\n\tf.Add(\"://\")\n\tf.Add(\"http://\")\n\tf.Add(\"http://@\")\n\tf.Add(\"http://:@\")\n\tf.Add(\"http://user:@host\")\n\tf.Add(\"http://:pass@host\")\n\tf.Add(\"http://host:99999\")\n\tf.Add(\"http://host:-1\")\n\tf.Add(\"http://host:abc\")\n\tf.Add(\"http://[invalid-ipv6]\")\n\tf.Add(\"http://host/path with spaces\")\n\tf.Add(\"http://host\\x00path\")\n\tf.Add(strings.Repeat(\"a\", 10000))\n\tf.Add(\"http://\" + strings.Repeat(\"a\", 1000) + \".com\")\n\tf.Add(\"http://host?\" + strings.Repeat(\"a=b&\", 1000))\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Test 1: Parsing should never panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"url.Parse panicked on input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\t\t\n\t\tparsed, err := url.Parse(input)\n\t\t\n\t\t// If parsing succeeded, validate the result\n\t\tif err == nil {\n\t\t\tvalidateParsedURL(t, input, parsed)\n\t\t} else {\n\t\t\t// If parsing failed, ensure error is reasonable\n\t\t\tvalidateParseError(t, input, err)\n\t\t}\n\t\t\n\t\t// Test 2: ParseRequestURI should handle HTTP URLs\n\t\tif strings.HasPrefix(input, \"http://\") || strings.HasPrefix(input, \"https://\") {\n\t\t\ttestParseRequestURI(t, input)\n\t\t}\n\t\t\n\t\t// Test 3: Round-trip test - if parsing succeeds, String() should work\n\t\tif err == nil && parsed != nil {\n\t\t\ttestRoundTrip(t, input, parsed)\n\t\t}\n\t\t\n\t\t// Test 4: Query parsing should never panic\n\t\ttestQueryParsing(t, input)\n\t})\n}\n\n// validateParsedURL checks that parsed URL has consistent properties\nfunc validateParsedURL(t *testing.T, input string, parsed *url.URL) {\n\t// Check that Scheme is lowercase if present\n\tif parsed.Scheme != \"\" && parsed.Scheme != strings.ToLower(parsed.Scheme) {\n\t\tt.Errorf(\"Scheme should be lowercase: got %q\", parsed.Scheme)\n\t}\n\t\n\t// Check that Host doesn't contain invalid characters\n\tif parsed.Host != \"\" {\n\t\tif strings.ContainsAny(parsed.Host, \" \\t\\n\\r\") {\n\t\t\tt.Errorf(\"Host contains whitespace: %q\", parsed.Host)\n\t\t}\n\t}\n\t\n\t// Check that Port is valid if present\n\tif port := parsed.Port(); port != \"\" {\n\t\t// Port should be numeric\n\t\tfor _, c := range port {\n\t\t\tif c < '0' || c > '9' {\n\t\t\t\tt.Errorf(\"Port contains non-numeric character: %q\", port)\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Check that Path is valid UTF-8\n\tif !utf8.ValidString(parsed.Path) {\n\t\tt.Errorf(\"Path is not valid UTF-8: %q\", parsed.Path)\n\t}\n\t\n\t// Check that RawQuery is valid UTF-8\n\tif !utf8.ValidString(parsed.RawQuery) {\n\t\tt.Errorf(\"RawQuery is not valid UTF-8: %q\", parsed.RawQuery)\n\t}\n\t\n\t// Check that Fragment is valid UTF-8\n\tif !utf8.ValidString(parsed.Fragment) {\n\t\tt.Errorf(\"Fragment is not valid UTF-8: %q\", parsed.Fragment)\n\t}\n\t\n\t// If URL has userinfo, validate it\n\tif parsed.User != nil {\n\t\tusername := parsed.User.Username()\n\t\tif !utf8.ValidString(username) {\n\t\t\tt.Errorf(\"Username is not valid UTF-8: %q\", username)\n\t\t}\n\t\t\n\t\tif password, ok := parsed.User.Password(); ok {\n\t\t\tif !utf8.ValidString(password) {\n\t\t\t\tt.Errorf(\"Password is not valid UTF-8: %q\", password)\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Hostname should not panic\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"Hostname() panicked: %v\", r)\n\t\t}\n\t}()\n\thostname := parsed.Hostname()\n\t\n\t// Hostname should be valid UTF-8\n\tif !utf8.ValidString(hostname) {\n\t\tt.Errorf(\"Hostname is not valid UTF-8: %q\", hostname)\n\t}\n}\n\n// validateParseError ensures error messages are reasonable\nfunc validateParseError(t *testing.T, input string, err error) {\n\t// Error message should not be empty\n\tif err.Error() == \"\" {\n\t\tt.Errorf(\"Parse error has empty message for input %q\", input)\n\t}\n\t\n\t// Error message should be valid UTF-8\n\tif !utf8.ValidString(err.Error()) {\n\t\tt.Errorf(\"Error message is not valid UTF-8: %q\", err.Error())\n\t}\n}\n\n// testParseRequestURI tests ParseRequestURI for HTTP URLs\nfunc testParseRequestURI(t *testing.T, input string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"ParseRequestURI panicked on input %q: %v\", input, r)\n\t\t}\n\t}()\n\t\n\tparsed, err := url.ParseRequestURI(input)\n\t\n\t// If successful, validate basic properties\n\tif err == nil && parsed != nil {\n\t\t// RequestURI should have a scheme\n\t\tif parsed.Scheme == \"\" {\n\t\t\tt.Errorf(\"ParseRequestURI returned URL without scheme\")\n\t\t}\n\t\t\n\t\t// Should be http or https\n\t\tif parsed.Scheme != \"http\" && parsed.Scheme != \"https\" {\n\t\t\tt.Errorf(\"ParseRequestURI returned non-HTTP scheme: %q\", parsed.Scheme)\n\t\t}\n\t}\n}\n\n// testRoundTrip verifies that String() produces valid output\nfunc testRoundTrip(t *testing.T, input string, parsed *url.URL) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"String() panicked: %v\", r)\n\t\t}\n\t}()\n\t\n\t// Get string representation\n\toutput := parsed.String()\n\t\n\t// Output should be valid UTF-8\n\tif !utf8.ValidString(output) {\n\t\tt.Errorf(\"String() output is not valid UTF-8: %q\", output)\n\t}\n\t\n\t// Try parsing the output\n\treparsed, err := url.Parse(output)\n\tif err != nil {\n\t\tt.Errorf(\"Failed to reparse String() output %q: %v\", output, err)\n\t\treturn\n\t}\n\t\n\t// Key properties should match\n\tif reparsed.Scheme != parsed.Scheme {\n\t\tt.Errorf(\"Scheme mismatch after round-trip: %q != %q\", \n\t\t\treparsed.Scheme, parsed.Scheme)\n\t}\n\t\n\tif reparsed.Host != parsed.Host {\n\t\tt.Errorf(\"Host mismatch after round-trip: %q != %q\",\n\t\t\treparsed.Host, parsed.Host)\n\t}\n}\n\n// testQueryParsing tests query string parsing\nfunc testQueryParsing(t *testing.T, input string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"Query parsing panicked on input %q: %v\", input, r)\n\t\t}\n\t}()\n\t\n\t// Try parsing as query string\n\tvalues, err := url.ParseQuery(input)\n\t\n\tif err == nil {\n\t\t// Validate parsed values\n\t\tfor key, vals := range values {\n\t\t\t// Keys should be valid UTF-8\n\t\t\tif !utf8.ValidString(key) {\n\t\t\t\tt.Errorf(\"Query key is not valid UTF-8: %q\", key)\n\t\t\t}\n\t\t\t\n\t\t\t// Values should be valid UTF-8\n\t\t\tfor _, val := range vals {\n\t\t\t\tif !utf8.ValidString(val) {\n\t\t\t\t\tt.Errorf(\"Query value is not valid UTF-8: %q\", val)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Encode should not panic\n\t\tencoded := values.Encode()\n\t\tif !utf8.ValidString(encoded) {\n\t\t\tt.Errorf(\"Encoded query is not valid UTF-8: %q\", encoded)\n\t\t}\n\t}\n}\n\n// FuzzURLEscape tests URL escaping functions\nfunc FuzzURLEscape(f *testing.F) {\n\t// Seed corpus\n\tf.Add(\"hello world\")\n\tf.Add(\"user@example.com\")\n\tf.Add(\"a=b&c=d\")\n\tf.Add(\"/path/to/resource\")\n\tf.Add(\"hello\\x00world\")\n\tf.Add(strings.Repeat(\"a\", 1000))\n\tf.Add(\"\u65e5\u672c\u8a9e\")\n\tf.Add(\"emoji\ud83c\udf89test\")\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// PathEscape should never panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"PathEscape panicked on input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\t\t\n\t\tescaped := url.PathEscape(input)\n\t\t\n\t\t// Escaped output should be valid UTF-8\n\t\tif !utf8.ValidString(escaped) {\n\t\t\tt.Errorf(\"PathEscape output is not valid UTF-8: %q\", escaped)\n\t\t}\n\t\t\n\t\t// Unescape should work\n\t\tunescaped, err := url.PathUnescape(escaped)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"PathUnescape failed on escaped input: %v\", err)\n\t\t} else if unescaped != input {\n\t\t\tt.Errorf(\"Round-trip failed: %q != %q\", unescaped, input)\n\t\t}\n\t\t\n\t\t// QueryEscape should never panic\n\t\tqueryEscaped := url.QueryEscape(input)\n\t\tif !utf8.ValidString(queryEscaped) {\n\t\t\tt.Errorf(\"QueryEscape output is not valid UTF-8: %q\", queryEscaped)\n\t\t}\n\t\t\n\t\t// QueryUnescape should work\n\t\tqueryUnescaped, err := url.QueryUnescape(queryEscaped)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"QueryUnescape failed: %v\", err)\n\t\t} else if queryUnescaped != input {\n\t\t\tt.Errorf(\"Query round-trip failed: %q != %q\", queryUnescaped, input)\n\t\t}\n\t})\n}\n\n// FuzzURLJoin tests URL joining/resolution\nfunc FuzzURLJoin(f *testing.F) {\n\t// Seed corpus with base and reference pairs\n\tf.Add(\"http://example.com/path\", \"other\")\n\tf.Add(\"http://example.com/path/\", \"../other\")\n\tf.Add(\"http://example.com\", \"/absolute\")\n\tf.Add(\"http://example.com/a/b\", \"../../c\")\n\tf.Add(\"http://example.com\", \"//other.com/path\")\n\tf.Add(\"http://example.com\", \"http://other.com\")\n\t\n\tf.Fuzz(func(t *testing.T, base, ref string) {\n\t\t// Parse base URL\n\t\tbaseURL, err := url.Parse(base)\n\t\tif err != nil {\n\t\t\treturn // Skip invalid base URLs\n\t\t}\n\t\t\n\t\t// Parse reference URL\n\t\trefURL, err := url.Parse(ref)\n\t\tif err != nil {\n\t\t\treturn // Skip invalid reference URLs\n\t\t}\n\t\t\n\t\t// ResolveReference should never panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"ResolveReference panicked with base=%q ref=%q: %v\",\n\t\t\t\t\tbase, ref, r)\n\t\t\t}\n\t\t}()\n\t\t\n\t\tresolved := baseURL.ResolveReference(refURL)\n\t\t\n\t\t// Resolved URL should be valid\n\t\tif resolved != nil {\n\t\t\tvalidateParsedURL(t, base+\" + \"+ref, resolved)\n\t\t\t\n\t\t\t// String() should work\n\t\t\toutput := resolved.String()\n\t\t\tif !utf8.ValidString(output) {\n\t\t\t\tt.Errorf(\"Resolved URL String() is not valid UTF-8: %q\", output)\n\t\t\t}\n\t\t}\n\t})\n}\n```\n\n## Running the Fuzz Tests\n\n### Basic Fuzzing\n\n```bash\n# Fuzz URL parsing (default 30 seconds)\ngo test -fuzz=FuzzURLParser\n\n# Fuzz for specific duration\ngo test -fuzz=FuzzURLParser -fuzztime=5m\n\n# Fuzz with specific number of iterations\ngo test -fuzz=FuzzURLParser -fuzztime=100000x\n\n# Fuzz URL escaping\ngo test -fuzz=FuzzURLEscape -fuzztime=1m\n\n# Fuzz URL joining\ngo test -fuzz=FuzzURLJoin -fuzztime=1m\n```\n\n### Running All Tests\n\n```bash\n# Run all fuzz tests sequentially\ngo test -fuzz=FuzzURLParser -fuzztime=1m\ngo test -fuzz=FuzzURLEscape -fuzztime=1m\ngo test -fuzz=FuzzURLJoin -fuzztime=1m\n\n# Or use a script\nfor fuzz in FuzzURLParser FuzzURLEscape FuzzURLJoin; do\n    echo \"Fuzzing $fuzz...\"\n    go test -fuzz=$fuzz -fuzztime=30s\ndone\n```\n\n### Reproducing Crashes\n\n```bash\n# If fuzzing finds a crash, it saves to testdata/fuzz/\n# Reproduce with:\ngo test -run=FuzzURLParser\n\n# Or run specific failing input:\ngo test -run=FuzzURLParser/[hash]\n```\n\n## Key Features\n\n### 1. Panic Detection\nEvery test uses `defer recover()` to catch panics:\n```go\ndefer func() {\n    if r := recover(); r != nil {\n        t.Errorf(\"Function panicked: %v\", r)\n    }\n}()\n```\n\n### 2. Property-Based Validation\nTests verify invariants like:\n- Schemes are lowercase\n- Ports are numeric\n- All strings are valid UTF-8\n- No whitespace in hosts\n\n### 3. Round-Trip Testing\n```go\n// Parse \u2192 String() \u2192 Parse should be consistent\noutput := parsed.String()\nreparsed, _ := url.Parse(output)\n// Verify key properties match\n```\n\n### 4. Multiple Fuzzing Targets\n- `FuzzURLParser` - Main URL parsing\n- `FuzzURLEscape` - Escape/unescape functions\n- `FuzzURLJoin` - URL resolution\n\n## Corpus Management\n\n### Viewing Corpus\n\n```bash\n# Corpus is stored in testdata/fuzz/\nls testdata/fuzz/FuzzURLParser/\n\n# View a specific input\ncat testdata/fuzz/FuzzURLParser/[hash]\n```\n\n### Adding Seed Inputs\n\n```bash\n# Create testdata directory\nmkdir",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5005,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive fuzz test for URL parsing. Since I don't see an existing URL parser library in the project, I'll create both a simple URL parser and a fuzz test for it.\n\n```go\n// internal/urlparser/parser.go\npackage urlparser\n\nimport (\n\t\"errors\"\n\t\"strings\"\n)\n\nvar (\n\tErrInvalidURL    = errors.New(\"invalid URL\")\n\tErrEmptyURL      = errors.New(\"empty URL\")\n\tErrInvalidScheme = errors.New(\"invalid scheme\")\n)\n\n// URL represents a parsed URL\ntype URL struct {\n\tScheme   string\n\tHost     string\n\tPort     string\n\tPath     string\n\tQuery    string\n\tFragment string\n}\n\n// Parse parses a URL string into its components\nfunc Parse(rawURL string) (*URL, error) {\n\tif rawURL == \"\" {\n\t\treturn nil, ErrEmptyURL\n\t}\n\n\turl := &URL{}\n\tremaining := rawURL\n\n\t// Extract scheme\n\tif idx := strings.Index(remaining, \"://\"); idx != -1 {\n\t\turl.Scheme = remaining[:idx]\n\t\tif url.Scheme == \"\" || !isValidScheme(url.Scheme) {\n\t\t\treturn nil, ErrInvalidScheme\n\t\t}\n\t\tremaining = remaining[idx+3:]\n\t}\n\n\t// Extract fragment\n\tif idx := strings.Index(remaining, \"#\"); idx != -1 {\n\t\turl.Fragment = remaining[idx+1:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract query\n\tif idx := strings.Index(remaining, \"?\"); idx != -1 {\n\t\turl.Query = remaining[idx+1:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract path\n\tif idx := strings.Index(remaining, \"/\"); idx != -1 {\n\t\turl.Path = remaining[idx:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract host and port\n\tif remaining != \"\" {\n\t\tif idx := strings.LastIndex(remaining, \":\"); idx != -1 {\n\t\t\turl.Host = remaining[:idx]\n\t\t\turl.Port = remaining[idx+1:]\n\t\t} else {\n\t\t\turl.Host = remaining\n\t\t}\n\t}\n\n\treturn url, nil\n}\n\n// isValidScheme checks if a scheme contains only valid characters\nfunc isValidScheme(scheme string) bool {\n\tif scheme == \"\" {\n\t\treturn false\n\t}\n\tfor i, c := range scheme {\n\t\tif i == 0 {\n\t\t\tif !isAlpha(c) {\n\t\t\t\treturn false\n\t\t\t}\n\t\t} else {\n\t\t\tif !isAlpha(c) && !isDigit(c) && c != '+' && c != '-' && c != '.' {\n\t\t\t\treturn false\n\t\t\t}\n\t\t}\n\t}\n\treturn true\n}\n\nfunc isAlpha(c rune) bool {\n\treturn (c >= 'a' && c <= 'z') || (c >= 'A' && c <= 'Z')\n}\n\nfunc isDigit(c rune) bool {\n\treturn c >= '0' && c <= '9'\n}\n\n// String reconstructs the URL string\nfunc (u *URL) String() string {\n\tvar sb strings.Builder\n\n\tif u.Scheme != \"\" {\n\t\tsb.WriteString(u.Scheme)\n\t\tsb.WriteString(\"://\")\n\t}\n\n\tif u.Host != \"\" {\n\t\tsb.WriteString(u.Host)\n\t}\n\n\tif u.Port != \"\" {\n\t\tsb.WriteString(\":\")\n\t\tsb.WriteString(u.Port)\n\t}\n\n\tif u.Path != \"\" {\n\t\tsb.WriteString(u.Path)\n\t}\n\n\tif u.Query != \"\" {\n\t\tsb.WriteString(\"?\")\n\t\tsb.WriteString(u.Query)\n\t}\n\n\tif u.Fragment != \"\" {\n\t\tsb.WriteString(\"#\")\n\t\tsb.WriteString(u.Fragment)\n\t}\n\n\treturn sb.String()\n}\n```\n\n```go\n// internal/urlparser/parser_fuzz_test.go\npackage urlparser\n\nimport (\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with valid and edge case URLs\n\tseeds := []string{\n\t\t\"http://example.com\",\n\t\t\"https://example.com:8080/path\",\n\t\t\"https://example.com/path?query=value\",\n\t\t\"https://example.com/path?query=value#fragment\",\n\t\t\"ftp://ftp.example.com:21/file.txt\",\n\t\t\"http://user:pass@example.com\",\n\t\t\"http://192.168.1.1:8080\",\n\t\t\"http://[::1]:8080/path\",\n\t\t\"\",\n\t\t\"://example.com\",\n\t\t\"http://\",\n\t\t\"http:/example.com\",\n\t\t\"http:///path\",\n\t\t\"example.com\",\n\t\t\"/path/to/resource\",\n\t\t\"?query=value\",\n\t\t\"#fragment\",\n\t\t\"http://example.com:99999\",\n\t\t\"http://example.com:-1\",\n\t\t\"http://example.com:\",\n\t\t\"123://example.com\",\n\t\t\"ht!tp://example.com\",\n\t\t\"http://exam ple.com\",\n\t\t\"http://example..com\",\n\t\t\"http://.example.com\",\n\t\t\"http://example.com.\",\n\t\t\"http://example.com/path with spaces\",\n\t\t\"http://example.com/path?key=val&key2=val2\",\n\t\t\"http://example.com/path/../other\",\n\t\t\"http://example.com//double//slash\",\n\t\t\"http://example.com/path%20encoded\",\n\t\t\"http://example.com:8080:9090\",\n\t\t\"http://example.com::8080\",\n\t\t\"http://example.com/path?#\",\n\t\t\"http://example.com/#?\",\n\t\t\"http://example.com/path??query\",\n\t\t\"http://example.com/path##fragment\",\n\t\t\"HTTP://EXAMPLE.COM\",\n\t\t\"http://\u4f8b\u3048.jp\",\n\t\t\"http://example.com/\u30d1\u30b9\",\n\t\tstrings.Repeat(\"a\", 1000),\n\t\t\"http://\" + strings.Repeat(\"a\", 500) + \".com\",\n\t\t\"http://example.com/\" + strings.Repeat(\"p\", 500),\n\t\t\"http://example.com?\" + strings.Repeat(\"q\", 500),\n\t\t\"http://example.com#\" + strings.Repeat(\"f\", 500),\n\t}\n\n\tfor _, seed := range seeds {\n\t\tf.Add(seed)\n\t}\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Ensure we don't panic on any input\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Parse panicked on input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Test parsing\n\t\tparsed, err := Parse(input)\n\n\t\t// Basic invariants that should always hold\n\t\tif err == nil {\n\t\t\tif parsed == nil {\n\t\t\t\tt.Errorf(\"Parse returned nil URL with nil error for input %q\", input)\n\t\t\t}\n\n\t\t\t// Check for invalid UTF-8 in results\n\t\t\tif !utf8.ValidString(parsed.Scheme) {\n\t\t\t\tt.Errorf(\"Scheme contains invalid UTF-8: %q\", parsed.Scheme)\n\t\t\t}\n\t\t\tif !utf8.ValidString(parsed.Host) {\n\t\t\t\tt.Errorf(\"Host contains invalid UTF-8: %q\", parsed.Host)\n\t\t\t}\n\t\t\tif !utf8.ValidString(parsed.Port) {\n\t\t\t\tt.Errorf(\"Port contains invalid UTF-8: %q\", parsed.Port)\n\t\t\t}\n\t\t\tif !utf8.ValidString(parsed.Path) {\n\t\t\t\tt.Errorf(\"Path contains invalid UTF-8: %q\", parsed.Path)\n\t\t\t}\n\t\t\tif !utf8.ValidString(parsed.Query) {\n\t\t\t\tt.Errorf(\"Query contains invalid UTF-8: %q\", parsed.Query)\n\t\t\t}\n\t\t\tif !utf8.ValidString(parsed.Fragment) {\n\t\t\t\tt.Errorf(\"Fragment contains invalid UTF-8: %q\", parsed.Fragment)\n\t\t\t}\n\n\t\t\t// Verify scheme validity if present\n\t\t\tif parsed.Scheme != \"\" {\n\t\t\t\tif !isValidScheme(parsed.Scheme) {\n\t\t\t\t\tt.Errorf(\"Parse accepted invalid scheme %q for input %q\", parsed.Scheme, input)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test String() method doesn't panic\n\t\t\treconstructed := parsed.String()\n\t\t\tif !utf8.ValidString(reconstructed) {\n\t\t\t\tt.Errorf(\"String() returned invalid UTF-8: %q\", reconstructed)\n\t\t\t}\n\n\t\t\t// Test idempotency: parsing the reconstructed URL should not error\n\t\t\t// (though it may differ from original due to normalization)\n\t\t\treparsed, err2 := Parse(reconstructed)\n\t\t\tif err2 != nil {\n\t\t\t\tt.Errorf(\"Reparsing reconstructed URL failed: %v\\nOriginal: %q\\nReconstructed: %q\", \n\t\t\t\t\terr2, input, reconstructed)\n\t\t\t}\n\t\t\tif reparsed == nil {\n\t\t\t\tt.Errorf(\"Reparsing returned nil for reconstructed URL: %q\", reconstructed)\n\t\t\t}\n\t\t}\n\n\t\t// Test specific error conditions\n\t\tif input == \"\" && err != ErrEmptyURL {\n\t\t\tt.Errorf(\"Expected ErrEmptyURL for empty input, got: %v\", err)\n\t\t}\n\n\t\t// If input contains \"://\" but has invalid scheme, should return ErrInvalidScheme\n\t\tif strings.Contains(input, \"://\") {\n\t\t\tparts := strings.SplitN(input, \"://\", 2)\n\t\t\tif len(parts) == 2 && parts[0] != \"\" && !isValidScheme(parts[0]) {\n\t\t\t\tif err != ErrInvalidScheme {\n\t\t\t\t\tt.Errorf(\"Expected ErrInvalidScheme for input %q with invalid scheme %q, got: %v\", \n\t\t\t\t\t\tinput, parts[0], err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\n\t\t// Test that parsing is deterministic\n\t\tparsed2, err2 := Parse(input)\n\t\tif (err == nil) != (err2 == nil) {\n\t\t\tt.Errorf(\"Non-deterministic error result for input %q: first=%v, second=%v\", \n\t\t\t\tinput, err, err2)\n\t\t}\n\t\tif err == nil && err2 == nil {\n\t\t\tif parsed.Scheme != parsed2.Scheme ||\n\t\t\t\tparsed.Host != parsed2.Host ||\n\t\t\t\tparsed.Port != parsed2.Port ||\n\t\t\t\tparsed.Path != parsed2.Path ||\n\t\t\t\tparsed.Query != parsed2.Query ||\n\t\t\t\tparsed.Fragment != parsed2.Fragment {\n\t\t\t\tt.Errorf(\"Non-deterministic parse result for input %q\", input)\n\t\t\t}\n\t\t}\n\t})\n}\n\n// FuzzURLParserComponents tests individual component extraction\nfunc FuzzURLParserComponents(f *testing.F) {\n\t// Seed with component-focused inputs\n\tf.Add(\"http\", \"example.com\", \"8080\", \"/path\", \"query=1\", \"frag\")\n\tf.Add(\"https\", \"localhost\", \"\", \"/\", \"\", \"\")\n\tf.Add(\"\", \"\", \"\", \"\", \"\", \"\")\n\tf.Add(\"ftp\", \"192.168.1.1\", \"21\", \"/file.txt\", \"\", \"\")\n\n\tf.Fuzz(func(t *testing.T, scheme, host, port, path, query, fragment string) {\n\t\t// Build a URL from components\n\t\tvar sb strings.Builder\n\t\tif scheme != \"\" {\n\t\t\tsb.WriteString(scheme)\n\t\t\tsb.WriteString(\"://\")\n\t\t}\n\t\tif host != \"\" {\n\t\t\tsb.WriteString(host)\n\t\t}\n\t\tif port != \"\" {\n\t\t\tsb.WriteString(\":\")\n\t\t\tsb.WriteString(port)\n\t\t}\n\t\tif path != \"\" {\n\t\t\tsb.WriteString(path)\n\t\t}\n\t\tif query != \"\" {\n\t\t\tsb.WriteString(\"?\")\n\t\t\tsb.WriteString(query)\n\t\t}\n\t\tif fragment != \"\" {\n\t\t\tsb.WriteString(\"#\")\n\t\t\tsb.WriteString(fragment)\n\t\t}\n\n\t\tinput := sb.String()\n\n\t\t// Ensure no panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Parse panicked on constructed input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\tparsed, err := Parse(input)\n\t\tif err != nil {\n\t\t\t// It's okay to error on malformed input\n\t\t\treturn\n\t\t}\n\n\t\t// If parsing succeeded, verify components are reasonable\n\t\tif parsed.Scheme != \"\" && scheme != \"\" {\n\t\t\t// Scheme should match if it was valid\n\t\t\tif isValidScheme(scheme) && parsed.Scheme != scheme {\n\t\t\t\tt.Errorf(\"Scheme mismatch: expected %q, got %q\", scheme, parsed.Scheme)\n\t\t\t}\n\t\t}\n\n\t\t// Host should be preserved if present\n\t\tif host != \"\" && parsed.Host == \"\" && scheme != \"\" {\n\t\t\tt.Errorf(\"Host was lost during parsing: input=%q\", input)\n\t\t}\n\t})\n}\n```\n\n```go\n// internal/urlparser/parser_test.go\npackage urlparser\n\nimport (\n\t\"testing\"\n)\n\nfunc TestParseValid(t *testing.T) {\n\ttests := []struct {\n\t\tname     string\n\t\tinput    string\n\t\texpected URL\n\t}{\n\t\t{\n\t\t\tname:  \"simple http\",\n\t\t\tinput: \"http://example.com\",\n\t\t\texpected: URL{\n\t\t\t\tScheme: \"http\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"with port\",\n\t\t\tinput: \"https://example.com:8080\",\n\t\t\texpected: URL{\n\t\t\t\tScheme: \"https\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t\tPort:   \"8080\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"with path\",\n\t\t\tinput: \"https://example.com/path/to/resource\",\n\t\t\texpected: URL{\n\t\t\t\tScheme: \"https\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t\tPath:   \"/path/to/resource\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"full url\",\n\t\t\tinput: \"https://example.com:8080/path?query=value#fragment\",\n\t\t\texpected: URL{\n\t\t\t\tScheme:   \"https\",\n\t\t\t\tHost:     \"example.com\",\n\t\t\t\tPort:     \"8080\",\n\t\t\t\tPath:     \"/path\",\n\t\t\t\tQuery:    \"query=value\",\n\t\t\t\tFragment: \"fragment\",\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\tresult, err := Parse(tt.input)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t\t}\n\t\t\tif result.Scheme != tt.expected.Scheme {\n\t\t\t\tt.Errorf(\"Scheme: got %q, want %q\", result.Scheme, tt.expected.Scheme)\n\t\t\t}\n\t\t\tif result.Host != tt.expected.Host {\n\t\t\t\tt.Errorf(\"Host: got %q, want %q\", result.Host, tt.expected.Host)\n\t\t\t}\n\t\t\tif result.Port != tt.expected.Port {\n\t\t\t\tt.Errorf(\"Port: got %q, want %q\", result.Port, tt.expected.Port)\n\t\t\t}\n\t\t\tif result.Path != tt.expected.Path {\n\t\t\t\tt.Errorf(\"Path: got %q, want %q\", result.Path, tt.expected.Path)\n\t\t\t}\n\t\t\tif result.Query != tt.expected.Query {\n\t\t\t\tt.Errorf(\"Query: got %q, want %q\", result.Query, tt.expected.Query)\n\t\t\t}\n\t\t\tif result.Fragment != tt.expected.Fragment {\n\t\t\t\tt.Errorf(\"Fragment: got %q, want %q\", result.Fragment, tt.expected.Fragment)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestParseErrors(t *testing.T) {\n\ttests := []struct {\n\t\tname        string\n\t\tinput       string\n\t\texpectedErr error\n\t}{\n\t\t{\n\t\t\tname:        \"empty string\",\n\t\t\tinput:       \"\",\n\t\t\texpectedErr: ErrEmptyURL,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid scheme with number\",\n\t\t\tinput:       \"123://example.com\",\n\t\t\texpectedErr: ErrInvalidScheme,\n\t\t},\n\t\t{\n\t\t\tname:        \"invalid scheme with special char\",\n\t\t\tinput:       \"ht!tp://example.com\",\n\t\t\texpectedErr: ErrInvalidScheme,\n\t\t},\n\t}\n\n\tfor _, tt",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5489,
            "output_tokens": 4096,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "# Go Fuzz Test for URL Parser\n\nHere's a comprehensive fuzz test for a URL parser library using Go's native fuzzing framework:\n\n```go\npackage urlparser\n\nimport (\n\t\"net/url\"\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\n// FuzzURLParser tests URL parsing with various malformed inputs\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with interesting test cases\n\tf.Add(\"https://example.com\")\n\tf.Add(\"http://user:pass@example.com:8080/path?query=value#fragment\")\n\tf.Add(\"ftp://ftp.example.com/file.txt\")\n\tf.Add(\"mailto:test@example.com\")\n\tf.Add(\"file:///path/to/file\")\n\tf.Add(\"//example.com/path\")\n\tf.Add(\"/path/to/resource\")\n\tf.Add(\"?query=only\")\n\tf.Add(\"#fragment-only\")\n\tf.Add(\"http://[::1]:8080\")\n\tf.Add(\"http://192.168.1.1:80/path\")\n\tf.Add(\"http://example.com:99999\") // Invalid port\n\tf.Add(\"http://user@:password@example.com\") // Malformed auth\n\tf.Add(\"http://example.com/../../../etc/passwd\") // Path traversal\n\tf.Add(\"http://example.com/path with spaces\")\n\tf.Add(\"http://example.com/path%20encoded\")\n\tf.Add(\"http://example.com?a=1&b=2&a=3\") // Duplicate params\n\tf.Add(\"http://example.com?key=value%\")\n\tf.Add(\"http://exa mple.com\") // Space in host\n\tf.Add(\"http:/example.com\") // Missing slash\n\tf.Add(\"http:///example.com\") // Extra slash\n\tf.Add(\"http://\") // Incomplete URL\n\tf.Add(\"://example.com\") // Missing scheme\n\tf.Add(\"http://user:pa$$word@example.com\")\n\tf.Add(\"http://example.com:abc\") // Non-numeric port\n\tf.Add(strings.Repeat(\"a\", 10000)) // Very long input\n\tf.Add(\"http://\\x00example.com\") // Null byte\n\tf.Add(\"http://example.com/\\x00path\") // Null in path\n\tf.Add(\"http://\u4f8b\u3048.jp\") // Unicode domain\n\tf.Add(\"http://example.com/path?q=\\xFF\\xFE\") // Invalid UTF-8\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Test 1: Ensure parsing doesn't panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"url.Parse panicked on input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\tparsed, err := url.Parse(input)\n\n\t\t// If parsing succeeded, perform validation checks\n\t\tif err == nil && parsed != nil {\n\t\t\t// Test 2: Verify round-trip consistency\n\t\t\t// Parse -> String -> Parse should yield equivalent results\n\t\t\tstringified := parsed.String()\n\t\t\treparsed, err2 := url.Parse(stringified)\n\t\t\t\n\t\t\tif err2 != nil {\n\t\t\t\tt.Logf(\"Round-trip failed: original=%q, stringified=%q, error=%v\", \n\t\t\t\t\tinput, stringified, err2)\n\t\t\t} else if reparsed != nil {\n\t\t\t\t// Check key components match\n\t\t\t\tif parsed.Scheme != reparsed.Scheme {\n\t\t\t\t\tt.Errorf(\"Scheme mismatch after round-trip: %q vs %q\", \n\t\t\t\t\t\tparsed.Scheme, reparsed.Scheme)\n\t\t\t\t}\n\t\t\t\tif parsed.Host != reparsed.Host {\n\t\t\t\t\tt.Errorf(\"Host mismatch after round-trip: %q vs %q\", \n\t\t\t\t\t\tparsed.Host, reparsed.Host)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 3: Validate URL components\n\t\t\tvalidateURLComponents(t, input, parsed)\n\n\t\t\t// Test 4: Test URL methods don't panic\n\t\t\ttestURLMethods(t, parsed)\n\n\t\t\t// Test 5: Test query parsing\n\t\t\ttestQueryParsing(t, parsed)\n\n\t\t\t// Test 6: Test URL resolution\n\t\t\ttestURLResolution(t, parsed)\n\t\t}\n\n\t\t// Test 7: Ensure error handling is consistent\n\t\tif err != nil {\n\t\t\t// Try parsing again - should get same error\n\t\t\t_, err2 := url.Parse(input)\n\t\t\tif (err == nil) != (err2 == nil) {\n\t\t\t\tt.Errorf(\"Inconsistent error handling for %q\", input)\n\t\t\t}\n\t\t}\n\n\t\t// Test 8: Test ParseRequestURI separately (stricter validation)\n\t\ttestParseRequestURI(t, input)\n\t})\n}\n\n// validateURLComponents checks that parsed URL components are valid\nfunc validateURLComponents(t *testing.T, input string, u *url.URL) {\n\t// Check scheme is lowercase or empty\n\tif u.Scheme != \"\" && u.Scheme != strings.ToLower(u.Scheme) {\n\t\tt.Errorf(\"Scheme should be lowercase: %q in URL %q\", u.Scheme, input)\n\t}\n\n\t// Check host doesn't contain invalid characters\n\tif u.Host != \"\" {\n\t\tif strings.Contains(u.Host, \" \") {\n\t\t\tt.Logf(\"Host contains spaces: %q\", u.Host)\n\t\t}\n\t\tif strings.Contains(u.Host, \"\\x00\") {\n\t\t\tt.Errorf(\"Host contains null byte: %q\", u.Host)\n\t\t}\n\t}\n\n\t// Check path is valid UTF-8\n\tif !utf8.ValidString(u.Path) {\n\t\tt.Logf(\"Path contains invalid UTF-8: %q\", u.Path)\n\t}\n\n\t// Check port if present\n\tif port := u.Port(); port != \"\" {\n\t\t// Port should be numeric\n\t\tfor _, c := range port {\n\t\t\tif c < '0' || c > '9' {\n\t\t\t\tt.Logf(\"Port contains non-numeric character: %q\", port)\n\t\t\t\tbreak\n\t\t\t}\n\t\t}\n\t}\n\n\t// Check user info doesn't contain certain characters\n\tif u.User != nil {\n\t\tusername := u.User.Username()\n\t\tif strings.Contains(username, \"\\x00\") {\n\t\t\tt.Errorf(\"Username contains null byte\")\n\t\t}\n\t\tif password, ok := u.User.Password(); ok {\n\t\t\tif strings.Contains(password, \"\\x00\") {\n\t\t\t\tt.Errorf(\"Password contains null byte\")\n\t\t\t}\n\t\t}\n\t}\n}\n\n// testURLMethods ensures URL methods don't panic\nfunc testURLMethods(t *testing.T, u *url.URL) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"URL method panicked: %v\", r)\n\t\t}\n\t}()\n\n\t_ = u.String()\n\t_ = u.Hostname()\n\t_ = u.Port()\n\t_ = u.RequestURI()\n\t_ = u.IsAbs()\n\t_ = u.Query()\n\t_ = u.EscapedPath()\n\t_ = u.EscapedFragment()\n\t\n\tif u.User != nil {\n\t\t_ = u.User.Username()\n\t\t_, _ = u.User.Password()\n\t}\n\n\t// Test Redacted (Go 1.15+)\n\t_ = u.Redacted()\n}\n\n// testQueryParsing tests query parameter parsing\nfunc testQueryParsing(t *testing.T, u *url.URL) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"Query parsing panicked: %v\", r)\n\t\t}\n\t}()\n\n\tquery := u.Query()\n\t\n\t// Iterate over all query parameters\n\tfor key, values := range query {\n\t\tif !utf8.ValidString(key) {\n\t\t\tt.Logf(\"Query key contains invalid UTF-8: %q\", key)\n\t\t}\n\t\tfor _, value := range values {\n\t\t\tif !utf8.ValidString(value) {\n\t\t\t\tt.Logf(\"Query value contains invalid UTF-8: %q\", value)\n\t\t\t}\n\t\t}\n\t}\n\n\t// Test query encoding round-trip\n\tencoded := query.Encode()\n\treparsed, err := url.ParseQuery(encoded)\n\tif err != nil {\n\t\tt.Logf(\"Query re-parsing failed: %v\", err)\n\t} else {\n\t\t// Check that we have the same keys\n\t\tif len(query) != len(reparsed) {\n\t\t\tt.Logf(\"Query parameter count changed after round-trip: %d vs %d\",\n\t\t\t\tlen(query), len(reparsed))\n\t\t}\n\t}\n}\n\n// testURLResolution tests URL resolution with ResolveReference\nfunc testURLResolution(t *testing.T, base *url.URL) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"URL resolution panicked: %v\", r)\n\t\t}\n\t}()\n\n\t// Test resolution with various reference URLs\n\treferences := []*url.URL{\n\t\t{Path: \"/absolute/path\"},\n\t\t{Path: \"relative/path\"},\n\t\t{Path: \"../parent/path\"},\n\t\t{Scheme: \"https\", Host: \"example.com\"},\n\t\t{Fragment: \"fragment\"},\n\t\t{RawQuery: \"query=value\"},\n\t}\n\n\tfor _, ref := range references {\n\t\tresolved := base.ResolveReference(ref)\n\t\tif resolved == nil {\n\t\t\tt.Errorf(\"ResolveReference returned nil\")\n\t\t}\n\t}\n}\n\n// testParseRequestURI tests the stricter ParseRequestURI function\nfunc testParseRequestURI(t *testing.T, input string) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"url.ParseRequestURI panicked on input %q: %v\", input, r)\n\t\t}\n\t}()\n\n\tparsed, err := url.ParseRequestURI(input)\n\t\n\t// ParseRequestURI is stricter than Parse\n\tif err == nil && parsed != nil {\n\t\t// Should have absolute URI or absolute path\n\t\tif !parsed.IsAbs() && !strings.HasPrefix(input, \"/\") {\n\t\t\tt.Logf(\"ParseRequestURI accepted relative URL: %q\", input)\n\t\t}\n\n\t\t// Should be parseable by regular Parse too\n\t\tparsed2, err2 := url.Parse(input)\n\t\tif err2 != nil {\n\t\t\tt.Errorf(\"Parse failed but ParseRequestURI succeeded for %q\", input)\n\t\t} else if parsed2 != nil {\n\t\t\t// Key components should match\n\t\t\tif parsed.Scheme != parsed2.Scheme || parsed.Host != parsed2.Host {\n\t\t\t\tt.Errorf(\"Parse and ParseRequestURI disagree on %q\", input)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// FuzzURLEscape tests URL escaping/unescaping\nfunc FuzzURLEscape(f *testing.F) {\n\tf.Add(\"hello world\")\n\tf.Add(\"user@example.com\")\n\tf.Add(\"a+b=c&d\")\n\tf.Add(\"100%\")\n\tf.Add(\"%20%2F%3F\")\n\tf.Add(\"\\x00\\x01\\x02\")\n\tf.Add(\"\u65e5\u672c\u8a9e\")\n\tf.Add(strings.Repeat(\"a\", 1000))\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"URL escape/unescape panicked: %v\", r)\n\t\t\t}\n\t\t}()\n\n\t\t// Test PathEscape/PathUnescape\n\t\tescaped := url.PathEscape(input)\n\t\tunescaped, err := url.PathUnescape(escaped)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"PathUnescape failed on escaped input: %v\", err)\n\t\t} else if unescaped != input {\n\t\t\tt.Errorf(\"PathEscape round-trip failed: %q -> %q -> %q\", \n\t\t\t\tinput, escaped, unescaped)\n\t\t}\n\n\t\t// Test QueryEscape/QueryUnescape\n\t\tqueryEscaped := url.QueryEscape(input)\n\t\tqueryUnescaped, err := url.QueryUnescape(queryEscaped)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"QueryUnescape failed on escaped input: %v\", err)\n\t\t} else if queryUnescaped != input {\n\t\t\tt.Errorf(\"QueryEscape round-trip failed: %q -> %q -> %q\",\n\t\t\t\tinput, queryEscaped, queryUnescaped)\n\t\t}\n\n\t\t// Test unescaping potentially malformed input\n\t\t_, _ = url.PathUnescape(input)\n\t\t_, _ = url.QueryUnescape(input)\n\t})\n}\n```\n\n## Running the Fuzz Tests\n\n```bash\n# Run the URL parser fuzz test\ngo test -fuzz=FuzzURLParser -fuzztime=30s\n\n# Run with more time\ngo test -fuzz=FuzzURLParser -fuzztime=5m\n\n# Run the escape/unescape fuzz test\ngo test -fuzz=FuzzURLEscape -fuzztime=30s\n\n# Run with parallel workers\ngo test -fuzz=FuzzURLParser -parallel=8\n\n# View coverage\ngo test -fuzz=FuzzURLParser -fuzztime=10s -coverprofile=coverage.out\ngo tool cover -html=coverage.out\n```\n\n## Example Test File Structure\n\n```\nurlparser/\n\u251c\u2500\u2500 parser.go          # Your URL parser implementation\n\u251c\u2500\u2500 parser_test.go     # Regular unit tests\n\u2514\u2500\u2500 fuzz_test.go       # This fuzz test file\n```\n\n## Key Features\n\n1. **Panic Detection**: Catches any panics during parsing\n2. **Round-trip Testing**: Ensures Parse -> String -> Parse consistency\n3. **Component Validation**: Validates individual URL components\n4. **Method Safety**: Tests all URL methods for panics\n5. **Query Parsing**: Tests query parameter handling\n6. **URL Resolution**: Tests ResolveReference functionality\n7. **Escape/Unescape**: Tests encoding round-trips\n8. **Edge Cases**: Includes malformed URLs, special characters, and boundary conditions\n\nThis fuzz test will help discover bugs, panics, and inconsistencies in URL parsing implementations!",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 59,
            "output_tokens": 3567,
            "cached": false
          },
          "with_skill": {
            "output": "# Go Native Fuzzing for URL Parser\n\nHere's a comprehensive fuzz test for a URL parser library using Go's native `testing.F` framework:\n\n## Complete Example\n\n```go\npackage urlparser_test\n\nimport (\n\t\"net/url\"\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\n// FuzzURLParser tests URL parsing with various malformed inputs\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with interesting test cases\n\tf.Add(\"https://example.com\")\n\tf.Add(\"http://user:pass@host:8080/path?query=value#fragment\")\n\tf.Add(\"//example.com/path\")\n\tf.Add(\"mailto:test@example.com\")\n\tf.Add(\"file:///path/to/file\")\n\tf.Add(\"ftp://ftp.example.com\")\n\tf.Add(\"http://[::1]:8080\")\n\tf.Add(\"http://192.168.1.1:80\")\n\t\n\t// Edge cases and malformed inputs\n\tf.Add(\"\")\n\tf.Add(\":\")\n\tf.Add(\"://\")\n\tf.Add(\"http://\")\n\tf.Add(\"http://?query\")\n\tf.Add(\"http://#fragment\")\n\tf.Add(\"http://user@\")\n\tf.Add(\"http://:password@host\")\n\tf.Add(\"http://host:99999\")\n\tf.Add(\"http://host:-1\")\n\tf.Add(\"http://host:abc\")\n\tf.Add(\"http://[invalid-ipv6]\")\n\tf.Add(\"http://host/path with spaces\")\n\tf.Add(\"http://host\\x00/path\")\n\tf.Add(\"http://\\n\\r\\t\")\n\tf.Add(strings.Repeat(\"a\", 10000)) // Very long input\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Test 1: Ensure parsing doesn't panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"url.Parse panicked on input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\t\t\n\t\tparsed, err := url.Parse(input)\n\t\t\n\t\t// Test 2: Valid UTF-8 input should not cause errors in most cases\n\t\tif utf8.ValidString(input) && len(input) < 2048 {\n\t\t\t// We can parse most valid UTF-8 strings, though they may not be valid URLs\n\t\t\tif parsed == nil && err == nil {\n\t\t\t\tt.Errorf(\"url.Parse returned nil URL and nil error for input %q\", input)\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Test 3: If parsing succeeded, verify basic invariants\n\t\tif err == nil && parsed != nil {\n\t\t\t// Test round-trip: String() should produce a parseable URL\n\t\t\tstringified := parsed.String()\n\t\t\treparsed, err := url.Parse(stringified)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"Round-trip failed: parsed.String() produced unparseable URL\\nOriginal: %q\\nStringified: %q\\nError: %v\",\n\t\t\t\t\tinput, stringified, err)\n\t\t\t}\n\t\t\t\n\t\t\t// Test idempotency: parsing the stringified version should produce equivalent result\n\t\t\tif reparsed != nil && parsed.String() != reparsed.String() {\n\t\t\t\tt.Errorf(\"Round-trip not idempotent\\nOriginal: %q\\nFirst parse: %q\\nSecond parse: %q\",\n\t\t\t\t\tinput, parsed.String(), reparsed.String())\n\t\t\t}\n\t\t\t\n\t\t\t// Test 4: Verify component consistency\n\t\t\tverifyURLComponents(t, input, parsed)\n\t\t}\n\t\t\n\t\t// Test 5: ParseRequestURI should be more strict\n\t\tif err == nil {\n\t\t\t_, strictErr := url.ParseRequestURI(input)\n\t\t\t// ParseRequestURI may reject some URLs that Parse accepts\n\t\t\t// This is expected behavior, just verify it doesn't panic\n\t\t\t_ = strictErr\n\t\t}\n\t\t\n\t\t// Test 6: Test URL methods don't panic\n\t\tif parsed != nil {\n\t\t\ttestURLMethods(t, input, parsed)\n\t\t}\n\t})\n}\n\n// verifyURLComponents checks that parsed URL components are consistent\nfunc verifyURLComponents(t *testing.T, original string, u *url.URL) {\n\t// Scheme should be lowercase or empty\n\tif u.Scheme != \"\" && u.Scheme != strings.ToLower(u.Scheme) {\n\t\tt.Errorf(\"Scheme not lowercase: %q in URL %q\", u.Scheme, original)\n\t}\n\t\n\t// Host should not contain port\n\tif strings.Contains(u.Host, \":\") {\n\t\thost, port, err := splitHostPort(u.Host)\n\t\tif err == nil {\n\t\t\t// If we can split it, verify it matches Hostname() and Port()\n\t\t\tif u.Hostname() != host {\n\t\t\t\tt.Errorf(\"Hostname() mismatch: got %q, expected %q from Host %q\",\n\t\t\t\t\tu.Hostname(), host, u.Host)\n\t\t\t}\n\t\t\tif u.Port() != port {\n\t\t\t\tt.Errorf(\"Port() mismatch: got %q, expected %q from Host %q\",\n\t\t\t\t\tu.Port(), port, u.Host)\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// Path should start with / for absolute URLs with host\n\tif u.Host != \"\" && u.Path != \"\" && !strings.HasPrefix(u.Path, \"/\") {\n\t\t// This is actually allowed for some schemes, but worth noting\n\t\tt.Logf(\"Path doesn't start with / for URL with host: %q\", original)\n\t}\n\t\n\t// Query values should be parseable\n\tif u.RawQuery != \"\" {\n\t\tvalues, err := url.ParseQuery(u.RawQuery)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"RawQuery not parseable: %q in URL %q, error: %v\",\n\t\t\t\tu.RawQuery, original, err)\n\t\t}\n\t\t\n\t\t// Verify Query() returns same values\n\t\tif err == nil {\n\t\t\tqueryValues := u.Query()\n\t\t\tif len(values) != len(queryValues) {\n\t\t\t\tt.Errorf(\"Query() length mismatch: ParseQuery returned %d values, Query() returned %d\",\n\t\t\t\t\tlen(values), len(queryValues))\n\t\t\t}\n\t\t}\n\t}\n\t\n\t// User info should be consistent\n\tif u.User != nil {\n\t\tusername := u.User.Username()\n\t\tpassword, hasPassword := u.User.Password()\n\t\t\n\t\t// Username should not be empty if User is set\n\t\tif username == \"\" && !hasPassword {\n\t\t\tt.Logf(\"User info set but username empty and no password: %q\", original)\n\t\t}\n\t\t\n\t\t// Verify String() representation\n\t\tuserStr := u.User.String()\n\t\tif hasPassword {\n\t\t\tif !strings.Contains(userStr, \":\") {\n\t\t\t\tt.Errorf(\"User.String() missing password separator: %q\", userStr)\n\t\t\t}\n\t\t}\n\t}\n}\n\n// testURLMethods calls various URL methods to ensure they don't panic\nfunc testURLMethods(t *testing.T, original string, u *url.URL) {\n\tdefer func() {\n\t\tif r := recover(); r != nil {\n\t\t\tt.Errorf(\"URL method panicked on %q: %v\", original, r)\n\t\t}\n\t}()\n\t\n\t// Test all getter methods\n\t_ = u.String()\n\t_ = u.Hostname()\n\t_ = u.Port()\n\t_ = u.Query()\n\t_ = u.RequestURI()\n\t_ = u.EscapedPath()\n\t_ = u.EscapedFragment()\n\t\n\t// Test IsAbs\n\tisAbs := u.IsAbs()\n\t// Absolute URLs should have a scheme\n\tif isAbs && u.Scheme == \"\" {\n\t\tt.Errorf(\"IsAbs() returned true but Scheme is empty: %q\", original)\n\t}\n\t\n\t// Test Parse with relative reference\n\t_, _ = u.Parse(\"relative/path\")\n\t_, _ = u.Parse(\"/absolute/path\")\n\t_, _ = u.Parse(\"?query\")\n\t_, _ = u.Parse(\"#fragment\")\n\t\n\t// Test ResolveReference\n\tref, _ := url.Parse(\"relative\")\n\tif ref != nil {\n\t\t_ = u.ResolveReference(ref)\n\t}\n\t\n\t// Test Redacted (Go 1.15+)\n\t_ = u.Redacted()\n\t\n\t// Test MarshalBinary/UnmarshalBinary\n\tdata, err := u.MarshalBinary()\n\tif err == nil && data != nil {\n\t\tvar u2 url.URL\n\t\t_ = u2.UnmarshalBinary(data)\n\t}\n}\n\n// splitHostPort is a helper that mimics net.SplitHostPort behavior\nfunc splitHostPort(hostport string) (host, port string, err error) {\n\t// Handle IPv6 addresses\n\tif strings.HasPrefix(hostport, \"[\") {\n\t\tend := strings.Index(hostport, \"]\")\n\t\tif end < 0 {\n\t\t\treturn \"\", \"\", &url.Error{Op: \"split\", URL: hostport, Err: nil}\n\t\t}\n\t\tif end+1 == len(hostport) {\n\t\t\treturn hostport[:end+1], \"\", nil\n\t\t}\n\t\tif hostport[end+1] != ':' {\n\t\t\treturn \"\", \"\", &url.Error{Op: \"split\", URL: hostport, Err: nil}\n\t\t}\n\t\treturn hostport[:end+1], hostport[end+2:], nil\n\t}\n\t\n\t// Handle regular host:port\n\tcolon := strings.LastIndex(hostport, \":\")\n\tif colon < 0 {\n\t\treturn hostport, \"\", nil\n\t}\n\treturn hostport[:colon], hostport[colon+1:], nil\n}\n\n// FuzzURLQueryParsing specifically tests query string parsing\nfunc FuzzURLQueryParsing(f *testing.F) {\n\t// Seed with various query formats\n\tf.Add(\"key=value\")\n\tf.Add(\"key1=value1&key2=value2\")\n\tf.Add(\"key=value1&key=value2\")\n\tf.Add(\"key=\")\n\tf.Add(\"=value\")\n\tf.Add(\"key\")\n\tf.Add(\"key1&key2\")\n\tf.Add(\"key=value%20with%20spaces\")\n\tf.Add(\"key=value+with+plus\")\n\tf.Add(\"key=%XX\") // Invalid encoding\n\tf.Add(\"key=%\")\n\tf.Add(\"key=%2\")\n\tf.Add(strings.Repeat(\"a=b&\", 1000)) // Many parameters\n\t\n\tf.Fuzz(func(t *testing.T, query string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"url.ParseQuery panicked on %q: %v\", query, r)\n\t\t\t}\n\t\t}()\n\t\t\n\t\tvalues, err := url.ParseQuery(query)\n\t\t\n\t\t// Test 1: If parsing succeeded, verify we can encode it back\n\t\tif err == nil && values != nil {\n\t\t\tencoded := values.Encode()\n\t\t\t\n\t\t\t// Re-parse the encoded version\n\t\t\treparsed, err := url.ParseQuery(encoded)\n\t\t\tif err != nil {\n\t\t\t\tt.Errorf(\"Round-trip failed: values.Encode() produced unparseable query\\nOriginal: %q\\nEncoded: %q\\nError: %v\",\n\t\t\t\t\tquery, encoded, err)\n\t\t\t}\n\t\t\t\n\t\t\t// Verify same keys exist\n\t\t\tif reparsed != nil {\n\t\t\t\tfor key := range values {\n\t\t\t\t\tif _, exists := reparsed[key]; !exists {\n\t\t\t\t\t\tt.Errorf(\"Key %q lost in round-trip\", key)\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t\t\n\t\t// Test 2: Verify individual value access doesn't panic\n\t\tif values != nil {\n\t\t\tfor key, vals := range values {\n\t\t\t\t_ = values.Get(key)\n\t\t\t\t_ = values.Has(key)\n\t\t\t\t\n\t\t\t\t// Verify Get returns first value\n\t\t\t\tif len(vals) > 0 && values.Get(key) != vals[0] {\n\t\t\t\t\tt.Errorf(\"Get(%q) returned %q, expected %q\",\n\t\t\t\t\t\tkey, values.Get(key), vals[0])\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\n// FuzzURLEscaping tests URL escaping/unescaping functions\nfunc FuzzURLEscaping(f *testing.F) {\n\tf.Add(\"hello world\")\n\tf.Add(\"hello+world\")\n\tf.Add(\"hello%20world\")\n\tf.Add(\"hello%2Bworld\")\n\tf.Add(\"%\")\n\tf.Add(\"%2\")\n\tf.Add(\"%XX\")\n\tf.Add(\"%%\")\n\tf.Add(string([]byte{0, 1, 2, 255}))\n\tf.Add(\"\u65e5\u672c\u8a9e\")\n\tf.Add(\"\\x00\\x01\\x02\")\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Test PathEscape/PathUnescape\n\t\tescaped := url.PathEscape(input)\n\t\tunescaped, err := url.PathUnescape(escaped)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"PathUnescape failed on PathEscape output: %v\\nInput: %q\\nEscaped: %q\",\n\t\t\t\terr, input, escaped)\n\t\t}\n\t\tif unescaped != input {\n\t\t\tt.Errorf(\"PathEscape/PathUnescape round-trip failed\\nInput: %q\\nEscaped: %q\\nUnescaped: %q\",\n\t\t\t\tinput, escaped, unescaped)\n\t\t}\n\t\t\n\t\t// Test QueryEscape/QueryUnescape\n\t\tqueryEscaped := url.QueryEscape(input)\n\t\tqueryUnescaped, err := url.QueryUnescape(queryEscaped)\n\t\tif err != nil {\n\t\t\tt.Errorf(\"QueryUnescape failed on QueryEscape output: %v\\nInput: %q\\nEscaped: %q\",\n\t\t\t\terr, input, queryEscaped)\n\t\t}\n\t\tif queryUnescaped != input {\n\t\t\tt.Errorf(\"QueryEscape/QueryUnescape round-trip failed\\nInput: %q\\nEscaped: %q\\nUnescaped: %q\",\n\t\t\t\tinput, queryEscaped, queryUnescaped)\n\t\t}\n\t\t\n\t\t// Test that unescaping arbitrary input doesn't panic\n\t\t_, _ = url.PathUnescape(input)\n\t\t_, _ = url.QueryUnescape(input)\n\t})\n}\n```\n\n## Running the Fuzz Tests\n\n```bash\n# Run all fuzz tests for 30 seconds each\ngo test -fuzz=FuzzURL -fuzztime=30s\n\n# Run specific fuzz test\ngo test -fuzz=FuzzURLParser -fuzztime=1m\n\n# Run with custom corpus directory\ngo test -fuzz=FuzzURLParser -fuzztime=30s -fuzz-corpus=./testdata/fuzz\n\n# Run until first failure\ngo test -fuzz=FuzzURLQueryParsing\n\n# Run with parallel workers\ngo test -fuzz=FuzzURLEscaping -parallel=8\n```\n\n## Key Testing Strategies\n\n| Strategy | Purpose | Example |\n|----------|---------|---------|\n| **Panic Detection** | Ensure no crashes | `defer recover()` wrapper |\n| **Round-trip Testing** | Verify consistency | Parse \u2192 String \u2192 Parse |\n| **Idempotency** | Multiple operations = same result | String() called twice |\n| **Component Validation** | Check internal consistency | Host vs Hostname/Port |\n| **Edge Case Seeds** | Guide fuzzer to interesting inputs | Empty strings, special chars |\n| **Method Coverage** | Test all public APIs | Call all getter methods |\n\n## What This Tests\n\n\u2705 **Crash Safety**: No panics on malformed input  \n\u2705 **Round-trip Consistency**: Parse \u2192 String \u2192 Parse preserves meaning  \n\u2705 **Component Coherence**: Host/Port/Hostname relationships  \n\u2705 **Query Parsing**: Parameter extraction and encoding  \n\u2705 **Escaping Functions**: URL encoding/decoding correctness  \n\u2705 **Edge Cases**: Empty strings, null bytes, very long inputs  \n\u2705 **Unicode Handling**: Non-ASCII characters in URLs  \n\n## Corpus Management\n\nThe fuzzer automatically maintains a corpus in `testdata/fuzz/FuzzURLParser/",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5005,
            "output_tokens": 4096,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a comprehensive Go fuzz test for URL parsing. Since I don't see an existing URL parser in the project, I'll create one along with the fuzz test.\n\n```go\n// internal/urlparser/parser.go\npackage urlparser\n\nimport (\n\t\"errors\"\n\t\"strings\"\n)\n\nvar (\n\tErrInvalidURL    = errors.New(\"invalid URL\")\n\tErrEmptyURL      = errors.New(\"empty URL\")\n\tErrInvalidScheme = errors.New(\"invalid scheme\")\n)\n\ntype URL struct {\n\tScheme   string\n\tHost     string\n\tPort     string\n\tPath     string\n\tQuery    string\n\tFragment string\n}\n\n// Parse parses a URL string into its components\nfunc Parse(rawURL string) (*URL, error) {\n\tif rawURL == \"\" {\n\t\treturn nil, ErrEmptyURL\n\t}\n\n\turl := &URL{}\n\tremaining := rawURL\n\n\t// Extract fragment\n\tif idx := strings.Index(remaining, \"#\"); idx != -1 {\n\t\turl.Fragment = remaining[idx+1:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract query\n\tif idx := strings.Index(remaining, \"?\"); idx != -1 {\n\t\turl.Query = remaining[idx+1:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract scheme\n\tif idx := strings.Index(remaining, \"://\"); idx != -1 {\n\t\turl.Scheme = remaining[:idx]\n\t\tif url.Scheme == \"\" {\n\t\t\treturn nil, ErrInvalidScheme\n\t\t}\n\t\tremaining = remaining[idx+3:]\n\t} else if idx := strings.Index(remaining, \":\"); idx != -1 {\n\t\t// Handle scheme without //\n\t\turl.Scheme = remaining[:idx]\n\t\tremaining = remaining[idx+1:]\n\t}\n\n\t// Extract path\n\tif idx := strings.Index(remaining, \"/\"); idx != -1 {\n\t\turl.Path = remaining[idx:]\n\t\tremaining = remaining[:idx]\n\t}\n\n\t// Extract host and port\n\tif remaining != \"\" {\n\t\tif idx := strings.LastIndex(remaining, \":\"); idx != -1 {\n\t\t\turl.Host = remaining[:idx]\n\t\t\turl.Port = remaining[idx+1:]\n\t\t} else {\n\t\t\turl.Host = remaining\n\t\t}\n\t}\n\n\treturn url, nil\n}\n\n// String reconstructs the URL from its components\nfunc (u *URL) String() string {\n\tvar sb strings.Builder\n\n\tif u.Scheme != \"\" {\n\t\tsb.WriteString(u.Scheme)\n\t\tsb.WriteString(\"://\")\n\t}\n\n\tif u.Host != \"\" {\n\t\tsb.WriteString(u.Host)\n\t}\n\n\tif u.Port != \"\" {\n\t\tsb.WriteString(\":\")\n\t\tsb.WriteString(u.Port)\n\t}\n\n\tif u.Path != \"\" {\n\t\tsb.WriteString(u.Path)\n\t}\n\n\tif u.Query != \"\" {\n\t\tsb.WriteString(\"?\")\n\t\tsb.WriteString(u.Query)\n\t}\n\n\tif u.Fragment != \"\" {\n\t\tsb.WriteString(\"#\")\n\t\tsb.WriteString(u.Fragment)\n\t}\n\n\treturn sb.String()\n}\n```\n\n```go\n// internal/urlparser/parser_fuzz_test.go\npackage urlparser\n\nimport (\n\t\"strings\"\n\t\"testing\"\n\t\"unicode/utf8\"\n)\n\nfunc FuzzURLParser(f *testing.F) {\n\t// Seed corpus with valid URLs\n\tf.Add(\"https://example.com\")\n\tf.Add(\"http://example.com:8080/path\")\n\tf.Add(\"https://example.com/path?query=value\")\n\tf.Add(\"https://example.com/path?query=value#fragment\")\n\tf.Add(\"ftp://ftp.example.com/file.txt\")\n\tf.Add(\"mailto:user@example.com\")\n\tf.Add(\"file:///path/to/file\")\n\t\n\t// Seed corpus with edge cases\n\tf.Add(\"\")\n\tf.Add(\":\")\n\tf.Add(\"://\")\n\tf.Add(\"http://\")\n\tf.Add(\"//example.com\")\n\tf.Add(\"example.com\")\n\tf.Add(\"/path/only\")\n\tf.Add(\"?query=only\")\n\tf.Add(\"#fragment-only\")\n\t\n\t// Seed corpus with malformed URLs\n\tf.Add(\"http:///no-host\")\n\tf.Add(\"http://host:invalid-port\")\n\tf.Add(\"http://host::double-colon\")\n\tf.Add(\"http://host:8080:extra\")\n\tf.Add(\"ht!tp://invalid-scheme.com\")\n\tf.Add(\"http://host#fragment?query\")\n\tf.Add(\"http://[::1]:8080\")\n\tf.Add(\"http://user:pass@host.com\")\n\t\n\t// Seed corpus with special characters\n\tf.Add(\"http://example.com/path with spaces\")\n\tf.Add(\"http://example.com/path%20encoded\")\n\tf.Add(\"http://example.com/?key=value&key2=value2\")\n\tf.Add(\"http://example.com/#fragment with spaces\")\n\t\n\t// Seed corpus with unicode\n\tf.Add(\"http://\u4f8b\u3048.jp\")\n\tf.Add(\"http://example.com/\u30d1\u30b9\")\n\tf.Add(\"http://example.com/?\u30ad\u30fc=\u5024\")\n\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\t// Test 1: Parser should never panic\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Parse panicked on input %q: %v\", input, r)\n\t\t\t}\n\t\t}()\n\n\t\t// Test 2: Parse the URL\n\t\turl, err := Parse(input)\n\t\t\n\t\t// Test 3: Empty input should return specific error\n\t\tif input == \"\" {\n\t\t\tif err != ErrEmptyURL {\n\t\t\t\tt.Errorf(\"Expected ErrEmptyURL for empty input, got: %v\", err)\n\t\t\t}\n\t\t\treturn\n\t\t}\n\n\t\t// Test 4: If parsing succeeded, validate the result\n\t\tif err == nil {\n\t\t\tif url == nil {\n\t\t\t\tt.Error(\"Parse returned nil URL with nil error\")\n\t\t\t\treturn\n\t\t\t}\n\n\t\t\t// Test 5: All fields should be valid UTF-8\n\t\t\tif !utf8.ValidString(url.Scheme) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in Scheme: %q\", url.Scheme)\n\t\t\t}\n\t\t\tif !utf8.ValidString(url.Host) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in Host: %q\", url.Host)\n\t\t\t}\n\t\t\tif !utf8.ValidString(url.Port) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in Port: %q\", url.Port)\n\t\t\t}\n\t\t\tif !utf8.ValidString(url.Path) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in Path: %q\", url.Path)\n\t\t\t}\n\t\t\tif !utf8.ValidString(url.Query) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in Query: %q\", url.Query)\n\t\t\t}\n\t\t\tif !utf8.ValidString(url.Fragment) {\n\t\t\t\tt.Errorf(\"Invalid UTF-8 in Fragment: %q\", url.Fragment)\n\t\t\t}\n\n\t\t\t// Test 6: Scheme should not contain invalid characters\n\t\t\tif url.Scheme != \"\" {\n\t\t\t\tif strings.ContainsAny(url.Scheme, \":/\\\\?#[]@!$&'()*+,;= \") {\n\t\t\t\t\tt.Errorf(\"Scheme contains invalid characters: %q\", url.Scheme)\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 7: Port should be numeric if present\n\t\t\tif url.Port != \"\" {\n\t\t\t\tfor _, c := range url.Port {\n\t\t\t\t\tif c < '0' || c > '9' {\n\t\t\t\t\t\tt.Errorf(\"Port contains non-numeric character: %q\", url.Port)\n\t\t\t\t\t\tbreak\n\t\t\t\t\t}\n\t\t\t\t}\n\t\t\t}\n\n\t\t\t// Test 8: String() should not panic\n\t\t\treconstructed := url.String()\n\t\t\tif !utf8.ValidString(reconstructed) {\n\t\t\t\tt.Errorf(\"String() returned invalid UTF-8: %q\", reconstructed)\n\t\t\t}\n\n\t\t\t// Test 9: Re-parsing the reconstructed URL should not panic\n\t\t\t_, err2 := Parse(reconstructed)\n\t\t\tif err2 != nil {\n\t\t\t\t// It's okay if re-parsing fails, but it shouldn't panic\n\t\t\t\t// This is logged for information but not failed\n\t\t\t\tt.Logf(\"Re-parsing reconstructed URL failed (acceptable): %v\", err2)\n\t\t\t}\n\n\t\t\t// Test 10: Check for potential injection issues\n\t\t\t// Fragment should not contain query markers\n\t\t\tif strings.Contains(url.Fragment, \"?\") {\n\t\t\t\tt.Logf(\"Warning: Fragment contains query marker: %q\", url.Fragment)\n\t\t\t}\n\n\t\t\t// Test 11: Check component lengths are reasonable\n\t\t\tconst maxLen = 10000\n\t\t\tif len(url.Scheme) > maxLen {\n\t\t\t\tt.Errorf(\"Scheme too long: %d bytes\", len(url.Scheme))\n\t\t\t}\n\t\t\tif len(url.Host) > maxLen {\n\t\t\t\tt.Errorf(\"Host too long: %d bytes\", len(url.Host))\n\t\t\t}\n\t\t\tif len(url.Port) > maxLen {\n\t\t\t\tt.Errorf(\"Port too long: %d bytes\", len(url.Port))\n\t\t\t}\n\t\t\tif len(url.Path) > maxLen {\n\t\t\t\tt.Errorf(\"Path too long: %d bytes\", len(url.Path))\n\t\t\t}\n\t\t\tif len(url.Query) > maxLen {\n\t\t\t\tt.Errorf(\"Query too long: %d bytes\", len(url.Query))\n\t\t\t}\n\t\t\tif len(url.Fragment) > maxLen {\n\t\t\t\tt.Errorf(\"Fragment too long: %d bytes\", len(url.Fragment))\n\t\t\t}\n\t\t}\n\n\t\t// Test 12: Verify error types are expected\n\t\tif err != nil {\n\t\t\tswitch err {\n\t\t\tcase ErrEmptyURL, ErrInvalidURL, ErrInvalidScheme:\n\t\t\t\t// Expected error types\n\t\t\tdefault:\n\t\t\t\t// Check if it's a wrapped error\n\t\t\t\tif !strings.Contains(err.Error(), \"invalid\") &&\n\t\t\t\t\t!strings.Contains(err.Error(), \"empty\") {\n\t\t\t\t\tt.Logf(\"Unexpected error type: %v\", err)\n\t\t\t\t}\n\t\t\t}\n\t\t}\n\t})\n}\n\n// FuzzURLParserRoundTrip tests that parsing and reconstructing maintains consistency\nfunc FuzzURLParserRoundTrip(f *testing.F) {\n\t// Seed with well-formed URLs that should round-trip\n\tf.Add(\"https://example.com/path\")\n\tf.Add(\"http://example.com:8080/path?query=value#fragment\")\n\tf.Add(\"ftp://ftp.example.com/file.txt\")\n\t\n\tf.Fuzz(func(t *testing.T, input string) {\n\t\tdefer func() {\n\t\t\tif r := recover(); r != nil {\n\t\t\t\tt.Errorf(\"Panic during round-trip test: %v\", r)\n\t\t\t}\n\t\t}()\n\n\t\turl1, err1 := Parse(input)\n\t\tif err1 != nil {\n\t\t\treturn // Skip invalid URLs\n\t\t}\n\n\t\treconstructed := url1.String()\n\t\turl2, err2 := Parse(reconstructed)\n\t\t\n\t\tif err2 != nil {\n\t\t\tt.Errorf(\"Failed to parse reconstructed URL: %v\\nOriginal: %q\\nReconstructed: %q\",\n\t\t\t\terr2, input, reconstructed)\n\t\t\treturn\n\t\t}\n\n\t\t// Compare components\n\t\tif url1.Scheme != url2.Scheme {\n\t\t\tt.Errorf(\"Scheme mismatch: %q != %q\", url1.Scheme, url2.Scheme)\n\t\t}\n\t\tif url1.Host != url2.Host {\n\t\t\tt.Errorf(\"Host mismatch: %q != %q\", url1.Host, url2.Host)\n\t\t}\n\t\tif url1.Port != url2.Port {\n\t\t\tt.Errorf(\"Port mismatch: %q != %q\", url1.Port, url2.Port)\n\t\t}\n\t\tif url1.Path != url2.Path {\n\t\t\tt.Errorf(\"Path mismatch: %q != %q\", url1.Path, url2.Path)\n\t\t}\n\t\tif url1.Query != url2.Query {\n\t\t\tt.Errorf(\"Query mismatch: %q != %q\", url1.Query, url2.Query)\n\t\t}\n\t\tif url1.Fragment != url2.Fragment {\n\t\t\tt.Errorf(\"Fragment mismatch: %q != %q\", url1.Fragment, url2.Fragment)\n\t\t}\n\t})\n}\n```\n\n```go\n// internal/urlparser/parser_test.go\npackage urlparser\n\nimport (\n\t\"testing\"\n)\n\nfunc TestParseValidURLs(t *testing.T) {\n\ttests := []struct {\n\t\tname     string\n\t\tinput    string\n\t\texpected URL\n\t}{\n\t\t{\n\t\t\tname:  \"simple http\",\n\t\t\tinput: \"http://example.com\",\n\t\t\texpected: URL{\n\t\t\t\tScheme: \"http\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"with port\",\n\t\t\tinput: \"http://example.com:8080\",\n\t\t\texpected: URL{\n\t\t\t\tScheme: \"http\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t\tPort:   \"8080\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"with path\",\n\t\t\tinput: \"https://example.com/path/to/resource\",\n\t\t\texpected: URL{\n\t\t\t\tScheme: \"https\",\n\t\t\t\tHost:   \"example.com\",\n\t\t\t\tPath:   \"/path/to/resource\",\n\t\t\t},\n\t\t},\n\t\t{\n\t\t\tname:  \"full url\",\n\t\t\tinput: \"https://example.com:443/path?query=value#fragment\",\n\t\t\texpected: URL{\n\t\t\t\tScheme:   \"https\",\n\t\t\t\tHost:     \"example.com\",\n\t\t\t\tPort:     \"443\",\n\t\t\t\tPath:     \"/path\",\n\t\t\t\tQuery:    \"query=value\",\n\t\t\t\tFragment: \"fragment\",\n\t\t\t},\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\turl, err := Parse(tt.input)\n\t\t\tif err != nil {\n\t\t\t\tt.Fatalf(\"unexpected error: %v\", err)\n\t\t\t}\n\t\t\tif url.Scheme != tt.expected.Scheme {\n\t\t\t\tt.Errorf(\"Scheme: got %q, want %q\", url.Scheme, tt.expected.Scheme)\n\t\t\t}\n\t\t\tif url.Host != tt.expected.Host {\n\t\t\t\tt.Errorf(\"Host: got %q, want %q\", url.Host, tt.expected.Host)\n\t\t\t}\n\t\t\tif url.Port != tt.expected.Port {\n\t\t\t\tt.Errorf(\"Port: got %q, want %q\", url.Port, tt.expected.Port)\n\t\t\t}\n\t\t\tif url.Path != tt.expected.Path {\n\t\t\t\tt.Errorf(\"Path: got %q, want %q\", url.Path, tt.expected.Path)\n\t\t\t}\n\t\t\tif url.Query != tt.expected.Query {\n\t\t\t\tt.Errorf(\"Query: got %q, want %q\", url.Query, tt.expected.Query)\n\t\t\t}\n\t\t\tif url.Fragment != tt.expected.Fragment {\n\t\t\t\tt.Errorf(\"Fragment: got %q, want %q\", url.Fragment, tt.expected.Fragment)\n\t\t\t}\n\t\t})\n\t}\n}\n\nfunc TestParseErrors(t *testing.T) {\n\ttests := []struct {\n\t\tname        string\n\t\tinput       string\n\t\texpectedErr error\n\t}{\n\t\t{\n\t\t\tname:        \"empty string\",\n\t\t\tinput:       \"\",\n\t\t\texpectedErr: ErrEmptyURL,\n\t\t},\n\t}\n\n\tfor _, tt := range tests {\n\t\tt.Run(tt.name, func(t *testing.T) {\n\t\t\t_, err := Parse(tt.input)\n\t\t\tif err != tt.expectedErr {\n\t\t\t\tt.Errorf(\"got error %v, want %v\", err, tt.expectedErr)\n\t\t\t}\n\t\t})\n\t}\n}\n```\n\nNow you can run the fuzz tests:\n\n```bash\n# Run the main fuzz test for 30 seconds\ngo test -fuzz=FuzzURLParser -fuzztime=30s ./internal/urlparser\n\n# Run the round-trip fuzz test\ngo test -fuzz=FuzzURLParserRoundTrip -fuzztime=30s ./internal/url",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5489,
            "output_tokens": 4096,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "ossfuzz-03",
      "task_type": "similar_syntax",
      "target_language": "python",
      "expected_patterns": [
        "import atheris",
        "atheris\\.instrument_func|@atheris\\.instrument_func",
        "atheris\\.FuzzedDataProvider",
        "atheris\\.Setup",
        "atheris\\.Fuzz",
        "compile_python_fuzzer",
        "yaml\\.safe_load|yaml\\.load"
      ],
      "anti_patterns": [
        "LLVMFuzzerTestOneInput",
        "\\$CXX.*\\$CXXFLAGS",
        "\\$LIB_FUZZING_ENGINE",
        "cargo fuzz",
        "extern.*int LLVMFuzzer"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/ujson_fuzzer.py",
          "description": "Atheris Python fuzzer example: import atheris, atheris.FuzzedDataProvider, atheris.Setup(), atheris.Fuzz() patterns"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/build.sh",
          "description": "OSS-Fuzz Python build.sh: compile_python_fuzzer usage for building Python fuzzers, looping through *_fuzzer.py files"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/project.yaml",
          "description": "OSS-Fuzz Python project.yaml: language: python, fuzzing_engines: libfuzzer, sanitizers: address and undefined"
        },
        {
          "url": "https://pyyaml.org/wiki/PyYAMLDocumentation",
          "description": "PyYAML documentation - source of yaml.safe_load() and yaml.load() YAML parsing functions for fuzzing YAML input"
        },
        {
          "url": "https://docs.python.org/3/reference/simple_stmts.html#import",
          "description": "Python import statement documentation - source of import keyword for importing atheris module"
        },
        {
          "url": "https://docs.python.org/3/glossary.html#term-decorator",
          "description": "Python decorator documentation - source of @ decorator syntax for @atheris.instrument_func"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new-project-guide.md",
          "description": "Anti-patterns: C++ LLVMFuzzerTestOneInput, $CXX, $CXXFLAGS, $LIB_FUZZING_ENGINE that should not appear in Python"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new-project-guide/rust_lang.md",
          "description": "Anti-patterns: Rust cargo fuzz patterns that should not appear in Python"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "# OSS-Fuzz Harness for PyYAML\n\nI'll provide a complete OSS-Fuzz setup for fuzzing PyYAML with Atheris.\n\n## 1. Fuzzing Harness (`fuzz_yaml.py`)\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML library using Atheris.\nThis fuzzer tests YAML parsing functionality.\n\"\"\"\n\nimport sys\nimport atheris\nimport yaml\nfrom io import StringIO\n\n\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML parsing.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    # Convert bytes to string for YAML parsing\n    try:\n        yaml_string = data.decode('utf-8', errors='ignore')\n    except Exception:\n        return\n    \n    if not yaml_string:\n        return\n    \n    # Test yaml.safe_load (most common and secure method)\n    try:\n        yaml.safe_load(yaml_string)\n    except yaml.YAMLError:\n        # Expected parsing errors - not bugs\n        pass\n    except ValueError:\n        # Can occur with certain malformed inputs\n        pass\n    except RecursionError:\n        # Can occur with deeply nested structures\n        pass\n    except KeyError:\n        # Can occur with certain merge key operations\n        pass\n    except AttributeError:\n        # Can occur with certain malformed structures\n        pass\n    except TypeError:\n        # Can occur with certain type mismatches\n        pass\n    \n    # Test yaml.safe_load_all for multi-document YAML\n    try:\n        list(yaml.safe_load_all(yaml_string))\n    except yaml.YAMLError:\n        pass\n    except ValueError:\n        pass\n    except RecursionError:\n        pass\n    except KeyError:\n        pass\n    except AttributeError:\n        pass\n    except TypeError:\n        pass\n    \n    # Test yaml.safe_dump (round-trip testing)\n    try:\n        parsed = yaml.safe_load(yaml_string)\n        if parsed is not None:\n            yaml.safe_dump(parsed)\n    except yaml.YAMLError:\n        pass\n    except ValueError:\n        pass\n    except RecursionError:\n        pass\n    except KeyError:\n        pass\n    except AttributeError:\n        pass\n    except TypeError:\n        pass\n    except MemoryError:\n        # Can occur with extremely large structures\n        pass\n    \n    # Test yaml.scan for tokenization\n    try:\n        list(yaml.scan(yaml_string))\n    except yaml.YAMLError:\n        pass\n    except ValueError:\n        pass\n    except RecursionError:\n        pass\n    except AttributeError:\n        pass\n    \n    # Test yaml.parse for parsing events\n    try:\n        list(yaml.parse(yaml_string))\n    except yaml.YAMLError:\n        pass\n    except ValueError:\n        pass\n    except RecursionError:\n        pass\n    except AttributeError:\n        pass\n    \n    # Test yaml.compose for node composition\n    try:\n        yaml.compose(yaml_string)\n    except yaml.YAMLError:\n        pass\n    except ValueError:\n        pass\n    except RecursionError:\n        pass\n    except KeyError:\n        pass\n    except AttributeError:\n        pass\n    except TypeError:\n        pass\n\n\ndef main():\n    \"\"\"Initialize Atheris and start fuzzing.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Build Script (`build.sh`)\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Install PyYAML\npip3 install --upgrade pip\npip3 install .\n\n# Build the fuzzer\ncompile_python_fuzzer $SRC/pyyaml/fuzz_yaml.py\n\n# Create seed corpus directory with sample YAML files\nmkdir -p $OUT/fuzz_yaml_seed_corpus\n\n# Add seed corpus examples\ncat > $OUT/fuzz_yaml_seed_corpus/simple.yaml << EOF\nkey: value\nnumber: 42\nlist:\n  - item1\n  - item2\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/nested.yaml << EOF\nroot:\n  child1:\n    grandchild: value\n  child2:\n    - list_item\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/types.yaml << EOF\nstring: \"hello\"\ninteger: 123\nfloat: 3.14\nboolean: true\nnull_value: null\ndate: 2024-01-01\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/multi_document.yaml << EOF\n---\ndocument: 1\n---\ndocument: 2\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/anchors.yaml << EOF\ndefaults: &defaults\n  adapter: postgres\n  host: localhost\n\ndevelopment:\n  <<: *defaults\n  database: dev_db\n\nproduction:\n  <<: *defaults\n  database: prod_db\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/complex.yaml << EOF\nusers:\n  - name: Alice\n    age: 30\n    roles:\n      - admin\n      - developer\n  - name: Bob\n    age: 25\n    roles:\n      - user\n\nsettings:\n  debug: false\n  timeout: 30\n  features:\n    feature1: enabled\n    feature2: disabled\nEOF\n\n# Create options file for the fuzzer\ncat > $OUT/fuzz_yaml.options << EOF\n[libfuzzer]\nmax_len = 65536\ntimeout = 25\nrss_limit_mb = 2048\nEOF\n\n# Create dictionary for YAML-specific tokens\ncat > $OUT/fuzz_yaml.dict << EOF\n# YAML special characters and keywords\n\":\"\n\"-\"\n\"---\"\n\"...\"\n\"&\"\n\"*\"\n\"<<\"\n\"!\"\n\"|\"\n\">\"\n\"[\"\n\"]\"\n\"{\"\n\"}\"\n\"true\"\n\"false\"\n\"null\"\n\"~\"\n\"yes\"\n\"no\"\n\"on\"\n\"off\"\n\n# YAML tags\n\"!!str\"\n\"!!int\"\n\"!!float\"\n\"!!bool\"\n\"!!null\"\n\"!!map\"\n\"!!seq\"\n\"!!set\"\n\"!!binary\"\n\"!!timestamp\"\n\n# Common keys\n\"key\"\n\"value\"\n\"name\"\n\"id\"\n\"type\"\n\"data\"\n\"config\"\n\"settings\"\nEOF\n```\n\n## 3. Project Configuration (`project.yaml`)\n\n```yaml\nhomepage: \"https://github.com/yaml/pyyaml\"\nlanguage: python\nmain_repo: \"https://github.com/yaml/pyyaml\"\nfile_github_issue: true\nsanitizers:\n  - address\n  - undefined\nvendor_ccs:\n  - david@adalogics.com\n  - adam@adalogics.com\n\nfuzzing_engines:\n  - libfuzzer\n\n# Auto-CC maintainers on bugs\nauto_ccs:\n  - \"xi.wang@gmail.com\"\n\n# Fuzzing configuration\nexperimental: false\n```\n\n## 4. Dockerfile (Optional but recommended)\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder-python\n\nRUN git clone --depth 1 https://github.com/yaml/pyyaml pyyaml\n\nWORKDIR pyyaml\n\nCOPY build.sh fuzz_yaml.py $SRC/pyyaml/\n```\n\n## 5. Additional Test Harness (`fuzz_yaml_advanced.py`)\n\nHere's an advanced version that tests more edge cases:\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nAdvanced OSS-Fuzz harness for PyYAML with additional coverage.\n\"\"\"\n\nimport sys\nimport atheris\nimport yaml\nfrom yaml import Loader, SafeLoader, FullLoader, UnsafeLoader\n\n\n@atheris.instrument_func\ndef test_different_loaders(yaml_string):\n    \"\"\"Test with different YAML loaders.\"\"\"\n    loaders = [SafeLoader, FullLoader]\n    \n    for loader in loaders:\n        try:\n            yaml.load(yaml_string, Loader=loader)\n        except yaml.YAMLError:\n            pass\n        except (ValueError, RecursionError, KeyError, \n                AttributeError, TypeError, MemoryError):\n            pass\n\n\n@atheris.instrument_func\ndef test_yaml_constructors(yaml_string):\n    \"\"\"Test YAML constructor methods.\"\"\"\n    try:\n        loader = yaml.SafeLoader(yaml_string)\n        while loader.check_node():\n            loader.get_node()\n    except yaml.YAMLError:\n        pass\n    except (ValueError, RecursionError, KeyError, \n            AttributeError, TypeError, StopIteration):\n        pass\n\n\n@atheris.instrument_func\ndef test_emit_and_serialize(yaml_string):\n    \"\"\"Test YAML emission and serialization.\"\"\"\n    try:\n        parsed = yaml.safe_load(yaml_string)\n        if parsed is not None:\n            # Test different dump options\n            yaml.safe_dump(parsed, default_flow_style=True)\n            yaml.safe_dump(parsed, default_flow_style=False)\n            yaml.safe_dump(parsed, allow_unicode=True)\n    except yaml.YAMLError:\n        pass\n    except (ValueError, RecursionError, KeyError, \n            AttributeError, TypeError, MemoryError):\n        pass\n\n\ndef TestOneInput(data):\n    \"\"\"Main fuzz target.\"\"\"\n    try:\n        yaml_string = data.decode('utf-8', errors='ignore')\n    except Exception:\n        return\n    \n    if not yaml_string or len(yaml_string) > 100000:\n        return\n    \n    # Basic safe_load test\n    try:\n        yaml.safe_load(yaml_string)\n    except (yaml.YAMLError, ValueError, RecursionError, \n            KeyError, AttributeError, TypeError):\n        pass\n    \n    # Test different loaders\n    test_different_loaders(yaml_string)\n    \n    # Test constructors\n    test_yaml_constructors(yaml_string)\n    \n    # Test serialization\n    test_emit_and_serialize(yaml_string)\n\n\ndef main():\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Usage Instructions\n\n1. **Place files in OSS-Fuzz repository structure:**\n   ```\n   projects/pyyaml/\n   \u251c\u2500\u2500 project.yaml\n   \u251c\u2500\u2500 Dockerfile\n   \u251c\u2500\u2500 build.sh\n   \u251c\u2500\u2500 fuzz_yaml.py\n   \u2514\u2500\u2500 fuzz_yaml_advanced.py\n   ```\n\n2. **Build the fuzzer:**\n   ```bash\n   python infra/helper.py build_fuzzers --sanitizer address pyyaml\n   ```\n\n3. **Run the fuzzer:**\n   ```bash\n   python infra/helper.py run_fuzzer pyyaml fuzz_yaml\n   ```\n\n4. **Check coverage:**\n   ```bash\n   python infra/helper.py coverage pyyaml\n   ```\n\nThis harness properly handles all expected exceptions from PyYAML and provides comprehensive coverage of the library's parsing functionality.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 67,
            "output_tokens": 3079,
            "cached": false
          },
          "with_skill": {
            "output": "# OSS-Fuzz Python Harness for PyYAML\n\nHere's a complete OSS-Fuzz integration for fuzzing PyYAML with Atheris:\n\n## Project Structure\n\n```\nprojects/pyyaml/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 build.sh\n\u2514\u2500\u2500 fuzz_yaml_load.py\n```\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/yaml/pyyaml\"\nlanguage: python\nprimary_contact: \"security@pyyaml.org\"\nmain_repo: \"https://github.com/yaml/pyyaml\"\nauto_ccs:\n  - \"your-backup-email@example.com\"\n\nfuzzing_engines:\n  - libfuzzer\n\nsanitizers:\n  - address\n  - undefined\n\nvendor_ccs:\n  - \"maintainer@pyyaml.org\"\n```\n\n## 2. Dockerfile\n\n```dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder-python\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y \\\n    libyaml-dev \\\n    python3-dev\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/yaml/pyyaml\n\n# Copy fuzzing harnesses\nCOPY fuzz_*.py $SRC/\nCOPY build.sh $SRC/\n\nWORKDIR $SRC/pyyaml\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Build and install PyYAML with C extensions\ncd $SRC/pyyaml\npip3 install --upgrade pip\npip3 install .\n\n# Verify installation\npython3 -c \"import yaml; print('PyYAML version:', yaml.__version__)\"\n\n# Compile all Python fuzzers\nfor fuzzer in $(find $SRC -name 'fuzz_*.py'); do\n  fuzzer_basename=$(basename -s .py $fuzzer)\n  fuzzer_package=${fuzzer_basename}.pkg\n  \n  # Create seed corpus if available\n  if [ -d \"$SRC/pyyaml/tests/data\" ]; then\n    zip -j $OUT/${fuzzer_basename}_seed_corpus.zip $SRC/pyyaml/tests/data/*.yaml || true\n  fi\n  \n  # Compile the fuzzer\n  compile_python_fuzzer $fuzzer \\\n    --add-binary /usr/local/lib/python3.*/dist-packages/yaml/*.so:yaml \\\n    --add-binary /usr/local/lib/python3.*/dist-packages/_yaml*.so:.\ndone\n```\n\n## 4. fuzz_yaml_load.py\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nFuzzing harness for PyYAML's yaml.load() function.\n\nThis harness tests the YAML parser with various inputs to find:\n- Memory corruption bugs in the C extension\n- Parsing logic errors\n- Unexpected exceptions\n- Resource exhaustion issues\n\"\"\"\n\nimport atheris\nimport sys\nimport io\n\nwith atheris.instrument_imports():\n    import yaml\n    from yaml import YAMLError\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for yaml.load() with safe_load and full_load.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Use FuzzedDataProvider to create varied test scenarios\n    yaml_input = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n    \n    # Test yaml.safe_load (most common, safest API)\n    try:\n        result = yaml.safe_load(yaml_input)\n        # If parsing succeeds, try to access the result\n        # This can trigger issues in object construction\n        if result is not None:\n            _ = str(result)\n            _ = repr(result)\n    except (YAMLError, ValueError, TypeError, AttributeError, KeyError):\n        # Expected exceptions during parsing\n        pass\n    except UnicodeDecodeError:\n        # Expected for invalid unicode sequences\n        pass\n    except RecursionError:\n        # Expected for deeply nested structures\n        pass\n    except MemoryError:\n        # Expected for extremely large structures\n        pass\n    \n    # Test yaml.full_load (allows more Python objects)\n    try:\n        result = yaml.full_load(yaml_input)\n        if result is not None:\n            _ = str(result)\n    except (YAMLError, ValueError, TypeError, AttributeError, KeyError):\n        pass\n    except UnicodeDecodeError:\n        pass\n    except RecursionError:\n        pass\n    except MemoryError:\n        pass\n\n\ndef main():\n    \"\"\"Initialize Atheris and start fuzzing.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 5. Additional Harness: fuzz_yaml_dump.py\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nFuzzing harness for PyYAML's yaml.dump() function.\n\nTests serialization of Python objects to YAML format.\n\"\"\"\n\nimport atheris\nimport sys\n\nwith atheris.instrument_imports():\n    import yaml\n    from yaml import YAMLError\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for yaml.dump() with various Python objects.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Create various Python objects to serialize\n    choice = fdp.ConsumeIntInRange(0, 6)\n    \n    try:\n        if choice == 0:\n            # Simple string\n            obj = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n        elif choice == 1:\n            # List of strings\n            obj = [\n                fdp.ConsumeUnicodeNoSurrogates(20)\n                for _ in range(fdp.ConsumeIntInRange(0, 10))\n            ]\n        elif choice == 2:\n            # Dictionary\n            obj = {\n                fdp.ConsumeUnicodeNoSurrogates(10): fdp.ConsumeUnicodeNoSurrogates(10)\n                for _ in range(fdp.ConsumeIntInRange(0, 10))\n            }\n        elif choice == 3:\n            # Nested structure\n            obj = {\n                'key1': [1, 2, 3],\n                'key2': {'nested': fdp.ConsumeUnicodeNoSurrogates(20)},\n                'key3': fdp.ConsumeInt(4)\n            }\n        elif choice == 4:\n            # Numbers\n            obj = [\n                fdp.ConsumeFloat(),\n                fdp.ConsumeInt(8),\n                fdp.ConsumeIntInRange(-1000, 1000)\n            ]\n        elif choice == 5:\n            # Boolean and None\n            obj = {\n                'bool': fdp.ConsumeBool(),\n                'none': None,\n                'list': [True, False, None]\n            }\n        else:\n            # Mixed types\n            obj = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n        \n        # Try to dump the object\n        yaml_output = yaml.dump(obj)\n        \n        # Try to load it back (round-trip test)\n        yaml.safe_load(yaml_output)\n        \n    except (YAMLError, ValueError, TypeError, AttributeError):\n        # Expected exceptions\n        pass\n    except RecursionError:\n        # Expected for deeply nested structures\n        pass\n    except MemoryError:\n        # Expected for extremely large structures\n        pass\n\n\ndef main():\n    \"\"\"Initialize Atheris and start fuzzing.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 6. Advanced Harness: fuzz_yaml_compose.py\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nFuzzing harness for PyYAML's low-level compose API.\n\nTests the node composition layer which is closer to the C extension.\n\"\"\"\n\nimport atheris\nimport sys\n\nwith atheris.instrument_imports():\n    import yaml\n    from yaml import YAMLError\n    from yaml.composer import Composer\n    from yaml.constructor import Constructor\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for yaml.compose() and related low-level APIs.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    yaml_input = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n    \n    # Test compose (returns node tree)\n    try:\n        node = yaml.compose(yaml_input)\n        if node is not None:\n            # Access node properties\n            _ = node.tag\n            _ = node.start_mark\n            _ = node.end_mark\n    except (YAMLError, ValueError, TypeError, AttributeError):\n        pass\n    except UnicodeDecodeError:\n        pass\n    except RecursionError:\n        pass\n    \n    # Test compose_all (returns all documents)\n    try:\n        nodes = list(yaml.compose_all(yaml_input))\n        for node in nodes:\n            if node is not None:\n                _ = node.tag\n    except (YAMLError, ValueError, TypeError, AttributeError):\n        pass\n    except UnicodeDecodeError:\n        pass\n    except RecursionError:\n        pass\n    \n    # Test scan (tokenization)\n    try:\n        tokens = list(yaml.scan(yaml_input))\n        for token in tokens:\n            _ = str(token)\n    except (YAMLError, ValueError, TypeError):\n        pass\n    except UnicodeDecodeError:\n        pass\n    except RecursionError:\n        pass\n\n\ndef main():\n    \"\"\"Initialize Atheris and start fuzzing.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Testing Locally\n\n### Step 1: Build the Project\n\n```bash\ncd /path/to/oss-fuzz\npython3 infra/helper.py build_image pyyaml\npython3 infra/helper.py build_fuzzers --sanitizer=address pyyaml\n```\n\n### Step 2: Run a Harness\n\n```bash\n# Run the main yaml.load fuzzer\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml_load\n\n# Run with a time limit (60 seconds)\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml_load -- -max_total_time=60\n\n# Run the dump fuzzer\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml_dump\n```\n\n### Step 3: Generate Coverage\n\n```bash\npython3 infra/helper.py build_fuzzers --sanitizer=coverage pyyaml\npython3 infra/helper.py coverage pyyaml\n```\n\n## Key Features\n\n### Exception Handling\n\nThe harnesses properly catch expected exceptions:\n\n| Exception | Why It's Expected |\n|-----------|-------------------|\n| `YAMLError` | Base exception for all YAML parsing errors |\n| `ValueError` | Invalid values in YAML structure |\n| `TypeError` | Type mismatches during parsing |\n| `AttributeError` | Missing attributes in parsed objects |\n| `KeyError` | Missing keys in dictionaries |\n| `UnicodeDecodeError` | Invalid UTF-8 sequences |\n| `RecursionError` | Deeply nested YAML structures |\n| `MemoryError` | Extremely large YAML documents |\n\n### FuzzedDataProvider Usage\n\n```python\nfdp = atheris.FuzzedDataProvider(data)\n\n# Consume different data types\nstring = fdp.ConsumeUnicodeNoSurrogates(100)  # Unicode string\ninteger = fdp.ConsumeInt(4)                    # 4-byte integer\nfloat_val = fdp.ConsumeFloat()                 # Float value\nbool_val = fdp.ConsumeBool()                   # Boolean\nchoice = fdp.ConsumeIntInRange(0, 5)          # Integer in range\n```\n\n### Seed Corpus\n\nThe build.sh automatically creates a seed corpus from PyYAML's test data:\n\n```bash\nzip -j $OUT/${fuzzer_basename}_seed_corpus.zip $SRC/pyyaml/tests/data/*.yaml\n```\n\n## Expected Output\n\nWhen running successfully, you'll see:\n\n```\nINFO: Running with entropic power schedule (0xFF, 100).\nINFO: Seed: 1234567890\nINFO: Loaded 1 modules   (12345 inline 8-bit counters): ...\nINFO:      150 files found in /tmp/fuzz_yaml_load_corpus\nINFO: seed corpus: files: 150 min: 1b max: 5000b total: 75000b rss: 45Mb\n#151    INITED cov: 1234 ft: 5678 corp: 120/50Kb exec/s: 0 rss: 50Mb\n#500    NEW    cov: 1240 ft: 5690 corp: 121/51Kb lim: 4096 exec/s: 250 rss: 52Mb\n```\n\n## Troubleshooting\n\n| Issue | Solution |\n|-------|----------|\n| **Import error for yaml** | Ensure `pip3 install .` runs successfully in build.sh |\n| **Missing C extension** | Check that libyaml-dev is installed in Dockerfile |\n| **Fuzzer crashes immediately** | Verify exception handling covers all expected errors |\n| **Low coverage** | Add more harnesses targeting different APIs |\n| **Binary not found** | Check --add-binary paths match your Python version |\n\nThis complete integration provides comprehensive fuzzing coverage for PyYAML's parsing, serialization, and low-level APIs while properly handling all expected exceptions.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5013,
            "output_tokens": 3529,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a complete OSS-Fuzz integration for fuzzing PyYAML with Atheris.\n\n## 1. Harness File\n\n<write_file>\n<path>fuzz_yaml.py</path>\n<content>#!/usr/bin/env python3\n\"\"\"Atheris fuzzing harness for PyYAML library.\"\"\"\n\nimport atheris\nimport sys\n\nwith atheris.instrument_imports():\n    import yaml\n    from yaml import YAMLError\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"Fuzz PyYAML's load functions with various input data.\n    \n    Args:\n        data: Raw bytes from fuzzer to parse as YAML\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Get fuzzer-controlled data as string\n    yaml_input = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n    \n    if not yaml_input:\n        return\n    \n    # Test yaml.safe_load (most common, security-focused API)\n    try:\n        yaml.safe_load(yaml_input)\n    except YAMLError:\n        # Expected parsing errors - not bugs\n        pass\n    except (ValueError, TypeError, AttributeError, RecursionError):\n        # Expected errors from malformed input\n        pass\n    \n    # Test yaml.safe_load_all for multi-document parsing\n    try:\n        list(yaml.safe_load_all(yaml_input))\n    except YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError, RecursionError):\n        pass\n    \n    # Test yaml.load with SafeLoader (equivalent to safe_load)\n    try:\n        yaml.load(yaml_input, Loader=yaml.SafeLoader)\n    except YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError, RecursionError):\n        pass\n    \n    # Test the scanner/parser directly for deeper coverage\n    try:\n        from yaml import scan, parse, compose\n        \n        # Scanner tokenization\n        list(scan(yaml_input))\n        \n        # Parser event generation\n        list(parse(yaml_input))\n        \n        # Composer node construction\n        compose(yaml_input)\n    except YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError, RecursionError, StopIteration):\n        pass\n\n\ndef main():\n    \"\"\"Initialize Atheris and start fuzzing.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n</content>\n</write_file>\n\n## 2. Build Script\n\n<write_file>\n<path>build.sh</path>\n<content>#!/bin/bash -eu\n# Build script for OSS-Fuzz integration with PyYAML\n\n# Install PyYAML from source to ensure we're fuzzing the latest version\n# and that it's instrumented properly\npip3 install --upgrade pip setuptools wheel\n\n# Clone PyYAML repository if not already present\nif [ ! -d \"pyyaml\" ]; then\n    git clone --depth 1 https://github.com/yaml/pyyaml.git\nfi\n\ncd pyyaml\n\n# Install PyYAML with instrumentation\npip3 install .\n\ncd ..\n\n# Compile all Python fuzzers in the project\n# compile_python_fuzzer is provided by OSS-Fuzz base-builder-python image\nfor fuzzer in $(find $SRC -name 'fuzz_*.py'); do\n    echo \"Compiling fuzzer: $fuzzer\"\n    compile_python_fuzzer \"$fuzzer\"\ndone\n\n# Optional: Add seed corpus if available\n# This would contain valid YAML samples to bootstrap fuzzing\nif [ -d \"$SRC/yaml_corpus\" ]; then\n    zip -j $OUT/fuzz_yaml_seed_corpus.zip $SRC/yaml_corpus/*\nfi\n\n# Optional: Add dictionary for better fuzzing efficiency\n# YAML-specific tokens and keywords\ncat > $OUT/fuzz_yaml.dict << EOF\n# YAML structural tokens\n\":\"\n\"-\"\n\"---\"\n\"...\"\n\"[\"\n\"]\"\n\"{\"\n\"}\"\n\"!\"\n\"&\"\n\"*\"\n\"|\"\n\">\"\n\"?\"\n\n# YAML keywords and values\n\"true\"\n\"false\"\n\"null\"\n\"~\"\n\"yes\"\n\"no\"\n\"on\"\n\"off\"\n\n# Common YAML tags\n\"!!str\"\n\"!!int\"\n\"!!float\"\n\"!!bool\"\n\"!!null\"\n\"!!seq\"\n\"!!map\"\n\"!!binary\"\n\"!!timestamp\"\n\"!!omap\"\n\"!!pairs\"\n\"!!set\"\n\n# YAML directives\n\"%YAML\"\n\"%TAG\"\n\n# Common keys\n\"name\"\n\"version\"\n\"description\"\n\"items\"\n\"data\"\n\"config\"\nEOF\n</content>\n</write_file>\n\n## 3. Project Configuration\n\n<write_file>\n<path>project.yaml</path>\n<content>homepage: \"https://github.com/yaml/pyyaml\"\nlanguage: python\nprimary_contact: \"security@example.com\"\nmain_repo: \"https://github.com/yaml/pyyaml\"\n\n# Use Atheris for Python fuzzing\nfuzzing_engines:\n  - libfuzzer\n\n# Python projects typically only support AddressSanitizer\nsanitizers:\n  - address\n  - undefined\n\n# Vendor-specific CCs (update with actual maintainer contacts)\nauto_ccs:\n  - \"yaml-maintainers@example.com\"\n\n# File issue on GitHub for bugs\nfile_github_issue: true\n\n# Help URL for bug reports\nhelp_url: \"https://github.com/yaml/pyyaml/security\"\n\n# Experimental features\nexperimental: false\n\n# View fuzzing stats\nview_restrictions: none\n</content>\n</write_file>\n\n## 4. Optional: Dockerfile (if custom dependencies needed)\n\n<write_file>\n<path>Dockerfile</path>\n<content>FROM gcr.io/oss-fuzz-base/base-builder-python\n\n# Install any additional system dependencies if needed\nRUN apt-get update && apt-get install -y \\\n    libyaml-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the PyYAML repository\nRUN git clone --depth 1 https://github.com/yaml/pyyaml.git pyyaml\n\n# Copy fuzzing harnesses and build script\nCOPY fuzz_*.py $SRC/\nCOPY build.sh $SRC/\n\nWORKDIR $SRC\n</content>\n</write_file>\n\n## 5. Example Seed Corpus (Optional)\n\n<write_file>\n<path>seed_corpus/simple.yaml</path>\n<content>name: example\nversion: 1.0\nitems:\n  - one\n  - two\n  - three\n</content>\n</write_file>\n\n<write_file>\n<path>seed_corpus/nested.yaml</path>\n<content>database:\n  host: localhost\n  port: 5432\n  credentials:\n    user: admin\n    password: secret\n</content>\n</write_file>\n\n<write_file>\n<path>seed_corpus/multiline.yaml</path>\n<content>description: |\n  This is a multi-line\n  string in YAML\n  with preserved newlines\n\nfolded: >\n  This is a folded\n  string that will\n  be joined into one line\n</content>\n</write_file>\n\n<write_file>\n<path>seed_corpus/anchors.yaml</path>\n<content>defaults: &defaults\n  adapter: postgres\n  host: localhost\n\ndevelopment:\n  <<: *defaults\n  database: dev_db\n\nproduction:\n  <<: *defaults\n  database: prod_db\n</content>\n</write_file>\n\n## Summary\n\nI've created a complete OSS-Fuzz integration for fuzzing PyYAML:\n\n### Key Features:\n\n1. **fuzz_yaml.py** - Comprehensive Atheris harness that:\n   - Uses `FuzzedDataProvider` for controlled input generation\n   - Tests multiple PyYAML APIs (`safe_load`, `safe_load_all`, `load`)\n   - Tests lower-level APIs (`scan`, `parse`, `compose`) for deeper coverage\n   - Properly handles expected exceptions (YAMLError, ValueError, etc.)\n   - Uses `@atheris.instrument_func` decorator for instrumentation\n\n2. **build.sh** - Build script that:\n   - Installs PyYAML from source with instrumentation\n   - Uses `compile_python_fuzzer` helper provided by OSS-Fuzz\n   - Creates a YAML-specific dictionary with common tokens\n   - Supports optional seed corpus\n\n3. **project.yaml** - OSS-Fuzz configuration with:\n   - Python language specification\n   - libFuzzer engine (used by Atheris)\n   - AddressSanitizer and UndefinedBehaviorSanitizer\n   - GitHub issue integration\n\n4. **Dockerfile** - Custom build environment with libyaml-dev\n\n5. **Seed corpus** - Example YAML files covering common patterns\n\n### Exception Handling:\n\nThe harness properly catches:\n- `YAMLError` - Expected parsing errors\n- `ValueError`, `TypeError`, `AttributeError` - Expected from malformed input\n- `RecursionError` - Deep nesting protection\n- `StopIteration` - Iterator exhaustion\n\nThis ensures only **real bugs** (crashes, memory issues) are reported, not expected parsing failures.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5539,
            "output_tokens": 2335,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "# OSS-Fuzz Harness for PyYAML\n\nI'll provide a complete OSS-Fuzz setup for fuzzing PyYAML with Atheris.\n\n## 1. Fuzzing Harness (`fuzz_yaml.py`)\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML library using Atheris.\nFuzzes YAML parsing functionality with various loaders.\n\"\"\"\n\nimport sys\nimport atheris\n\nwith atheris.instrument_imports():\n    import yaml\n    from yaml import YAMLError\n    import io\n\n\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML parsing.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    if len(data) < 1:\n        return\n    \n    # Convert bytes to string for YAML parsing\n    try:\n        yaml_string = data.decode('utf-8', errors='ignore')\n    except Exception:\n        return\n    \n    # Skip empty strings\n    if not yaml_string.strip():\n        return\n    \n    # Test different YAML loaders\n    loaders = [\n        yaml.SafeLoader,\n        yaml.BaseLoader,\n        yaml.FullLoader,\n    ]\n    \n    # Use first byte to select loader\n    loader_idx = data[0] % len(loaders)\n    loader = loaders[loader_idx]\n    \n    # Test yaml.load()\n    try:\n        result = yaml.load(yaml_string, Loader=loader)\n        # If successful, try to dump it back\n        if result is not None:\n            try:\n                yaml.dump(result)\n            except (YAMLError, TypeError, AttributeError, ValueError):\n                pass\n    except (YAMLError, UnicodeDecodeError, RecursionError, \n            MemoryError, ValueError, AttributeError, TypeError):\n        # Expected exceptions during parsing\n        pass\n    except KeyboardInterrupt:\n        raise\n    except SystemExit:\n        raise\n    \n    # Test yaml.safe_load()\n    try:\n        result = yaml.safe_load(yaml_string)\n        if result is not None:\n            try:\n                yaml.safe_dump(result)\n            except (YAMLError, TypeError, AttributeError, ValueError):\n                pass\n    except (YAMLError, UnicodeDecodeError, RecursionError,\n            MemoryError, ValueError, AttributeError, TypeError):\n        pass\n    except KeyboardInterrupt:\n        raise\n    except SystemExit:\n        raise\n    \n    # Test yaml.load_all() for multiple documents\n    try:\n        documents = list(yaml.load_all(yaml_string, Loader=loader))\n        if documents:\n            try:\n                yaml.dump_all(documents)\n            except (YAMLError, TypeError, AttributeError, ValueError):\n                pass\n    except (YAMLError, UnicodeDecodeError, RecursionError,\n            MemoryError, ValueError, AttributeError, TypeError):\n        pass\n    except KeyboardInterrupt:\n        raise\n    except SystemExit:\n        raise\n    \n    # Test yaml.safe_load_all()\n    try:\n        documents = list(yaml.safe_load_all(yaml_string))\n    except (YAMLError, UnicodeDecodeError, RecursionError,\n            MemoryError, ValueError, AttributeError, TypeError):\n        pass\n    except KeyboardInterrupt:\n        raise\n    except SystemExit:\n        raise\n    \n    # Test scanning (tokenization)\n    try:\n        stream = io.StringIO(yaml_string)\n        for token in yaml.scan(stream):\n            pass\n    except (YAMLError, UnicodeDecodeError, ValueError, AttributeError):\n        pass\n    except KeyboardInterrupt:\n        raise\n    except SystemExit:\n        raise\n    \n    # Test parsing (events)\n    try:\n        stream = io.StringIO(yaml_string)\n        for event in yaml.parse(stream):\n            pass\n    except (YAMLError, UnicodeDecodeError, ValueError, AttributeError):\n        pass\n    except KeyboardInterrupt:\n        raise\n    except SystemExit:\n        raise\n    \n    # Test composition (nodes)\n    try:\n        stream = io.StringIO(yaml_string)\n        for node in yaml.compose_all(stream):\n            pass\n    except (YAMLError, UnicodeDecodeError, ValueError, AttributeError,\n            RecursionError):\n        pass\n    except KeyboardInterrupt:\n        raise\n    except SystemExit:\n        raise\n\n\ndef main():\n    \"\"\"Main entry point for the fuzzer.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Build Script (`build.sh`)\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Install PyYAML\npip3 install --upgrade pip\npip3 install .\n\n# Build the fuzzer\ncompile_python_fuzzer $SRC/fuzz_yaml.py\n\n# Create seed corpus directory\nmkdir -p $OUT/fuzz_yaml_seed_corpus\n\n# Add seed corpus examples\ncat > $OUT/fuzz_yaml_seed_corpus/simple.yaml << EOF\nkey: value\nnumber: 42\nlist:\n  - item1\n  - item2\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/nested.yaml << EOF\nroot:\n  child1:\n    grandchild: value\n  child2:\n    - list_item\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/types.yaml << EOF\nstring: \"hello\"\ninteger: 123\nfloat: 3.14\nboolean: true\nnull_value: null\ndate: 2024-01-01\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/multi_doc.yaml << EOF\n---\ndocument: 1\n---\ndocument: 2\n---\ndocument: 3\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/anchors.yaml << EOF\ndefaults: &defaults\n  adapter: postgres\n  host: localhost\n\ndevelopment:\n  <<: *defaults\n  database: dev_db\n\nproduction:\n  <<: *defaults\n  database: prod_db\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/complex.yaml << EOF\nusers:\n  - name: Alice\n    age: 30\n    roles:\n      - admin\n      - user\n  - name: Bob\n    age: 25\n    roles:\n      - user\n\nsettings:\n  debug: false\n  timeout: 30\n  features:\n    feature_a: enabled\n    feature_b: disabled\nEOF\n\n# Create options file for better fuzzing\ncat > $OUT/fuzz_yaml.options << EOF\n[libfuzzer]\nmax_len = 4096\ntimeout = 25\nrss_limit_mb = 2048\nEOF\n\n# Create dictionary for YAML-specific tokens\ncat > $OUT/fuzz_yaml.dict << EOF\n# YAML special characters and keywords\n\":\"\n\"-\"\n\"---\"\n\"...\"\n\"&\"\n\"*\"\n\"!\"\n\"|\"\n\">\"\n\"[\"\n\"]\"\n\"{\"\n\"}\"\n\"true\"\n\"false\"\n\"null\"\n\"~\"\n\"yes\"\n\"no\"\n\"on\"\n\"off\"\n\"!!str\"\n\"!!int\"\n\"!!float\"\n\"!!bool\"\n\"!!null\"\n\"!!map\"\n\"!!seq\"\n\"!!timestamp\"\n\"!!binary\"\n\"!!python/object\"\n\"!!python/tuple\"\nEOF\n\necho \"Build completed successfully!\"\n```\n\n## 3. Project Configuration (`project.yaml`)\n\n```yaml\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nhomepage: \"https://pyyaml.org/\"\nlanguage: python\nprimary_contact: \"[email protected]\"\nmain_repo: \"https://github.com/yaml/pyyaml\"\n\nfile_github_issue: true\n\nfuzzing_engines:\n  - libfuzzer\n\nsanitizers:\n  - address\n  - undefined\n\narchitectures:\n  - x86_64\n\nvendor_ccs:\n  - [email protected]\n  - [email protected]\n```\n\n## 4. Dockerfile (Optional - for local testing)\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder-python\n\nRUN apt-get update && apt-get install -y \\\n    libyaml-dev \\\n    python3-dev\n\nRUN git clone --depth 1 https://github.com/yaml/pyyaml.git pyyaml\n\nWORKDIR pyyaml\n\nCOPY build.sh fuzz_yaml.py $SRC/\n```\n\n## Usage Instructions\n\n### Local Testing\n\n1. **Build the Docker container:**\n```bash\npython infra/helper.py build_image pyyaml\n```\n\n2. **Build the fuzzers:**\n```bash\npython infra/helper.py build_fuzzers --sanitizer address pyyaml\n```\n\n3. **Run the fuzzer:**\n```bash\npython infra/helper.py run_fuzzer pyyaml fuzz_yaml -- -max_total_time=60\n```\n\n4. **Check coverage:**\n```bash\npython infra/helper.py coverage pyyaml\n```\n\n### Key Features\n\n1. **Multiple Loaders**: Tests SafeLoader, BaseLoader, and FullLoader\n2. **Comprehensive API Coverage**: Tests load, safe_load, load_all, scan, parse, and compose\n3. **Exception Handling**: Properly catches expected exceptions without hiding real bugs\n4. **Seed Corpus**: Includes various YAML patterns for better coverage\n5. **Dictionary**: YAML-specific tokens to guide fuzzing\n6. **Round-trip Testing**: Attempts to dump parsed data back to YAML\n\n### Expected Exceptions Handled\n\n- `YAMLError`: Base exception for YAML parsing errors\n- `UnicodeDecodeError`: Invalid UTF-8 sequences\n- `RecursionError`: Deeply nested structures\n- `MemoryError`: Excessive memory allocation attempts\n- `ValueError`, `AttributeError`, `TypeError`: Various parsing edge cases\n\nThis harness is production-ready and follows OSS-Fuzz best practices for Python fuzzing!",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 67,
            "output_tokens": 2934,
            "cached": false
          },
          "with_skill": {
            "output": "# OSS-Fuzz Python Harness for PyYAML\n\nHere's a complete OSS-Fuzz integration for fuzzing PyYAML with Atheris:\n\n## Project Structure\n\n```\nprojects/pyyaml/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 build.sh\n\u2514\u2500\u2500 fuzz_yaml_load.py\n```\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/yaml/pyyaml\"\nlanguage: python\nprimary_contact: \"security@pyyaml.org\"\nmain_repo: \"https://github.com/yaml/pyyaml\"\nfuzzing_engines:\n  - libfuzzer\nsanitizers:\n  - address\n  - undefined\n```\n\n## 2. Dockerfile\n\n```dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder-python\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y \\\n    libyaml-dev \\\n    python3-dev\n\n# Clone PyYAML repository\nRUN git clone --depth 1 https://github.com/yaml/pyyaml.git pyyaml\n\n# Copy build script and harnesses\nWORKDIR pyyaml\nCOPY build.sh fuzz_*.py $SRC/\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Build and install PyYAML with C extensions\npip3 install --upgrade pip setuptools wheel\npip3 install .\n\n# Compile all Python fuzzers\nfor fuzzer in $(find $SRC -name 'fuzz_*.py'); do\n  compile_python_fuzzer $fuzzer\ndone\n\n# Copy seed corpus if available\nif [ -d \"$SRC/pyyaml/tests/data\" ]; then\n  zip -j $OUT/fuzz_yaml_load_seed_corpus.zip $SRC/pyyaml/tests/data/*.yaml || true\nfi\n\n# Create dictionary for YAML fuzzing\ncat > $OUT/fuzz_yaml_load.dict << EOF\n# YAML keywords\n\"true\"\n\"false\"\n\"null\"\n\"~\"\n\"yes\"\n\"no\"\n\"on\"\n\"off\"\n\n# YAML syntax\n\":\"\n\"-\"\n\"---\"\n\"...\"\n\"[\"\n\"]\"\n\"{\"\n\"}\"\n\"|\"\n\">\"\n\"&\"\n\"*\"\n\"!\"\n\"?\"\n\",\"\n\n# Common tags\n\"!!str\"\n\"!!int\"\n\"!!float\"\n\"!!bool\"\n\"!!null\"\n\"!!seq\"\n\"!!map\"\n\"!!python/object\"\n\"!!python/tuple\"\n\n# Anchors and aliases\n\"&anchor\"\n\"*anchor\"\nEOF\n```\n\n## 4. fuzz_yaml_load.py\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML using Atheris.\n\nThis harness fuzzes the yaml.safe_load() function, which is the recommended\nway to parse untrusted YAML data. It handles expected parsing exceptions\nand focuses on finding crashes, hangs, and memory issues.\n\"\"\"\n\nimport sys\nimport atheris\n\n# Suppress warnings to avoid noise in fuzzing output\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport yaml\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML's safe_load function.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Get fuzzer input as string (YAML is text-based)\n    yaml_input = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n    \n    # Test 1: Basic safe_load\n    try:\n        yaml.safe_load(yaml_input)\n    except yaml.YAMLError:\n        # Expected parsing errors - these are fine\n        pass\n    except (ValueError, TypeError, AttributeError):\n        # Expected errors from malformed data\n        pass\n    except RecursionError:\n        # Expected from deeply nested structures\n        pass\n    \n    # Test 2: safe_load_all for multi-document YAML\n    try:\n        list(yaml.safe_load_all(yaml_input))\n    except yaml.YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError):\n        pass\n    except RecursionError:\n        pass\n    \n    # Test 3: Compose (builds representation graph)\n    try:\n        yaml.compose(yaml_input)\n    except yaml.YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError):\n        pass\n    except RecursionError:\n        pass\n\n\ndef main():\n    \"\"\"Initialize and run the fuzzer.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 5. Additional Harness: fuzz_yaml_unsafe.py\n\nFor more aggressive fuzzing (optional, tests unsafe operations):\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML's unsafe operations.\n\nWARNING: This harness uses yaml.unsafe_load() which can execute arbitrary\nPython code. It's included to find vulnerabilities in the unsafe code paths.\n\"\"\"\n\nimport sys\nimport atheris\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport yaml\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML's unsafe operations.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    yaml_input = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n    \n    # Test unsafe_load (can execute code, but we're looking for crashes)\n    try:\n        yaml.unsafe_load(yaml_input)\n    except yaml.YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError, ImportError):\n        pass\n    except RecursionError:\n        pass\n    except Exception:\n        # Catch broader exceptions since unsafe_load can do anything\n        pass\n\n\ndef main():\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 6. Advanced Harness: fuzz_yaml_emit.py\n\nTests YAML serialization (dump operations):\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML's emit/dump functions.\n\nThis harness tests the serialization side of PyYAML by creating Python\nobjects from fuzzer data and attempting to serialize them to YAML.\n\"\"\"\n\nimport sys\nimport atheris\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport yaml\nfrom io import StringIO\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML's dump functions.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Build a Python object from fuzzer data\n    obj = build_object(fdp)\n    \n    # Test 1: safe_dump\n    try:\n        yaml.safe_dump(obj)\n    except yaml.YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError):\n        pass\n    except RecursionError:\n        pass\n    \n    # Test 2: safe_dump with various options\n    try:\n        output = StringIO()\n        yaml.safe_dump(\n            obj,\n            output,\n            default_flow_style=fdp.ConsumeBool(),\n            allow_unicode=fdp.ConsumeBool(),\n            width=fdp.ConsumeIntInRange(1, 1000),\n            indent=fdp.ConsumeIntInRange(1, 10)\n        )\n    except yaml.YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError):\n        pass\n    except RecursionError:\n        pass\n    \n    # Test 3: Round-trip (dump then load)\n    try:\n        dumped = yaml.safe_dump(obj)\n        yaml.safe_load(dumped)\n    except yaml.YAMLError:\n        pass\n    except (ValueError, TypeError, AttributeError):\n        pass\n    except RecursionError:\n        pass\n\n\ndef build_object(fdp):\n    \"\"\"\n    Build a Python object from fuzzer data.\n    \n    Args:\n        fdp: FuzzedDataProvider instance\n        \n    Returns:\n        A Python object (dict, list, str, int, float, bool, or None)\n    \"\"\"\n    choice = fdp.ConsumeIntInRange(0, 6)\n    \n    if choice == 0:\n        # String\n        return fdp.ConsumeUnicodeNoSurrogates(fdp.ConsumeIntInRange(0, 100))\n    elif choice == 1:\n        # Integer\n        return fdp.ConsumeInt(8)\n    elif choice == 2:\n        # Float\n        return fdp.ConsumeFloat()\n    elif choice == 3:\n        # Boolean\n        return fdp.ConsumeBool()\n    elif choice == 4:\n        # None\n        return None\n    elif choice == 5:\n        # List (limited depth to avoid infinite recursion)\n        size = fdp.ConsumeIntInRange(0, 5)\n        return [build_simple_value(fdp) for _ in range(size)]\n    else:\n        # Dict (limited depth)\n        size = fdp.ConsumeIntInRange(0, 5)\n        return {\n            fdp.ConsumeUnicodeNoSurrogates(10): build_simple_value(fdp)\n            for _ in range(size)\n        }\n\n\ndef build_simple_value(fdp):\n    \"\"\"Build a simple value (no nested structures).\"\"\"\n    choice = fdp.ConsumeIntInRange(0, 4)\n    \n    if choice == 0:\n        return fdp.ConsumeUnicodeNoSurrogates(20)\n    elif choice == 1:\n        return fdp.ConsumeInt(4)\n    elif choice == 2:\n        return fdp.ConsumeFloat()\n    elif choice == 3:\n        return fdp.ConsumeBool()\n    else:\n        return None\n\n\ndef main():\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Testing Locally\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Build the project image\npython3 infra/helper.py build_image pyyaml\n\n# Build fuzzers\npython3 infra/helper.py build_fuzzers --sanitizer=address pyyaml\n\n# Run the main harness\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml_load\n\n# Run with specific timeout and max length\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml_load -- -max_len=4096 -timeout=10\n\n# Generate coverage report\npython3 infra/helper.py build_fuzzers --sanitizer=coverage pyyaml\npython3 infra/helper.py coverage pyyaml\n```\n\n## Key Features\n\n### Exception Handling\n- **YAMLError**: Expected parsing errors from malformed YAML\n- **ValueError/TypeError**: Expected from invalid data types\n- **RecursionError**: Expected from deeply nested structures\n- **AttributeError**: Expected from malformed object references\n\n### Multiple Test Vectors\n1. **safe_load**: Standard parsing (most important)\n2. **safe_load_all**: Multi-document YAML\n3. **compose**: Low-level representation graph building\n\n### Fuzzing Optimizations\n- **Dictionary**: Common YAML syntax and keywords\n- **Seed corpus**: Uses existing test files from PyYAML repo\n- **FuzzedDataProvider**: Proper string handling for text-based format\n- **Limited nesting**: Prevents timeout from deep recursion\n\n### Safety Considerations\n- Uses `safe_load` by default (no arbitrary code execution)\n- Separate harness for `unsafe_load` testing\n- Proper exception handling to avoid false positives\n- Suppresses warnings to reduce noise\n\n## Expected Fuzzing Output\n\n```\nINFO: Running with entropic power schedule (0xFF, 100).\nINFO: Seed: 3847562910\nINFO: Loaded 1 modules   (12847 inline 8-bit counters)\nINFO: Loaded 1 PC tables (12847 PCs)\nINFO:      156 files found in /tmp/fuzz_yaml_load_corpus\nINFO: seed corpus: files: 156 min: 1b max: 2048b total: 45678b\n#157    INITED cov: 1247 ft: 2891 corp: 142/42Kb exec/s: 0 rss: 58Mb\n#165    NEW    cov: 1251 ft: 2903 corp: 143/42Kb lim: 2048 exec/s: 0 rss: 58Mb\n#178    NEW    cov: 1253 ft: 2915 corp: 144/43Kb lim: 2048 exec/s: 0 rss: 59Mb\n```\n\nThis integration provides comprehensive fuzzing coverage for PyYAML while properly handling expected exceptions and avoiding false positives.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5013,
            "output_tokens": 3362,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a complete OSS-Fuzz integration for fuzzing PyYAML with Atheris.\n\n## 1. Harness File\n\n<write_file>\n<path>fuzz_yaml.py</path>\n<content>#!/usr/bin/env python3\n\"\"\"Atheris fuzzing harness for PyYAML library.\"\"\"\n\nimport atheris\nimport sys\n\nwith atheris.instrument_imports():\n    import yaml\n    from yaml import YAMLError\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"Fuzz PyYAML's safe_load and load functions.\n    \n    Args:\n        data: Raw bytes from fuzzer to parse as YAML\n    \"\"\"\n    if len(data) == 0:\n        return\n    \n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Use FuzzedDataProvider to create string input\n    yaml_input = fdp.ConsumeUnicodeNoSurrogates(fdp.remaining_bytes())\n    \n    # Test safe_load (recommended for untrusted input)\n    try:\n        result = yaml.safe_load(yaml_input)\n        # If parsing succeeds, try to access the result to ensure it's valid\n        if result is not None:\n            _ = str(result)\n            _ = repr(result)\n    except (YAMLError, ValueError, TypeError, AttributeError, KeyError, \n            RecursionError, MemoryError) as e:\n        # Expected exceptions during fuzzing - these are handled correctly\n        pass\n    \n    # Also test full_load to find issues in extended YAML features\n    try:\n        result = yaml.full_load(yaml_input)\n        if result is not None:\n            _ = str(result)\n            _ = repr(result)\n    except (YAMLError, ValueError, TypeError, AttributeError, KeyError,\n            RecursionError, MemoryError) as e:\n        # Expected exceptions during fuzzing\n        pass\n    \n    # Test safe_load_all for multi-document YAML\n    try:\n        documents = list(yaml.safe_load_all(yaml_input))\n        for doc in documents:\n            if doc is not None:\n                _ = str(doc)\n    except (YAMLError, ValueError, TypeError, AttributeError, KeyError,\n            RecursionError, MemoryError) as e:\n        # Expected exceptions during fuzzing\n        pass\n\n\ndef main():\n    \"\"\"Initialize Atheris and start fuzzing.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n</content>\n</write_file>\n\n## 2. Build Script\n\n<write_file>\n<path>build.sh</path>\n<content>#!/bin/bash -eu\n# Build script for OSS-Fuzz integration with PyYAML\n\n# Install PyYAML from source to ensure we're fuzzing the latest version\n# and that it's instrumented properly\ncd $SRC\n\n# Clone PyYAML if not already present\nif [ ! -d \"pyyaml\" ]; then\n    git clone --depth 1 https://github.com/yaml/pyyaml.git\nfi\n\ncd pyyaml\n\n# Install PyYAML with instrumentation\npip3 install .\n\n# Build the fuzzing harness\n# compile_python_fuzzer is provided by OSS-Fuzz base-builder-python\ncompile_python_fuzzer $SRC/fuzz_yaml.py\n\n# Optional: Add seed corpus if available\n# This would be a zip file containing example YAML files\n# cp $SRC/yaml_seed_corpus.zip $OUT/fuzz_yaml_seed_corpus.zip\n\n# Optional: Add dictionary for better fuzzing coverage\n# Create a simple YAML dictionary\ncat > $OUT/fuzz_yaml.dict << EOF\n# YAML syntax elements\n\":\"\n\"-\"\n\"---\"\n\"...\"\n\"[\"\n\"]\"\n\"{\"\n\"}\"\n\"!\"\n\"&\"\n\"*\"\n\"|\"\n\">\"\n\"'\"\n\"\\\"\"\n\"true\"\n\"false\"\n\"null\"\n\"~\"\n\".inf\"\n\".nan\"\n\"key: value\"\n\"- item\"\n\"!!str\"\n\"!!int\"\n\"!!float\"\n\"!!bool\"\n\"!!null\"\n\"!!seq\"\n\"!!map\"\nEOF\n</content>\n</write_file>\n\n## 3. Project Configuration\n\n<write_file>\n<path>project.yaml</path>\n<content>homepage: \"https://github.com/yaml/pyyaml\"\nlanguage: python\nprimary_contact: \"security@pyyaml.org\"\nmain_repo: \"https://github.com/yaml/pyyaml\"\n\n# Use Atheris for Python fuzzing\nfuzzing_engines:\n  - libfuzzer\n\n# Python projects with C extensions only support AddressSanitizer\nsanitizers:\n  - address\n\n# Vendor-specific configuration\nvendor_ccs:\n  - \"your-email@example.com\"\n\n# File issue template\nfile_github_issue: true\n</content>\n</write_file>\n\n## 4. Dockerfile\n\n<write_file>\n<path>Dockerfile</path>\n<content>FROM gcr.io/oss-fuzz-base/base-builder-python\n\n# Install build dependencies for PyYAML (requires libyaml)\nRUN apt-get update && apt-get install -y \\\n    libyaml-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the PyYAML repository\nRUN git clone --depth 1 https://github.com/yaml/pyyaml.git $SRC/pyyaml\n\n# Copy build script and fuzzing harness\nCOPY build.sh fuzz_yaml.py $SRC/\n\nWORKDIR $SRC\n</content>\n</write_file>\n\n## Summary\n\nI've created a complete OSS-Fuzz integration for fuzzing PyYAML:\n\n### **Key Features:**\n\n1. **fuzz_yaml.py** - Atheris harness that:\n   - Uses `FuzzedDataProvider` for proper input handling\n   - Tests multiple YAML loading functions (`safe_load`, `full_load`, `safe_load_all`)\n   - Handles expected exceptions (YAMLError, ValueError, etc.)\n   - Exercises parsed results to catch deeper bugs\n\n2. **build.sh** - Build script that:\n   - Installs PyYAML from source with instrumentation\n   - Uses `compile_python_fuzzer` helper from OSS-Fuzz\n   - Includes a YAML-specific dictionary for better coverage\n   - Structured for easy corpus addition\n\n3. **project.yaml** - Configuration with:\n   - Python language specification\n   - libFuzzer engine (required for Atheris)\n   - AddressSanitizer only (Python limitation)\n   - Proper metadata for OSS-Fuzz enrollment\n\n4. **Dockerfile** - Build environment with:\n   - `base-builder-python` image\n   - libyaml-dev for PyYAML's C extension\n   - Repository cloning and file copying\n\n### **Testing Locally:**\n\n```bash\n# From OSS-Fuzz directory\npython3 infra/helper.py build_image pyyaml\npython3 infra/helper.py build_fuzzers --sanitizer=address pyyaml\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml\n```\n\nThe harness properly handles expected exceptions while allowing real crashes (buffer overflows, use-after-free, etc.) to be caught by AddressSanitizer.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5539,
            "output_tokens": 1850,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "# OSS-Fuzz Harness for PyYAML\n\nI'll provide a complete OSS-Fuzz setup for fuzzing PyYAML with Atheris.\n\n## 1. Fuzzing Harness (`fuzz_yaml.py`)\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML library using Atheris.\nThis fuzzer tests YAML parsing functionality with various inputs.\n\"\"\"\n\nimport sys\nimport atheris\nimport yaml\nimport io\n\n# Expected exceptions that should not be reported as bugs\nEXPECTED_EXCEPTIONS = (\n    yaml.YAMLError,\n    yaml.scanner.ScannerError,\n    yaml.parser.ParserError,\n    yaml.constructor.ConstructorError,\n    yaml.composer.ComposerError,\n    yaml.reader.ReaderError,\n    RecursionError,\n    MemoryError,\n    ValueError,\n    UnicodeDecodeError,\n    UnicodeError,\n)\n\n\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML parsing.\n    \n    Args:\n        data: Raw bytes to be parsed as YAML\n    \"\"\"\n    if len(data) == 0:\n        return\n    \n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Choose different parsing modes\n    parse_mode = fdp.ConsumeIntInRange(0, 5)\n    yaml_data = fdp.ConsumeRemainingBytes()\n    \n    try:\n        if parse_mode == 0:\n            # Test yaml.safe_load (most common usage)\n            yaml.safe_load(yaml_data)\n            \n        elif parse_mode == 1:\n            # Test yaml.safe_load_all (multiple documents)\n            list(yaml.safe_load_all(yaml_data))\n            \n        elif parse_mode == 2:\n            # Test yaml.load with SafeLoader\n            yaml.load(yaml_data, Loader=yaml.SafeLoader)\n            \n        elif parse_mode == 3:\n            # Test yaml.load_all with SafeLoader\n            list(yaml.load_all(yaml_data, Loader=yaml.SafeLoader))\n            \n        elif parse_mode == 4:\n            # Test yaml.scan (tokenization)\n            list(yaml.scan(yaml_data))\n            \n        elif parse_mode == 5:\n            # Test yaml.parse (parsing events)\n            list(yaml.parse(yaml_data))\n            \n    except EXPECTED_EXCEPTIONS:\n        # These are expected errors during fuzzing and should not be reported\n        pass\n    except Exception as e:\n        # Unexpected exceptions might indicate bugs\n        # Let them propagate to be caught by the fuzzer\n        raise\n\n\ndef main():\n    \"\"\"Initialize and run the fuzzer.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 2. Build Script (`build.sh`)\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Build script for PyYAML fuzzing\n\n# Install PyYAML from source\npip3 install --upgrade pip\npip3 install .\n\n# Compile the fuzzer\ncompile_python_fuzzer $SRC/pyyaml/fuzz_yaml.py\n\n# Create seed corpus directory\nmkdir -p $OUT/fuzz_yaml_seed_corpus\n\n# Add some seed inputs for better fuzzing coverage\ncat > $OUT/fuzz_yaml_seed_corpus/simple.yaml << EOF\nname: John Doe\nage: 30\ncity: New York\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/list.yaml << EOF\n- apple\n- banana\n- cherry\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/nested.yaml << EOF\nperson:\n  name: Jane\n  address:\n    street: 123 Main St\n    city: Boston\n  hobbies:\n    - reading\n    - coding\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/multiline.yaml << EOF\ndescription: |\n  This is a multiline\n  string in YAML\n  with multiple lines\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/anchor.yaml << EOF\ndefaults: &defaults\n  adapter: postgres\n  host: localhost\n\ndevelopment:\n  <<: *defaults\n  database: dev_db\n\nproduction:\n  <<: *defaults\n  database: prod_db\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/types.yaml << EOF\nstring: \"hello\"\ninteger: 42\nfloat: 3.14\nboolean: true\nnull_value: null\ndate: 2024-01-01\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/multi_document.yaml << EOF\n---\ndocument: 1\n---\ndocument: 2\n---\ndocument: 3\nEOF\n\ncat > $OUT/fuzz_yaml_seed_corpus/complex.yaml << EOF\napiVersion: v1\nkind: Service\nmetadata:\n  name: my-service\nspec:\n  selector:\n    app: MyApp\n  ports:\n    - protocol: TCP\n      port: 80\n      targetPort: 9376\nEOF\n\n# Create options file for better fuzzing\ncat > $OUT/fuzz_yaml.options << EOF\n[libfuzzer]\nmax_len = 65536\ntimeout = 25\nrss_limit_mb = 2048\nEOF\n\n# Create dictionary for YAML-specific tokens\ncat > $OUT/fuzz_yaml.dict << EOF\n# YAML special characters and keywords\n\":\"\n\"-\"\n\"---\"\n\"...\"\n\"&\"\n\"*\"\n\"!\"\n\"|\"\n\">\"\n\"?\"\n\"[\"\n\"]\"\n\"{\"\n\"}\"\n\"true\"\n\"false\"\n\"null\"\n\"~\"\n\"<<\"\n\"!!\"\n\"!!str\"\n\"!!int\"\n\"!!float\"\n\"!!bool\"\n\"!!null\"\n\"!!map\"\n\"!!seq\"\nEOF\n\necho \"Build completed successfully\"\n```\n\n## 3. Project Configuration (`project.yaml`)\n\n```yaml\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nhomepage: \"https://pyyaml.org/\"\nlanguage: python\nprimary_contact: \"security@pyyaml.org\"\nmain_repo: \"https://github.com/yaml/pyyaml\"\n\nfile_github_issue: true\n\nsanitizers:\n  - address\n  - undefined\n\narchitectures:\n  - x86_64\n\nfuzzing_engines:\n  - libfuzzer\n\nvendor_ccs:\n  - david@adalogics.com\n\n```\n\n## 4. Dockerfile (Optional, for local testing)\n\n```dockerfile\n# Dockerfile for local testing\nFROM gcr.io/oss-fuzz-base/base-builder-python\n\nRUN git clone --depth 1 https://github.com/yaml/pyyaml.git pyyaml\n\nWORKDIR pyyaml\n\nCOPY build.sh fuzz_yaml.py project.yaml $SRC/pyyaml/\n```\n\n## 5. Additional Test Harness (`fuzz_yaml_advanced.py`)\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nAdvanced OSS-Fuzz harness for PyYAML with more coverage.\nTests additional functionality like dumping and custom constructors.\n\"\"\"\n\nimport sys\nimport atheris\nimport yaml\nfrom yaml import Node\n\nEXPECTED_EXCEPTIONS = (\n    yaml.YAMLError,\n    yaml.scanner.ScannerError,\n    yaml.parser.ParserError,\n    yaml.constructor.ConstructorError,\n    yaml.composer.ComposerError,\n    yaml.reader.ReaderError,\n    yaml.emitter.EmitterError,\n    yaml.representer.RepresenterError,\n    yaml.serializer.SerializerError,\n    RecursionError,\n    MemoryError,\n    ValueError,\n    TypeError,\n    UnicodeDecodeError,\n    UnicodeError,\n    AttributeError,\n)\n\n\ndef TestOneInput(data):\n    \"\"\"Advanced fuzz target for PyYAML.\"\"\"\n    if len(data) < 2:\n        return\n    \n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Choose operation\n    operation = fdp.ConsumeIntInRange(0, 7)\n    yaml_data = fdp.ConsumeRemainingBytes()\n    \n    try:\n        if operation == 0:\n            # Parse and dump cycle\n            obj = yaml.safe_load(yaml_data)\n            if obj is not None:\n                yaml.safe_dump(obj)\n                \n        elif operation == 1:\n            # Parse with different loaders\n            yaml.load(yaml_data, Loader=yaml.BaseLoader)\n            \n        elif operation == 2:\n            # Compose nodes\n            list(yaml.compose_all(yaml_data))\n            \n        elif operation == 3:\n            # Serialize\n            obj = yaml.safe_load(yaml_data)\n            if obj is not None:\n                list(yaml.serialize_all([obj]))\n                \n        elif operation == 4:\n            # Test with explicit encoding\n            try:\n                yaml.safe_load(yaml_data.decode('utf-8', errors='ignore'))\n            except (UnicodeDecodeError, AttributeError):\n                pass\n                \n        elif operation == 5:\n            # Test canonical output\n            obj = yaml.safe_load(yaml_data)\n            if obj is not None:\n                yaml.safe_dump(obj, canonical=True)\n                \n        elif operation == 6:\n            # Test with different width settings\n            obj = yaml.safe_load(yaml_data)\n            if obj is not None:\n                yaml.safe_dump(obj, width=50, indent=4)\n                \n        elif operation == 7:\n            # Test emit\n            events = list(yaml.parse(yaml_data))\n            if events:\n                yaml.emit(events)\n                \n    except EXPECTED_EXCEPTIONS:\n        pass\n    except Exception as e:\n        raise\n\n\ndef main():\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Usage Instructions\n\n### Local Testing\n\n1. **Build the Docker container:**\n```bash\ndocker build -t pyyaml-fuzzer .\n```\n\n2. **Compile the fuzzer:**\n```bash\ndocker run --rm -v $(pwd)/out:/out pyyaml-fuzzer\n```\n\n3. **Run the fuzzer:**\n```bash\ndocker run --rm -v $(pwd)/out:/out -v $(pwd)/corpus:/corpus \\\n  gcr.io/oss-fuzz-base/base-runner \\\n  run_fuzzer fuzz_yaml -max_total_time=60\n```\n\n### Integration with OSS-Fuzz\n\nPlace these files in the OSS-Fuzz repository structure:\n- `projects/pyyaml/project.yaml`\n- `projects/pyyaml/build.sh`\n- `projects/pyyaml/fuzz_yaml.py`\n\nThe fuzzer will:\n- \u2705 Handle all expected YAML parsing exceptions\n- \u2705 Test multiple parsing modes (safe_load, load_all, scan, parse)\n- \u2705 Include seed corpus for better coverage\n- \u2705 Use a dictionary for YAML-specific tokens\n- \u2705 Catch unexpected exceptions that might indicate bugs\n- \u2705 Follow OSS-Fuzz best practices\n\nThis setup provides comprehensive fuzzing coverage for PyYAML while properly handling expected exceptions.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 67,
            "output_tokens": 3104,
            "cached": false
          },
          "with_skill": {
            "output": "# OSS-Fuzz Python Harness for PyYAML\n\nHere's a complete OSS-Fuzz integration for fuzzing PyYAML with Atheris:\n\n## Project Structure\n\n```\nprojects/pyyaml/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 build.sh\n\u2514\u2500\u2500 fuzz_yaml_load.py\n```\n\n## 1. project.yaml\n\n```yaml\nhomepage: \"https://github.com/yaml/pyyaml\"\nlanguage: python\nprimary_contact: \"security@pyyaml.org\"\nauto_ccs:\n  - \"your-email@example.com\"\nmain_repo: \"https://github.com/yaml/pyyaml\"\nfuzzing_engines:\n  - libfuzzer\nsanitizers:\n  - address\n  - undefined\n```\n\n## 2. Dockerfile\n\n```dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder-python\n\n# Install build dependencies\nRUN apt-get update && apt-get install -y \\\n    libyaml-dev \\\n    python3-dev\n\n# Clone the main repository\nRUN git clone --depth 1 https://github.com/yaml/pyyaml\n\n# Copy build script and harnesses\nCOPY build.sh fuzz_*.py $SRC/\n\nWORKDIR $SRC/pyyaml\n```\n\n## 3. build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Build and install PyYAML with LibYAML bindings\ncd $SRC/pyyaml\npip3 install --upgrade pip\npip3 install .\n\n# Compile all Python fuzzers\nfor fuzzer in $(find $SRC -name 'fuzz_*.py'); do\n  compile_python_fuzzer $fuzzer\ndone\n```\n\n## 4. fuzz_yaml_load.py\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML using Atheris.\n\nThis harness fuzzes the yaml.load() and yaml.safe_load() functions\nto discover parsing vulnerabilities, crashes, and unexpected behavior.\n\"\"\"\n\nimport sys\nimport atheris\nimport yaml\nimport io\n\n\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML parsing functions.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    if len(data) < 1:\n        return\n    \n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Use first byte to select which loader to test\n    loader_choice = fdp.ConsumeIntInRange(0, 3)\n    \n    # Get YAML content to parse\n    yaml_content = fdp.ConsumeRemainingBytes()\n    \n    # Convert bytes to string for YAML parsing\n    try:\n        yaml_str = yaml_content.decode('utf-8', errors='ignore')\n    except Exception:\n        return\n    \n    # Skip empty strings\n    if not yaml_str.strip():\n        return\n    \n    # Test different loaders based on choice\n    try:\n        if loader_choice == 0:\n            # Test safe_load (most common, safest)\n            yaml.safe_load(yaml_str)\n            \n        elif loader_choice == 1:\n            # Test safe_load with stream\n            stream = io.StringIO(yaml_str)\n            yaml.safe_load(stream)\n            \n        elif loader_choice == 2:\n            # Test full_load (allows Python objects but safer than load)\n            yaml.full_load(yaml_str)\n            \n        else:\n            # Test safe_load_all for multiple documents\n            list(yaml.safe_load_all(yaml_str))\n            \n    except yaml.YAMLError:\n        # Expected parsing errors - not bugs\n        pass\n    except yaml.scanner.ScannerError:\n        # Expected scanner errors - not bugs\n        pass\n    except yaml.parser.ParserError:\n        # Expected parser errors - not bugs\n        pass\n    except yaml.constructor.ConstructorError:\n        # Expected constructor errors - not bugs\n        pass\n    except yaml.composer.ComposerError:\n        # Expected composer errors - not bugs\n        pass\n    except RecursionError:\n        # Expected for deeply nested structures\n        pass\n    except ValueError:\n        # Expected for invalid values\n        pass\n    except KeyError:\n        # Expected for missing keys in mappings\n        pass\n    except TypeError:\n        # Expected for type mismatches\n        pass\n    except AttributeError:\n        # Expected for invalid attribute access\n        pass\n    except UnicodeDecodeError:\n        # Expected for invalid unicode\n        pass\n    except MemoryError:\n        # Expected for extremely large inputs\n        pass\n\n\ndef main():\n    \"\"\"Initialize and run the fuzzer.\"\"\"\n    atheris.instrument_all()\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## 5. Additional Harness: fuzz_yaml_dump.py\n\n```python\n#!/usr/bin/env python3\n\"\"\"\nOSS-Fuzz harness for PyYAML dump functions using Atheris.\n\nThis harness fuzzes yaml.dump() and yaml.safe_dump() to discover\nserialization issues.\n\"\"\"\n\nimport sys\nimport atheris\nimport yaml\nimport io\n\n\n@atheris.instrument_func\ndef create_fuzzed_object(fdp):\n    \"\"\"\n    Create a Python object from fuzzed data.\n    \n    Args:\n        fdp: FuzzedDataProvider instance\n        \n    Returns:\n        A Python object constructed from fuzzed data\n    \"\"\"\n    choice = fdp.ConsumeIntInRange(0, 7)\n    \n    if choice == 0:\n        # String\n        return fdp.ConsumeUnicodeNoSurrogates(fdp.ConsumeIntInRange(0, 100))\n    elif choice == 1:\n        # Integer\n        return fdp.ConsumeInt(8)\n    elif choice == 2:\n        # Float\n        return fdp.ConsumeFloat()\n    elif choice == 3:\n        # Boolean\n        return fdp.ConsumeBool()\n    elif choice == 4:\n        # None\n        return None\n    elif choice == 5:\n        # List\n        size = fdp.ConsumeIntInRange(0, 10)\n        return [create_fuzzed_object(fdp) for _ in range(size)]\n    elif choice == 6:\n        # Dict\n        size = fdp.ConsumeIntInRange(0, 10)\n        result = {}\n        for _ in range(size):\n            key = fdp.ConsumeUnicodeNoSurrogates(20)\n            if key:  # Avoid empty keys\n                result[key] = create_fuzzed_object(fdp)\n        return result\n    else:\n        # Tuple\n        size = fdp.ConsumeIntInRange(0, 5)\n        return tuple(create_fuzzed_object(fdp) for _ in range(size))\n\n\ndef TestOneInput(data):\n    \"\"\"\n    Fuzz target for PyYAML dump functions.\n    \n    Args:\n        data: Raw bytes from the fuzzer\n    \"\"\"\n    if len(data) < 1:\n        return\n    \n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Create object to serialize\n    try:\n        obj = create_fuzzed_object(fdp)\n    except Exception:\n        return\n    \n    # Choose dump method\n    dump_choice = fdp.ConsumeIntInRange(0, 3)\n    \n    try:\n        if dump_choice == 0:\n            # Test safe_dump\n            yaml.safe_dump(obj)\n            \n        elif dump_choice == 1:\n            # Test safe_dump with stream\n            stream = io.StringIO()\n            yaml.safe_dump(obj, stream)\n            \n        elif dump_choice == 2:\n            # Test safe_dump with options\n            yaml.safe_dump(\n                obj,\n                default_flow_style=fdp.ConsumeBool(),\n                allow_unicode=fdp.ConsumeBool(),\n                width=fdp.ConsumeIntInRange(20, 200)\n            )\n            \n        else:\n            # Test safe_dump_all with multiple documents\n            yaml.safe_dump_all([obj, obj])\n            \n    except yaml.YAMLError:\n        pass\n    except yaml.representer.RepresenterError:\n        pass\n    except RecursionError:\n        pass\n    except ValueError:\n        pass\n    except TypeError:\n        pass\n    except AttributeError:\n        pass\n    except MemoryError:\n        pass\n\n\ndef main():\n    \"\"\"Initialize and run the fuzzer.\"\"\"\n    atheris.instrument_all()\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n```\n\n## Testing Locally\n\n### Build and Run\n\n```bash\n# From OSS-Fuzz root directory\ncd oss-fuzz\n\n# Build the project image\npython3 infra/helper.py build_image pyyaml\n\n# Build the fuzzers\npython3 infra/helper.py build_fuzzers --sanitizer=address pyyaml\n\n# Run the load fuzzer\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml_load\n\n# Run the dump fuzzer\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml_dump\n\n# Generate coverage report\npython3 infra/helper.py coverage pyyaml\n```\n\n## Key Design Decisions\n\n### 1. Exception Handling Strategy\n\nThe harness catches **expected exceptions** that indicate valid error handling:\n\n```python\nexcept yaml.YAMLError:\n    # Base class for all YAML errors\n    pass\nexcept yaml.scanner.ScannerError:\n    # Tokenization errors\n    pass\nexcept yaml.parser.ParserError:\n    # Grammar errors\n    pass\n```\n\n**Why:** These exceptions are part of PyYAML's normal error handling. We only want to catch **unexpected crashes** (segfaults, assertion failures, etc.).\n\n### 2. Multiple Loader Testing\n\n```python\nloader_choice = fdp.ConsumeIntInRange(0, 3)\n```\n\nTests different parsing paths:\n- `safe_load()` - Most restrictive, production use\n- `full_load()` - Allows more Python types\n- `safe_load_all()` - Multiple YAML documents\n\n**Why:** Different loaders have different code paths and security implications.\n\n### 3. UTF-8 Decoding with Error Handling\n\n```python\nyaml_str = yaml_content.decode('utf-8', errors='ignore')\n```\n\n**Why:** YAML expects text input. Using `errors='ignore'` prevents crashes on invalid UTF-8 while still testing parsing logic.\n\n### 4. Dump Harness Object Construction\n\n```python\n@atheris.instrument_func\ndef create_fuzzed_object(fdp):\n```\n\n**Why:** The `@atheris.instrument_func` decorator ensures Atheris tracks coverage in helper functions, improving fuzzing effectiveness.\n\n## Expected Fuzzing Behavior\n\n### What the Fuzzer Will Find\n\n\u2705 **Memory safety issues** (buffer overflows, use-after-free)  \n\u2705 **Assertion failures** in parsing logic  \n\u2705 **Infinite loops** or hangs  \n\u2705 **Unexpected exceptions** not in the catch list  \n\u2705 **Resource exhaustion** (if not caught by MemoryError)\n\n### What the Fuzzer Will Ignore\n\n\u274c **Valid YAML parsing errors** (caught exceptions)  \n\u274c **Expected recursion limits**  \n\u274c **Type errors from invalid constructions**\n\n## Advanced: Seed Corpus\n\nCreate `fuzz_yaml_load_seed_corpus/` directory with example YAML files:\n\n```yaml\n# seed1.yaml\nkey: value\nlist:\n  - item1\n  - item2\nnested:\n  deep:\n    value: 123\n```\n\n```yaml\n# seed2.yaml\n---\ndocument: 1\n---\ndocument: 2\n```\n\nAdd to build.sh:\n```bash\n# Create seed corpus\nmkdir -p $OUT/fuzz_yaml_load_seed_corpus\ncp $SRC/pyyaml/tests/data/*.yaml $OUT/fuzz_yaml_load_seed_corpus/ || true\n```\n\n## Monitoring and Maintenance\n\n### Check Build Status\n\nVisit: `https://oss-fuzz-build-logs.storage.googleapis.com/index.html#pyyaml`\n\n### View Coverage\n\nVisit: `https://oss-fuzz-introspector.storage.googleapis.com/pyyaml/`\n\n### Bug Reports\n\nCheck: `https://issues.oss-fuzz.com/issues?q=proj:pyyaml`\n\nThis complete integration provides robust fuzzing coverage for PyYAML while properly handling expected exceptions and testing multiple code paths.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5013,
            "output_tokens": 3184,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create a complete OSS-Fuzz integration for fuzzing PyYAML with Atheris.\n\n## 1. Harness File\n\n<write_file>\n<path>fuzz_yaml.py</path>\n<content>#!/usr/bin/env python3\n\"\"\"Atheris fuzzing harness for PyYAML library.\"\"\"\n\nimport atheris\nimport sys\n\nwith atheris.instrument_imports():\n    import yaml\n    from yaml import YAMLError\n\n\n@atheris.instrument_func\ndef TestOneInput(data):\n    \"\"\"Fuzz PyYAML's load functions with various input data.\n    \n    Args:\n        data: Raw bytes from fuzzer to parse as YAML\n    \"\"\"\n    fdp = atheris.FuzzedDataProvider(data)\n    \n    # Get fuzzer-generated bytes to use as YAML input\n    yaml_input = fdp.ConsumeBytes(fdp.remaining_bytes())\n    \n    # Try to decode as string for text-based parsing\n    try:\n        yaml_str = yaml_input.decode('utf-8', errors='ignore')\n    except Exception:\n        return\n    \n    # Test yaml.safe_load (recommended for untrusted input)\n    try:\n        yaml.safe_load(yaml_str)\n    except (YAMLError, ValueError, RecursionError, MemoryError):\n        # Expected exceptions during fuzzing:\n        # - YAMLError: malformed YAML syntax\n        # - ValueError: invalid values in YAML\n        # - RecursionError: deeply nested structures\n        # - MemoryError: extremely large structures\n        pass\n    except Exception as e:\n        # Catch unexpected exceptions that might indicate bugs\n        # Re-raise to report to OSS-Fuzz\n        raise\n    \n    # Test yaml.safe_load_all for multi-document parsing\n    try:\n        list(yaml.safe_load_all(yaml_str))\n    except (YAMLError, ValueError, RecursionError, MemoryError):\n        pass\n    except Exception as e:\n        raise\n    \n    # Test yaml.safe_dump for round-trip fuzzing\n    # Only if we successfully parsed something\n    try:\n        parsed = yaml.safe_load(yaml_str)\n        if parsed is not None:\n            yaml.safe_dump(parsed)\n    except (YAMLError, ValueError, RecursionError, MemoryError, TypeError):\n        # TypeError can occur with non-serializable objects\n        pass\n    except Exception as e:\n        raise\n\n\ndef main():\n    \"\"\"Initialize Atheris and start fuzzing.\"\"\"\n    atheris.Setup(sys.argv, TestOneInput)\n    atheris.Fuzz()\n\n\nif __name__ == \"__main__\":\n    main()\n</content>\n</write_file>\n\n## 2. Build Script\n\n<write_file>\n<path>build.sh</path>\n<content>#!/bin/bash -eu\n# Build script for OSS-Fuzz integration with PyYAML\n\n# Install PyYAML from source\ncd $SRC/pyyaml\npip3 install .\n\n# Compile all Python fuzzers found in the source directory\nfor fuzzer in $(find $SRC -name 'fuzz_*.py'); do\n  fuzzer_basename=$(basename -s .py $fuzzer)\n  fuzzer_package=${fuzzer_basename}.pkg\n  \n  # Use OSS-Fuzz's compile_python_fuzzer helper\n  # This handles Atheris instrumentation and linking\n  compile_python_fuzzer $fuzzer\n  \n  echo \"Compiled fuzzer: $fuzzer_basename\"\ndone\n\n# Optional: Add seed corpus if available\n# This would contain valid YAML examples to improve fuzzing\nif [ -d \"$SRC/yaml-corpus\" ]; then\n  zip -j $OUT/fuzz_yaml_seed_corpus.zip $SRC/yaml-corpus/*\n  echo \"Added seed corpus\"\nfi\n\n# Optional: Add dictionary for better fuzzing coverage\n# YAML-specific tokens that help the fuzzer generate valid structures\ncat > $OUT/fuzz_yaml.dict << EOF\n# YAML structural tokens\n\":\"\n\"-\"\n\"---\"\n\"...\"\n\"[\"\n\"]\"\n\"{\"\n\"}\"\n\"!\"\n\"&\"\n\"*\"\n\"|\"\n\">\"\n\"'\"\n\"\\\"\"\n\"#\"\n\"true\"\n\"false\"\n\"null\"\n\"~\"\n\n# Common YAML keys\n\"name\"\n\"value\"\n\"key\"\n\"data\"\n\"config\"\n\"version\"\n\"type\"\n\"id\"\n\n# YAML tags\n\"!!str\"\n\"!!int\"\n\"!!float\"\n\"!!bool\"\n\"!!null\"\n\"!!map\"\n\"!!seq\"\n\"!!binary\"\nEOF\n\necho \"Build completed successfully\"\n</content>\n</write_file>\n\n## 3. Project Configuration\n\n<write_file>\n<path>project.yaml</path>\n<content>homepage: \"https://github.com/yaml/pyyaml\"\nlanguage: python\nprimary_contact: \"security@pyyaml.org\"\nauto_ccs:\n  - \"your-email@example.com\"\n\nmain_repo: \"https://github.com/yaml/pyyaml\"\n\nfuzzing_engines:\n  - libfuzzer\n\nsanitizers:\n  - address\n  - undefined\n\n# Vendor-specific settings\nvendor_ccs:\n  - \"yaml-maintainers@example.com\"\n\n# Build configuration\nfile_github_issue: true\n\n# Coverage settings\ncoverage_extra_args: \"\"\n</content>\n</write_file>\n\n## 4. Dockerfile\n\n<write_file>\n<path>Dockerfile</path>\n<content>FROM gcr.io/oss-fuzz-base/base-builder-python\n\n# Install build dependencies for PyYAML (requires libyaml)\nRUN apt-get update && apt-get install -y \\\n    libyaml-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone PyYAML repository\nRUN git clone --depth 1 https://github.com/yaml/pyyaml $SRC/pyyaml\n\n# Copy fuzzing harness and build script\nCOPY fuzz_*.py $SRC/\nCOPY build.sh $SRC/\n\nWORKDIR $SRC/pyyaml\n</content>\n</write_file>\n\n## Summary\n\nI've created a complete OSS-Fuzz integration for fuzzing PyYAML:\n\n### **Key Features:**\n\n1. **fuzz_yaml.py** - Atheris harness that:\n   - Uses `FuzzedDataProvider` for controlled input generation\n   - Tests `safe_load()`, `safe_load_all()`, and `safe_dump()` functions\n   - Properly handles expected exceptions (YAMLError, ValueError, RecursionError, MemoryError)\n   - Re-raises unexpected exceptions to report bugs\n   - Includes round-trip fuzzing (parse \u2192 dump)\n\n2. **build.sh** - Build script that:\n   - Installs PyYAML from source\n   - Uses `compile_python_fuzzer` helper (provided by OSS-Fuzz)\n   - Automatically compiles all `fuzz_*.py` files\n   - Includes optional seed corpus support\n   - Generates a YAML-specific dictionary with common tokens\n\n3. **project.yaml** - Configuration with:\n   - Python language specification\n   - libFuzzer engine\n   - AddressSanitizer and UndefinedBehaviorSanitizer\n   - Contact information and repository details\n\n4. **Dockerfile** - Build environment with:\n   - Python base builder image\n   - libyaml-dev dependency (required for PyYAML C extensions)\n   - Repository cloning and file copying\n\n### **Testing Locally:**\n\n```bash\n# From OSS-Fuzz root directory\npython3 infra/helper.py build_image pyyaml\npython3 infra/helper.py build_fuzzers --sanitizer=address pyyaml\npython3 infra/helper.py run_fuzzer pyyaml fuzz_yaml\n```\n\nThe harness focuses on `safe_load` functions (not `load`) since those are designed for untrusted input, making them the most security-critical targets for fuzzing.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5539,
            "output_tokens": 1994,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "ossfuzz-04",
      "task_type": "grounded",
      "target_language": "bash",
      "expected_patterns": [
        "\\$CXX",
        "\\$CXXFLAGS",
        "\\$LIB_FUZZING_ENGINE",
        "libmyproject\\.a|\\.a\\b",
        "--disable-shared|static",
        "seed_corpus\\.zip|_seed_corpus"
      ],
      "anti_patterns": [
        "compile_python_fuzzer",
        "atheris",
        "cargo fuzz build",
        "pip3 install",
        "\\bgcc\\b"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new_project_guide.md",
          "description": "OSS-Fuzz C++ build patterns: $CXX compiler variable, $CXXFLAGS for compiler flags, $LIB_FUZZING_ENGINE for linking, static library (.a) linking requirements, seed corpus naming as my_fuzzer_seed_corpus.zip"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/further-reading/fuzzer_environment.md",
          "description": "OSS-Fuzz environment: $OUT directory for build artifacts, static linking recommendations"
        },
        {
          "url": "https://pubs.opengroup.org/onlinepubs/9699919799/utilities/V3_chap02.html",
          "description": "POSIX shell command language - source of bash variable expansion syntax ($VAR) used in build.sh scripts"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/build.sh",
          "description": "Anti-patterns: Python compile_python_fuzzer, pip3 install that should not appear in C++ build"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "Here are the issues with the build script and the fixed version:\n\n**Issues:**\n1. Using `gcc` instead of `g++` or `$CXX` for C++ files\n2. Not using OSS-Fuzz required compiler flags (`$CXXFLAGS`, `$LIB_FUZZING_ENGINE`)\n3. Not linking with the fuzzing engine\n4. Linking with shared library (`.so`) instead of static library (`.a`)\n5. Corpus files should go to a corpus directory, not directly to `$OUT`\n\n**Fixed build.sh:**\n\n```bash\n#!/bin/bash -eu\ncd $SRC/myproject\n./configure --enable-static --disable-shared\nmake\n\n$CXX $CXXFLAGS -I. fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -I. fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Copy corpus files to appropriate directories\nmkdir -p $OUT/parse_harness_seed_corpus\nmkdir -p $OUT/validate_harness_seed_corpus\ncp fuzz/corpus/* $OUT/parse_harness_seed_corpus/ || true\ncp fuzz/corpus/* $OUT/validate_harness_seed_corpus/ || true\n```\n\n**Key changes:**\n- Use `$CXX` (C++ compiler) instead of `gcc`\n- Add `$CXXFLAGS` for sanitizer and coverage flags\n- Add `$LIB_FUZZING_ENGINE` to link the fuzzing engine (libFuzzer/AFL++)\n- Configure with `--enable-static --disable-shared` to build static library\n- Link against `libmyproject.a` instead of `.so`\n- Create proper seed corpus directories for each harness\n- Add `|| true` to prevent failures if corpus directory is empty",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 155,
            "output_tokens": 483,
            "cached": false
          },
          "with_skill": {
            "output": "# Fixed OSS-Fuzz build.sh\n\nHere's the corrected version with explanations:\n\n```bash\n#!/bin/bash -eu\n\n# Navigate to project directory\ncd $SRC/myproject\n\n# Configure with --disable-shared to build static library\n./configure --disable-shared\n\n# Build the project\nmake -j$(nproc)\n\n# Build harnesses using correct compiler and flags\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Copy corpus as zip files with proper naming\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/parse/*\nzip -j $OUT/validate_harness_seed_corpus.zip fuzz/corpus/validate/*\n\n# Copy dictionaries if they exist\nif [ -f fuzz/parse.dict ]; then\n    cp fuzz/parse.dict $OUT/parse_harness.dict\nfi\nif [ -f fuzz/validate.dict ]; then\n    cp fuzz/validate.dict $OUT/validate_harness.dict\nfi\n```\n\n## Issues Fixed\n\n| Issue | Problem | Fix |\n|-------|---------|-----|\n| **Wrong compiler** | Used `gcc` for C++ code | Use `$CXX` (OSS-Fuzz provided C++ compiler) |\n| **Missing flags** | No sanitizer/fuzzing flags | Use `$CXXFLAGS` and `$LIB_FUZZING_ENGINE` |\n| **Shared library** | Linked against `.so` file | Build static library (`.a`) with `--disable-shared` |\n| **Corpus format** | Copied raw files | Create properly named zip archives |\n| **Parallel builds** | Single-threaded make | Use `make -j$(nproc)` for faster builds |\n\n## Key Changes Explained\n\n### 1. Compiler Variables\n```bash\n# Wrong\ngcc -std=c++11 ...\n\n# Correct\n$CXX $CXXFLAGS -std=c++11 ...\n```\nOSS-Fuzz provides `$CXX` with the correct compiler (Clang) and `$CXXFLAGS` with sanitizer flags.\n\n### 2. Fuzzing Engine\n```bash\n# Wrong\n... -o $OUT/parse_harness ./libmyproject.so\n\n# Correct\n... -o $OUT/parse_harness $LIB_FUZZING_ENGINE ./libmyproject.a\n```\n`$LIB_FUZZING_ENGINE` provides the fuzzing runtime (libFuzzer, AFL++, etc.).\n\n### 3. Static Linking\n```bash\n# Wrong\n./configure\nmake\n\n# Correct\n./configure --disable-shared\nmake -j$(nproc)\n```\nStatic libraries (`.a`) are required for proper fuzzer linking. Shared libraries cause runtime issues.\n\n### 4. Corpus Packaging\n```bash\n# Wrong\ncp fuzz/corpus/* $OUT/\n\n# Correct\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/parse/*\n```\nOSS-Fuzz expects corpus as `<harness_name>_seed_corpus.zip`.\n\n## Alternative: If Corpus is Already Organized\n\nIf your corpus is already in separate directories:\n\n```bash\n# If corpus structure is:\n# fuzz/corpus/parse/...\n# fuzz/corpus/validate/...\n\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/parse/*\nzip -j $OUT/validate_harness_seed_corpus.zip fuzz/corpus/validate/*\n```\n\n## Alternative: Single Corpus for Both Harnesses\n\nIf both harnesses share the same corpus:\n\n```bash\n# Use same corpus for both\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/*\ncp $OUT/parse_harness_seed_corpus.zip $OUT/validate_harness_seed_corpus.zip\n```\n\n## Testing the Fix\n\n```bash\n# Build the project image\npython3 infra/helper.py build_image myproject\n\n# Build fuzzers with AddressSanitizer\npython3 infra/helper.py build_fuzzers --sanitizer=address myproject\n\n# Run each harness to verify\npython3 infra/helper.py run_fuzzer myproject parse_harness\npython3 infra/helper.py run_fuzzer myproject validate_harness\n```\n\nExpected output should show successful initialization and fuzzing progress, not build errors.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5101,
            "output_tokens": 1170,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "Here's the corrected build.sh with explanations:\n\n```bash\n#!/bin/bash -eu\n\n# Build the project with static libraries (required for fuzzing)\ncd $SRC/myproject\n./autogen.sh  # Generate configure script if needed\n./configure --disable-shared  # Build static library, not shared\nmake -j$(nproc)  # Parallel build for faster compilation\n\n# Build fuzz harnesses with correct compiler and flags\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    $SRC/myproject/fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    $SRC/myproject/fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Copy corpus as seed corpus with proper naming\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/*\nzip -j $OUT/validate_harness_seed_corpus.zip fuzz/corpus/*\n\n# Copy dictionaries if they exist\nif [ -f fuzz/parse.dict ]; then\n    cp fuzz/parse.dict $OUT/parse_harness.dict\nfi\nif [ -f fuzz/validate.dict ]; then\n    cp fuzz/validate.dict $OUT/validate_harness.dict\nfi\n```\n\n## Key fixes:\n\n1. **Use `$CXX` instead of `gcc`** - OSS-Fuzz provides the correct C++ compiler with instrumentation\n2. **Add `$CXXFLAGS`** - Required for sanitizer instrumentation (AddressSanitizer, etc.)\n3. **Add `$LIB_FUZZING_ENGINE`** - Links the fuzzing engine (libFuzzer/AFL++)\n4. **Use `.a` not `.so`** - Static linking required for fuzzing\n5. **Add `--disable-shared`** - Ensures autotools builds static library\n6. **Add `./autogen.sh`** - Generates configure script if using autotools\n7. **Zip corpus files** - OSS-Fuzz expects `<harness>_seed_corpus.zip` format\n8. **Use absolute paths** - `$SRC/myproject/` ensures correct location\n\nThe original script would fail because it used the wrong compiler, missing fuzzing engine linkage, and tried to link against a shared library that wouldn't work with fuzzing instrumentation.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5386,
            "output_tokens": 626,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "Here are the issues with the build.sh and the corrected version:\n\n**Issues:**\n1. Using `gcc` instead of `g++` for C++ files\n2. Missing OSS-Fuzz required compiler flags (`$CXXFLAGS`, `$LIB_FUZZING_ENGINE`)\n3. Not linking properly for fuzzing (needs fuzzing engine)\n4. Using `.so` instead of `.a` (static library preferred for fuzzing)\n5. Corpus files should go to a corpus directory, not directly to `$OUT`\n\n**Fixed version:**\n\n```bash\n#!/bin/bash -eu\ncd $SRC/myproject\n./configure --disable-shared\nmake\n\n$CXX $CXXFLAGS -I. fuzz/parse_harness.cc $LIB_FUZZING_ENGINE ./libmyproject.a -o $OUT/parse_harness\n$CXX $CXXFLAGS -I. fuzz/validate_harness.cc $LIB_FUZZING_ENGINE ./libmyproject.a -o $OUT/validate_harness\n\n# Copy corpus files to appropriate directories\nmkdir -p $OUT/parse_harness_seed_corpus\nmkdir -p $OUT/validate_harness_seed_corpus\ncp fuzz/corpus/* $OUT/parse_harness_seed_corpus/\ncp fuzz/corpus/* $OUT/validate_harness_seed_corpus/\n```\n\n**Key changes:**\n- `gcc` \u2192 `$CXX` (uses the correct C++ compiler with OSS-Fuzz settings)\n- Added `$CXXFLAGS` for compilation flags (includes sanitizers, coverage)\n- Added `$LIB_FUZZING_ENGINE` for libFuzzer linking\n- Added `--disable-shared` to configure to build static library\n- Changed `.so` \u2192 `.a` for static linking\n- Created proper seed corpus directories for each harness\n- Proper linking order: source \u2192 fuzzing engine \u2192 library \u2192 output",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 155,
            "output_tokens": 465,
            "cached": false
          },
          "with_skill": {
            "output": "# Fixed OSS-Fuzz build.sh\n\nHere's the corrected version with explanations:\n\n```bash\n#!/bin/bash -eu\n\n# Navigate to project directory\ncd $SRC/myproject\n\n# Configure with --disable-shared to build static library\n./configure --disable-shared\n\n# Build the project\nmake -j$(nproc)\n\n# Build harnesses using correct compiler and flags\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Copy corpus as zip files with proper naming\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/parse/*\nzip -j $OUT/validate_harness_seed_corpus.zip fuzz/corpus/validate/*\n\n# Copy dictionaries if they exist\nif [ -f fuzz/parse.dict ]; then\n    cp fuzz/parse.dict $OUT/parse_harness.dict\nfi\nif [ -f fuzz/validate.dict ]; then\n    cp fuzz/validate.dict $OUT/validate_harness.dict\nfi\n```\n\n## Issues Fixed\n\n| Issue | Problem | Fix |\n|-------|---------|-----|\n| **Wrong compiler** | Used `gcc` for C++ code | Use `$CXX` (OSS-Fuzz provided C++ compiler) |\n| **Missing CXXFLAGS** | No sanitizer/coverage flags | Add `$CXXFLAGS` (includes sanitizer flags) |\n| **Missing fuzzing engine** | No libFuzzer linkage | Add `$LIB_FUZZING_ENGINE` |\n| **Shared library** | Used `.so` instead of `.a` | Configure with `--disable-shared`, link `.a` |\n| **Corpus format** | Copied raw files | Zip corpus files with `_seed_corpus.zip` suffix |\n| **Corpus organization** | Single corpus for both harnesses | Separate corpus per harness |\n| **Missing parallel build** | Slow builds | Add `-j$(nproc)` to make |\n\n## Key Changes Explained\n\n### 1. Use OSS-Fuzz Environment Variables\n\n```bash\n$CXX $CXXFLAGS ... $LIB_FUZZING_ENGINE\n```\n\nThese variables are provided by OSS-Fuzz and include:\n- **$CXX**: Correct C++ compiler (clang++)\n- **$CXXFLAGS**: Sanitizer flags (AddressSanitizer, etc.)\n- **$LIB_FUZZING_ENGINE**: libFuzzer linkage\n\n### 2. Static Library Linking\n\n```bash\n./configure --disable-shared\n# Links against libmyproject.a instead of .so\n```\n\nStatic linking ensures all code is instrumented by sanitizers.\n\n### 3. Proper Corpus Format\n\n```bash\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/parse/*\n```\n\nOSS-Fuzz expects:\n- Corpus as zip files\n- Named `<harness_name>_seed_corpus.zip`\n- `-j` flag to strip directory structure\n\n### 4. Separate Corpus Per Harness\n\nEach harness should have its own corpus directory:\n```\nfuzz/corpus/parse/     \u2192 parse_harness_seed_corpus.zip\nfuzz/corpus/validate/  \u2192 validate_harness_seed_corpus.zip\n```\n\n## Alternative: If Corpus Structure Differs\n\nIf your corpus is organized differently:\n\n```bash\n# If all corpus files are in fuzz/corpus/ without subdirectories\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/*\nzip -j $OUT/validate_harness_seed_corpus.zip fuzz/corpus/*\n\n# If no corpus exists yet (will use empty corpus)\n# Just omit the zip commands - OSS-Fuzz will build corpus over time\n```\n\n## Testing Locally\n\n```bash\n# Build and test\npython3 infra/helper.py build_fuzzers --sanitizer=address myproject\npython3 infra/helper.py run_fuzzer myproject parse_harness\npython3 infra/helper.py run_fuzzer myproject validate_harness\n```",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5101,
            "output_tokens": 1093,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "Here's the corrected `build.sh`:\n\n```bash\n#!/bin/bash -eu\n\n# Build the project\ncd $SRC/myproject\n./autogen.sh || ./bootstrap.sh || true  # Generate configure if needed\n./configure --disable-shared  # Build static library for fuzzing\nmake -j$(nproc)\n\n# Build fuzz harnesses\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    $SRC/myproject/fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    $SRC/myproject/fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Copy corpus files properly\nif [ -d \"$SRC/myproject/fuzz/corpus\" ]; then\n    zip -j $OUT/parse_harness_seed_corpus.zip $SRC/myproject/fuzz/corpus/*\n    zip -j $OUT/validate_harness_seed_corpus.zip $SRC/myproject/fuzz/corpus/*\nfi\n\n# Copy dictionaries if they exist\nif [ -f \"$SRC/myproject/fuzz/parse.dict\" ]; then\n    cp $SRC/myproject/fuzz/parse.dict $OUT/parse_harness.dict\nfi\nif [ -f \"$SRC/myproject/fuzz/validate.dict\" ]; then\n    cp $SRC/myproject/fuzz/validate.dict $OUT/validate_harness.dict\nfi\n```\n\n## Key fixes:\n\n1. **Use `$CXX` instead of `gcc`** - OSS-Fuzz provides the correct C++ compiler with sanitizers\n2. **Use `$CXXFLAGS`** - Contains sanitizer flags and optimization settings\n3. **Use `$LIB_FUZZING_ENGINE`** - Links the fuzzing engine (libFuzzer/AFL++)\n4. **Link against `.a` not `.so`** - Static linking required for fuzzing\n5. **Add `--disable-shared`** to configure - Ensures static library is built\n6. **Generate configure script** - Call autogen.sh/bootstrap.sh if needed\n7. **Use `-j$(nproc)`** - Parallel build for faster compilation\n8. **Zip corpus files** - OSS-Fuzz expects `<harness>_seed_corpus.zip` format\n9. **Name corpus per harness** - Each harness gets its own corpus\n10. **Add dictionary support** - Copy `.dict` files if they exist",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5386,
            "output_tokens": 659,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "Here are the issues with the build script and the corrected version:\n\n**Issues:**\n1. Using `gcc` instead of `g++` for C++ files\n2. Missing OSS-Fuzz required compiler flags (`$CXXFLAGS`, `$LIB_FUZZING_ENGINE`)\n3. Not linking properly for fuzzing (needs fuzzing engine)\n4. Corpus files should go to specific directories per fuzzer\n5. Should use static library (`.a`) instead of shared library (`.so`) for better fuzzing\n\n**Fixed build.sh:**\n\n```bash\n#!/bin/bash -eu\ncd $SRC/myproject\n./configure --disable-shared\nmake\n\n$CXX $CXXFLAGS -I. fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -I. fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Copy corpus files to appropriate directories\nmkdir -p $OUT/parse_harness_seed_corpus\nmkdir -p $OUT/validate_harness_seed_corpus\ncp fuzz/corpus/* $OUT/parse_harness_seed_corpus/ || true\ncp fuzz/corpus/* $OUT/validate_harness_seed_corpus/ || true\n```\n\n**Key changes:**\n- `gcc` \u2192 `$CXX` (uses the correct C++ compiler with sanitizers)\n- Added `$CXXFLAGS` (includes sanitizer flags, coverage instrumentation)\n- Added `$LIB_FUZZING_ENGINE` (links libFuzzer or AFL++)\n- Added `--disable-shared` to configure (builds static library)\n- `.so` \u2192 `.a` (static linking preferred for fuzzing)\n- Created separate seed corpus directories for each fuzzer\n- Added `|| true` to prevent failures if corpus directory is empty",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 155,
            "output_tokens": 475,
            "cached": false
          },
          "with_skill": {
            "output": "# Fixed OSS-Fuzz build.sh\n\nHere are the issues and the corrected build script:\n\n## Issues Identified\n\n1. **Wrong compiler**: Using `gcc` instead of `$CXX` for C++ code\n2. **Missing fuzzing engine**: Not linking `$LIB_FUZZING_ENGINE`\n3. **Missing compiler flags**: Not using `$CXXFLAGS` (includes sanitizer flags)\n4. **Shared library**: Using `.so` instead of static library `.a`\n5. **Missing static build**: Not configuring for static linking\n6. **Corpus handling**: Copying files directly instead of creating seed corpus archives\n7. **Missing dictionary**: No dictionary files included\n\n## Corrected build.sh\n\n```bash\n#!/bin/bash -eu\n\ncd $SRC/myproject\n\n# Configure for static build (required for fuzzing)\n./autogen.sh  # If project uses autogen\n./configure --disable-shared --enable-static\n\n# Build the project\nmake -j$(nproc)\n\n# Build fuzz harnesses with proper flags and linking\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Create seed corpus archives (if corpus exists)\nif [ -d \"fuzz/parse_corpus\" ]; then\n    zip -j $OUT/parse_harness_seed_corpus.zip fuzz/parse_corpus/*\nfi\n\nif [ -d \"fuzz/validate_corpus\" ]; then\n    zip -j $OUT/validate_harness_seed_corpus.zip fuzz/validate_corpus/*\nfi\n\n# Copy dictionaries if they exist\nif [ -f \"fuzz/parse.dict\" ]; then\n    cp fuzz/parse.dict $OUT/parse_harness.dict\nfi\n\nif [ -f \"fuzz/validate.dict\" ]; then\n    cp fuzz/validate.dict $OUT/validate_harness.dict\nfi\n```\n\n## Key Changes Explained\n\n| Change | Why It's Needed |\n|--------|-----------------|\n| `$CXX` instead of `gcc` | OSS-Fuzz provides correct C++ compiler with sanitizer support |\n| `$CXXFLAGS` | Includes sanitizer flags (`-fsanitize=address`, etc.) |\n| `$LIB_FUZZING_ENGINE` | Links libFuzzer or other fuzzing engine |\n| `--disable-shared` | Static linking required for fuzzing harnesses |\n| `.a` instead of `.so` | Static library prevents runtime dependency issues |\n| `zip` for corpus | OSS-Fuzz expects `<harness>_seed_corpus.zip` format |\n| Separate corpus per harness | Each harness gets its own corpus archive |\n| `-j$(nproc)` | Parallel build for faster compilation |\n\n## Alternative: If Library Name Differs\n\nIf the library isn't named `libmyproject.a`, find it:\n\n```bash\n# After make, find the actual library name\nLIBRARY=$(find . -name \"*.a\" | grep -v test | head -n 1)\n\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE $LIBRARY\n```\n\n## Testing Locally\n\n```bash\n# Build and test\npython3 infra/helper.py build_fuzzers --sanitizer=address myproject\npython3 infra/helper.py run_fuzzer myproject parse_harness\npython3 infra/helper.py run_fuzzer myproject validate_harness\n```\n\nThe corrected script now properly uses OSS-Fuzz environment variables, links statically, and packages corpus files correctly.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5101,
            "output_tokens": 989,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "Here's the corrected `build.sh`:\n\n```bash\n#!/bin/bash -eu\n\ncd $SRC/myproject\n\n# Configure with --disable-shared to build static library\n./configure --disable-shared\n\n# Build the project\nmake -j$(nproc)\n\n# Build fuzz harnesses using correct compiler and flags\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/parse_harness.cc -o $OUT/parse_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n$CXX $CXXFLAGS -std=c++11 -I. \\\n    fuzz/validate_harness.cc -o $OUT/validate_harness \\\n    $LIB_FUZZING_ENGINE ./libmyproject.a\n\n# Copy corpus as properly named seed corpus archives\nzip -j $OUT/parse_harness_seed_corpus.zip fuzz/corpus/*\nzip -j $OUT/validate_harness_seed_corpus.zip fuzz/corpus/*\n```\n\n## Key fixes:\n\n1. **Use `$CXX` instead of `gcc`** - OSS-Fuzz provides the correct C++ compiler with instrumentation\n2. **Add `$CXXFLAGS`** - Required for sanitizer instrumentation and fuzzing coverage\n3. **Add `$LIB_FUZZING_ENGINE`** - Links the libFuzzer runtime\n4. **Use static library (`.a`)** - Changed from `.so` to `.a` and added `--disable-shared` to configure\n5. **Link order matters** - `$LIB_FUZZING_ENGINE` must come before the static library\n6. **Proper corpus format** - OSS-Fuzz expects `<harness>_seed_corpus.zip` files, not loose files\n7. **Parallel build** - Added `-j$(nproc)` for faster compilation\n\nThe original script would fail because it didn't use OSS-Fuzz's environment variables for compilation and linking, which are essential for fuzzing instrumentation.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5386,
            "output_tokens": 493,
            "cached": false
          }
        }
      ]
    },
    {
      "task_id": "ossfuzz-05",
      "task_type": "adjacent_domain",
      "target_language": "dockerfile",
      "expected_patterns": [
        "FROM gcr\\.io/oss-fuzz-base/base-builder",
        "RUN.*git clone",
        "WORKDIR",
        "COPY build\\.sh",
        "language:\\s*rust",
        "address"
      ],
      "anti_patterns": [
        "base-builder-python|base_builder_python",
        "apt-get.*install.*python",
        "compile_python_fuzzer",
        "\\$CXX.*\\$CXXFLAGS",
        "LLVMFuzzerTestOneInput"
      ],
      "pattern_sources": [
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new-project-guide/rust_lang.md",
          "description": "OSS-Fuzz Rust projects: FROM gcr.io/oss-fuzz-base/base-builder-rust, language: rust in project.yaml, cargo fuzz build patterns, address sanitizer support"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/docs/getting-started/new_project_guide.md",
          "description": "OSS-Fuzz Dockerfile patterns: FROM base-builder, RUN git clone, WORKDIR, COPY build.sh to $SRC"
        },
        {
          "url": "https://docs.docker.com/reference/dockerfile/",
          "description": "Dockerfile reference - source of FROM, RUN, WORKDIR, COPY instruction syntax for building Docker images"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/Dockerfile",
          "description": "Anti-patterns: Python base-builder-python image, pip3 install that should not appear in Rust Dockerfile"
        },
        {
          "url": "https://raw.githubusercontent.com/google/oss-fuzz/refs/heads/master/projects/ujson/project.yaml",
          "description": "Anti-patterns: Python language: python that should not appear in Rust project.yaml"
        }
      ],
      "runs": [
        {
          "run_index": 0,
          "baseline": {
            "output": "# Dockerfile for OSS-Fuzz Rust Cryptographic Library\n\nHere's a complete setup for fuzzing a Rust cryptographic library with OSS-Fuzz:\n\n## Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies for cryptographic operations\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    cmake \\\n    pkg-config \\\n    libssl-dev \\\n    libgmp-dev \\\n    clang \\\n    llvm \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set the working directory\nWORKDIR $SRC\n\n# Clone the cryptographic library repository\n# Replace with your actual repository URL\nRUN git clone --depth 1 https://github.com/example/rust-crypto-lib rust-crypto-lib\n\n# Set the project directory\nWORKDIR $SRC/rust-crypto-lib\n\n# Copy build script\nCOPY build.sh $SRC/\n\n# Set environment variables for Rust fuzzing\nENV RUSTFLAGS=\"-Cdebug-assertions=on -Coverflow-checks=on\"\nENV CARGO_BUILD_TARGET=\"x86_64-unknown-linux-gnu\"\n\n# Ensure the build script is executable\nRUN chmod +x $SRC/build.sh\n```\n\n## build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Navigate to project directory\ncd $SRC/rust-crypto-lib\n\n# Build fuzz targets using cargo-fuzz\ncargo fuzz build -O --debug-assertions\n\n# Copy fuzz targets to output directory\nFUZZ_TARGET_OUTPUT_DIR=$SRC/rust-crypto-lib/fuzz/target/x86_64-unknown-linux-gnu/release\n\n# List of fuzz targets to copy\nFUZZ_TARGETS=(\n    \"fuzz_aes_encrypt\"\n    \"fuzz_aes_decrypt\"\n    \"fuzz_rsa_sign\"\n    \"fuzz_rsa_verify\"\n    \"fuzz_hash_sha256\"\n    \"fuzz_hash_sha512\"\n    \"fuzz_ecdsa_sign\"\n    \"fuzz_ecdsa_verify\"\n    \"fuzz_key_derivation\"\n    \"fuzz_hmac\"\n)\n\n# Copy each fuzz target\nfor target in \"${FUZZ_TARGETS[@]}\"; do\n    if [ -f \"$FUZZ_TARGET_OUTPUT_DIR/$target\" ]; then\n        cp \"$FUZZ_TARGET_OUTPUT_DIR/$target\" $OUT/\n        echo \"Copied $target to $OUT/\"\n    else\n        echo \"Warning: $target not found in $FUZZ_TARGET_OUTPUT_DIR\"\n    fi\ndone\n\n# Copy seed corpus if it exists\nif [ -d \"$SRC/rust-crypto-lib/fuzz/corpus\" ]; then\n    for target in \"${FUZZ_TARGETS[@]}\"; do\n        if [ -d \"$SRC/rust-crypto-lib/fuzz/corpus/$target\" ]; then\n            zip -j $OUT/${target}_seed_corpus.zip $SRC/rust-crypto-lib/fuzz/corpus/$target/*\n            echo \"Created seed corpus for $target\"\n        fi\n    done\nfi\n\n# Copy dictionaries if they exist\nif [ -d \"$SRC/rust-crypto-lib/fuzz/dict\" ]; then\n    cp $SRC/rust-crypto-lib/fuzz/dict/*.dict $OUT/ 2>/dev/null || true\nfi\n\n# Generate options files for specific targets\ncat > $OUT/fuzz_aes_encrypt.options << EOF\n[libfuzzer]\nmax_len = 65536\ntimeout = 25\nEOF\n\ncat > $OUT/fuzz_rsa_sign.options << EOF\n[libfuzzer]\nmax_len = 8192\ntimeout = 30\nrss_limit_mb = 2048\nEOF\n\ncat > $OUT/fuzz_ecdsa_sign.options << EOF\n[libfuzzer]\nmax_len = 4096\ntimeout = 25\nEOF\n```\n\n## project.yaml\n\n```yaml\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nhomepage: \"https://github.com/example/rust-crypto-lib\"\nlanguage: rust\nprimary_contact: \"security@example.com\"\nmain_repo: \"https://github.com/example/rust-crypto-lib\"\n\n# Specify Rust-specific constraints\nfuzzing_engines:\n  - libfuzzer\n  - afl\n  - honggfuzz\n\nsanitizers:\n  - address\n  - undefined\n  - memory\n\n# Rust-specific architecture constraints\narchitectures:\n  - x86_64\n\n# Vendor crates to avoid network access during build\nvendor_crates: true\n\n# File size limits for fuzzing\nfile_size_limit: 65536\n\n# Auto-CC configuration\nauto_ccs:\n  - \"maintainer1@example.com\"\n  - \"maintainer2@example.com\"\n\n# Disable coverage builds if needed (optional)\ncoverage_extra_args: \"\"\n\n# Experimental features\nexperimental: false\n\n# Build configuration\nmain_repo: 'https://github.com/example/rust-crypto-lib'\ndockerfile_path: 'projects/rust-crypto-lib/Dockerfile'\n\n# Fuzzing configuration\nfuzzing_engines:\n  - libfuzzer\n\nsanitizers:\n  - address\n  - undefined\n\n# Rust-specific: Use nightly toolchain if needed\n# This can be set in the Dockerfile or build.sh\nlabels:\n  rust_toolchain: stable  # or 'nightly' if needed\n  \n# Blackbox fuzzing (if applicable)\nblackbox: false\n\n# Help URL for bug reports\nhelp_url: \"https://github.com/example/rust-crypto-lib/blob/main/SECURITY.md\"\n\n# View restrictions (public or restricted)\nview_restrictions: none\n\n# Disk usage limit\ndisk_usage_limit: 10240  # 10 GB\n```\n\n## Example Cargo.toml for fuzz targets\n\n```toml\n[package]\nname = \"rust-crypto-lib-fuzz\"\nversion = \"0.0.0\"\npublish = false\nedition = \"2021\"\n\n[package.metadata]\ncargo-fuzz = true\n\n[dependencies]\nlibfuzzer-sys = \"0.4\"\nrust-crypto-lib = { path = \"..\" }\n\n# Prevent this from interfering with workspaces\n[workspace]\nmembers = [\".\"]\n\n[[bin]]\nname = \"fuzz_aes_encrypt\"\npath = \"fuzz_targets/fuzz_aes_encrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_aes_decrypt\"\npath = \"fuzz_targets/fuzz_aes_decrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_rsa_sign\"\npath = \"fuzz_targets/fuzz_rsa_sign.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_rsa_verify\"\npath = \"fuzz_targets/fuzz_rsa_verify.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_hash_sha256\"\npath = \"fuzz_targets/fuzz_hash_sha256.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_ecdsa_sign\"\npath = \"fuzz_targets/fuzz_ecdsa_sign.rs\"\ntest = false\ndoc = false\n```\n\n## Example Fuzz Target (fuzz_targets/fuzz_aes_encrypt.rs)\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto_lib::aes::{Aes256, BlockCipher};\n\nfuzz_target!(|data: &[u8]| {\n    // Ensure we have enough data for key and plaintext\n    if data.len() < 32 {\n        return;\n    }\n\n    let (key, plaintext) = data.split_at(32);\n    \n    // Attempt to create cipher and encrypt\n    if let Ok(cipher) = Aes256::new(key) {\n        let _ = cipher.encrypt(plaintext);\n    }\n});\n```\n\nThis setup provides:\n\n1. **Proper base image** for Rust fuzzing\n2. **System dependencies** for cryptographic operations\n3. **Build script** that compiles and packages fuzz targets\n4. **Rust-specific constraints** in project.yaml\n5. **Multiple sanitizers** and fuzzing engines\n6. **Seed corpus and dictionary support**\n7. **Target-specific options** for resource limits\n\nAdjust repository URLs, target names, and dependencies according to your specific cryptographic library.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 71,
            "output_tokens": 2543,
            "cached": false
          },
          "with_skill": {
            "output": "# OSS-Fuzz Rust Cryptographic Library Integration\n\nHere's a complete setup for fuzzing a Rust cryptographic library in OSS-Fuzz:\n\n## project.yaml\n\n```yaml\nhomepage: \"https://github.com/cryptolib/rust-crypto\"\nlanguage: rust\nprimary_contact: \"security@cryptolib.org\"\nauto_ccs:\n  - \"maintainer@cryptolib.org\"\n  - \"fuzzing-team@cryptolib.org\"\nmain_repo: \"https://github.com/cryptolib/rust-crypto\"\n\n# Rust only supports libfuzzer engine\nfuzzing_engines:\n  - libfuzzer\n\n# Rust only supports address sanitizer with libfuzzer\nsanitizers:\n  - address\n\n# Enable coverage builds for analysis\ncoverage_extra_args: \"\"\n\n# Vendor dependencies to avoid network access during build\nvendor_crates: true\n\n# File bug reports for crashes\nfile_github_issue: true\n\n# Disclosure policy\nview_restrictions: none\n```\n\n## Dockerfile\n\n```dockerfile\n# Use Rust-specific base builder image\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies for cryptographic operations\n# Many crypto libraries need OpenSSL, assembly tools, or specific build tools\nRUN apt-get update && apt-get install -y \\\n    # Build essentials\n    build-essential \\\n    cmake \\\n    pkg-config \\\n    # Cryptographic library dependencies\n    libssl-dev \\\n    # Assembly and low-level tools (common for crypto)\n    nasm \\\n    yasm \\\n    # Additional tools that might be needed\n    clang \\\n    llvm \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the main repository\n# Use --depth 1 for faster cloning, remove if you need full history\nRUN git clone --depth 1 https://github.com/cryptolib/rust-crypto.git rust-crypto\n\n# Set working directory\nWORKDIR rust-crypto\n\n# Copy build script\nCOPY build.sh $SRC/\n```\n\n## build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Navigate to project directory\ncd $SRC/rust-crypto\n\n# Install cargo-fuzz if not already available\n# (base-builder-rust should have it, but ensure it's present)\nif ! command -v cargo-fuzz &> /dev/null; then\n    cargo install cargo-fuzz\nfi\n\n# Build all fuzz targets with optimizations and debug assertions\n# -O enables optimizations for better performance\n# --debug-assertions keeps safety checks that can catch bugs\ncargo fuzz build -O --debug-assertions\n\n# Copy fuzz targets to output directory\n# Fuzz targets are built to fuzz/target/x86_64-unknown-linux-gnu/release/\nFUZZ_TARGET_DIR=\"fuzz/target/x86_64-unknown-linux-gnu/release\"\n\n# Copy each fuzz target\nfor fuzz_target in $(cargo fuzz list); do\n    cp \"$FUZZ_TARGET_DIR/$fuzz_target\" \"$OUT/\"\ndone\n\n# Copy seed corpus if it exists\n# Corpus files should be in fuzz/corpus/<target_name>/\nif [ -d \"fuzz/corpus\" ]; then\n    for target_dir in fuzz/corpus/*; do\n        if [ -d \"$target_dir\" ]; then\n            target_name=$(basename \"$target_dir\")\n            # Create zip file for seed corpus\n            if [ \"$(ls -A $target_dir)\" ]; then\n                zip -j \"$OUT/${target_name}_seed_corpus.zip\" \"$target_dir\"/*\n            fi\n        fi\n    done\nfi\n\n# Copy dictionaries if they exist\n# Dictionaries should be in fuzz/dict/<target_name>.dict\nif [ -d \"fuzz/dict\" ]; then\n    for dict_file in fuzz/dict/*.dict; do\n        if [ -f \"$dict_file\" ]; then\n            cp \"$dict_file\" \"$OUT/\"\n        fi\n    done\nfi\n\n# Copy options files if they exist\n# Options files control fuzzer behavior (max_len, timeout, etc.)\nif [ -d \"fuzz/options\" ]; then\n    for options_file in fuzz/options/*.options; do\n        if [ -f \"$options_file\" ]; then\n            cp \"$options_file\" \"$OUT/\"\n        fi\n    done\nfi\n```\n\n## Example Fuzz Target Structure\n\nYour project should have a `fuzz/` directory with this structure:\n\n```\nrust-crypto/\n\u251c\u2500\u2500 Cargo.toml\n\u251c\u2500\u2500 src/\n\u2502   \u2514\u2500\u2500 lib.rs\n\u2514\u2500\u2500 fuzz/\n    \u251c\u2500\u2500 Cargo.toml\n    \u251c\u2500\u2500 fuzz_targets/\n    \u2502   \u251c\u2500\u2500 fuzz_aes_encrypt.rs\n    \u2502   \u251c\u2500\u2500 fuzz_rsa_sign.rs\n    \u2502   \u2514\u2500\u2500 fuzz_hash_functions.rs\n    \u251c\u2500\u2500 corpus/\n    \u2502   \u251c\u2500\u2500 fuzz_aes_encrypt/\n    \u2502   \u2502   \u251c\u2500\u2500 sample1\n    \u2502   \u2502   \u2514\u2500\u2500 sample2\n    \u2502   \u2514\u2500\u2500 fuzz_rsa_sign/\n    \u2502       \u2514\u2500\u2500 sample1\n    \u251c\u2500\u2500 dict/\n    \u2502   \u251c\u2500\u2500 fuzz_aes_encrypt.dict\n    \u2502   \u2514\u2500\u2500 fuzz_rsa_sign.dict\n    \u2514\u2500\u2500 options/\n        \u2514\u2500\u2500 fuzz_aes_encrypt.options\n```\n\n### fuzz/Cargo.toml\n\n```toml\n[package]\nname = \"rust-crypto-fuzz\"\nversion = \"0.0.0\"\npublish = false\nedition = \"2021\"\n\n[package.metadata]\ncargo-fuzz = true\n\n[dependencies]\nlibfuzzer-sys = \"0.4\"\nrust-crypto = { path = \"..\" }\n\n# Prevent this from interfering with workspaces\n[workspace]\nmembers = [\".\"]\n\n[[bin]]\nname = \"fuzz_aes_encrypt\"\npath = \"fuzz_targets/fuzz_aes_encrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_rsa_sign\"\npath = \"fuzz_targets/fuzz_rsa_sign.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_hash_functions\"\npath = \"fuzz_targets/fuzz_hash_functions.rs\"\ntest = false\ndoc = false\n```\n\n### Example Fuzz Target: fuzz/fuzz_targets/fuzz_aes_encrypt.rs\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto::aes::{Aes128, Aes256};\nuse rust_crypto::cipher::{BlockEncrypt, KeyInit};\n\nfuzz_target!(|data: &[u8]| {\n    // Need at least 16 bytes for key\n    if data.len() < 16 {\n        return;\n    }\n\n    // Split data into key and plaintext\n    let (key_data, plaintext) = data.split_at(16);\n    \n    // Test AES-128\n    if let Ok(cipher) = Aes128::new_from_slice(key_data) {\n        // Only process if we have a full block\n        if plaintext.len() >= 16 {\n            let mut block = [0u8; 16];\n            block.copy_from_slice(&plaintext[..16]);\n            cipher.encrypt_block(&mut block.into());\n        }\n    }\n\n    // Test AES-256 if we have enough data\n    if data.len() >= 32 {\n        let (key_data, plaintext) = data.split_at(32);\n        if let Ok(cipher) = Aes256::new_from_slice(key_data) {\n            if plaintext.len() >= 16 {\n                let mut block = [0u8; 16];\n                block.copy_from_slice(&plaintext[..16]);\n                cipher.encrypt_block(&mut block.into());\n            }\n        }\n    }\n});\n```\n\n### Example Dictionary: fuzz/dict/fuzz_aes_encrypt.dict\n\n```\n# Common AES test vectors and patterns\n\"YELLOW SUBMARINE\"\n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\"\n\"\\x00\\x01\\x02\\x03\\x04\\x05\\x06\\x07\\x08\\x09\\x0a\\x0b\\x0c\\x0d\\x0e\\x0f\"\n```\n\n### Example Options: fuzz/options/fuzz_aes_encrypt.options\n\n```\n[libfuzzer]\nmax_len = 1024\ntimeout = 25\n```\n\n## Key Rust-Specific Considerations\n\n| Aspect | Rust Constraint | Reason |\n|--------|----------------|---------|\n| **Fuzzing Engine** | libfuzzer only | Rust's fuzzing infrastructure is built around libfuzzer |\n| **Sanitizer** | address only | Other sanitizers not supported with Rust in OSS-Fuzz |\n| **Build Flags** | `-O --debug-assertions` | Balance performance with safety checks |\n| **Cargo Fuzz** | Required tool | Standard way to build Rust fuzz targets |\n| **Vendor Crates** | Recommended | Avoid network access during OSS-Fuzz builds |\n\n## Testing Locally\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Build the project image\npython3 infra/helper.py build_image rust-crypto\n\n# Build fuzzers\npython3 infra/helper.py build_fuzzers --sanitizer=address rust-crypto\n\n# Run a specific fuzzer\npython3 infra/helper.py run_fuzzer rust-crypto fuzz_aes_encrypt\n\n# Generate coverage report\npython3 infra/helper.py build_fuzzers --sanitizer=coverage rust-crypto\npython3 infra/helper.py coverage rust-crypto\n```\n\n## Common Pitfalls for Rust Crypto Projects\n\n| Issue | Problem | Solution |\n|-------|---------|----------|\n| **Constant-time violations** | Timing side-channels | Use constant-time implementations, test with timing analysis |\n| **Panic on invalid input** | Fuzzer finds panics | Use `Result` types, handle errors gracefully |\n| **Insufficient input validation** | Processing malformed data | Add length checks before operations |\n| **Missing edge cases** | Boundary conditions not tested | Include edge cases in seed corpus |\n| **Slow operations** | Fuzzer timeout on expensive ops | Set appropriate timeout in .options file |\n\nThis setup provides a complete OSS-Fuzz integration for a Rust cryptographic library with proper constraints, dependencies, and example fuzz targets.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5017,
            "output_tokens": 2684,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create the OSS-Fuzz integration files for a Rust cryptographic library project.\n\n```dockerfile\n# Dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies commonly needed for cryptographic libraries\nRUN apt-get update && apt-get install -y \\\n    pkg-config \\\n    libssl-dev \\\n    cmake \\\n    build-essential\n\n# Clone the cryptographic library repository\n# Replace with actual repository URL\nRUN git clone --depth 1 https://github.com/example/crypto-lib crypto-lib\n\n# Set working directory\nWORKDIR crypto-lib\n\n# Copy build script\nCOPY build.sh $SRC/\n```\n\n```yaml\n# project.yaml\nhomepage: \"https://github.com/example/crypto-lib\"\nlanguage: rust\nprimary_contact: \"security@example.com\"\nmain_repo: \"https://github.com/example/crypto-lib\"\n\n# Rust only supports libfuzzer as fuzzing engine\nfuzzing_engines:\n  - libfuzzer\n\n# Rust only supports AddressSanitizer with libfuzzer\nsanitizers:\n  - address\n\n# Optional: specify if project is critical infrastructure\n# vendor_ccs:\n#   - \"additional-contact@example.com\"\n```\n\n```bash\n# build.sh\n#!/bin/bash -eu\n\n# Navigate to project directory\ncd $SRC/crypto-lib\n\n# Build fuzzers with cargo-fuzz in release mode with debug assertions\n# This ensures optimized code while keeping safety checks\ncargo fuzz build -O --debug-assertions\n\n# Copy all fuzzer binaries to output directory\n# Assumes fuzzers are in fuzz/fuzz_targets/ directory\nfor fuzzer in fuzz/target/x86_64-unknown-linux-gnu/release/fuzz_*; do\n    if [ -f \"$fuzzer\" ]; then\n        fuzzer_name=$(basename \"$fuzzer\")\n        cp \"$fuzzer\" $OUT/\n        echo \"Copied fuzzer: $fuzzer_name\"\n    fi\ndone\n\n# Optional: Copy seed corpus if available\n# Format: <fuzzer_name>_seed_corpus.zip\nif [ -d \"fuzz/corpus\" ]; then\n    for corpus_dir in fuzz/corpus/*; do\n        if [ -d \"$corpus_dir\" ]; then\n            corpus_name=$(basename \"$corpus_dir\")\n            zip -j $OUT/${corpus_name}_seed_corpus.zip $corpus_dir/*\n            echo \"Created corpus for: $corpus_name\"\n        fi\n    done\nfi\n\n# Optional: Copy dictionaries if available\n# Format: <fuzzer_name>.dict\nif [ -d \"fuzz/dictionaries\" ]; then\n    cp fuzz/dictionaries/*.dict $OUT/ 2>/dev/null || true\nfi\n```\n\nThese files set up a complete OSS-Fuzz integration for a Rust cryptographic library:\n\n**Key features:**\n\n1. **Dockerfile**: Uses `base-builder-rust` which includes Rust toolchain and cargo-fuzz\n2. **System dependencies**: Includes common crypto library requirements (OpenSSL, CMake)\n3. **project.yaml**: Specifies Rust-specific constraints:\n   - Only `libfuzzer` engine (Rust limitation)\n   - Only `address` sanitizer (Rust limitation with libfuzzer)\n4. **build.sh**: \n   - Builds fuzzers with optimizations but keeps debug assertions\n   - Automatically copies all fuzzer binaries\n   - Handles optional corpus and dictionary files\n\n**To customize for your specific project:**\n- Replace `https://github.com/example/crypto-lib` with actual repository\n- Update `primary_contact` email\n- Adjust system dependencies based on your crypto library's needs\n- Ensure your project has a `fuzz/` directory with cargo-fuzz targets",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5302,
            "output_tokens": 914,
            "cached": false
          }
        },
        {
          "run_index": 1,
          "baseline": {
            "output": "# Dockerfile for OSS-Fuzz Rust Cryptographic Library\n\nHere's a complete setup for fuzzing a Rust cryptographic library with OSS-Fuzz:\n\n## Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies for cryptographic operations\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    cmake \\\n    pkg-config \\\n    libssl-dev \\\n    libgmp-dev \\\n    clang \\\n    llvm \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set the working directory\nWORKDIR $SRC\n\n# Clone the cryptographic library repository\n# Replace with your actual repository\nRUN git clone --depth 1 https://github.com/example/rust-crypto-lib rust-crypto-lib\n\n# Set the project directory\nWORKDIR $SRC/rust-crypto-lib\n\n# Copy build script\nCOPY build.sh $SRC/\n\n# Set the working directory back to SRC for the build process\nWORKDIR $SRC\n```\n\n## build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nPROJECT_DIR=\"$SRC/rust-crypto-lib\"\ncd $PROJECT_DIR\n\n# Build fuzz targets\ncargo fuzz build -O --debug-assertions\n\n# Copy fuzz targets to output directory\nFUZZ_TARGET_OUTPUT_DIR=\"$PROJECT_DIR/fuzz/target/x86_64-unknown-linux-gnu/release\"\n\n# List of fuzz targets to copy\nFUZZ_TARGETS=(\n    \"fuzz_aes_encrypt\"\n    \"fuzz_aes_decrypt\"\n    \"fuzz_rsa_sign\"\n    \"fuzz_rsa_verify\"\n    \"fuzz_hash_sha256\"\n    \"fuzz_hash_sha512\"\n    \"fuzz_ecdsa_sign\"\n    \"fuzz_ecdsa_verify\"\n    \"fuzz_key_derivation\"\n)\n\nfor target in \"${FUZZ_TARGETS[@]}\"; do\n    if [ -f \"$FUZZ_TARGET_OUTPUT_DIR/$target\" ]; then\n        cp \"$FUZZ_TARGET_OUTPUT_DIR/$target\" \"$OUT/\"\n    fi\ndone\n\n# Copy seed corpus if available\nif [ -d \"$PROJECT_DIR/fuzz/corpus\" ]; then\n    for target in \"${FUZZ_TARGETS[@]}\"; do\n        if [ -d \"$PROJECT_DIR/fuzz/corpus/$target\" ]; then\n            zip -j \"$OUT/${target}_seed_corpus.zip\" \"$PROJECT_DIR/fuzz/corpus/$target\"/*\n        fi\n    done\nfi\n\n# Copy dictionaries if available\nif [ -d \"$PROJECT_DIR/fuzz/dictionaries\" ]; then\n    for target in \"${FUZZ_TARGETS[@]}\"; do\n        if [ -f \"$PROJECT_DIR/fuzz/dictionaries/${target}.dict\" ]; then\n            cp \"$PROJECT_DIR/fuzz/dictionaries/${target}.dict\" \"$OUT/\"\n        fi\n    done\nfi\n```\n\n## project.yaml\n\n```yaml\nhomepage: \"https://github.com/example/rust-crypto-lib\"\nlanguage: rust\nprimary_contact: \"security@example.com\"\nmain_repo: \"https://github.com/example/rust-crypto-lib\"\n\n# Rust-specific configuration\nfuzzing_engines:\n  - libfuzzer\n  - afl\n  - honggfuzz\n\n# Sanitizers supported by Rust\nsanitizers:\n  - address\n  - memory\n  - undefined\n  - thread\n\n# Architecture support\narchitectures:\n  - x86_64\n  - i386\n\n# Vendor cq_buildbot for continuous integration\nvendor_ccs:\n  - \"maintainer1@example.com\"\n  - \"maintainer2@example.com\"\n\n# Auto-CC security contacts on bugs\nauto_ccs:\n  - \"security-team@example.com\"\n\n# File size limits for test cases\nfile_github_issue: true\n\n# Rust-specific build configuration\nexperimental: false\n\n# Coverage reports\ncoverage_extra_args: \"\"\n\n# Disable broken fuzz targets temporarily if needed\ndisabled: false\n\n# Run options\nrun_tests: false\n\n# Blackbox fuzzing (if applicable)\nblackbox: false\n\n# Rust-specific: Use cargo-fuzz\nbuild_type: rust\n\n# Timeout for individual test cases (in seconds)\ntimeout: 25\n\n# Maximum length of test input\nmax_len: 65536\n\n# Rust toolchain specification\nrust_toolchain: nightly\n\n# Additional Rust flags for fuzzing\nrust_flags:\n  - \"-Zsanitizer=address\"\n  - \"-C codegen-units=1\"\n  - \"-C opt-level=3\"\n  - \"-C target-cpu=native\"\n  - \"-C debuginfo=0\"\n\n# Cargo features to enable during fuzzing\ncargo_features:\n  - \"fuzz\"\n  - \"no-default-features\"\n\n# Environment variables for the build\nenvironment:\n  RUST_BACKTRACE: \"1\"\n  RUSTFLAGS: \"-Zsanitizer=address -C codegen-units=1\"\n  CARGO_INCREMENTAL: \"0\"\n  RUST_LOG: \"debug\"\n\n# Fuzzing dictionary\ndictionaries:\n  - \"crypto.dict\"\n\n# Corpus pruning\ncorpus_prune: true\n\n# Minimize crash reports\nminimize_crash: true\n```\n\n## Cargo.toml (Fuzz Configuration)\n\n```toml\n[package]\nname = \"rust-crypto-lib-fuzz\"\nversion = \"0.0.0\"\npublish = false\nedition = \"2021\"\n\n[package.metadata]\ncargo-fuzz = true\n\n[dependencies]\nlibfuzzer-sys = \"0.4\"\nrust-crypto-lib = { path = \"..\" }\n\n# Prevent this from interfering with workspaces\n[workspace]\nmembers = [\".\"]\n\n[[bin]]\nname = \"fuzz_aes_encrypt\"\npath = \"fuzz_targets/fuzz_aes_encrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_aes_decrypt\"\npath = \"fuzz_targets/fuzz_aes_decrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_rsa_sign\"\npath = \"fuzz_targets/fuzz_rsa_sign.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_rsa_verify\"\npath = \"fuzz_targets/fuzz_rsa_verify.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_hash_sha256\"\npath = \"fuzz_targets/fuzz_hash_sha256.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_hash_sha512\"\npath = \"fuzz_targets/fuzz_hash_sha512.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_ecdsa_sign\"\npath = \"fuzz_targets/fuzz_ecdsa_sign.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_ecdsa_verify\"\npath = \"fuzz_targets/fuzz_ecdsa_verify.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_key_derivation\"\npath = \"fuzz_targets/fuzz_key_derivation.rs\"\ntest = false\ndoc = false\n```\n\n## Example Fuzz Target (fuzz_targets/fuzz_aes_encrypt.rs)\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto_lib::aes::{Aes256, BlockCipher};\n\nfuzz_target!(|data: &[u8]| {\n    // Ensure we have enough data for key and plaintext\n    if data.len() < 32 {\n        return;\n    }\n\n    let (key, plaintext) = data.split_at(32);\n    \n    // Create cipher instance\n    if let Ok(cipher) = Aes256::new(key) {\n        // Attempt encryption\n        let _ = cipher.encrypt(plaintext);\n    }\n});\n```\n\n## Example Fuzz Target (fuzz_targets/fuzz_hash_sha256.rs)\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto_lib::hash::Sha256;\n\nfuzz_target!(|data: &[u8]| {\n    let mut hasher = Sha256::new();\n    hasher.update(data);\n    let _ = hasher.finalize();\n});\n```\n\n## crypto.dict (Fuzzing Dictionary)\n\n```\n# Common cryptographic constants and patterns\n\"\\x00\\x00\\x00\\x00\"\n\"\\xFF\\xFF\\xFF\\xFF\"\n\"\\x01\\x00\\x00\\x00\"\n\"\\x00\\x01\\x00\\x00\"\n\n# Common key sizes (in bytes)\n\"0123456789ABCDEF\"  # 16 bytes (128-bit)\n\"0123456789ABCDEF0123456789ABCDEF\"  # 32 bytes (256-bit)\n\n# ASN.1 markers\n\"\\x30\"\n\"\\x02\"\n\"\\x04\"\n\n# Common padding bytes\n\"\\x01\\x01\"\n\"\\x02\\x02\"\n\"\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\\x10\"\n\n# Magic numbers\n\"SSH-\"\n\"-----BEGIN\"\n\"-----END\"\n```\n\nThis complete setup provides:\n\n1. **Dockerfile** with Rust base image and crypto dependencies\n2. **build.sh** for compiling fuzz targets\n3. **project.yaml** with Rust-specific constraints\n4. **Cargo.toml** configuration for cargo-fuzz\n5. **Example fuzz targets** for common crypto operations\n6. **Fuzzing dictionary** for crypto-specific inputs\n\nThe configuration is optimized for fuzzing cryptographic code with proper sanitizers and Rust toolchain settings.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 71,
            "output_tokens": 2782,
            "cached": false
          },
          "with_skill": {
            "output": "# OSS-Fuzz Rust Cryptographic Library Setup\n\nHere's a complete OSS-Fuzz integration for a Rust cryptographic library, using a realistic example based on common crypto library patterns.\n\n## Directory Structure\n\n```\noss-fuzz/projects/rust-crypto-lib/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 build.sh\n```\n\n## project.yaml\n\n```yaml\nhomepage: \"https://github.com/example-org/rust-crypto-lib\"\nlanguage: rust\nprimary_contact: \"security@example-org.com\"\nauto_ccs:\n  - \"maintainer@example-org.com\"\n  - \"fuzzing-team@example-org.com\"\n\n# Main repository\nmain_repo: \"https://github.com/example-org/rust-crypto-lib\"\n\n# Rust only supports AddressSanitizer with libfuzzer\n# See: https://google.github.io/oss-fuzz/getting-started/new-project-guide/rust-lang/#projectyaml\nfuzzing_engines:\n  - libfuzzer\n\nsanitizers:\n  - address  # Only AddressSanitizer is supported for Rust\n\n# Vendor security contacts for critical issues\nvendor_ccs:\n  - \"cve-team@example-org.com\"\n\n# File size limits for fuzzing inputs (in bytes)\nfile_github_issue: true\n\n# View build logs and coverage reports\nview_restrictions: none\n```\n\n## Dockerfile\n\n```dockerfile\n# Use the Rust-specific base builder image\n# This includes Rust toolchain, cargo-fuzz, and necessary build tools\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies required for cryptographic operations\n# Common dependencies for crypto libraries:\nRUN apt-get update && apt-get install -y \\\n    # Build essentials\n    build-essential \\\n    pkg-config \\\n    # Cryptographic library dependencies\n    libssl-dev \\\n    libgmp-dev \\\n    # Assembly optimization support\n    nasm \\\n    yasm \\\n    # Additional tools\n    cmake \\\n    git \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the main project repository\n# Using --depth 1 for faster cloning, remove if you need full history\nRUN git clone --depth 1 https://github.com/example-org/rust-crypto-lib.git rust-crypto-lib\n\n# Set working directory to the cloned repository\nWORKDIR $SRC/rust-crypto-lib\n\n# Copy the build script\nCOPY build.sh $SRC/\n```\n\n## build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\n# Navigate to the project directory\ncd $SRC/rust-crypto-lib\n\n# Build fuzz targets with optimizations and debug assertions\n# -O: Enable optimizations for better performance\n# --debug-assertions: Keep assertions for better bug detection\ncargo fuzz build -O --debug-assertions\n\n# Copy all fuzz targets to the output directory\n# Rust fuzz targets are built to target/x86_64-unknown-linux-gnu/release/\nFUZZ_TARGET_DIR=\"fuzz/target/x86_64-unknown-linux-gnu/release\"\n\n# Copy each fuzz target\nfor fuzz_target in $(ls $FUZZ_TARGET_DIR | grep -v \"\\.d$\" | grep -v \"deps\" | grep -v \"build\" | grep -v \"incremental\")\ndo\n    # Only copy executable files (fuzz targets)\n    if [ -x \"$FUZZ_TARGET_DIR/$fuzz_target\" ]; then\n        echo \"Copying fuzz target: $fuzz_target\"\n        cp \"$FUZZ_TARGET_DIR/$fuzz_target\" \"$OUT/\"\n        \n        # Copy seed corpus if it exists\n        if [ -d \"fuzz/corpus/$fuzz_target\" ]; then\n            echo \"Copying seed corpus for $fuzz_target\"\n            zip -j \"$OUT/${fuzz_target}_seed_corpus.zip\" fuzz/corpus/$fuzz_target/*\n        fi\n        \n        # Copy dictionary if it exists\n        if [ -f \"fuzz/dict/$fuzz_target.dict\" ]; then\n            echo \"Copying dictionary for $fuzz_target\"\n            cp \"fuzz/dict/$fuzz_target.dict\" \"$OUT/$fuzz_target.dict\"\n        fi\n    fi\ndone\n\n# Alternative: If you know specific target names, copy them explicitly\n# cp $FUZZ_TARGET_DIR/fuzz_aes_encrypt $OUT/\n# cp $FUZZ_TARGET_DIR/fuzz_rsa_sign $OUT/\n# cp $FUZZ_TARGET_DIR/fuzz_ecdsa_verify $OUT/\n```\n\n## Example Fuzz Targets Structure\n\nYour Rust project should have fuzz targets in `fuzz/fuzz_targets/`:\n\n```\nrust-crypto-lib/\n\u251c\u2500\u2500 Cargo.toml\n\u251c\u2500\u2500 src/\n\u2502   \u251c\u2500\u2500 lib.rs\n\u2502   \u251c\u2500\u2500 aes.rs\n\u2502   \u251c\u2500\u2500 rsa.rs\n\u2502   \u2514\u2500\u2500 ecdsa.rs\n\u2514\u2500\u2500 fuzz/\n    \u251c\u2500\u2500 Cargo.toml\n    \u251c\u2500\u2500 fuzz_targets/\n    \u2502   \u251c\u2500\u2500 fuzz_aes_encrypt.rs\n    \u2502   \u251c\u2500\u2500 fuzz_rsa_sign.rs\n    \u2502   \u2514\u2500\u2500 fuzz_ecdsa_verify.rs\n    \u251c\u2500\u2500 corpus/\n    \u2502   \u251c\u2500\u2500 fuzz_aes_encrypt/\n    \u2502   \u2502   \u251c\u2500\u2500 seed1\n    \u2502   \u2502   \u2514\u2500\u2500 seed2\n    \u2502   \u2514\u2500\u2500 fuzz_rsa_sign/\n    \u2502       \u2514\u2500\u2500 seed1\n    \u2514\u2500\u2500 dict/\n        \u2514\u2500\u2500 fuzz_aes_encrypt.dict\n```\n\n### Example Fuzz Target: `fuzz/fuzz_targets/fuzz_aes_encrypt.rs`\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto_lib::aes::{Aes256, BlockCipher};\n\nfuzz_target!(|data: &[u8]| {\n    // Need at least 32 bytes for key and some data\n    if data.len() < 32 {\n        return;\n    }\n    \n    // Split input into key and plaintext\n    let (key, plaintext) = data.split_at(32);\n    \n    // Ensure plaintext is block-aligned (16 bytes for AES)\n    if plaintext.len() < 16 || plaintext.len() % 16 != 0 {\n        return;\n    }\n    \n    // Create cipher instance\n    let cipher = match Aes256::new(key) {\n        Ok(c) => c,\n        Err(_) => return,\n    };\n    \n    // Encrypt\n    let mut buffer = plaintext.to_vec();\n    let _ = cipher.encrypt(&mut buffer);\n    \n    // Decrypt and verify round-trip\n    let _ = cipher.decrypt(&mut buffer);\n    assert_eq!(&buffer, plaintext);\n});\n```\n\n### Example Dictionary: `fuzz/dict/fuzz_aes_encrypt.dict`\n\n```\n# Common AES test vectors and patterns\n\"YELLOW SUBMARINE\"\n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n\"\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\"\n\"\\x00\\x11\\x22\\x33\\x44\\x55\\x66\\x77\\x88\\x99\\xaa\\xbb\\xcc\\xdd\\xee\\xff\"\n```\n\n## Advanced Dockerfile with Multiple Crypto Dependencies\n\nFor a more complex cryptographic library with multiple system dependencies:\n\n```dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install comprehensive cryptographic dependencies\nRUN apt-get update && apt-get install -y \\\n    # Core build tools\n    build-essential \\\n    pkg-config \\\n    cmake \\\n    autoconf \\\n    automake \\\n    libtool \\\n    # Cryptographic libraries\n    libssl-dev \\\n    libgmp-dev \\\n    libsodium-dev \\\n    # Hardware acceleration support\n    nasm \\\n    yasm \\\n    # Additional math libraries\n    libmpfr-dev \\\n    libmpc-dev \\\n    # For testing and benchmarking\n    valgrind \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Set Rust-specific environment variables for optimization\nENV RUSTFLAGS=\"-C target-cpu=native\"\nENV CARGO_BUILD_JOBS=4\n\n# Clone the repository\nRUN git clone --depth 1 https://github.com/example-org/rust-crypto-lib.git rust-crypto-lib\n\nWORKDIR $SRC/rust-crypto-lib\n\n# Pre-fetch dependencies to speed up builds\n# This is optional but recommended for faster iteration\nRUN cargo fetch\n\nCOPY build.sh $SRC/\n```\n\n## Enhanced build.sh with Error Handling\n\n```bash\n#!/bin/bash -eu\n\nset -o pipefail\n\necho \"Building Rust crypto library fuzz targets...\"\n\ncd $SRC/rust-crypto-lib\n\n# Ensure we're using the latest dependencies\necho \"Updating dependencies...\"\ncargo update\n\n# Build all fuzz targets with optimizations\necho \"Building fuzz targets...\"\ncargo fuzz build -O --debug-assertions || {\n    echo \"ERROR: Failed to build fuzz targets\"\n    exit 1\n}\n\nFUZZ_TARGET_DIR=\"fuzz/target/x86_64-unknown-linux-gnu/release\"\n\n# Verify the build directory exists\nif [ ! -d \"$FUZZ_TARGET_DIR\" ]; then\n    echo \"ERROR: Fuzz target directory not found: $FUZZ_TARGET_DIR\"\n    exit 1\nfi\n\n# Count targets copied\nTARGET_COUNT=0\n\n# Copy fuzz targets\nfor fuzz_target in $(ls $FUZZ_TARGET_DIR)\ndo\n    # Skip non-executable files and build artifacts\n    if [ ! -x \"$FUZZ_TARGET_DIR/$fuzz_target\" ]; then\n        continue\n    fi\n    \n    # Skip if it's a directory\n    if [ -d \"$FUZZ_TARGET_DIR/$fuzz_target\" ]; then\n        continue\n    fi\n    \n    # Skip build artifacts\n    case \"$fuzz_target\" in\n        *.d|deps|build|incremental|.fingerprint)\n            continue\n            ;;\n    esac\n    \n    echo \"Copying fuzz target: $fuzz_target\"\n    cp \"$FUZZ_TARGET_DIR/$fuzz_target\" \"$OUT/\"\n    TARGET_COUNT=$((TARGET_COUNT + 1))\n    \n    # Copy seed corpus\n    CORPUS_DIR=\"fuzz/corpus/$fuzz_target\"\n    if [ -d \"$CORPUS_DIR\" ] && [ \"$(ls -A $CORPUS_DIR)\" ]; then\n        echo \"  - Packaging seed corpus\"\n        zip -q -j \"$OUT/${fuzz_target}_seed_corpus.zip\" $CORPUS_DIR/* || true\n    fi\n    \n    # Copy dictionary\n    DICT_FILE=\"fuzz/dict/$fuzz_target.dict\"\n    if [ -f \"$DICT_FILE\" ]; then\n        echo \"  - Copying dictionary\"\n        cp \"$DICT_FILE\" \"$OUT/$fuzz_target.dict\"\n    fi\n    \n    # Copy options file if it exists\n    OPTIONS_FILE=\"fuzz/options/$fuzz_target.options\"\n    if [ -f \"$OPTIONS_FILE\" ]; then\n        echo \"  - Copying options file\"\n        cp \"$OPTIONS_FILE\" \"$OUT/$fuzz_target.options\"\n    fi\ndone\n\necho \"Successfully copied $TARGET_COUNT fuzz targets\"\n\nif [ $TARGET_COUNT -eq 0 ]; then\n    echo \"ERROR: No fuzz targets were copied!\"\n    exit 1\nfi\n```\n\n## Testing Locally\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Build the project image\npython3 infra/helper.py build_image rust-crypto-lib\n\n# Build fuzzers\npython3 infra/helper.py build_fuzzers --sanitizer=address rust-crypto-lib\n\n# Run a specific fuzzer\npython3 infra/helper.py run_fuzzer rust-crypto-lib fuzz_aes_encrypt\n\n# Check coverage\npython3 infra/helper.py coverage rust-crypto-lib\n```\n\n## Key Points for Rust Crypto Projects\n\n| Aspect | Consideration |\n|--------|---------------|\n| **Sanitizer Support** | Only AddressSanitizer works with Rust in OSS-Fuzz |\n| **Build Flags** | Use `-O --debug-assertions` for optimized but safe builds |\n| **Dependencies** | Install system crypto libraries (OpenSSL, libsodium, GMP) |\n| **Target Architecture** | Fuzz targets built for `x86_64-unknown-linux-gnu` |\n| **Corpus Management** | Place seed inputs in `fuzz/corpus/<target_name>/` |\n| **Dictionaries** | Store in `fuzz/dict/<target_name>.dict` |\n| **Performance** | Consider `target-cpu=native` for hardware acceleration |\n\nThis setup provides a production-ready OSS-Fuzz integration for Rust cryptographic libraries with proper error handling, corpus management, and build optimization.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5017,
            "output_tokens": 3446,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create the OSS-Fuzz integration files for a Rust cryptographic library project.\n\n```dockerfile\n# Dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies commonly needed for cryptographic libraries\nRUN apt-get update && apt-get install -y \\\n    pkg-config \\\n    libssl-dev \\\n    cmake \\\n    clang \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the cryptographic library repository\n# Replace with your actual repository URL\nRUN git clone --depth 1 https://github.com/example/crypto-lib.git crypto-lib\n\n# Set working directory\nWORKDIR crypto-lib\n\n# Copy build script\nCOPY build.sh $SRC/\n```\n\n```yaml\n# project.yaml\nhomepage: \"https://github.com/example/crypto-lib\"\nlanguage: rust\nprimary_contact: \"security@example.com\"\nmain_repo: \"https://github.com/example/crypto-lib\"\n\n# Rust only supports libfuzzer as fuzzing engine\nfuzzing_engines:\n  - libfuzzer\n\n# Rust only supports AddressSanitizer\nsanitizers:\n  - address\n\n# Optional: Specify vendor contact if different from primary\n# vendor_ccs:\n#   - \"maintainer@example.com\"\n\n# Optional: Specify if project has a security policy\n# auto_ccs:\n#   - \"security-team@example.com\"\n```\n\n```bash\n#!/bin/bash -eu\n# build.sh\n\n# Navigate to project directory\ncd $SRC/crypto-lib\n\n# Install cargo-fuzz if not already available\nif ! command -v cargo-fuzz &> /dev/null; then\n    cargo install cargo-fuzz\nfi\n\n# Build all fuzz targets with optimizations and debug assertions\n# -O enables optimizations for better performance\n# --debug-assertions keeps assertions for better bug detection\ncargo fuzz build -O --debug-assertions\n\n# Copy all fuzz targets to output directory\n# Fuzz targets are built to fuzz/target/x86_64-unknown-linux-gnu/release/\nfor target in fuzz/target/x86_64-unknown-linux-gnu/release/fuzz_*; do\n    if [ -f \"$target\" ] && [ -x \"$target\" ]; then\n        cp \"$target\" $OUT/\n        \n        # Get the target name without path\n        target_name=$(basename \"$target\")\n        \n        # Copy seed corpus if it exists\n        if [ -d \"fuzz/corpus/$target_name\" ]; then\n            zip -j $OUT/${target_name}_seed_corpus.zip fuzz/corpus/$target_name/*\n        fi\n        \n        # Copy dictionary if it exists\n        if [ -f \"fuzz/dict/$target_name.dict\" ]; then\n            cp fuzz/dict/$target_name.dict $OUT/${target_name}.dict\n        fi\n    fi\ndone\n\n# Optional: Copy any additional dictionaries or options files\n# if [ -f \"fuzz/common.dict\" ]; then\n#     for target in $OUT/fuzz_*; do\n#         target_name=$(basename \"$target\")\n#         cp fuzz/common.dict $OUT/${target_name}.dict\n#     done\n# fi\n```\n\nNow let me create an example fuzz target structure that would go in your crypto library repository:\n\n```rust\n// fuzz/fuzz_targets/fuzz_encryption.rs\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse crypto_lib::{encrypt, decrypt, KeyPair};\n\nfuzz_target!(|data: &[u8]| {\n    // Skip inputs that are too small\n    if data.len() < 16 {\n        return;\n    }\n    \n    // Generate a keypair (use deterministic seed for reproducibility)\n    let keypair = KeyPair::from_seed(&data[0..16]);\n    \n    // Use remaining data as plaintext\n    let plaintext = &data[16..];\n    \n    // Fuzz the encryption/decryption cycle\n    if let Ok(ciphertext) = encrypt(&keypair.public_key, plaintext) {\n        // Verify decryption works\n        if let Ok(decrypted) = decrypt(&keypair.private_key, &ciphertext) {\n            // Assert round-trip correctness\n            assert_eq!(plaintext, decrypted.as_slice());\n        }\n    }\n});\n```\n\n```toml\n# fuzz/Cargo.toml\n[package]\nname = \"crypto-lib-fuzz\"\nversion = \"0.0.0\"\npublish = false\nedition = \"2021\"\n\n[package.metadata]\ncargo-fuzz = true\n\n[dependencies]\nlibfuzzer-sys = \"0.4\"\ncrypto-lib = { path = \"..\" }\n\n# Prevent this from interfering with workspaces\n[workspace]\nmembers = [\".\"]\n\n[[bin]]\nname = \"fuzz_encryption\"\npath = \"fuzz_targets/fuzz_encryption.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_signature\"\npath = \"fuzz_targets/fuzz_signature.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_hash\"\npath = \"fuzz_targets/fuzz_hash.rs\"\ntest = false\ndoc = false\n```\n\nKey points about this OSS-Fuzz Rust setup:\n\n1. **Base Image**: Uses `base-builder-rust` which includes Rust toolchain and cargo-fuzz\n2. **Rust Constraints**: Only AddressSanitizer and libfuzzer are supported (as specified in project.yaml)\n3. **Build Process**: Uses `cargo fuzz build -O --debug-assertions` for optimized builds with safety checks\n4. **Output Structure**: Copies binaries, seed corpus (zipped), and dictionaries to `$OUT/`\n5. **System Dependencies**: Includes common crypto library dependencies (OpenSSL, CMake, etc.)\n\nThe fuzz targets should be in your repository under `fuzz/fuzz_targets/` and follow the libfuzzer-sys pattern with `#![no_main]` and `fuzz_target!` macro.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5302,
            "output_tokens": 1501,
            "cached": false
          }
        },
        {
          "run_index": 2,
          "baseline": {
            "output": "# Dockerfile for OSS-Fuzz Rust Cryptographic Library Fuzzing\n\nHere's a complete setup for fuzzing a Rust cryptographic library with OSS-Fuzz:\n\n## Dockerfile\n\n```dockerfile\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies for cryptographic operations\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    cmake \\\n    libssl-dev \\\n    pkg-config \\\n    libgmp-dev \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the project repository\n# Example: Using a hypothetical rust-crypto library\nRUN git clone --depth 1 https://github.com/RustCrypto/crypto.git $SRC/crypto\n\n# Set working directory\nWORKDIR $SRC/crypto\n\n# Copy build script\nCOPY build.sh $SRC/\n\n# Copy fuzzing harnesses\nCOPY fuzz/ $SRC/crypto/fuzz/\n```\n\n## project.yaml\n\n```yaml\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n\nhomepage: \"https://github.com/RustCrypto/crypto\"\nlanguage: rust\nprimary_contact: \"security@rustcrypto.org\"\nmain_repo: \"https://github.com/RustCrypto/crypto\"\n\n# Rust-specific constraints\nsanitizers:\n  - address\n  - memory\n  - undefined\n  \n# Rust fuzzing typically uses libFuzzer\nfuzzing_engines:\n  - libfuzzer\n  - afl\n  \n# Architecture support\narchitectures:\n  - x86_64\n\n# Vendor CXX to ensure compatibility\nvendor_cxx: true\n\n# File size limit for test cases (in bytes)\nfile_size_limit: 10240\n\n# Experimental features\nexperimental: false\n\n# Auto-CC configuration\nauto_ccs:\n  - \"maintainer1@example.com\"\n  - \"maintainer2@example.com\"\n\n# View restrictions (public/restricted)\nview_restrictions: none\n\n# Build configuration\nbuild_type: release\n\n# Rust-specific: Use cargo-fuzz\nmain_build_script: build.sh\n```\n\n## build.sh\n\n```bash\n#!/bin/bash -eu\n# Copyright 2024 Google LLC\n#\n# Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n#      http://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.\n#\n################################################################################\n\n# Navigate to project directory\ncd $SRC/crypto\n\n# Install cargo-fuzz if not already installed\nif ! command -v cargo-fuzz &> /dev/null; then\n    cargo install cargo-fuzz\nfi\n\n# Build fuzz targets\n# The cargo fuzz build command will compile all fuzz targets\ncargo fuzz build --release\n\n# Copy fuzz targets to output directory\nFUZZ_TARGET_OUTPUT_DIR=$SRC/crypto/fuzz/target/x86_64-unknown-linux-gnu/release\n\n# List of fuzz targets to build\nFUZZ_TARGETS=(\n    \"fuzz_aes_encrypt\"\n    \"fuzz_aes_decrypt\"\n    \"fuzz_sha256\"\n    \"fuzz_hmac\"\n    \"fuzz_rsa_encrypt\"\n    \"fuzz_rsa_decrypt\"\n    \"fuzz_ecdsa_sign\"\n    \"fuzz_ecdsa_verify\"\n)\n\n# Copy each fuzz target to the output directory\nfor target in \"${FUZZ_TARGETS[@]}\"; do\n    if [ -f \"$FUZZ_TARGET_OUTPUT_DIR/$target\" ]; then\n        cp \"$FUZZ_TARGET_OUTPUT_DIR/$target\" $OUT/\n        \n        # Create seed corpus if available\n        if [ -d \"$SRC/crypto/fuzz/corpus/$target\" ]; then\n            zip -rj $OUT/${target}_seed_corpus.zip $SRC/crypto/fuzz/corpus/$target/\n        fi\n        \n        # Copy dictionary if available\n        if [ -f \"$SRC/crypto/fuzz/dict/$target.dict\" ]; then\n            cp $SRC/crypto/fuzz/dict/$target.dict $OUT/${target}.dict\n        fi\n    fi\ndone\n\n# Build coverage instrumentation for continuous fuzzing\nif [ \"$SANITIZER\" = \"coverage\" ]; then\n    # Rebuild with coverage instrumentation\n    cargo fuzz coverage --release\nfi\n```\n\n## Example Fuzz Target (fuzz/fuzz_targets/fuzz_aes_encrypt.rs)\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse aes::Aes128;\nuse aes::cipher::{\n    BlockEncrypt, KeyInit,\n    generic_array::GenericArray,\n};\n\nfuzz_target!(|data: &[u8]| {\n    // Ensure we have enough data for key and plaintext\n    if data.len() < 32 {\n        return;\n    }\n    \n    // Split data into key and plaintext\n    let (key_data, plaintext_data) = data.split_at(16);\n    \n    // Create cipher instance\n    let key = GenericArray::from_slice(key_data);\n    let cipher = Aes128::new(&key);\n    \n    // Process blocks\n    for chunk in plaintext_data.chunks_exact(16) {\n        let mut block = GenericArray::clone_from_slice(chunk);\n        cipher.encrypt_block(&mut block);\n    }\n});\n```\n\n## Cargo.toml for Fuzz Targets\n\n```toml\n[package]\nname = \"crypto-fuzz\"\nversion = \"0.0.0\"\npublish = false\nedition = \"2021\"\n\n[package.metadata]\ncargo-fuzz = true\n\n[dependencies]\nlibfuzzer-sys = \"0.4\"\naes = \"0.8\"\nsha2 = \"0.10\"\nhmac = \"0.12\"\nrsa = \"0.9\"\necdsa = \"0.16\"\n\n[[bin]]\nname = \"fuzz_aes_encrypt\"\npath = \"fuzz_targets/fuzz_aes_encrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_aes_decrypt\"\npath = \"fuzz_targets/fuzz_aes_decrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_sha256\"\npath = \"fuzz_targets/fuzz_sha256.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_hmac\"\npath = \"fuzz_targets/fuzz_hmac.rs\"\ntest = false\ndoc = false\n\n[profile.release]\ndebug = true\n```\n\n## Directory Structure\n\n```\ncrypto/\n\u251c\u2500\u2500 Dockerfile\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 build.sh\n\u251c\u2500\u2500 fuzz/\n\u2502   \u251c\u2500\u2500 Cargo.toml\n\u2502   \u251c\u2500\u2500 fuzz_targets/\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_aes_encrypt.rs\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_aes_decrypt.rs\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_sha256.rs\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_hmac.rs\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_rsa_encrypt.rs\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_rsa_decrypt.rs\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_ecdsa_sign.rs\n\u2502   \u2502   \u2514\u2500\u2500 fuzz_ecdsa_verify.rs\n\u2502   \u251c\u2500\u2500 corpus/\n\u2502   \u2502   \u251c\u2500\u2500 fuzz_aes_encrypt/\n\u2502   \u2502   \u2514\u2500\u2500 fuzz_sha256/\n\u2502   \u2514\u2500\u2500 dict/\n\u2502       \u2514\u2500\u2500 crypto.dict\n\u2514\u2500\u2500 src/\n    \u2514\u2500\u2500 lib.rs\n```\n\nThis setup provides a complete OSS-Fuzz integration for a Rust cryptographic library with proper sanitizer support, multiple fuzz targets, and Rust-specific optimizations.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 71,
            "output_tokens": 2298,
            "cached": false
          },
          "with_skill": {
            "output": "# OSS-Fuzz Rust Cryptographic Library Setup\n\nHere's a complete OSS-Fuzz integration for a Rust cryptographic library, using a realistic example structure:\n\n## Project Structure\n\n```\nprojects/rust-crypto-lib/\n\u251c\u2500\u2500 project.yaml\n\u251c\u2500\u2500 Dockerfile\n\u2514\u2500\u2500 build.sh\n```\n\n## project.yaml\n\n```yaml\nhomepage: \"https://github.com/example-org/rust-crypto-lib\"\nlanguage: rust\nprimary_contact: \"security@example-org.com\"\nauto_ccs:\n  - \"maintainer@example-org.com\"\n  - \"fuzzing-team@example-org.com\"\n\nmain_repo: \"https://github.com/example-org/rust-crypto-lib\"\n\n# Rust only supports AddressSanitizer with libfuzzer\nsanitizers:\n  - address\n\nfuzzing_engines:\n  - libfuzzer\n\n# Vendor C/C++ dependencies to avoid network access during build\nvendor_ccs: true\n\n# File size limits for fuzzing inputs\nfile_github_issue: true\n\n# Coverage reports\ncoverage_extra_args: --ignore-filename-regex=\"(tests?|benches|examples)/\"\n```\n\n## Dockerfile\n\n```dockerfile\n# Use Rust-specific base builder image\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies for cryptographic operations\n# Common dependencies for crypto libraries:\n# - OpenSSL development headers (if using OpenSSL bindings)\n# - Assembly optimizations support\n# - Additional crypto libraries for testing\nRUN apt-get update && apt-get install -y \\\n    libssl-dev \\\n    pkg-config \\\n    cmake \\\n    clang \\\n    llvm \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the main repository\n# Use --depth 1 for faster cloning, --recurse-submodules if needed\nRUN git clone --depth 1 https://github.com/example-org/rust-crypto-lib.git rust-crypto-lib\n\n# Set working directory\nWORKDIR rust-crypto-lib\n\n# Optional: Clone fuzzing harnesses if maintained separately\n# This is recommended for keeping fuzzing code separate from main repo\nRUN git clone --depth 1 https://github.com/example-org/rust-crypto-lib-fuzz.git fuzz\n\n# Copy build script\nCOPY build.sh $SRC/\n```\n\n## build.sh\n\n```bash\n#!/bin/bash -eu\n\n# Navigate to project directory\ncd $SRC/rust-crypto-lib\n\n# If using separate fuzzing repository\nif [ -d \"$SRC/rust-crypto-lib/fuzz\" ]; then\n    cd fuzz\nelse\n    # If fuzz targets are in main repo under fuzz/ directory\n    cd $SRC/rust-crypto-lib\nfi\n\n# Build all fuzz targets with cargo-fuzz\n# The -O flag enables optimizations\n# --debug-assertions keeps debug assertions for better bug detection\ncargo fuzz build -O --debug-assertions\n\n# Copy fuzz targets to output directory\n# Targets are built to: fuzz/target/x86_64-unknown-linux-gnu/release/\nFUZZ_TARGET_DIR=\"fuzz/target/x86_64-unknown-linux-gnu/release\"\n\n# Copy each fuzz target\nfor fuzz_target in $(cargo fuzz list); do\n    cp $FUZZ_TARGET_DIR/$fuzz_target $OUT/\ndone\n\n# Copy seed corpus if available\n# Corpus files should be in fuzz/corpus/<target_name>/\nif [ -d \"fuzz/corpus\" ]; then\n    for fuzz_target in $(cargo fuzz list); do\n        if [ -d \"fuzz/corpus/$fuzz_target\" ]; then\n            zip -j $OUT/${fuzz_target}_seed_corpus.zip fuzz/corpus/$fuzz_target/*\n        fi\n    done\nfi\n\n# Copy dictionaries if available\n# Dictionary files should be named fuzz/<target_name>.dict\nif [ -d \"fuzz\" ]; then\n    for dict in fuzz/*.dict; do\n        if [ -f \"$dict\" ]; then\n            cp \"$dict\" $OUT/\n        fi\n    done\nfi\n\n# Optional: Copy options files for specific fuzz targets\n# Options files control fuzzer behavior (max_len, timeout, etc.)\n# Format: <target_name>.options\nif [ -d \"fuzz\" ]; then\n    for options in fuzz/*.options; do\n        if [ -f \"$options\" ]; then\n            cp \"$options\" $OUT/\n        fi\n    done\nfi\n```\n\n## Example Fuzz Target Structure\n\nIf harnesses are in the main repository, they should be in `fuzz/fuzz_targets/`:\n\n### fuzz/Cargo.toml\n\n```toml\n[package]\nname = \"rust-crypto-lib-fuzz\"\nversion = \"0.0.0\"\npublish = false\nedition = \"2021\"\n\n[package.metadata]\ncargo-fuzz = true\n\n[dependencies]\nlibfuzzer-sys = \"0.4\"\nrust-crypto-lib = { path = \"..\" }\n\n# Prevent this from interfering with workspaces\n[workspace]\nmembers = [\".\"]\n\n[[bin]]\nname = \"fuzz_aes_encrypt\"\npath = \"fuzz_targets/fuzz_aes_encrypt.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_rsa_sign\"\npath = \"fuzz_targets/fuzz_rsa_sign.rs\"\ntest = false\ndoc = false\n\n[[bin]]\nname = \"fuzz_hash_sha256\"\npath = \"fuzz_targets/fuzz_hash_sha256.rs\"\ntest = false\ndoc = false\n```\n\n### fuzz/fuzz_targets/fuzz_aes_encrypt.rs\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto_lib::aes::{Aes256, BlockCipher};\n\nfuzz_target!(|data: &[u8]| {\n    // Need at least 32 bytes for key + some data\n    if data.len() < 33 {\n        return;\n    }\n\n    // Split input into key and plaintext\n    let (key_bytes, plaintext) = data.split_at(32);\n    \n    // Create cipher instance\n    let cipher = match Aes256::new_from_slice(key_bytes) {\n        Ok(c) => c,\n        Err(_) => return,\n    };\n\n    // Pad plaintext to block size if needed\n    let block_size = 16;\n    if plaintext.len() < block_size {\n        return;\n    }\n\n    // Take first complete block\n    let block = &plaintext[..block_size];\n    let mut buffer = block.to_vec();\n\n    // Fuzz encryption\n    cipher.encrypt_block(&mut buffer);\n    \n    // Fuzz decryption\n    cipher.decrypt_block(&mut buffer);\n    \n    // Verify round-trip (should match original)\n    assert_eq!(&buffer[..], block);\n});\n```\n\n### fuzz/fuzz_targets/fuzz_rsa_sign.rs\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto_lib::rsa::{RsaPrivateKey, RsaPublicKey, PaddingScheme};\n\nfuzz_target!(|data: &[u8]| {\n    // Skip empty inputs\n    if data.is_empty() {\n        return;\n    }\n\n    // Use deterministic key generation for reproducibility\n    let mut rng = rust_crypto_lib::test_utils::DeterministicRng::new(42);\n    \n    // Generate keys (in real fuzzing, you'd cache these)\n    let private_key = match RsaPrivateKey::new(&mut rng, 2048) {\n        Ok(k) => k,\n        Err(_) => return,\n    };\n    let public_key = RsaPublicKey::from(&private_key);\n\n    // Fuzz signing\n    let signature = match private_key.sign(\n        PaddingScheme::PKCS1v15Sign,\n        data\n    ) {\n        Ok(sig) => sig,\n        Err(_) => return,\n    };\n\n    // Fuzz verification\n    let _ = public_key.verify(\n        PaddingScheme::PKCS1v15Sign,\n        data,\n        &signature\n    );\n});\n```\n\n### fuzz/fuzz_targets/fuzz_hash_sha256.rs\n\n```rust\n#![no_main]\n\nuse libfuzzer_sys::fuzz_target;\nuse rust_crypto_lib::hash::{Sha256, Digest};\n\nfuzz_target!(|data: &[u8]| {\n    // Test basic hashing\n    let mut hasher = Sha256::new();\n    hasher.update(data);\n    let result1 = hasher.finalize();\n\n    // Test incremental hashing with different chunk sizes\n    if data.len() > 1 {\n        let mut hasher2 = Sha256::new();\n        let mid = data.len() / 2;\n        hasher2.update(&data[..mid]);\n        hasher2.update(&data[mid..]);\n        let result2 = hasher2.finalize();\n        \n        // Results should be identical\n        assert_eq!(result1, result2);\n    }\n\n    // Test reset functionality\n    let mut hasher3 = Sha256::new();\n    hasher3.update(b\"dummy data\");\n    hasher3.reset();\n    hasher3.update(data);\n    let result3 = hasher3.finalize();\n    \n    assert_eq!(result1, result3);\n});\n```\n\n## Optional Configuration Files\n\n### fuzz/fuzz_aes_encrypt.options\n\n```\n[libfuzzer]\nmax_len = 1024\ntimeout = 10\n```\n\n### fuzz/fuzz_rsa_sign.options\n\n```\n[libfuzzer]\nmax_len = 2048\ntimeout = 30\nrss_limit_mb = 4096\n```\n\n### fuzz/aes.dict\n\n```\n# Common AES test vectors\n\"\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\"\n\"\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\\xFF\"\n\"\\x01\\x23\\x45\\x67\\x89\\xAB\\xCD\\xEF\"\n\"AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAA\"\n```\n\n## Testing Locally\n\n```bash\n# Clone OSS-Fuzz\ngit clone https://github.com/google/oss-fuzz\ncd oss-fuzz\n\n# Build the project image\npython3 infra/helper.py build_image rust-crypto-lib\n\n# Build fuzzers\npython3 infra/helper.py build_fuzzers --sanitizer=address rust-crypto-lib\n\n# Run a specific fuzzer\npython3 infra/helper.py run_fuzzer rust-crypto-lib fuzz_aes_encrypt\n\n# Check coverage\npython3 infra/helper.py coverage rust-crypto-lib\n```\n\n## Key Rust-Specific Considerations\n\n### 1. **Sanitizer Limitations**\n```yaml\n# Rust only supports AddressSanitizer\nsanitizers:\n  - address\n# NOT supported: undefined, memory, thread\n```\n\n### 2. **Cargo-Fuzz Integration**\nThe build.sh uses `cargo fuzz` which:\n- Automatically links with libfuzzer\n- Handles Rust-specific compilation flags\n- Manages target discovery\n\n### 3. **Performance Optimization**\n```bash\n# Use release mode with debug assertions\ncargo fuzz build -O --debug-assertions\n```\n\n### 4. **Deterministic Testing**\nFor crypto libraries, use deterministic RNGs in fuzz targets to ensure reproducibility:\n```rust\nlet mut rng = DeterministicRng::new(seed);\n```\n\n### 5. **Memory Management**\nRust's ownership system prevents many memory bugs, but fuzzing still finds:\n- Logic errors\n- Panics from unwrap()\n- Integer overflows\n- Algorithmic complexity issues\n\n## Common Pitfalls to Avoid\n\n| Issue | Problem | Solution |\n|-------|---------|----------|\n| **Using unwrap() in fuzz targets** | Causes panics on invalid input | Use `match` or `if let` |\n| **Not checking input size** | Wastes fuzzing time | Add early returns for invalid sizes |\n| **Expensive key generation** | Slows fuzzing | Cache keys or use deterministic generation |\n| **Missing corpus** | Slow initial coverage | Provide seed corpus with valid inputs |\n| **No dictionaries** | Misses structured inputs | Add dictionary with common values |\n\nThis setup provides a production-ready OSS-Fuzz integration for a Rust cryptographic library with proper sanitizer configuration, multiple fuzz targets, and comprehensive testing infrastructure.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5017,
            "output_tokens": 3212,
            "cached": false
          },
          "skill_md_only": null,
          "realistic": {
            "output": "I'll create the OSS-Fuzz integration files for a Rust cryptographic library project.\n\n```dockerfile\n# Dockerfile\nFROM gcr.io/oss-fuzz-base/base-builder-rust\n\n# Install system dependencies commonly needed for cryptographic libraries\nRUN apt-get update && apt-get install -y \\\n    build-essential \\\n    pkg-config \\\n    libssl-dev \\\n    cmake \\\n    && rm -rf /var/lib/apt/lists/*\n\n# Clone the cryptographic library repository\n# Replace with your actual repository URL\nRUN git clone --depth 1 https://github.com/yourorg/crypto-lib crypto-lib\n\n# Set working directory\nWORKDIR crypto-lib\n\n# Copy build script\nCOPY build.sh $SRC/\n```\n\n```yaml\n# project.yaml\nhomepage: \"https://github.com/yourorg/crypto-lib\"\nlanguage: rust\nprimary_contact: \"security@yourorg.com\"\nmain_repo: \"https://github.com/yourorg/crypto-lib\"\n\n# Rust only supports libfuzzer as fuzzing engine\nfuzzing_engines:\n  - libfuzzer\n\n# Rust only supports AddressSanitizer with libfuzzer\nsanitizers:\n  - address\n\n# Optional: Specify vendor-specific settings\nvendor: True\n\n# Optional: Add additional contacts\nauto_ccs:\n  - \"maintainer@yourorg.com\"\n  - \"fuzzing-team@yourorg.com\"\n\n# Optional: File size limits (in MB)\nfile_github_issue: true\n```\n\n```bash\n# build.sh\n#!/bin/bash -eu\n\n# Navigate to project directory\ncd $SRC/crypto-lib\n\n# Build fuzzers with cargo-fuzz in release mode with debug assertions\n# This provides good performance while keeping safety checks\ncargo fuzz build -O --debug-assertions\n\n# Copy all fuzzer binaries to output directory\n# cargo-fuzz builds to target/x86_64-unknown-linux-gnu/release/\nfor fuzzer in fuzz/target/x86_64-unknown-linux-gnu/release/fuzz_*; do\n    if [ -f \"$fuzzer\" ]; then\n        fuzzer_name=$(basename \"$fuzzer\")\n        cp \"$fuzzer\" $OUT/\n        echo \"Copied fuzzer: $fuzzer_name\"\n    fi\ndone\n\n# Optional: Copy seed corpus if available\n# Corpus files should be in fuzz/corpus/<fuzzer_name>/\nfor corpus_dir in fuzz/corpus/*; do\n    if [ -d \"$corpus_dir\" ]; then\n        fuzzer_name=$(basename \"$corpus_dir\")\n        if [ -d \"$corpus_dir\" ] && [ \"$(ls -A $corpus_dir)\" ]; then\n            zip -j $OUT/${fuzzer_name}_seed_corpus.zip $corpus_dir/*\n            echo \"Created seed corpus for: $fuzzer_name\"\n        fi\n    fi\ndone\n\n# Optional: Copy dictionaries if available\n# Dictionary files should be named fuzz/<fuzzer_name>.dict\nfor dict_file in fuzz/*.dict; do\n    if [ -f \"$dict_file\" ]; then\n        cp \"$dict_file\" $OUT/\n        echo \"Copied dictionary: $(basename $dict_file)\"\n    fi\ndone\n```\n\nThese files set up a complete OSS-Fuzz integration for a Rust cryptographic library with:\n\n1. **Dockerfile**: Uses `base-builder-rust` image, installs common crypto dependencies (OpenSSL, CMake), and clones the repository\n\n2. **project.yaml**: Specifies Rust-specific constraints:\n   - Only `libfuzzer` engine (Rust limitation)\n   - Only `address` sanitizer (Rust limitation)\n   - Includes contact information and GitHub integration\n\n3. **build.sh**: \n   - Builds fuzzers with optimizations and debug assertions\n   - Copies all fuzzer binaries to `$OUT`\n   - Handles seed corpus and dictionaries if present\n\nTo use these files, place them in `oss-fuzz/projects/crypto-lib/` and ensure your Rust project has fuzz targets set up with `cargo-fuzz`.",
            "model": "claude-sonnet-4-5-20250929",
            "input_tokens": 5302,
            "output_tokens": 989,
            "cached": false
          }
        }
      ]
    }
  ]
}