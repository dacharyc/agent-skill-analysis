<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Agent Skill Analysis — Interactive Report</title>
    <meta name="description" content="A systematic audit of 673 Agent Skills across 41 repositories. Explore validation results, content quality scores, contamination risk, and behavioral evaluation findings.">

    <!-- Open Graph (LinkedIn, Facebook, etc.) -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://agentskillreport.com/">
    <meta property="og:title" content="Agent Skill Analysis — 673 Skills Audited">
    <meta property="og:description" content="22% fail validation. 52% of tokens are waste. Most skills restate what the LLM already knows. Explore the interactive report.">
    <meta property="og:image" content="https://agentskillreport.com/og-image.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">

    <!-- Twitter/X -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Agent Skill Analysis — 673 Skills Audited">
    <meta name="twitter:description" content="22% fail validation. 52% of tokens are waste. Most skills restate what the LLM already knows. Explore the interactive report.">
    <meta name="twitter:image" content="https://agentskillreport.com/og-image.png">

    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.7/dist/chart.umd.min.js"></script>
</head>
<body>
    <header>
        <h1>Agent Skill Analysis</h1>
        <p class="subtitle-lead">A systematic ecosystem-wide audit of 673 Agent Skills</p>
        <p class="subtitle">Structural compliance, content quality, context efficiency, and cross-contamination risk</p>
        <div class="header-meta">
            <span class="meta-chip">673 Skills</span>
            <span class="meta-chip">41 Repositories</span>
            <span class="meta-chip">February 2026</span>
            <a href="quality-in-the-agent-skills-ecosystem.pdf" class="meta-chip meta-chip-link" download>Download Paper (PDF)</a>
        </div>
    </header>

    <nav>
        <a href="#overview">Overview</a>
        <a href="#validation">Validation</a>
        <a href="#content">Content Quality</a>
        <a href="#contamination">Contamination</a>
        <a href="#behavioral">Behavioral</a>
        <a href="#llm-quality">LLM Quality</a>
        <a href="#table">All Skills</a>
        <button id="theme-toggle" aria-label="Toggle dark mode"></button>
    </nav>

    <main>
        <!-- Overview Dashboard -->
        <section id="overview">
            <h2>Overview</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-value" id="stat-total">—</div>
                    <div class="stat-label">Total Skills</div>
                </div>
                <div class="stat-card pass">
                    <div class="stat-value" id="stat-passed">—</div>
                    <div class="stat-label">Passed Validation</div>
                </div>
                <div class="stat-card fail">
                    <div class="stat-value" id="stat-failed">—</div>
                    <div class="stat-label">Failed Validation</div>
                </div>
                <div class="stat-card warn">
                    <div class="stat-value" id="stat-high-risk">—</div>
                    <div class="stat-label">High Contamination</div>
                </div>
                <div class="stat-card waste">
                    <div class="stat-value" id="stat-waste">—</div>
                    <div class="stat-label">Context Window Waste</div>
                </div>
                <div class="stat-card llm">
                    <div class="stat-value" id="stat-llm-overall">—</div>
                    <div class="stat-label">Mean LLM Quality</div>
                </div>
                <div class="stat-card net-neg">
                    <div class="stat-value" id="stat-net-negative">—</div>
                    <div class="stat-label">Low Value-Add</div>
                </div>
            </div>
            <div class="chart-row">
                <div class="chart-container">
                    <canvas id="chart-pass-fail"></canvas>
                </div>
                <div class="chart-container">
                    <canvas id="chart-risk"></canvas>
                </div>
            </div>
            <div class="key-findings">
                <h3>Key Findings</h3>
                <ol>
                    <li><strong>22% fail validation</strong> &mdash; company-authored skills underperform community collections on structural compliance</li>
                    <li><strong>52% of all tokens are nonstandard files</strong> wasting context window space (LICENSE, build artifacts, schemas)</li>
                    <li><strong>Novelty is the key quality differentiator</strong> &mdash; most skills restate what the LLM already knows; craft dimensions cluster tightly but novelty varies independently</li>
                    <li><strong>66 skills have hidden contamination</strong> invisible to SKILL.md-only analysis, carried in reference files</li>
                    <li><strong>No correlation between structural risk and actual degradation</strong> (r&nbsp;=&nbsp;0.077, n&nbsp;=&nbsp;19) &mdash; content-specific mechanisms like template propagation and API hallucination drive observed effects</li>
                </ol>
            </div>
        </section>

        <!-- Validation Results -->
        <section id="validation">
            <h2>Validation Results by Source</h2>
            <p>Validation checks whether each skill complies with the <a href="https://agentskills.io" target="_blank">Agent Skills specification</a> &mdash; required files present, correct structure, valid metadata, and properly formatted content. Skills that fail validation may not load correctly or may confuse the agent about how to use them.</p>
            <div class="chart-container wide">
                <canvas id="chart-by-source"></canvas>
            </div>
            <div class="chart-container wide">
                <canvas id="chart-tokens"></canvas>
            </div>
            <h3>Token Budget Composition</h3>
            <p>How token budgets break down across SKILL.md, references, assets, and nonstandard files. Nonstandard files (LICENSE, build artifacts, schemas) waste context window space.</p>
            <div class="chart-container wide">
                <canvas id="chart-token-budget"></canvas>
            </div>
        </section>

        <!-- Content Quality -->
        <section id="content">
            <h2>Content Quality</h2>
            <p>Two automated metrics assess how well a skill's instruction file communicates with the agent. <strong>Information density</strong> measures the ratio of actionable content (code blocks, specific instructions, structured data) to total text &mdash; higher values mean less filler. <strong>Instruction specificity</strong> measures how concrete and directive the language is versus vague advisory text like "consider" or "be careful."</p>
            <div class="chart-row">
                <div class="chart-container">
                    <canvas id="chart-density"></canvas>
                </div>
                <div class="chart-container">
                    <canvas id="chart-specificity"></canvas>
                </div>
            </div>
        </section>

        <!-- Contamination Risk -->
        <section id="contamination">
            <h2>Cross-Contamination</h2>
            <p>Skills that reference multi-interface tools or mix code examples across languages carry structural complexity that may cross-contaminate agent behavior. These scores measure structural language complexity. An exploratory behavioral evaluation (n&nbsp;=&nbsp;19) found no correlation between these structural scores and measured degradation (r&nbsp;=&nbsp;0.077), suggesting content-specific factors may matter more than language mixing.</p>
            <div class="chart-container wide">
                <canvas id="chart-risk-detail"></canvas>
            </div>
            <div id="high-risk-list">
                <h3>High-Contamination Skills</h3>
                <div class="contam-explainer-cards">
                    <div class="contam-explainer-card">
                        <h4>Why We Measure This</h4>
                        <p>Skills scoring &ge;&nbsp;0.5 on our structural contamination metric. This dimension is motivated by research on <strong>Programming Language Confusion</strong> (Moumoula et al., 2025), which shows LLMs can generate code using patterns from the wrong language &mdash; particularly between syntactically similar pairs like C#/Java or JavaScript/TypeScript. Copy bias in in-context learning (Ali et al., 2024) and LLM susceptibility to irrelevant context (Shi et al., 2023) further support the concern that mixed-language skill content could interfere with code generation.</p>
                    </div>
                    <div class="contam-explainer-card">
                        <h4>How the Score Works</h4>
                        <p>The score combines three factors: <strong>multi-interface tools</strong> (e.g., a database with both shell and language SDKs), <strong>scope breadth</strong> (number of distinct technology categories referenced), and <strong>language mismatch</strong>. <strong>Mismatched categories</strong> are code language families that differ from the skill's primary language &mdash; each classified as <em>application</em> (Python, JavaScript, Java, .NET, mobile) or <em>auxiliary</em> (shell, config, query, markup). Mismatches are weighted by syntactic similarity, following the PLC finding that confusion occurs primarily between similar languages: application + application (e.g., Python + Java) carries weight 1.0, application + auxiliary (e.g., Python + shell) 0.25, and auxiliary + auxiliary just 0.1.</p>
                    </div>
                    <div class="contam-explainer-card">
                        <h4>What We Actually Found</h4>
                        <p>In theory, these mismatches could cause the model to bleed syntax or API patterns from one language into another. In practice, our <a href="#behavioral">behavioral evaluation</a> found that structural scores did not predict actual degradation &mdash; content-specific mechanisms like template propagation and API hallucination mattered more. Cross-language code bleed (the PLC mechanism) did appear in some cases, but accounted for a minority of the total degradation observed. These scores are best understood as a measure of structural complexity, not a direct predictor of harm.</p>
                    </div>
                </div>
                <div id="high-risk-cards"></div>
            </div>
            <div id="hidden-contamination-list">
                <h3>Hidden Contamination</h3>
                <p>The contamination scoring <a href="#high-risk-list">described above</a> applies to <code>SKILL.md</code> content. But skills can also include reference files that are loaded into context alongside the instruction file. These 66 skills score as low-risk on their <code>SKILL.md</code> alone, yet carry medium or high contamination in their reference files &mdash; language mixing invisible to instruction-file-only analysis.</p>
                <div id="hidden-contamination-cards"></div>
            </div>
        </section>

        <!-- Behavioral Insights -->
        <section id="behavioral">
            <h2>Behavioral Insights</h2>
            <p>An exploratory behavioral evaluation of 19 skills tested whether structural contamination scores predict actual code generation degradation. Each skill was evaluated across 5 task types under 3 conditions (baseline, skill-loaded, skill + realistic context), with 3 runs each at temperature 0.3.</p>
            <div class="chart-container wide">
                <canvas id="chart-behavioral-scatter"></canvas>
            </div>
            <div class="behavioral-callout">
                <h4>The Disconnect</h4>
                <p><strong>react-native-best-practices</strong> (contamination 0.07, B-A = &minus;0.384) produces the largest degradation despite near-zero structural risk. <strong>sharp-edges</strong> (contamination 0.62, B-A = &minus;0.083) has high structural risk but minimal behavioral impact. Structural scores alone don't predict what hurts.</p>
            </div>
            <h3>Content Interference Mechanisms</h3>
            <p>Six distinct mechanisms drive degradation &mdash; only one (cross-language code bleed) is captured by structural contamination scoring:</p>
            <div class="mechanism-cards">
                <div class="mechanism-card">
                    <h4>Template Propagation</h4>
                    <p>Skill output templates reproduced verbatim in unrelated contexts. Invalid <code>// comments</code> in JSON templates bleed into all output.</p>
                    <div class="mechanism-example">claude-settings-audit (B-A = &minus;0.483)</div>
                </div>
                <div class="mechanism-card">
                    <h4>Textual Frame Leakage</h4>
                    <p>Non-code skill content reshapes how the model frames responses, adding verbose commentary at the expense of code completeness.</p>
                    <div class="mechanism-example">monitoring-observability (B-A = &minus;0.233)</div>
                </div>
                <div class="mechanism-card">
                    <h4>Token Budget Competition</h4>
                    <p>With skill loaded, outputs allocate more tokens to explanatory text and less to code, producing incomplete implementations under output limits.</p>
                    <div class="mechanism-example">react-native-best-practices (B-A = &minus;0.384)</div>
                </div>
                <div class="mechanism-card">
                    <h4>API Hallucination</h4>
                    <p>The model invents plausible but nonexistent API methods that follow naming conventions seen in skill content. The code is in the <em>correct</em> language &mdash; the API surface is wrong.</p>
                    <div class="mechanism-example">upgrade-stripe (B-A = &minus;0.117)</div>
                </div>
                <div class="mechanism-card">
                    <h4>Cross-Language Code Bleed</h4>
                    <p>The classic programming language confusion: shell syntax in JavaScript, mongosh operators in JSON. The <em>only</em> mechanism structural scoring detects.</p>
                    <div class="mechanism-example">MongoDB skills</div>
                </div>
                <div class="mechanism-card">
                    <h4>Architectural Pattern Bleed</h4>
                    <p>Skill-specific architectural conventions (error handling, config patterns) propagate to unrelated code, even when the language is correct.</p>
                    <div class="mechanism-example">provider-resources (B-A = &minus;0.317)</div>
                </div>
            </div>
            <div class="behavioral-callout mitigation">
                <h4>Context Mitigation</h4>
                <p>When skills are loaded alongside realistic agentic context (system prompt, tools, conversation history), mean degradation drops from &minus;0.080 to &minus;0.023 &mdash; a ~62&ndash;75% attenuation. Real-world impact may be substantially smaller than isolated evaluation suggests.</p>
            </div>
        </section>

        <!-- LLM Quality -->
        <section id="llm-quality">
            <h2>LLM-as-Judge Quality</h2>
            <p>All 673 skills scored by Claude Sonnet across 6 dimensions (1-5 scale): clarity, actionability, token efficiency, scope discipline, directive precision, and novelty.</p>
            <div class="chart-container wide">
                <canvas id="chart-llm-by-source"></canvas>
            </div>
            <div class="chart-row">
                <div class="chart-container">
                    <canvas id="chart-novelty-dist"></canvas>
                </div>
                <div class="chart-container">
                    <canvas id="chart-llm-spread"></canvas>
                </div>
            </div>
            <h3>Craft vs. Novelty</h3>
            <p>Skills cluster tightly on craft dimensions (clarity, actionability, efficiency, scope, precision) but spread independently on novelty &mdash; a two-factor quality structure.</p>
            <div class="chart-container wide">
                <canvas id="chart-craft-novelty"></canvas>
            </div>
            <h3>Low Value-Add Risk</h3>
            <p>Skills that score low on novelty (score &le; 2) <em>and</em> medium-to-high on <a href="#contamination">structural contamination</a> (score &ge; 0.2). The idea: if a skill doesn't teach the model anything new but does add mixed-language complexity to the context window, the theoretical cost-benefit is unfavorable. These skills are candidates for removal or consolidation.</p>
            <p>That said, in our <a href="#behavioral">behavioral evaluation</a> of 6 low value-add skills, the actual measured degradation was modest (mean B&minus;A&nbsp;=&nbsp;&minus;0.072) &mdash; suggesting that while these skills aren't helping, they may not be actively hurting as much as the structural scores imply. The strongest degradation we observed came from high-novelty skills with content-specific interference mechanisms, not from low-novelty ones.</p>
            <div id="net-negative-summary" class="callout-box"></div>
            <div id="net-negative-cards"></div>
        </section>

        <!-- Filterable Table -->
        <section id="table">
            <h2>All Skills</h2>
            <div class="filters">
                <label>
                    Source:
                    <select id="filter-source">
                        <option value="">All</option>
                    </select>
                </label>
                <label>
                    Status:
                    <select id="filter-status">
                        <option value="">All</option>
                        <option value="passed">Passed</option>
                        <option value="failed">Failed</option>
                    </select>
                </label>
                <label>
                    Risk:
                    <select id="filter-risk">
                        <option value="">All</option>
                        <option value="high">High</option>
                        <option value="medium">Medium</option>
                        <option value="low">Low</option>
                    </select>
                </label>
                <label>
                    Search:
                    <input type="text" id="filter-search" placeholder="Skill name...">
                </label>
                <button id="btn-download-csv">Download CSV</button>
            </div>
            <div class="table-wrapper">
                <table id="skills-table">
                    <thead>
                        <tr>
                            <th data-sort="name">Name</th>
                            <th data-sort="source">Source</th>
                            <th data-sort="passed">Status</th>
                            <th data-sort="errors">Errors</th>
                            <th data-sort="warnings">Warnings</th>
                            <th data-sort="total_tokens">Tokens</th>
                            <th data-sort="information_density">Density</th>
                            <th data-sort="instruction_specificity">Specificity</th>
                            <th data-sort="contamination_score">Contamination</th>
                            <th data-sort="llm_overall">LLM Score</th>
                            <th data-sort="llm_novelty">Novelty</th>
                        </tr>
                    </thead>
                    <tbody id="skills-tbody">
                    </tbody>
                </table>
            </div>
            <div id="skill-detail" class="detail-panel hidden">
                <button id="close-detail">&times;</button>
                <div id="detail-content"></div>
            </div>
        </section>
    </main>

    <footer>
        <p>Author: <a href="https://dacharycarey.com">Dachary Carey</a> | Data: <a href="https://github.com/dacharyc/skill-validator">skill-validator</a> | <a href="https://github.com/dacharyc/agent-skill-analysis">Full paper &amp; analysis</a> | February 2026</p>
    </footer>

    <script src="app.js"></script>
</body>
</html>
