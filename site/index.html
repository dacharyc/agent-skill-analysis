<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Agent Skill Analysis — Interactive Report</title>
    <meta name="description" content="A systematic audit of 673 Agent Skills across 41 repositories. Explore validation results, content quality scores, contamination risk, and behavioral evaluation findings.">

    <!-- Open Graph (LinkedIn, Facebook, etc.) -->
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://agentskillreport.com/">
    <meta property="og:title" content="Agent Skill Analysis — 673 Skills Audited">
    <meta property="og:description" content="22% fail validation. 52% of tokens are waste. Most skills restate what the LLM already knows. Explore the interactive report.">
    <meta property="og:image" content="https://agentskillreport.com/og-image.png">
    <meta property="og:image:width" content="1200">
    <meta property="og:image:height" content="630">

    <!-- Twitter/X -->
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Agent Skill Analysis — 673 Skills Audited">
    <meta name="twitter:description" content="22% fail validation. 52% of tokens are waste. Most skills restate what the LLM already knows. Explore the interactive report.">
    <meta name="twitter:image" content="https://agentskillreport.com/og-image.png">

    <link rel="stylesheet" href="style.css">
    <script src="https://cdn.jsdelivr.net/npm/chart.js@4.4.7/dist/chart.umd.min.js"></script>
</head>
<body>
    <header>
        <h1>Agent Skill Analysis</h1>
        <p class="subtitle-lead">A systematic ecosystem-wide audit of 673 Agent Skills</p>
        <p class="subtitle">Structural compliance, content quality, context efficiency, and cross-contamination risk</p>
        <div class="header-meta">
            <span class="meta-chip">673 Skills</span>
            <span class="meta-chip">41 Repositories</span>
            <span class="meta-chip">February 2026</span>
            <a href="quality-in-the-agent-skills-ecosystem.pdf" class="meta-chip meta-chip-link" download>Download Paper (PDF)</a>
        </div>
    </header>

    <div class="nav-wrapper">
        <nav>
            <a href="#overview">Overview</a>
            <a href="#validation">Validation</a>
            <a href="#content">Content Quality</a>
            <a href="#contamination">Contamination</a>
            <a href="#behavioral">Behavioral</a>
            <a href="#llm-quality">LLM Quality</a>
            <a href="#open-questions">Practitioner</a>
            <a href="#table">All Skills</a>
            <button id="theme-toggle" aria-label="Toggle dark mode"></button>
        </nav>
        <div class="nav-fade nav-fade-left" aria-hidden="true"></div>
        <div class="nav-fade nav-fade-right" aria-hidden="true"></div>
    </div>

    <div class="intro-context">
        <p>Agent Skills are the primary way to extend what coding agents know. But the ecosystem is growing faster than anyone's ability to evaluate it. If you're <strong>installing skills</strong>, how do you know which ones are worth the context window cost? If you're <strong>building skills</strong>, what actually makes one useful versus noise?</p>
        <p>This report explores those questions across 673 published skills. The structural data is comprehensive. The behavioral data is exploratory (n&nbsp;=&nbsp;19). The uncomfortable finding: the things that are easy to measure don't predict the things that matter. We can't make a deterministic checklist, but we can help you focus on key considerations.</p>
    </div>

    <main>
        <!-- Overview Dashboard -->
        <section id="overview">
            <h2>Overview</h2>
            <div class="stats-grid">
                <div class="stat-card">
                    <div class="stat-value" id="stat-total">—</div>
                    <div class="stat-label">Total Skills</div>
                </div>
                <div class="stat-card pass">
                    <div class="stat-value" id="stat-passed">—</div>
                    <div class="stat-label">Passed Validation</div>
                </div>
                <div class="stat-card fail">
                    <div class="stat-value" id="stat-failed">—</div>
                    <div class="stat-label">Failed Validation</div>
                </div>
                <div class="stat-card warn">
                    <div class="stat-value" id="stat-high-risk">—</div>
                    <div class="stat-label">High Contamination</div>
                </div>
                <div class="stat-card waste">
                    <div class="stat-value" id="stat-waste">—</div>
                    <div class="stat-label">Context Window Waste</div>
                </div>
                <div class="stat-card llm">
                    <div class="stat-value" id="stat-llm-overall">—</div>
                    <div class="stat-label">Mean LLM Quality</div>
                </div>
                <div class="stat-card net-neg">
                    <div class="stat-value" id="stat-net-negative">—</div>
                    <div class="stat-label">Low Value-Add</div>
                </div>
                <div class="stat-card hidden-contam">
                    <div class="stat-value" id="stat-hidden-contam">—</div>
                    <div class="stat-label">Hidden Contamination</div>
                </div>
            </div>
            <div class="chart-row">
                <div class="chart-container">
                    <canvas id="chart-pass-fail"></canvas>
                </div>
                <div class="chart-container">
                    <canvas id="chart-risk"></canvas>
                </div>
            </div>
            <div class="key-findings">
                <h3>Key Findings</h3>
                <ol>
                    <li><strong>22% fail validation</strong> &mdash; company-authored skills underperform community collections on structural compliance</li>
                    <li><strong>52% of all tokens are nonstandard files</strong> wasting context window space (LICENSE, build artifacts, schemas)</li>
                    <li><strong>Novelty is the key quality differentiator</strong> &mdash; most skills restate what the LLM already knows; craft dimensions cluster tightly but novelty varies independently</li>
                    <li><strong>66 skills have hidden contamination</strong> invisible to SKILL.md-only analysis, carried in reference files</li>
                    <li><strong>No correlation between structural risk and actual degradation</strong> (r&nbsp;=&nbsp;0.077, n&nbsp;=&nbsp;19) &mdash; content-specific mechanisms like template propagation and API hallucination drive observed effects</li>
                </ol>
            </div>
        </section>

        <!-- Validation Results -->
        <section id="validation">
            <h2>Validation Results by Source</h2>
            <p>Validation checks whether each skill complies with the <a href="https://agentskills.io" target="_blank">Agent Skills specification</a> &mdash; required files present, correct structure, valid metadata, and properly formatted content. Skills that fail validation may not load correctly or may confuse the agent about how to use them.</p>
            <div class="chart-container wide tall">
                <canvas id="chart-by-source"></canvas>
            </div>
            <div class="chart-container wide tall">
                <canvas id="chart-tokens"></canvas>
            </div>
            <h3>Token Budget Composition</h3>
            <p>How token budgets break down across SKILL.md, references, assets, and nonstandard files. Nonstandard files (LICENSE, build artifacts, schemas) waste context window space.</p>
            <div class="chart-container wide tall">
                <canvas id="chart-token-budget"></canvas>
            </div>
            <div class="practitioner-callout">
                <h4>If you're evaluating skills</h4>
                <p><strong>Validation is a necessary first filter.</strong> The 22% of skills that don't match the spec may not load correctly, so checking compliance saves you from obvious failures. But passing validation tells you nothing about whether a skill improves agent output. Think of it like type checking: it catches a class of errors, but doesn't tell you whether the program does what you want.</p>
            </div>
        </section>

        <!-- Content Quality -->
        <section id="content">
            <h2>Content Quality</h2>
            <p>Two automated metrics assess how well a skill's instruction file communicates with the agent. <strong>Information density</strong> measures the ratio of actionable content (code blocks, specific instructions, structured data) to total text &mdash; higher values mean less filler. <strong>Instruction specificity</strong> measures how concrete and directive the language is versus vague advisory text like "consider" or "be careful."</p>
            <div class="chart-row">
                <div class="chart-container">
                    <canvas id="chart-density"></canvas>
                </div>
                <div class="chart-container">
                    <canvas id="chart-specificity"></canvas>
                </div>
            </div>
            <div class="practitioner-callout">
                <h4>If you're building skills</h4>
                <p>Every token your skill consumes is a token unavailable for the user's actual task&mdash;their codebase context, conversation history, tool definitions. The 52% waste figure is mostly a packaging problem, not a content problem, which means it's straightforward to fix. Remove LICENSE files, build artifacts, etc. from your skills. Beyond that, writing for high information density and specificity means writing the way you'd write a good API reference: concrete, directive, minimal preamble.</p>
            </div>
        </section>

        <!-- Contamination Risk -->
        <section id="contamination">
            <h2>Cross-Contamination</h2>
            <p>Skills that reference multi-interface tools or mix code examples across languages carry structural complexity that may cross-contaminate agent behavior. These scores measure structural language complexity. An exploratory behavioral evaluation (n&nbsp;=&nbsp;19) found no correlation between these structural scores and measured degradation (r&nbsp;=&nbsp;0.077), suggesting content-specific factors may matter more than language mixing.</p>
            <div class="chart-container wide tall">
                <canvas id="chart-risk-detail"></canvas>
            </div>
            <div id="high-risk-list">
                <h3>High-Contamination Skills</h3>
                <div class="contam-explainer-cards">
                    <div class="contam-explainer-card">
                        <h4>Why We Measure This</h4>
                        <p>Skills scoring &ge;&nbsp;0.5 on our structural contamination metric. This dimension is motivated by research on <strong>Programming Language Confusion</strong> (Moumoula et al., 2025), which shows LLMs can generate code using patterns from the wrong language &mdash; particularly between syntactically similar pairs like C#/Java or JavaScript/TypeScript. Copy bias in in-context learning (Ali et al., 2024) and LLM susceptibility to irrelevant context (Shi et al., 2023) further support the concern that mixed-language skill content could interfere with code generation.</p>
                    </div>
                    <div class="contam-explainer-card">
                        <h4>How the Score Works</h4>
                        <p>The score combines three factors: <strong>multi-interface tools</strong> (e.g., a database with both shell and language SDKs), <strong>scope breadth</strong> (number of distinct technology categories referenced), and <strong>language mismatch</strong>. <strong>Mismatched categories</strong> are code language families that differ from the skill's primary language &mdash; each classified as <em>application</em> (Python, JavaScript, Java, .NET, mobile) or <em>auxiliary</em> (shell, config, query, markup). Mismatches are weighted by syntactic similarity, following the PLC finding that confusion occurs primarily between similar languages: application + application (e.g., Python + Java) carries weight 1.0, application + auxiliary (e.g., Python + shell) 0.25, and auxiliary + auxiliary just 0.1.</p>
                    </div>
                    <div class="contam-explainer-card">
                        <h4>What We Actually Found</h4>
                        <p>In theory, these mismatches could cause the model to bleed syntax or API patterns from one language into another. In practice, our <a href="#behavioral">behavioral evaluation</a> found that structural scores did not predict actual degradation &mdash; content-specific mechanisms like template propagation and API hallucination mattered more. Cross-language code bleed (the PLC mechanism) did appear in some cases, but accounted for a minority of the total degradation observed. These scores are best understood as a measure of structural complexity, not a direct predictor of harm.</p>
                    </div>
                </div>
                <div id="high-risk-cards"></div>
            </div>
            <div id="hidden-contamination-list">
                <h3>Hidden Contamination</h3>
                <p>The contamination scoring <a href="#high-risk-list">described above</a> applies to <code>SKILL.md</code> content. But skills can also include reference files that are loaded into context alongside the instruction file. These 66 skills score as low-risk on their <code>SKILL.md</code> alone, yet carry medium or high contamination in their reference files &mdash; language mixing invisible to instruction-file-only analysis.</p>
                <div id="hidden-contamination-cards"></div>
            </div>
            <div class="practitioner-callout">
                <h4>If you're building for multi-language tools</h4>
                <p>If your tool has a CLI, multiple language SDKs, and a query language (think databases, cloud providers, observability platforms), these structural scores flag complexity worth being intentional about. Our behavioral data didn't find that structural complexity alone predicted problems, but the content interference mechanisms we <em>did</em> observe (API hallucination, cross-language bleed) tend to appear in exactly these kinds of skills. The structural score won't tell you if your skill will cause harm, but it can tell you where to focus your testing.</p>
            </div>
        </section>

        <!-- Behavioral Insights -->
        <section id="behavioral">
            <h2>Behavioral Insights</h2>
            <p>An exploratory behavioral evaluation of 19 skills tested whether structural contamination scores predict actual code generation degradation. Each skill was evaluated across 5 task types under 3 conditions (baseline, skill-loaded, skill + realistic context), with 3 runs each at temperature 0.3.</p>
            <div class="chart-container wide tall">
                <canvas id="chart-behavioral-scatter"></canvas>
            </div>
            <div class="behavioral-callout">
                <h4>The Disconnect</h4>
                <p><strong>react-native-best-practices</strong> (contamination 0.07, B-A = &minus;0.384) produces the largest degradation despite near-zero structural risk. <strong>sharp-edges</strong> (contamination 0.62, B-A = &minus;0.083) has high structural risk but minimal behavioral impact. Structural scores alone don't predict what hurts.</p>
            </div>
            <h3>Content Interference Mechanisms</h3>
            <p>Six distinct mechanisms drive degradation &mdash; only one (cross-language code bleed) is captured by structural contamination scoring:</p>
            <div class="mechanism-cards">
                <div class="mechanism-card">
                    <h4>Template Propagation</h4>
                    <p>Skill output templates reproduced verbatim in unrelated contexts. Invalid <code>// comments</code> in JSON templates bleed into all output.</p>
                    <div class="mechanism-example">claude-settings-audit (B-A = &minus;0.483)</div>
                </div>
                <div class="mechanism-card">
                    <h4>Textual Frame Leakage</h4>
                    <p>Non-code skill content reshapes how the model frames responses, adding verbose commentary at the expense of code completeness.</p>
                    <div class="mechanism-example">monitoring-observability (B-A = &minus;0.233)</div>
                </div>
                <div class="mechanism-card">
                    <h4>Token Budget Competition</h4>
                    <p>With skill loaded, outputs allocate more tokens to explanatory text and less to code, producing incomplete implementations under output limits.</p>
                    <div class="mechanism-example">react-native-best-practices (B-A = &minus;0.384)</div>
                </div>
                <div class="mechanism-card">
                    <h4>API Hallucination</h4>
                    <p>The model invents plausible but nonexistent API methods that follow naming conventions seen in skill content. The code is in the <em>correct</em> language &mdash; the API surface is wrong.</p>
                    <div class="mechanism-example">upgrade-stripe (B-A = &minus;0.117)</div>
                </div>
                <div class="mechanism-card">
                    <h4>Cross-Language Code Bleed</h4>
                    <p>The classic programming language confusion: shell syntax in JavaScript, mongosh operators in JSON. The <em>only</em> mechanism structural scoring detects.</p>
                    <div class="mechanism-example">MongoDB skills</div>
                </div>
                <div class="mechanism-card">
                    <h4>Architectural Pattern Bleed</h4>
                    <p>Skill-specific architectural conventions (error handling, config patterns) propagate to unrelated code, even when the language is correct.</p>
                    <div class="mechanism-example">provider-resources (B-A = &minus;0.317)</div>
                </div>
            </div>
            <div class="behavioral-callout mitigation">
                <h4>Context Mitigation</h4>
                <p>When skills are loaded alongside realistic agentic context (system prompt, tools, conversation history), mean degradation drops from &minus;0.080 to &minus;0.023 &mdash; a ~62&ndash;75% attenuation. Real-world impact may be substantially smaller than isolated evaluation suggests.</p>
            </div>
            <div class="practitioner-callout">
                <h4>If you're debugging unexpected agent behavior</h4>
                <p>The six interference mechanisms above are hypotheses drawn from a small evaluation, not proven failure modes. But they describe recognizable patterns. If you've added a skill and noticed your agent suddenly producing verbose commentary instead of code, or inventing API methods that don't exist, or using shell syntax in your JavaScript&mdash;these categories give you a vocabulary for diagnosing what's happening. The context mitigation finding also matters: in realistic conditions, the effects attenuate substantially, so isolated testing may overstate real-world impact.</p>
            </div>
        </section>

        <!-- LLM Quality -->
        <section id="llm-quality">
            <h2>LLM-as-Judge Quality</h2>
            <p>All 673 skills scored by Claude Sonnet across 6 dimensions (1-5 scale): clarity, actionability, token efficiency, scope discipline, directive precision, and novelty.</p>
            <div class="chart-container wide extra-tall">
                <canvas id="chart-llm-by-source"></canvas>
            </div>
            <div class="chart-row">
                <div class="chart-container tall">
                    <canvas id="chart-novelty-dist"></canvas>
                </div>
                <div class="chart-container">
                    <canvas id="chart-llm-spread"></canvas>
                </div>
            </div>
            <h3>Craft vs. Novelty</h3>
            <p>Skills cluster tightly on craft dimensions (clarity, actionability, efficiency, scope, precision) but spread independently on novelty &mdash; a two-factor quality structure.</p>
            <div class="chart-container wide tall">
                <canvas id="chart-craft-novelty"></canvas>
            </div>
            <h3>Low Value-Add Risk</h3>
            <p>Skills that score low on novelty (score &le; 2) <em>and</em> medium-to-high on <a href="#contamination">structural contamination</a> (score &ge; 0.2). The idea: if a skill doesn't teach the model anything new but does add mixed-language complexity to the context window, the theoretical cost-benefit is unfavorable. These skills are candidates for removal or consolidation.</p>
            <p>That said, in our <a href="#behavioral">behavioral evaluation</a> of 6 low value-add skills, the actual measured degradation was modest (mean B&minus;A&nbsp;=&nbsp;&minus;0.072) &mdash; suggesting that while these skills aren't helping, they may not be actively hurting as much as the structural scores imply. The strongest degradation we observed came from high-novelty skills with content-specific interference mechanisms, not from low-novelty ones. Skills in this quadrant are tagged <span class="badge badge-net-neg">evaluate</span> in the <a href="#table">skills table</a>&mdash;if you're considering using one, it's worth testing its impact on your agent's output for your specific tasks before committing to it.</p>
            <div id="net-negative-summary" class="callout-box"></div>
            <div id="net-negative-cards"></div>
            <div class="practitioner-callout">
                <h4>If you're deciding what to put in a skill</h4>
                <p>The craft dimensions (clarity, actionability, efficiency) are table stakes&mdash;most skills score similarly on them, and they're the kind of thing you can get right with careful editing. Novelty is harder and appears to matter more. A skill that restates what the model already knows is, at best, an expensive no-op. If you're considering whether a skill is worth creating and maintaining, the first question to ask is: does this teach the agent something it genuinely doesn't know? If the answer is no, the maintenance cost probably isn't justified, even if the skill is well-written.</p>
            </div>
        </section>

        <section id="open-questions">
            <h2>Open Questions for Practitioners</h2>
            <p>This analysis raises questions we think are worth sitting with, even where the data doesn't yet support definitive answers.</p>
            <div class="mechanism-cards">
                <div class="mechanism-card">
                    <h4>How should you evaluate a skill before installing it?</h4>
                    <p>Structural validation catches broken skills. LLM-as-judge scoring can flag low-novelty content. But neither predicted behavioral degradation in our evaluation. The honest answer may be that there isn't a reliable shortcut. Skills that look good on paper can still interfere with agent output in ways you'll only catch by testing on your own tasks.</p>
                </div>
                <div class="mechanism-card">
                    <h4>What predicts whether a skill actually helps?</h4>
                    <p>Our data points toward novelty as the strongest signal (r&nbsp;=&nbsp;+0.327 for degradation magnitude), but this is from 19 skills. This is a direction to investigate, not a conclusion to rely on. If novelty does turn out to be the key variable, it would reframe skill creation: the goal isn't to write well, it's to teach something new.</p>
                </div>
                <div class="mechanism-card">
                    <h4>Can you generate skills from existing published content?</h4>
                    <p>If most skills restate what the model already knows, and novelty is what differentiates useful ones, then auto-generating skills from documentation, articles, or other published content may produce exactly the kind of low-novelty content the ecosystem already has too much of. The skills that scored highest on novelty in our analysis tend to encode operational knowledge; the kind of hard-won expertise that doesn't live in docs.</p>
                </div>
                <div class="mechanism-card">
                    <h4>When is a skill not worth maintaining?</h4>
                    <p>A skill has ongoing costs: it consumes context tokens on every invocation, it needs updating as APIs and tools change, and it can interfere with the agent in ways that are hard to detect. If the skill doesn't teach the model something new&mdash;and especially if it adds structural complexity from mixed languages or multi-interface tools&mdash;the cost-benefit may not justify keeping it active.</p>
                </div>
                <div class="mechanism-card">
                    <h4>How can you test skills?</h4>
                    <p>If you're planning to distribute skills&mdash;especially as official company-provided resources&mdash;structural validation and manual review aren't enough. Our behavioral evaluation found interference patterns that no static analysis would catch: templates bleeding into unrelated output, plausible-but-wrong API methods, architectural conventions propagating where they don't belong. The only way to know if a skill helps or hurts is to test it against representative tasks with and without the skill loaded, and compare the outputs. That's expensive, but so is distributing a skill that degrades your users' experience in ways neither you nor they will easily trace back to the skill.</p>
                </div>
                <div class="mechanism-card">
                    <h4>How can you decide whether to install a skill?</h4>
                    <p>There's no reliable shortcut yet. Validation tells you if a skill is structurally sound. Novelty scoring can flag whether it's likely to teach the model something new. But the gap between "looks good" and "actually helps" is real&mdash;our best structural metrics didn't predict behavioral outcomes. If you're adopting a skill for your team or organization, treat it like any other dependency: try it on your actual workloads, watch for the <a href="#behavioral">interference patterns</a> described above, and be willing to remove it if the results don't justify the context window cost. The ecosystem will get better tooling for this over time, but right now, informed skepticism is your best filter.</p>
                </div>
            </div>
        </section>

        <!-- Filterable Table -->
        <section id="table">
            <h2>All Skills</h2>
            <div class="filters">
                <label>
                    Source:
                    <select id="filter-source">
                        <option value="">All</option>
                    </select>
                </label>
                <label>
                    Status:
                    <select id="filter-status">
                        <option value="">All</option>
                        <option value="passed">Passed</option>
                        <option value="failed">Failed</option>
                    </select>
                </label>
                <label>
                    Risk:
                    <select id="filter-risk">
                        <option value="">All</option>
                        <option value="high">High</option>
                        <option value="medium">Medium</option>
                        <option value="low">Low</option>
                    </select>
                </label>
                <label>
                    Search:
                    <input type="text" id="filter-search" placeholder="Skill name...">
                </label>
                <button id="btn-download-csv">Download CSV</button>
            </div>
            <div class="table-key">
                <h4>Column Key</h4>
                <dl>
                    <div><dt>Tokens</dt><dd>Total context window tokens consumed by all skill files</dd></div>
                    <div><dt>Density</dt><dd><a href="#content">Information density</a> &mdash; ratio of actionable content to total text (higher = less filler)</dd></div>
                    <div><dt>Specificity</dt><dd><a href="#content">Instruction specificity</a> &mdash; how concrete and directive the language is (higher = more precise)</dd></div>
                    <div><dt>Contamination</dt><dd><a href="#contamination">Structural contamination score</a> &mdash; language mixing complexity (higher = more mixed)</dd></div>
                    <div><dt>LLM Score</dt><dd><a href="#llm-quality">Overall LLM-as-judge quality</a> &mdash; mean of 6 dimensions scored 1&ndash;5</dd></div>
                    <div><dt>Novelty</dt><dd><a href="#llm-quality">Novelty score</a> (1&ndash;5) &mdash; does the skill teach the model something it doesn't already know?</dd></div>
                    <div><dt><span class="badge badge-net-neg">evaluate</span></dt><dd>Low novelty (&le;&nbsp;2) + medium-to-high contamination (&ge;&nbsp;0.2) &mdash; <a href="#llm-quality">worth testing</a> before adopting</dd></div>
                </dl>
            </div>
            <div class="table-wrapper">
                <table id="skills-table">
                    <thead>
                        <tr>
                            <th data-sort="name">Name</th>
                            <th data-sort="source">Source</th>
                            <th data-sort="passed">Status</th>
                            <th data-sort="errors">Errors</th>
                            <th data-sort="warnings">Warnings</th>
                            <th data-sort="total_tokens">Tokens</th>
                            <th data-sort="information_density">Density</th>
                            <th data-sort="instruction_specificity">Specificity</th>
                            <th data-sort="contamination_score">Contamination</th>
                            <th data-sort="llm_overall">LLM Score</th>
                            <th data-sort="llm_novelty">Novelty</th>
                        </tr>
                    </thead>
                    <tbody id="skills-tbody">
                    </tbody>
                </table>
            </div>
            <div id="skill-detail" class="detail-panel hidden">
                <button id="close-detail">&times;</button>
                <div id="detail-content"></div>
            </div>
        </section>
    </main>

    <footer>
        <p>Author: <a href="https://dacharycarey.com">Dachary Carey</a> | Data: <a href="https://github.com/dacharyc/skill-validator">skill-validator</a> | <a href="https://github.com/dacharyc/agent-skill-analysis">Full paper &amp; analysis</a> | February 2026</p>
    </footer>

    <script src="app.js"></script>
</body>
</html>
